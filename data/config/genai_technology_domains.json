{
    "Transformer-Based Models": [
        "transformer",
        "gpt",
        "bert",
        "t5",
        "llama",
        "palm",
        "chatgpt",
        "gpt-2",
        "gpt-3",
        "gpt-4",
        "large language model",
        "llm",
        "small language model",
        "slm",
        "foundation model",
        "pretrained language model",
        "encoder-decoder",
        "attention mechanism",
        "self-attention",
        "generative pretrained transformer",
        "claude",
        "bard",
        "google bard",
        "mistral",
        "gemini",
        "genai",
        "large flow model",
        "lfm",
        "flow model",
        "foundation framework",
        "foundational framework",
        "gen ai",
        "generative capability",
        "generative capabilities",
        "generative model",
        "designed with ai",
        "genai",
        "ai capability"
    ],
    "Generative Adversarial Networks": [
        "gan",
        "generative adversarial network",
        "wgan",
        "wgan-gp",
        "conditional gan",
        "cgan",
        "cycle gan",
        "cyclegan",
        "pix2pix",
        "pix2pixhd",
        "sr-gan",
        "srgan",
        "progressive gan",
        "biggan",
        "stylegan",
        "5gt-gan",
        "tabular gan",
        "ctgan",
        "stargan",
        "adv-gan"
    ],
    "Diffusion Models": [
        "diffusion model",
        "ddpm",
        "stable diffusion",
        "latent diffusion",
        "score-based model",
        "noise prediction",
        "denoising diffusion",
        "ddim",
        "guided diffusion",
        "classifier-free guidance",
        "ddpo",
        "text-to-image diffusion"
    ],
    "Variational Autoencoders": [
        "vae",
        "variational autoencoder",
        "beta-vae",
        "conditional vae",
        "cvae",
        "vq-vae",
        "vector quantized vae",
        "hierarchical vae",
        "disentangled vae",
        "autoregressive models",
        "autoencoder",
        "latent space modeling"
    ],
    "Neural Radiance Fields & 3D Models": [
        "nerf",
        "neural radiance field",
        "3d gan",
        "3d generative model",
        "neural rendering",
        "implicit representation",
        "point cloud generation",
        "mesh generation",
        "shape generation",
        "3d reconstruction",
        "neural implicit surface",
        "occupancy network",
        "signed distance function"
    ],
    "Hybrid & Multimodal Architectures": [
        "multimodal model",
        "vision-language model",
        "clip",
        "dall-e",
        "imagen",
        "flamingo",
        "multimodal transformer",
        "cross-attention",
        "contrastive learning",
        "multimodal embedding",
        "cross-modal generation",
        "multimodal fusion",
        "multimodal alignment"
    ]
}
