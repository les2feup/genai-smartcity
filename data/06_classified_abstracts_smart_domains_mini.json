[
  {
    "abstract": "Building rooftop extraction has been applied in various fields, such as cartography, urban planning, automatic driving, and intelligent city construction. Automatic building detection and extraction algorithms using high spatial resolution aerial images can provide precise location and geometry information, significantly reducing time, costs, and labor. Recently, deep learning algorithms, especially convolution neural networks (CNNs) and Transformer, have robust local or global feature extraction ability, achieving advanced performance in intelligent interpretation compared with conventional methods. However, buildings often exhibit scale variation, spectral heterogeneity, and similarity with complex geometric shapes. Hence, the building rooftop extraction results exist fragmentation and lack spatial details using these methods. To address these issues, this study developed a multi-scale global perceptron network based on Transformer and CNN using novel encoder-decoders for enhancing contextual representation of buildings. Specifically, an improved multi-head-attention encoder is employed by constructing multi-scale tokens to enhance global semantic correlations. Meanwhile, the context refinement decoder is developed and synergistically uses high-level semantic representation and shallow features to restore spatial details. Overall, quantitative analysis and visual experiments confirmed that the proposed model is more efficient and superior to other state-of-the-art methods, with a 95.18% F1 score on the WHU dataset and a 93.29% F1 score on the Massub dataset.",
    "doi": "10.1038/s41598-025-91206-6",
    "author_keywords": [
      "Building extraction",
      "Multi-scale global perceptron",
      "Remote sensing",
      "Spatial context refinement",
      "Vision transformer"
    ],
    "contribution": "To address these issues, this study developed a multi-scale global perceptron network based on Transformer and CNN using novel encoder-decoders for enhancing contextual representation of buildings. Specifically, an improved multi-head-attention encoder is employed by constructing multi-scale tokens to enhance global semantic correlations. Meanwhile, the context refinement decoder is developed and synergistically uses high-level semantic representation and shallow features to restore spatial details. Overall, quantitative analysis and visual experiments confirmed that the proposed model is more efficient and superior to other state-of-the-art methods, with a 95.18% F1 score on the WHU dataset and a 93.29% F1 score on the Massub dataset.",
    "introduction": "Building rooftop extraction has been applied in various fields, such as cartography, urban planning, automatic driving, and intelligent city construction. Automatic building detection and extraction algorithms using high spatial resolution aerial images can provide precise location and geometry information, significantly reducing time, costs, and labor. Recently, deep learning algorithms, especially convolution neural networks (CNNs) and Transformer, have robust local or global feature extraction ability, achieving advanced performance in intelligent interpretation compared with conventional methods. However, buildings often exhibit scale variation, spectral heterogeneity, and similarity with complex geometric shapes. Hence, the building rooftop extraction results exist fragmentation and lack spatial details using these methods.",
    "classification_result": {
      "labels": [
        "Buildings",
        "Environment",
        "Urban Planning",
        "Public Services",
        "Industry",
        "Housing",
        "Business",
        "Learning and Teaching",
        "Mobility",
        "Innovation Policy",
        "Multimodal Transport",
        "Logistics",
        "Public Policies",
        "Emergency Safety",
        "Governance",
        "Electric Vehicles",
        "Socioeconomics",
        "Citizens",
        "Economy",
        "Economic Management",
        "Power Distribution",
        "Public Transit",
        "Education",
        "Transportation Systems",
        "People",
        "Citizen Engagement",
        "Lightning",
        "Living",
        "Smart Grids",
        "Climate Change",
        "Sustainability",
        "Social Equity",
        "Renewable Energy",
        "Pedestrian",
        "Culture",
        "Cybersecurity",
        "Resource Conservation",
        "Energy Management",
        "Tourism",
        "Water Quality",
        "Air Quality",
        "Green Spaces",
        "Finance",
        "Marketing",
        "Bicycle",
        "Healthcare",
        "Traffic Management",
        "Waste Management",
        "Pollution Control"
      ],
      "scores": [
        0.9833354949951172,
        0.1094711646437645,
        0.008741778321564198,
        0.004331371746957302,
        0.0036913917865604162,
        0.001516055897809565,
        0.0013838307932019234,
        0.0007914633024483919,
        0.0007147302967496216,
        0.000549577409401536,
        0.0005438483785837889,
        0.00048071370110847056,
        0.0004784094344358891,
        0.0004532605526037514,
        0.0004495096218306571,
        0.0004425994702614844,
        0.00044220019481144845,
        0.00044207219616509974,
        0.0004355013370513916,
        0.00043268344597890973,
        0.0004291903751436621,
        0.00041611806955188513,
        0.00041225404129363596,
        0.0004068996640853584,
        0.00040177907794713974,
        0.0003981390327680856,
        0.00039561279118061066,
        0.00038560116081498563,
        0.0003845991159323603,
        0.000379532459191978,
        0.0003731877950485796,
        0.00037313310895115137,
        0.00036858973908238113,
        0.000365449144737795,
        0.00036307863774709404,
        0.0003556257870513946,
        0.000352702772943303,
        0.0003415483806747943,
        0.0003372924111317843,
        0.0003356236848048866,
        0.0003234317700844258,
        0.0003211038128938526,
        0.0003196248144377023,
        0.0003173432778567076,
        0.00030607718508690596,
        0.0003057402209378779,
        0.00030166335636749864,
        0.00029186418396420777,
        0.0002910176117438823
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Living",
        "score": 0.9833354949951172
      }
    ]
  },
  {
    "abstract": "Problem: Modernizing and standardizing place names and addresses is a key challenge in the development of smart cities. Purpose: This paper proposes a solution to address matching challenges, such as incomplete descriptions, reversed word order, and the diverse descriptions often found in Chinese addresses. Method: Leveraging the hierarchical structure of Chinese addresses, this study introduces the interactive address matching graph attention model (IAMGAM). In the IAMGAM, an attention-based feature interaction method (AFIM) is employed. To reflect the hierarchical nature of address elements, a directed graph is used to model the address data, and the model is trained and tested using a graph attention mechanism. Results: Experiments demonstrate that the IAMGAM achieves an accuracy and F1-score of 99.61%. Compared with the existing address matching methods, the IAMGAM improves the accuracy by 0.66% to 2.57%, and the F1-score by 0.68% to 2.55%, outperforming baseline models. Additionally, ablation experiments confirm the effectiveness of each component within the model. Furthermore, when fine-tuned using ChatGLM2-6B, the results show that the IAMGAM still outperforms ChatGLM2-6B. Conclusion: IAMGAM demonstrates excellent performance in Chinese address matching tasks, and the Large Language Model (LLM)-based methods, such as ChatGLM2-6B, show great potential for future development in this area.",
    "doi": "10.1016/j.ijcce.2024.12.003",
    "author_keywords": [
      "Address matching",
      "Attention-based feature interaction method",
      "Directed graph",
      "Interactive address matching graph attention model"
    ],
    "contribution": "Purpose: This paper proposes a solution to address matching challenges, such as incomplete descriptions, reversed word order, and the diverse descriptions often found in Chinese addresses. Method: Leveraging the hierarchical structure of Chinese addresses, this study introduces the interactive address matching graph attention model (IAMGAM). In the IAMGAM, an attention-based feature interaction method (AFIM) is employed. To reflect the hierarchical nature of address elements, a directed graph is used to model the address data, and the model is trained and tested using a graph attention mechanism. Results: Experiments demonstrate that the IAMGAM achieves an accuracy and F1-score of 99.61%. Compared with the existing address matching methods, the IAMGAM improves the accuracy by 0.66% to 2.57%, and the F1-score by 0.68% to 2.55%, outperforming baseline models. Additionally, ablation experiments confirm the effectiveness of each component within the model. Furthermore, when fine-tuned using ChatGLM2-6B, the results show that the IAMGAM still outperforms ChatGLM2-6B. Conclusion: IAMGAM demonstrates excellent performance in Chinese address matching tasks, and the Large Language Model (LLM)-based methods, such as ChatGLM2-6B, show great potential for future development in this area.",
    "introduction": "Problem: Modernizing and standardizing place names and addresses is a key challenge in the development of smart cities.",
    "classification_result": {
      "labels": [
        "Governance",
        "Urban Planning",
        "Public Policies",
        "Living",
        "Citizens",
        "Public Services",
        "Housing",
        "Citizen Engagement",
        "Business",
        "Buildings",
        "Economic Management",
        "Tourism",
        "Logistics",
        "Innovation Policy",
        "Socioeconomics",
        "Economy",
        "Environment",
        "Learning and Teaching",
        "Mobility",
        "Industry",
        "Multimodal Transport",
        "Transportation Systems",
        "People",
        "Emergency Safety",
        "Electric Vehicles",
        "Public Transit",
        "Smart Grids",
        "Social Equity",
        "Pedestrian",
        "Education",
        "Green Spaces",
        "Culture",
        "Sustainability",
        "Renewable Energy",
        "Resource Conservation",
        "Finance",
        "Climate Change",
        "Energy Management",
        "Marketing",
        "Traffic Management",
        "Power Distribution",
        "Waste Management",
        "Air Quality",
        "Water Quality",
        "Pollution Control",
        "Cybersecurity",
        "Healthcare",
        "Bicycle",
        "Lightning"
      ],
      "scores": [
        0.6886762380599976,
        0.15419352054595947,
        0.06684140861034393,
        0.06519486010074615,
        0.023560578003525734,
        0.0148799829185009,
        0.010721228085458279,
        0.00298487301915884,
        0.0027593146078288555,
        0.002214164240285754,
        0.0010447658132761717,
        0.0010013157734647393,
        0.0009700368391349912,
        0.0008557196124456823,
        0.0008159681456163526,
        0.0007367145735770464,
        0.0007347026839852333,
        0.0006308511947281659,
        0.0005679031019099057,
        0.0005677210865542293,
        0.0005027343286201358,
        0.0004724322643596679,
        0.0004482290823943913,
        0.00043295882642269135,
        0.00041727948701009154,
        0.00040822490700520575,
        0.0004079447244293988,
        0.00039698078762739897,
        0.00039643674972467124,
        0.00039063949952833354,
        0.0003870212531182915,
        0.00037878440343774855,
        0.00037631893064826727,
        0.00037508871173486114,
        0.00036768391146324575,
        0.0003665861440822482,
        0.000363374623702839,
        0.0003530779795255512,
        0.0003448285278864205,
        0.00033225849620066583,
        0.00033077155239880085,
        0.00032926781568676233,
        0.00032702815951779485,
        0.0003189276612829417,
        0.00031870597740635276,
        0.00031593983294442296,
        0.0003037057467736304,
        0.00030126256751827896,
        0.0002930378832388669
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Governance",
        "score": 0.6886762380599976
      }
    ]
  },
  {
    "abstract": "Distributed multivariate time series anomaly detection is widely-used in industrial equipment monitoring, financial risk management, and smart cities. Although Federated learning (FL) has garnered significant interest and achieved decent performance in various scenarios, most existing FL-based distributed anomaly detection methods still face challenges including: inadequate detection performance in global model, insufficient essential features extraction caused by the fragmentation of local time series, and lack for practical anomaly localization. To address these challenges, we propose an Unsupervised Federated Hypernetwork Method for Distributed Multivariate Time Series Anomaly Detection and Diagnosis (uFedHy-DisMTSADD). Specifically, we introduce a federated hypernetwork architecture that effectively mitigates the heterogeneity and fluctuations in distributed environments while protecting client data privacy. Then, we adopt the Series Conversion Normalization Transformer (SC Nor-Transformer) to tackle the timing bias due to model aggregation through series conversion. Series normalization improves the temporal dependence of capturing subsequences. Finally, uFedHy-DisMTSADD simultaneously localizes the root cause of the anomaly by reconstructing the anomaly scores obtained from each subsequence. We performed an extensive evaluation on nine datasets, in which uFedHy-DisMTSADD outperformed the existing state-of-the-art baseline average F1 score by 9.19% and the average AUROC by 2.41%. Moreover, the average localization fault accuracy of uFedHy-DisMTSADD is 9.23% higher than that of the optimal baseline method. Code is available at this repository:https://github.com/Hjfyoyo/uFedHy-DisMTSADD.",
    "doi": "10.1016/j.ipm.2025.104107",
    "author_keywords": [
      "Distributed anomaly detection",
      "Federated learning",
      "Hypernetworks",
      "Multivariate time series",
      "Series conversion and normalization",
      "Transformer"
    ],
    "contribution": "To address these challenges, we propose an Unsupervised Federated Hypernetwork Method for Distributed Multivariate Time Series Anomaly Detection and Diagnosis (uFedHy-DisMTSADD). Specifically, we introduce a federated hypernetwork architecture that effectively mitigates the heterogeneity and fluctuations in distributed environments while protecting client data privacy. Then, we adopt the Series Conversion Normalization Transformer (SC Nor-Transformer) to tackle the timing bias due to model aggregation through series conversion. Series normalization improves the temporal dependence of capturing subsequences. Finally, uFedHy-DisMTSADD simultaneously localizes the root cause of the anomaly by reconstructing the anomaly scores obtained from each subsequence. We performed an extensive evaluation on nine datasets, in which uFedHy-DisMTSADD outperformed the existing state-of-the-art baseline average F1 score by 9.19% and the average AUROC by 2.41%. Moreover, the average localization fault accuracy of uFedHy-DisMTSADD is 9.23% higher than that of the optimal baseline method. Code is available at this repository:https://github.com/Hjfyoyo/uFedHy-DisMTSADD.",
    "introduction": "Distributed multivariate time series anomaly detection is widely-used in industrial equipment monitoring, financial risk management, and smart cities. Although Federated learning (FL) has garnered significant interest and achieved decent performance in various scenarios, most existing FL-based distributed anomaly detection methods still face challenges including: inadequate detection performance in global model, insufficient essential features extraction caused by the fragmentation of local time series, and lack for practical anomaly localization.",
    "classification_result": {
      "labels": [
        "Industry",
        "Cybersecurity",
        "Business",
        "Environment",
        "Finance",
        "Public Services",
        "Smart Grids",
        "Multimodal Transport",
        "Emergency Safety",
        "Air Quality",
        "Energy Management",
        "Sustainability",
        "Economic Management",
        "Lightning",
        "Climate Change",
        "Power Distribution",
        "Renewable Energy",
        "Logistics",
        "Electric Vehicles",
        "Water Quality",
        "Mobility",
        "Socioeconomics",
        "Innovation Policy",
        "Transportation Systems",
        "Economy",
        "Buildings",
        "Resource Conservation",
        "Learning and Teaching",
        "Governance",
        "Public Transit",
        "Pedestrian",
        "Public Policies",
        "Citizens",
        "Green Spaces",
        "Social Equity",
        "Pollution Control",
        "Education",
        "Living",
        "People",
        "Citizen Engagement",
        "Traffic Management",
        "Bicycle",
        "Urban Planning",
        "Marketing",
        "Housing",
        "Waste Management",
        "Healthcare",
        "Culture",
        "Tourism"
      ],
      "scores": [
        0.3200001120567322,
        0.05945054441690445,
        0.030235446989536285,
        0.00381937506608665,
        0.0036683448124676943,
        0.0015989168314263225,
        0.0013267402537167072,
        0.001166061614640057,
        0.0011618402786552906,
        0.0009902137098833919,
        0.0009371478226967156,
        0.0009114702115766704,
        0.0008989603957161307,
        0.0008960447739809752,
        0.0007338328287005424,
        0.0007251353817991912,
        0.0007081403746269643,
        0.000707410741597414,
        0.0007013083668425679,
        0.0006822557770647109,
        0.0006810164195485413,
        0.0006063454784452915,
        0.0005876915529370308,
        0.0005844846018590033,
        0.0005762039218097925,
        0.0005552591755986214,
        0.0005450349417515099,
        0.000517820124514401,
        0.0005005800048820674,
        0.00047695921966806054,
        0.00046434460091404617,
        0.00045963615411892533,
        0.0004510642902459949,
        0.00044860277557745576,
        0.0004467544495128095,
        0.0004357762518338859,
        0.0004248239565640688,
        0.00042007796582765877,
        0.00040436533163301647,
        0.00037952009006403387,
        0.00037476103170774877,
        0.0003653625608421862,
        0.000353427225491032,
        0.0003531997208483517,
        0.00035314683918841183,
        0.0003461382002569735,
        0.0003237968485336751,
        0.0003227625275030732,
        0.0003177608596161008
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "The integration of renewable energy into power networks introduces challenges due to intermittency and unpredictability, making precise expansion planning essential. This research introduces a novel two-stage stochastic approach for distribution network expansion planning in smart grids with high renewable energy penetration, addressing uncertainty, risk, and distributed generators' remuneration. Key contributions include: the incorporation of third-party generation owners' economic remuneration into a risk-based stochastic model; the use of conditional value-at-risk to manage uncertainty and extreme events, with a detailed analysis of cost evolution for various confidence levels and risk aversion parameters; the optimization of energy storage systems sizing and placement, alongside the location and type of new power lines and substation transformers, ensuring a reliable and radial network topology; and the integration of multiple factors, including uncertainty, risk aversion, ESS allocation, remuneration, and reliability, into a unified model that ensures optimal network design under technical constraints. Tested on a 180-bus network in Leiria, Portugal and on a 13-bus smart city mockup from Salamanca, Spain, the approach proved economically viable, reducing extreme scenario costs by up to 34 % through CVaR-based risk management, and demonstrating its potential for sustainable, risk-averse network expansion.",
    "doi": "10.1016/j.apenergy.2025.125531",
    "author_keywords": [
      "Conditional value-at-risk",
      "Optimal planning",
      "Remuneration",
      "Renewable generation",
      "Seasonal impacts",
      "Uncertainty"
    ],
    "contribution": "This research introduces a novel two-stage stochastic approach for distribution network expansion planning in smart grids with high renewable energy penetration, addressing uncertainty, risk, and distributed generators' remuneration. Key contributions include: the incorporation of third-party generation owners' economic remuneration into a risk-based stochastic model; the use of conditional value-at-risk to manage uncertainty and extreme events, with a detailed analysis of cost evolution for various confidence levels and risk aversion parameters; the optimization of energy storage systems sizing and placement, alongside the location and type of new power lines and substation transformers, ensuring a reliable and radial network topology; and the integration of multiple factors, including uncertainty, risk aversion, ESS allocation, remuneration, and reliability, into a unified model that ensures optimal network design under technical constraints. Tested on a 180-bus network in Leiria, Portugal and on a 13-bus smart city mockup from Salamanca, Spain, the approach proved economically viable, reducing extreme scenario costs by up to 34 % through CVaR-based risk management, and demonstrating its potential for sustainable, risk-averse network expansion.",
    "introduction": "The integration of renewable energy into power networks introduces challenges due to intermittency and unpredictability, making precise expansion planning essential.",
    "classification_result": {
      "labels": [
        "Renewable Energy",
        "Sustainability",
        "Energy Management",
        "Power Distribution",
        "Environment",
        "Business",
        "Industry",
        "Public Policies",
        "Economy",
        "Public Services",
        "Climate Change",
        "Logistics",
        "Socioeconomics",
        "Innovation Policy",
        "Economic Management",
        "Smart Grids",
        "Urban Planning",
        "Living",
        "Governance",
        "Citizens",
        "Resource Conservation",
        "Emergency Safety",
        "Multimodal Transport",
        "Buildings",
        "People",
        "Learning and Teaching",
        "Finance",
        "Mobility",
        "Green Spaces",
        "Air Quality",
        "Pollution Control",
        "Transportation Systems",
        "Electric Vehicles",
        "Citizen Engagement",
        "Lightning",
        "Cybersecurity",
        "Social Equity",
        "Housing",
        "Education",
        "Public Transit",
        "Healthcare",
        "Traffic Management",
        "Water Quality",
        "Pedestrian",
        "Marketing",
        "Waste Management",
        "Culture",
        "Tourism",
        "Bicycle"
      ],
      "scores": [
        0.9989933967590332,
        0.6991653442382812,
        0.5467529892921448,
        0.5153037905693054,
        0.2687591016292572,
        0.207524836063385,
        0.1365790069103241,
        0.1117606833577156,
        0.05901167914271355,
        0.0434136763215065,
        0.02419484779238701,
        0.02021409384906292,
        0.010295188054442406,
        0.009242484346032143,
        0.00878099910914898,
        0.004452638793736696,
        0.003202591324225068,
        0.0019085367675870657,
        0.001523257582448423,
        0.0014376867329701781,
        0.0012924250913783908,
        0.000669591361656785,
        0.0006567828240804374,
        0.0006378735415637493,
        0.0006070566014386714,
        0.0006034115795046091,
        0.0005588993080891669,
        0.0005554616800509393,
        0.0004827063821721822,
        0.00047688017366454005,
        0.0004585857386700809,
        0.0004504666430875659,
        0.0004375159915070981,
        0.00042921543354168534,
        0.00039631148683838546,
        0.0003947164223063737,
        0.0003797487006522715,
        0.00037933094426989555,
        0.00037015776615589857,
        0.00036637851735576987,
        0.00035990431206300855,
        0.0003565313236322254,
        0.00033514900133013725,
        0.0003182548680342734,
        0.0003176905447617173,
        0.00031556873000226915,
        0.0003131474368274212,
        0.00030919344862923026,
        0.0002972808724734932
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Environment",
        "score": 0.9989933967590332
      }
    ]
  },
  {
    "abstract": "Crowd anomaly detection is one of the most popular topics in computer vision in the context of smart cities. A plethora of deep learning methods have been proposed that generally outperform other machine learning solutions. Our review primarily discusses algorithms that were published in mainstream conferences and journals between 2020 and 2022. We present datasets that are typically used for benchmarking, produce a taxonomy of the developed algorithms, and discuss and compare their performances. Our main findings are that the heterogeneities of pre-trained convolutional models have a negligible impact on crowd video anomaly detection performance. We conclude our discussion with fruitful directions for future research.",
    "doi": "10.1007/s10462-024-11092-8",
    "author_keywords": [
      "AUC",
      "Autoencoder",
      "CNN",
      "Crowd",
      "DenseNet",
      "Nonparametric test",
      "Transformer",
      "VGGNet",
      "Video anomaly detection"
    ],
    "contribution": "We present datasets that are typically used for benchmarking, produce a taxonomy of the developed algorithms, and discuss and compare their performances. Our main findings are that the heterogeneities of pre-trained convolutional models have a negligible impact on crowd video anomaly detection performance. We conclude our discussion with fruitful directions for future research.",
    "introduction": "Crowd anomaly detection is one of the most popular topics in computer vision in the context of smart cities. A plethora of deep learning methods have been proposed that generally outperform other machine learning solutions. Our review primarily discusses algorithms that were published in mainstream conferences and journals between 2020 and 2022.",
    "classification_result": {
      "labels": [
        "Industry",
        "Environment",
        "Learning and Teaching",
        "Cybersecurity",
        "Public Services",
        "Business",
        "People",
        "Citizens",
        "Emergency Safety",
        "Living",
        "Mobility",
        "Innovation Policy",
        "Renewable Energy",
        "Economic Management",
        "Education",
        "Multimodal Transport",
        "Governance",
        "Citizen Engagement",
        "Socioeconomics",
        "Buildings",
        "Sustainability",
        "Climate Change",
        "Lightning",
        "Energy Management",
        "Economy",
        "Electric Vehicles",
        "Transportation Systems",
        "Public Policies",
        "Urban Planning",
        "Social Equity",
        "Pedestrian",
        "Housing",
        "Water Quality",
        "Air Quality",
        "Resource Conservation",
        "Logistics",
        "Public Transit",
        "Green Spaces",
        "Waste Management",
        "Healthcare",
        "Traffic Management",
        "Tourism",
        "Finance",
        "Power Distribution",
        "Bicycle",
        "Pollution Control",
        "Smart Grids",
        "Marketing",
        "Culture"
      ],
      "scores": [
        0.015186888165771961,
        0.0077928779646754265,
        0.006524142809212208,
        0.0019228286109864712,
        0.0016293979715555906,
        0.0012528483057394624,
        0.0009646615362726152,
        0.0009244859684258699,
        0.0007339175208471715,
        0.0005611542728729546,
        0.0005426095449365675,
        0.0005386979319155216,
        0.0005307438550516963,
        0.0005085387965664268,
        0.0005051008192822337,
        0.0005049837054684758,
        0.00048625137424096465,
        0.00048006046563386917,
        0.000476688175695017,
        0.0004754394758492708,
        0.00046826733159832656,
        0.00045807508286088705,
        0.0004547737189568579,
        0.0004462466749828309,
        0.0004459026677068323,
        0.0004444544028956443,
        0.00044375259312801063,
        0.0004391384427435696,
        0.00043417708366177976,
        0.00043368618935346603,
        0.0004067881091032177,
        0.0003905571938958019,
        0.00038863319787196815,
        0.0003860675496980548,
        0.0003843060112558305,
        0.0003818582044914365,
        0.00037579602212645113,
        0.00036789008299820125,
        0.00036425801226869226,
        0.00035162281710654497,
        0.00034801592119038105,
        0.00034119622432626784,
        0.00033341359812766314,
        0.00033155048731714487,
        0.00032984669087454677,
        0.0003253750328440219,
        0.0003204357053618878,
        0.00030889417394064367,
        0.0003076319699175656
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "Point-of-interest (POI) extraction aims to extract text POIs from real-world data. Existing POI methods, such as social media-based user generating and web crawling, either require massive human resources or cannot guarantee integrity and reliability. Therefore, in this paper, an end-to-end POI extraction framework based on digital city is proposed. It is built of digital models, textures, tiles and other digital assets collected by aircraft. The extraction process for POIs consists of segmenting it into four sequential stages: collecting, segmentation, recognition and cleaning, each enhanced through fine-tuning on a proposed specialised digital scene dataset or via the development of tailored algorithms. Specifically, in the last stage, the application of large language model (LLM) is explored in the POI data cleaning field. By testing several LLMs of different scales using diverse chain-of-thought (CoT) strategies, the relatively optimal prompt scheme for different LLMs is identified regarding noise handling, formatted output and overall cleaning capability. Ultimately, POIs extracted through the proposed methodology exhibit superior quality and accuracy, surpassing the comprehensiveness of existing public commercial POI datasets, with the F1-score increased by 19.6%, 21.1% and 23.8% on Amap, Baidu and Google POI datasets, respectively.",
    "doi": "10.1111/exsy.70001",
    "author_keywords": [
      "artificial intelligence",
      "data cleaning",
      "large language models",
      "point-of-interest"
    ],
    "contribution": "Therefore, in this paper, an end-to-end POI extraction framework based on digital city is proposed. It is built of digital models, textures, tiles and other digital assets collected by aircraft. The extraction process for POIs consists of segmenting it into four sequential stages: collecting, segmentation, recognition and cleaning, each enhanced through fine-tuning on a proposed specialised digital scene dataset or via the development of tailored algorithms. Specifically, in the last stage, the application of large language model (LLM) is explored in the POI data cleaning field. By testing several LLMs of different scales using diverse chain-of-thought (CoT) strategies, the relatively optimal prompt scheme for different LLMs is identified regarding noise handling, formatted output and overall cleaning capability. Ultimately, POIs extracted through the proposed methodology exhibit superior quality and accuracy, surpassing the comprehensiveness of existing public commercial POI datasets, with the F1-score increased by 19.6%, 21.1% and 23.8% on Amap, Baidu and Google POI datasets, respectively.",
    "introduction": "Point-of-interest (POI) extraction aims to extract text POIs from real-world data. Existing POI methods, such as social media-based user generating and web crawling, either require massive human resources or cannot guarantee integrity and reliability.",
    "classification_result": {
      "labels": [
        "Industry",
        "Business",
        "Urban Planning",
        "Marketing",
        "Tourism",
        "Logistics",
        "Public Services",
        "Electric Vehicles",
        "Environment",
        "Innovation Policy",
        "Mobility",
        "Transportation Systems",
        "Buildings",
        "Climate Change",
        "Renewable Energy",
        "Cybersecurity",
        "Public Transit",
        "Multimodal Transport",
        "People",
        "Air Quality",
        "Emergency Safety",
        "Learning and Teaching",
        "Governance",
        "Living",
        "Finance",
        "Economic Management",
        "Sustainability",
        "Smart Grids",
        "Water Quality",
        "Socioeconomics",
        "Energy Management",
        "Public Policies",
        "Waste Management",
        "Power Distribution",
        "Lightning",
        "Citizens",
        "Education",
        "Pollution Control",
        "Economy",
        "Citizen Engagement",
        "Housing",
        "Healthcare",
        "Green Spaces",
        "Social Equity",
        "Bicycle",
        "Culture",
        "Pedestrian",
        "Traffic Management",
        "Resource Conservation"
      ],
      "scores": [
        0.058512408286333084,
        0.03704599663615227,
        0.015499424189329147,
        0.015213964506983757,
        0.015060167759656906,
        0.013579978607594967,
        0.012724337168037891,
        0.008022058755159378,
        0.007712067104876041,
        0.007340820040553808,
        0.007255242206156254,
        0.0064328876323997974,
        0.0034781512804329395,
        0.0025358740240335464,
        0.0022701825946569443,
        0.001999914413318038,
        0.0018920381553471088,
        0.001600552350282669,
        0.0014339294284582138,
        0.001297085196711123,
        0.0012136045843362808,
        0.0011131248902529478,
        0.0010850816033780575,
        0.0009889365173876286,
        0.0009624440572224557,
        0.0009355549700558186,
        0.0009225980611518025,
        0.0008861942333169281,
        0.0008614498074166477,
        0.0007611167384311557,
        0.0007297848933376372,
        0.0007202386041171849,
        0.0007167578442022204,
        0.0006638685008510947,
        0.0006637955084443092,
        0.0006251581944525242,
        0.0006195519817993045,
        0.0006087155197747052,
        0.0005808784626424313,
        0.0005791319417767227,
        0.000546204624697566,
        0.0005384382093325257,
        0.0005261932383291423,
        0.0005144593305885792,
        0.0005020318785682321,
        0.0004916317411698401,
        0.00045080683776177466,
        0.000387546606361866,
        0.00038459766074083745
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "The efficient management and prediction of urban traffic flow are paramount in the age of beyond 5G smart cities and advanced transportation systems. Traditional methods often fail to handle the nonlinear and dynamic nature of traffic data, necessitating more advanced solutions. This paper introduces NeuroSync, a novel neural network architecture designed to leverage the strengths of spiking neuron layers and gated recurrent units (GRUs) combined with temporal pattern attention mechanisms to effectively forecast traffic patterns. The architecture is specifically tailored to address the complexities inherent in nonstationary urban traffic datasets, capturing both spatial and temporal relationships within the data. NeuroSync not only outperforms traditional forecasting models such as ARIMA and exponential smoothing but also shows significant improvement over contemporary neural network approaches like LSTM, CNN, Seq2Seq, RNN, GRU, Transformer, and Autoencoder in terms of mean squared error (MSE) and mean absolute error (MAE). The model's efficacy is demonstrated through extensive experiments with real-world traffic data, underscoring its potential to enhance urban mobility management and support the infrastructure of intelligent transportation systems.",
    "doi": "10.1002/dac.70035",
    "author_keywords": [
      "gated recurrent units (GRU)",
      "intelligent transportation systems (ITS)",
      "SDG",
      "smart cities",
      "spiking neuron layers",
      "temporal pattern attention",
      "time series analysis",
      "traffic forecasting",
      "urban mobility management"
    ],
    "contribution": "This paper introduces NeuroSync, a novel neural network architecture designed to leverage the strengths of spiking neuron layers and gated recurrent units (GRUs) combined with temporal pattern attention mechanisms to effectively forecast traffic patterns. The architecture is specifically tailored to address the complexities inherent in nonstationary urban traffic datasets, capturing both spatial and temporal relationships within the data. NeuroSync not only outperforms traditional forecasting models such as ARIMA and exponential smoothing but also shows significant improvement over contemporary neural network approaches like LSTM, CNN, Seq2Seq, RNN, GRU, Transformer, and Autoencoder in terms of mean squared error (MSE) and mean absolute error (MAE). The model's efficacy is demonstrated through extensive experiments with real-world traffic data, underscoring its potential to enhance urban mobility management and support the infrastructure of intelligent transportation systems.",
    "introduction": "The efficient management and prediction of urban traffic flow are paramount in the age of beyond 5G smart cities and advanced transportation systems. Traditional methods often fail to handle the nonlinear and dynamic nature of traffic data, necessitating more advanced solutions.",
    "classification_result": {
      "labels": [
        "Traffic Management",
        "Transportation Systems",
        "Mobility",
        "Logistics",
        "Public Services",
        "Public Policies",
        "Business",
        "Urban Planning",
        "Environment",
        "Multimodal Transport",
        "Citizens",
        "Living",
        "Industry",
        "Socioeconomics",
        "People",
        "Governance",
        "Economic Management",
        "Economy",
        "Public Transit",
        "Innovation Policy",
        "Smart Grids",
        "Emergency Safety",
        "Electric Vehicles",
        "Resource Conservation",
        "Learning and Teaching",
        "Sustainability",
        "Power Distribution",
        "Citizen Engagement",
        "Energy Management",
        "Finance",
        "Cybersecurity",
        "Buildings",
        "Marketing",
        "Climate Change",
        "Lightning",
        "Tourism",
        "Bicycle",
        "Pedestrian",
        "Education",
        "Renewable Energy",
        "Green Spaces",
        "Pollution Control",
        "Social Equity",
        "Healthcare",
        "Culture",
        "Air Quality",
        "Housing",
        "Waste Management",
        "Water Quality"
      ],
      "scores": [
        0.9994895458221436,
        0.9955254793167114,
        0.9875157475471497,
        0.8948059678077698,
        0.41270947456359863,
        0.26797473430633545,
        0.18341036140918732,
        0.15322168171405792,
        0.06398993730545044,
        0.04560448229312897,
        0.03335781395435333,
        0.030047789216041565,
        0.029311709105968475,
        0.017853930592536926,
        0.015242951922118664,
        0.008611549623310566,
        0.004456538241356611,
        0.004159414675086737,
        0.004154517315328121,
        0.0014008843572810292,
        0.0008220333838835359,
        0.0007911307620815933,
        0.0006251508602872491,
        0.000610691960901022,
        0.0005653699627146125,
        0.0005489552859216928,
        0.0005442792898975313,
        0.0005156454863026738,
        0.00046487239887937903,
        0.000440473755588755,
        0.0004243861767463386,
        0.00041821837658062577,
        0.00041805399814620614,
        0.00041516326018609107,
        0.00041178709943778813,
        0.000396935036405921,
        0.00038555136416107416,
        0.00038140860851854086,
        0.0003813828225247562,
        0.0003787140012718737,
        0.00037140093627385795,
        0.0003684071125462651,
        0.00036759927752427757,
        0.0003498029545880854,
        0.00034614495234563947,
        0.0003431590448599309,
        0.00033522280864417553,
        0.0003261537931393832,
        0.0003162416978739202
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Mobility",
        "score": 0.9994895458221436
      },
      {
        "domain": "Smart Economy",
        "score": 0.8948059678077698
      }
    ]
  },
  {
    "abstract": "The main purpose of Smart Environments (SE) is to conveniently improve the human's daily life. Internet of Things (IoT) is a developing network for smart objects. Privacy-based security is a significant issue in any real-world smart environments centered on the IoT system. Security susceptibility in the IoT-centered systems provides a risk of security affecting smart environment applications. In this manuscript, Strengthening Security in IoT-Based Smart Cities utilizing Cycle-Consistent Generative Adversarial Networks for Attack Detection and Secure Data Transmission (IoT-SC-CCGAN-ADSDT) is proposed. Here, input information is gathered from NSL-KDD. The NSL-KDD input is pre-processed. Then, the important features of the pre-processed data are selected by using Wild horse optimizer (WHO). After feature selection, the chosen features are provided to cycle-consistent generative adversarial network classifier for classifying the attack and normal data. The selected features are sent to the use after the prediction of outcomes using Advanced Encryption Standard (AES). The AES is optimized using Chameleon Swarm Algorithm for transmitting the data in a safer way. After transmitting the data securely, the normal data outcomes obviously shown in LCD monitor. To show these results, major problems in the smart cities are simply detected. The proposed model is activated using java. The efficiency is examined with performance metrics, like precision, sensitivity, specificity, accuracy, computational time, encryption time, decryption time, security level. The proposed IoT-SC-CCGAN-ADSDT approach provides 96.68%, 7.142%, 94.65%, and 97.58% greater accuracy compared to the existing DL-IOT-SCA, IoT-SC-PCA, IoT-SCA-DL methods respectively.",
    "doi": "10.1007/s12083-024-01838-0",
    "author_keywords": [
      "Advanced encryption standard",
      "Attack detection",
      "Chameleon swarm algorithm",
      "Internet of Things",
      "Smart cities",
      "Wild horse optimizer"
    ],
    "contribution": "In this manuscript, Strengthening Security in IoT-Based Smart Cities utilizing Cycle-Consistent Generative Adversarial Networks for Attack Detection and Secure Data Transmission (IoT-SC-CCGAN-ADSDT) is proposed. Here, input information is gathered from NSL-KDD. The NSL-KDD input is pre-processed. Then, the important features of the pre-processed data are selected by using Wild horse optimizer (WHO). After feature selection, the chosen features are provided to cycle-consistent generative adversarial network classifier for classifying the attack and normal data. The selected features are sent to the use after the prediction of outcomes using Advanced Encryption Standard (AES). The AES is optimized using Chameleon Swarm Algorithm for transmitting the data in a safer way. After transmitting the data securely, the normal data outcomes obviously shown in LCD monitor. To show these results, major problems in the smart cities are simply detected. The proposed model is activated using java. The efficiency is examined with performance metrics, like precision, sensitivity, specificity, accuracy, computational time, encryption time, decryption time, security level. The proposed IoT-SC-CCGAN-ADSDT approach provides 96.68%, 7.142%, 94.65%, and 97.58% greater accuracy compared to the existing DL-IOT-SCA, IoT-SC-PCA, IoT-SCA-DL methods respectively.",
    "introduction": "The main purpose of Smart Environments (SE) is to conveniently improve the human's daily life. Internet of Things (IoT) is a developing network for smart objects. Privacy-based security is a significant issue in any real-world smart environments centered on the IoT system. Security susceptibility in the IoT-centered systems provides a risk of security affecting smart environment applications.",
    "classification_result": {
      "labels": [
        "Environment",
        "Industry",
        "Living",
        "Innovation Policy",
        "Business",
        "Cybersecurity",
        "Public Services",
        "Citizens",
        "Public Policies",
        "Buildings",
        "People",
        "Socioeconomics",
        "Governance",
        "Learning and Teaching",
        "Citizen Engagement",
        "Urban Planning",
        "Economy",
        "Economic Management",
        "Smart Grids",
        "Housing",
        "Multimodal Transport",
        "Emergency Safety",
        "Education",
        "Marketing",
        "Energy Management",
        "Mobility",
        "Air Quality",
        "Electric Vehicles",
        "Public Transit",
        "Renewable Energy",
        "Power Distribution",
        "Social Equity",
        "Logistics",
        "Resource Conservation",
        "Pedestrian",
        "Healthcare",
        "Culture",
        "Water Quality",
        "Finance",
        "Climate Change",
        "Sustainability",
        "Lightning",
        "Traffic Management",
        "Tourism",
        "Transportation Systems",
        "Pollution Control",
        "Bicycle",
        "Waste Management",
        "Green Spaces"
      ],
      "scores": [
        0.8403687477111816,
        0.13523976504802704,
        0.09048555046319962,
        0.08527546375989914,
        0.07540401071310043,
        0.024251403287053108,
        0.02331351488828659,
        0.01271322462707758,
        0.011609024368226528,
        0.0033740082290023565,
        0.0032897836063057184,
        0.001977438572794199,
        0.001372246420942247,
        0.000644607818685472,
        0.0006343591376207769,
        0.0006072219694033265,
        0.0005396707565523684,
        0.0005380418733693659,
        0.0005355107714422047,
        0.00053489173296839,
        0.0005256685544736683,
        0.0005107895703986287,
        0.0004940213402733207,
        0.0004920262726955116,
        0.00045778078492730856,
        0.00043764602742157876,
        0.0004328241047915071,
        0.0004312285454943776,
        0.00042978828423656523,
        0.0004113902396056801,
        0.0004099283250980079,
        0.0004002968198619783,
        0.0003971222322434187,
        0.00039496523095294833,
        0.00039051470230333507,
        0.0003889789804816246,
        0.0003837284166365862,
        0.0003819621342699975,
        0.00037576971226371825,
        0.0003694240585900843,
        0.0003644096141215414,
        0.0003616801113821566,
        0.0003609044651966542,
        0.00034224832779727876,
        0.00033853965578600764,
        0.0003290009335614741,
        0.0003228401474189013,
        0.00032086108694784343,
        0.000317553523927927
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Environment",
        "score": 0.8403687477111816
      }
    ]
  },
  {
    "abstract": "In the construction of smart cities in the new era, traffic prediction is an important component. Precise traffic flow prediction faces significant challenges due to spatial heterogeneity, dynamic correlations, and uncertainty. Most existing methods typically learn from a single spatial or temporal perspective, or at best combine the two in a limited dual-perspective manner, which limits their ability to capture complex spatio-temporal relationships. In this paper, we propose a novel Multi-view Spatio-Temporal Dynamic Fusion Graph Convolutional Recurrent Network (MSTDFGRN) to address these limitations. The core idea is to learn dynamic spatial dependencies alongside both short- and long-term temporal patterns through multi-view learning. First, we introduce a multi-view spatial convolution module that dynamically fuses static and adaptive graphs in multiple subspaces to learn intrinsic and potential spatial dependencies of nodes. Simultaneously, in the temporal view, we design both short-range and long-range recurrent networks to aggregate spatial domain knowledge of nodes at multiple granularities and capture forward and backward temporal dependencies. Furthermore, we design a spatio-temporal attention model that applies an attention mechanism to each node, capturing global spatio-temporal dependencies. Comprehensive experiments on four real traffic flow datasets demonstrate MSTDFGRN's excellent predictive accuracy. Specifically, compared to the Spatialâ€“Temporal Graph Attention Gated Recurrent Transformer Network model, our method improves the MAE by 4.69% on the PeMS08 dataset.",
    "doi": "10.1016/j.compeleceng.2024.110046",
    "author_keywords": [
      "Graph Convolutional Network",
      "Multi-view learning",
      "Spatio-temporal dependencies",
      "Traffic flow prediction"
    ],
    "contribution": "In this paper, we propose a novel Multi-view Spatio-Temporal Dynamic Fusion Graph Convolutional Recurrent Network (MSTDFGRN) to address these limitations. The core idea is to learn dynamic spatial dependencies alongside both short- and long-term temporal patterns through multi-view learning. First, we introduce a multi-view spatial convolution module that dynamically fuses static and adaptive graphs in multiple subspaces to learn intrinsic and potential spatial dependencies of nodes. Simultaneously, in the temporal view, we design both short-range and long-range recurrent networks to aggregate spatial domain knowledge of nodes at multiple granularities and capture forward and backward temporal dependencies. Furthermore, we design a spatio-temporal attention model that applies an attention mechanism to each node, capturing global spatio-temporal dependencies. Comprehensive experiments on four real traffic flow datasets demonstrate MSTDFGRN's excellent predictive accuracy. Specifically, compared to the Spatialâ€“Temporal Graph Attention Gated Recurrent Transformer Network model, our method improves the MAE by 4.69% on the PeMS08 dataset.",
    "introduction": "In the construction of smart cities in the new era, traffic prediction is an important component. Precise traffic flow prediction faces significant challenges due to spatial heterogeneity, dynamic correlations, and uncertainty. Most existing methods typically learn from a single spatial or temporal perspective, or at best combine the two in a limited dual-perspective manner, which limits their ability to capture complex spatio-temporal relationships.",
    "classification_result": {
      "labels": [
        "Transportation Systems",
        "Mobility",
        "Logistics",
        "Traffic Management",
        "Business",
        "Public Services",
        "Industry",
        "Multimodal Transport",
        "Environment",
        "Urban Planning",
        "Public Policies",
        "Economic Management",
        "Living",
        "Governance",
        "Economy",
        "Socioeconomics",
        "Innovation Policy",
        "Citizens",
        "Learning and Teaching",
        "People",
        "Emergency Safety",
        "Smart Grids",
        "Electric Vehicles",
        "Sustainability",
        "Power Distribution",
        "Resource Conservation",
        "Renewable Energy",
        "Climate Change",
        "Energy Management",
        "Pedestrian",
        "Citizen Engagement",
        "Public Transit",
        "Social Equity",
        "Education",
        "Finance",
        "Buildings",
        "Cybersecurity",
        "Green Spaces",
        "Culture",
        "Marketing",
        "Lightning",
        "Bicycle",
        "Healthcare",
        "Waste Management",
        "Tourism",
        "Water Quality",
        "Air Quality",
        "Housing",
        "Pollution Control"
      ],
      "scores": [
        0.9578182697296143,
        0.9468547701835632,
        0.7310879230499268,
        0.6047520637512207,
        0.11031515896320343,
        0.10160518437623978,
        0.05770334601402283,
        0.046178169548511505,
        0.04400566965341568,
        0.038857560604810715,
        0.008602974936366081,
        0.003659747540950775,
        0.0033721583895385265,
        0.0022440452594310045,
        0.0018463152227923274,
        0.0016644431743770838,
        0.001327110338024795,
        0.0008851963793858886,
        0.0008522717980667949,
        0.000741358962841332,
        0.0005925237783230841,
        0.000562465691473335,
        0.000525268551427871,
        0.0004871877026744187,
        0.0004423859645612538,
        0.00043671848834492266,
        0.00042565169860608876,
        0.0004194291541352868,
        0.00041474634781479836,
        0.000413186993682757,
        0.00041240366408601403,
        0.00041159955435432494,
        0.0004067464906256646,
        0.00040089484537020326,
        0.0004002419882453978,
        0.00039812742033973336,
        0.00039172996184788644,
        0.0003793608630076051,
        0.0003758740785997361,
        0.0003757414233405143,
        0.00037017243448644876,
        0.00036979690776206553,
        0.0003493489930406213,
        0.0003472928947303444,
        0.0003414905513636768,
        0.00033910555066540837,
        0.0003381738788448274,
        0.00033133564284071326,
        0.0003281732206232846
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Mobility",
        "score": 0.9578182697296143
      },
      {
        "domain": "Smart Economy",
        "score": 0.7310879230499268
      }
    ]
  },
  {
    "abstract": "Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologiesâ€”such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworksâ€”to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flowsâ€”namely mobility, goods, energy, waste, materials, and biodiversityâ€”critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.",
    "doi": "10.1016/j.ese.2025.100526",
    "author_keywords": [
      "Foundation models",
      "Generative artificial intelligence",
      "Generative spatial artificial intelligence",
      "Large flow model",
      "Sustainable smart cities",
      "Urban digital twin",
      "Urban planning and design"
    ],
    "contribution": "This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flowsâ€”namely mobility, goods, energy, waste, materials, and biodiversityâ€”critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.",
    "introduction": "Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologiesâ€”such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworksâ€”to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption.",
    "classification_result": {
      "labels": [
        "Urban Planning",
        "Sustainability",
        "Innovation Policy",
        "Multimodal Transport",
        "Environment",
        "Mobility",
        "Living",
        "Public Services",
        "Socioeconomics",
        "Buildings",
        "Business",
        "Public Policies",
        "People",
        "Water Quality",
        "Transportation Systems",
        "Housing",
        "Energy Management",
        "Public Transit",
        "Industry",
        "Logistics",
        "Power Distribution",
        "Economy",
        "Citizens",
        "Governance",
        "Learning and Teaching",
        "Pollution Control",
        "Emergency Safety",
        "Green Spaces",
        "Air Quality",
        "Economic Management",
        "Citizen Engagement",
        "Waste Management",
        "Resource Conservation",
        "Social Equity",
        "Smart Grids",
        "Lightning",
        "Climate Change",
        "Marketing",
        "Culture",
        "Finance",
        "Traffic Management",
        "Pedestrian",
        "Electric Vehicles",
        "Education",
        "Renewable Energy",
        "Tourism",
        "Healthcare",
        "Cybersecurity",
        "Bicycle"
      ],
      "scores": [
        0.9958809614181519,
        0.40149733424186707,
        0.03813999146223068,
        0.036717578768730164,
        0.025792213156819344,
        0.023289533331990242,
        0.020863818004727364,
        0.018191752955317497,
        0.016547949984669685,
        0.011019108816981316,
        0.009585642255842686,
        0.009083228185772896,
        0.008373809047043324,
        0.006123322993516922,
        0.005314484238624573,
        0.004601793363690376,
        0.004012417513877153,
        0.003949211444705725,
        0.0037901215255260468,
        0.002846295712515712,
        0.0021594767458736897,
        0.0021186545491218567,
        0.0017655990086495876,
        0.0015084663173183799,
        0.0013085502432659268,
        0.0013012917479500175,
        0.001288047176785767,
        0.0012604983057826757,
        0.001230898080393672,
        0.0011368588311597705,
        0.001082148402929306,
        0.0008959373808465898,
        0.0008744510123506188,
        0.0008505237638019025,
        0.0007977609056979418,
        0.000761312257964164,
        0.0007329455693252385,
        0.0006267133285291493,
        0.0005887585575692356,
        0.000582708278670907,
        0.0005570424254983664,
        0.0005515279481187463,
        0.000504992320202291,
        0.0004963246756233275,
        0.0004536673368420452,
        0.0004521783266682178,
        0.0004368916852399707,
        0.0004083257226739079,
        0.000385222549084574
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Governance",
        "score": 0.9958809614181519
      }
    ]
  },
  {
    "abstract": "Intersections are frequently identified as crash hotspots for roadways in major cities, leading to significant human casualties. We propose crash likelihood prediction as an effective strategy to proactively prevent intersection crashes. So far, no reliable models have been developed for intersections that effectively account for the variation in crash types and the cyclical nature of Signal Phasing and Timing (SPaT) and traffic flow. Moreover, the limited research available has primarily relied on sampling techniques to address data imbalance, without exploring alternative solutions. We develop an anomaly detection framework by integrating Generative Adversarial Networks (GANs) and Transformers to predict the likelihood of cycle-level crashes at intersections. The model is built using high-resolution event data extracted from Automated Traffic Signal Performance Measures (ATSPM), including SPaT and traffic flow insights from 11 intersections in Seminole County, Florida. Our framework demonstrates a sensitivity of 76% in predicting crash events using highly imbalanced crash data along with real-world SPaT and traffic data, highlighting its potential for deployment at smart intersections. Overall, the results provide a roadmap for city-wide implementation at smart intersections, with the potential for multiple real-time solutions for impending crashes. These include adjustments in signal timing, driver warnings using various means, and more efficient emergency response, all with major implications for creating more livable and safe cities.",
    "doi": "10.1016/j.aap.2024.107908",
    "author_keywords": [
      "Anomaly detection",
      "Crash likelihood prediction",
      "GANs",
      "Proactive safety measures",
      "Smart cities",
      "Smart intersections",
      "Transformers"
    ],
    "contribution": "We propose crash likelihood prediction as an effective strategy to proactively prevent intersection crashes. So far, no reliable models have been developed for intersections that effectively account for the variation in crash types and the cyclical nature of Signal Phasing and Timing (SPaT) and traffic flow. Moreover, the limited research available has primarily relied on sampling techniques to address data imbalance, without exploring alternative solutions. We develop an anomaly detection framework by integrating Generative Adversarial Networks (GANs) and Transformers to predict the likelihood of cycle-level crashes at intersections. The model is built using high-resolution event data extracted from Automated Traffic Signal Performance Measures (ATSPM), including SPaT and traffic flow insights from 11 intersections in Seminole County, Florida. Our framework demonstrates a sensitivity of 76% in predicting crash events using highly imbalanced crash data along with real-world SPaT and traffic data, highlighting its potential for deployment at smart intersections. Overall, the results provide a roadmap for city-wide implementation at smart intersections, with the potential for multiple real-time solutions for impending crashes. These include adjustments in signal timing, driver warnings using various means, and more efficient emergency response, all with major implications for creating more livable and safe cities.",
    "introduction": "Intersections are frequently identified as crash hotspots for roadways in major cities, leading to significant human casualties.",
    "classification_result": {
      "labels": [
        "Transportation Systems",
        "Mobility",
        "Traffic Management",
        "Urban Planning",
        "Living",
        "Emergency Safety",
        "People",
        "Logistics",
        "Environment",
        "Citizens",
        "Public Services",
        "Public Policies",
        "Economic Management",
        "Socioeconomics",
        "Multimodal Transport",
        "Business",
        "Citizen Engagement",
        "Governance",
        "Economy",
        "Learning and Teaching",
        "Social Equity",
        "Pedestrian",
        "Innovation Policy",
        "Energy Management",
        "Industry",
        "Electric Vehicles",
        "Resource Conservation",
        "Public Transit",
        "Power Distribution",
        "Sustainability",
        "Climate Change",
        "Renewable Energy",
        "Pollution Control",
        "Smart Grids",
        "Air Quality",
        "Green Spaces",
        "Finance",
        "Education",
        "Bicycle",
        "Culture",
        "Buildings",
        "Waste Management",
        "Cybersecurity",
        "Housing",
        "Healthcare",
        "Marketing",
        "Tourism",
        "Water Quality",
        "Lightning"
      ],
      "scores": [
        0.9720866084098816,
        0.9552193880081177,
        0.8788825869560242,
        0.3919627368450165,
        0.09785451740026474,
        0.07365965098142624,
        0.04867616295814514,
        0.03790934756398201,
        0.02381794899702072,
        0.02099897898733616,
        0.010285456664860249,
        0.008759688585996628,
        0.0012403459986671805,
        0.0009135864092968404,
        0.0007903873920440674,
        0.0006355522200465202,
        0.000492441060487181,
        0.00047924675163812935,
        0.00044243005686439574,
        0.00042732764268293977,
        0.0004161562246736139,
        0.000401018129196018,
        0.00038218963891267776,
        0.0003603260265663266,
        0.0003536044096108526,
        0.00035147982998751104,
        0.00035084833507426083,
        0.00033979187719523907,
        0.00033463857835158706,
        0.00033008967875503004,
        0.0003258200886193663,
        0.0003103807393927127,
        0.0003032537060789764,
        0.00030147601501084864,
        0.00029371195705607533,
        0.00029049342265352607,
        0.0002900732506532222,
        0.0002894701319746673,
        0.0002846886054612696,
        0.00028449035016819835,
        0.0002843592083081603,
        0.00028314246446825564,
        0.0002826131822075695,
        0.000280469364952296,
        0.00027896571555174887,
        0.0002786343975458294,
        0.00027820683317258954,
        0.0002778838970698416,
        0.00027220469200983644
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Mobility",
        "score": 0.9720866084098816
      }
    ]
  },
  {
    "abstract": "In recent years, the Internet of Things devices have progressively deployed in various applications including smart cities, intelligent transportation, healthcare, and agriculture. However, this widespread adaptation of the Internet of Things networks has been vulnerable to several attacks. Lack of security protocols, unauthorized access, and improper device updates lead the Internet of Things environment to several attacks, which impact network security and confidentiality of users. This paper develops an innovative approach that integrates Edge Implicit Weighting and Aggregated Graph Transformer architecture for accurate and timely intrusion detection. The proposed technique aggregates information from both one-hop and two-hop neighbors to derive immediate and extended relational context thereby improving the detection of complex attacks. This approach designs an Edge Implicit Weighting mechanism that allows the model to prioritize structurally significant relationships and enhance the accuracy of attack detection. The multi-head attention mechanism is introduced to enhance the detection of relevant patterns even in highly variable traffic scenarios. Further, the proposed framework incorporates the Synthetic Minority Over-sampling Technique to generate synthetic samples of minority classes to reduce class imbalance problems and attain balanced detection performance across all classes. The performance of the proposed detection technique is analyzed using multiple datasets with standard evaluation parameters. The proposed technique achieves outstanding performance results including an accuracy of 98.87% and a recall of 98.36%. From this experimental validation, it's clear that the proposed framework provides robust performance under diverse network conditions and handles imbalanced data effectively.",
    "doi": "10.1016/j.cose.2024.104299",
    "author_keywords": [
      "Class imbalance",
      "Dual aggregation",
      "Edge Implicit Weighting",
      "Graph transformer",
      "Internet of Things",
      "Intrusion detection system",
      "Multi-head attention mechanism",
      "Network security"
    ],
    "contribution": "This paper develops an innovative approach that integrates Edge Implicit Weighting and Aggregated Graph Transformer architecture for accurate and timely intrusion detection. The proposed technique aggregates information from both one-hop and two-hop neighbors to derive immediate and extended relational context thereby improving the detection of complex attacks. This approach designs an Edge Implicit Weighting mechanism that allows the model to prioritize structurally significant relationships and enhance the accuracy of attack detection. The multi-head attention mechanism is introduced to enhance the detection of relevant patterns even in highly variable traffic scenarios. Further, the proposed framework incorporates the Synthetic Minority Over-sampling Technique to generate synthetic samples of minority classes to reduce class imbalance problems and attain balanced detection performance across all classes. The performance of the proposed detection technique is analyzed using multiple datasets with standard evaluation parameters. The proposed technique achieves outstanding performance results including an accuracy of 98.87% and a recall of 98.36%. From this experimental validation, it's clear that the proposed framework provides robust performance under diverse network conditions and handles imbalanced data effectively.",
    "introduction": "In recent years, the Internet of Things devices have progressively deployed in various applications including smart cities, intelligent transportation, healthcare, and agriculture. However, this widespread adaptation of the Internet of Things networks has been vulnerable to several attacks. Lack of security protocols, unauthorized access, and improper device updates lead the Internet of Things environment to several attacks, which impact network security and confidentiality of users.",
    "classification_result": {
      "labels": [
        "Cybersecurity",
        "Industry",
        "Environment",
        "Business",
        "Public Services",
        "Living",
        "Socioeconomics",
        "Innovation Policy",
        "Smart Grids",
        "Citizens",
        "Economy",
        "Public Policies",
        "Governance",
        "Economic Management",
        "Emergency Safety",
        "Healthcare",
        "Logistics",
        "Sustainability",
        "Buildings",
        "Learning and Teaching",
        "Energy Management",
        "Pedestrian",
        "Urban Planning",
        "Power Distribution",
        "Electric Vehicles",
        "Air Quality",
        "Transportation Systems",
        "Mobility",
        "Renewable Energy",
        "Traffic Management",
        "Water Quality",
        "Multimodal Transport",
        "Citizen Engagement",
        "Housing",
        "Lightning",
        "Climate Change",
        "Resource Conservation",
        "Social Equity",
        "Green Spaces",
        "People",
        "Education",
        "Culture",
        "Public Transit",
        "Finance",
        "Waste Management",
        "Marketing",
        "Bicycle",
        "Pollution Control",
        "Tourism"
      ],
      "scores": [
        0.6749411821365356,
        0.561129629611969,
        0.20876172184944153,
        0.0790865495800972,
        0.007723047863692045,
        0.006207888945937157,
        0.003929521888494492,
        0.002903799759224057,
        0.0027186356019228697,
        0.002683819504454732,
        0.0024520065635442734,
        0.001730539952404797,
        0.0013176839565858245,
        0.001012512482702732,
        0.000986994942650199,
        0.000938254117500037,
        0.0007640921394340694,
        0.0006955363205634058,
        0.0006593892467208207,
        0.0006569081451743841,
        0.0006539089954458177,
        0.0005925817531533539,
        0.0005890484899282455,
        0.0005882776458747685,
        0.0005601627053692937,
        0.0005528549081645906,
        0.0005404152907431126,
        0.0005253939889371395,
        0.0005161018925718963,
        0.0005021632532589138,
        0.0004969413857907057,
        0.0004923085798509419,
        0.00048786046681925654,
        0.0004826783260796219,
        0.00047759676817804575,
        0.0004733473469968885,
        0.00047216564416885376,
        0.0004568533331621438,
        0.0004547866992652416,
        0.0004530101432465017,
        0.00044167207670398057,
        0.00043495697900652885,
        0.0004321327432990074,
        0.0004288349882699549,
        0.00042125265463255346,
        0.00041807940579019487,
        0.0004144349950365722,
        0.00041109713492915034,
        0.00040271962643601
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Governance",
        "score": 0.6749411821365356
      },
      {
        "domain": "Smart Economy",
        "score": 0.561129629611969
      }
    ]
  },
  {
    "abstract": "The intelligent design of shear wall structures is a critical aspect of smart construction, with a high demand for research and applications. Accurately predicting the shear wall ratio (i.e., the shear wall area-to-floor area ratio) during cost estimation and rapidly generating shear wall layouts during early design is essential. However, the unclear influences of numerous design feature parameters hinder the enhancement of generative AI design. This affects both the prediction of shear wall ratios from multidimensional features and the generation of shear wall layouts from high-dimensional features. Therefore, a method for generating key structural design features using machine learning (ML) and generative adversarial networks (GANs), along with model interpretation, is proposed in this study. Existing shear wall design data are collected, and features such as the architectural plan geometry, seismic design conditions, and shear wall ratios are extracted to establish a dataset. Key shear wall ratio parameters are predicted using an ML model with multidimensional design features as inputs, and interpretability analysis is conducted using Shapley Additive Explanations (SHAP). Concurrently, a GAN model is built to generate shear wall designs using fused image-text high-dimensional features, and the influence patterns of design features are explained through sensitivity analysis. The analysis results indicate that the prediction accuracy is effectively enhanced by ML-based multidimensional feature learning, shear wall designs are effectively generated by GAN-based high-dimensional feature learning, and seismic design intensity and structural height are revealed as significant factors through interpretability analysis. Furthermore, when high-dimensional feature inputs are available, the generation of comprehensive features should be prioritized for shear wall structural designs.",
    "doi": "10.1016/j.engstruct.2024.119472",
    "author_keywords": [
      "Generative adversarial networks",
      "Intelligent structural design",
      "Interpretable machine learning",
      "Multi- and high-dimensional feature analysis",
      "Shear wall structure"
    ],
    "contribution": "Therefore, a method for generating key structural design features using machine learning (ML) and generative adversarial networks (GANs), along with model interpretation, is proposed in this study. Existing shear wall design data are collected, and features such as the architectural plan geometry, seismic design conditions, and shear wall ratios are extracted to establish a dataset. Key shear wall ratio parameters are predicted using an ML model with multidimensional design features as inputs, and interpretability analysis is conducted using Shapley Additive Explanations (SHAP). Concurrently, a GAN model is built to generate shear wall designs using fused image-text high-dimensional features, and the influence patterns of design features are explained through sensitivity analysis. The analysis results indicate that the prediction accuracy is effectively enhanced by ML-based multidimensional feature learning, shear wall designs are effectively generated by GAN-based high-dimensional feature learning, and seismic design intensity and structural height are revealed as significant factors through interpretability analysis. Furthermore, when high-dimensional feature inputs are available, the generation of comprehensive features should be prioritized for shear wall structural designs.",
    "introduction": "The intelligent design of shear wall structures is a critical aspect of smart construction, with a high demand for research and applications. Accurately predicting the shear wall ratio (i.e., the shear wall area-to-floor area ratio) during cost estimation and rapidly generating shear wall layouts during early design is essential. However, the unclear influences of numerous design feature parameters hinder the enhancement of generative AI design. This affects both the prediction of shear wall ratios from multidimensional features and the generation of shear wall layouts from high-dimensional features.",
    "classification_result": {
      "labels": [
        "Industry",
        "Buildings",
        "Housing",
        "Business",
        "Public Services",
        "Environment",
        "Sustainability",
        "Emergency Safety",
        "Living",
        "Resource Conservation",
        "Transportation Systems",
        "Power Distribution",
        "Learning and Teaching",
        "Green Spaces",
        "Multimodal Transport",
        "Smart Grids",
        "Mobility",
        "Logistics",
        "Renewable Energy",
        "Economy",
        "Innovation Policy",
        "Citizens",
        "Energy Management",
        "Healthcare",
        "Public Transit",
        "Lightning",
        "Water Quality",
        "Urban Planning",
        "People",
        "Air Quality",
        "Electric Vehicles",
        "Pollution Control",
        "Education",
        "Climate Change",
        "Economic Management",
        "Cybersecurity",
        "Socioeconomics",
        "Social Equity",
        "Waste Management",
        "Finance",
        "Tourism",
        "Public Policies",
        "Governance",
        "Traffic Management",
        "Pedestrian",
        "Citizen Engagement",
        "Culture",
        "Bicycle",
        "Marketing"
      ],
      "scores": [
        0.24205279350280762,
        0.1610279530286789,
        0.038067836314439774,
        0.024986563250422478,
        0.009117072448134422,
        0.007782268803566694,
        0.0038519687950611115,
        0.0033830981701612473,
        0.003069985192269087,
        0.002792100189253688,
        0.002724755322560668,
        0.0026227720081806183,
        0.0022039359901100397,
        0.002012397162616253,
        0.0018706823466345668,
        0.001550769549794495,
        0.0014282538322731853,
        0.00136107939761132,
        0.001177514554001391,
        0.001081432099454105,
        0.0010101718362420797,
        0.0009692928870208561,
        0.0009548672824166715,
        0.0009509992669336498,
        0.0009372002677991986,
        0.0009364914149045944,
        0.0008799752104096115,
        0.0008216974092647433,
        0.000793180544860661,
        0.0007570554153062403,
        0.000746164470911026,
        0.0007429162506014109,
        0.0006755914073437452,
        0.0006722866673953831,
        0.0006630652933381498,
        0.0006460434524342418,
        0.0006273487233556807,
        0.0006055693374946713,
        0.0006014166283421218,
        0.0005789825809188187,
        0.0005654058186337352,
        0.0005540682468563318,
        0.000548982119653374,
        0.000548978743609041,
        0.000529142445884645,
        0.0005241523031145334,
        0.00048758770572021604,
        0.000460274051874876,
        0.00042487599421292543
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "Internet of Things (IoT) applications in smart cities (SCs) rely on free-flow services streamlined by artificial intelligence (AI) paradigms. However, the nature of resource constraint prevails due to external infrastructure costs and energy-based allocations. Existing approaches to smart city resource distribution rely on static thresholds or reactive responses, which are not always sufficient. These approaches may limit system performance and scalability in dynamic IoT environments owing to increased energy consumption, postponed resource allocation, and frequent device failures. This article introduces a Concerted Resource Management (CRM) using the Leveled Reinforcement Training (LRT) method. The proposed method accurately identifies cost-complex and high energy-consuming sharing intervals based on service response time and device failure. The reinforcement learning and training concerts both energy and device incorporations for SC applications based on its demand. This process requires leveled training in resource management, from energy depletion to device activeness. The interrupted sessions are identified using resource allocation failures, and the active resources with optimal energy expenses are selected to pursue resource management. The training method thus identifies the demands based on independent or concerted resource allocations to mitigate the management constraints in an SC environment. This proposed method reduces the resource constraint-based waiting for allocations and allocation failures in any SC application services. Under the varying devices, the following is observed: Improvements: 9.1% (Allocation Rate), 10% (Device Detection), 11.88% (Constraint Mitigationâ€” Energy), 9.06% (Constraint Mitigationâ€”Resource Allocation); Reduced: 8.01% (Allocation Failure), 9.64% (Waiting Time).",
    "doi": "10.32985/ijeces.16.2.1",
    "author_keywords": [
      "high frequency transformer",
      "phase shift control technique",
      "Power flow control",
      "three port converter"
    ],
    "contribution": "This article introduces a Concerted Resource Management (CRM) using the Leveled Reinforcement Training (LRT) method. The proposed method accurately identifies cost-complex and high energy-consuming sharing intervals based on service response time and device failure. The reinforcement learning and training concerts both energy and device incorporations for SC applications based on its demand. This process requires leveled training in resource management, from energy depletion to device activeness. The interrupted sessions are identified using resource allocation failures, and the active resources with optimal energy expenses are selected to pursue resource management. The training method thus identifies the demands based on independent or concerted resource allocations to mitigate the management constraints in an SC environment. This proposed method reduces the resource constraint-based waiting for allocations and allocation failures in any SC application services. Under the varying devices, the following is observed: Improvements: 9.1% (Allocation Rate), 10% (Device Detection), 11.88% (Constraint Mitigationâ€” Energy), 9.06% (Constraint Mitigationâ€”Resource Allocation); Reduced: 8.01% (Allocation Failure), 9.64% (Waiting Time).",
    "introduction": "Internet of Things (IoT) applications in smart cities (SCs) rely on free-flow services streamlined by artificial intelligence (AI) paradigms. However, the nature of resource constraint prevails due to external infrastructure costs and energy-based allocations. Existing approaches to smart city resource distribution rely on static thresholds or reactive responses, which are not always sufficient. These approaches may limit system performance and scalability in dynamic IoT environments owing to increased energy consumption, postponed resource allocation, and frequent device failures.",
    "classification_result": {
      "labels": [
        "Resource Conservation",
        "Environment",
        "Energy Management",
        "Socioeconomics",
        "Business",
        "Public Services",
        "Economic Management",
        "Power Distribution",
        "Urban Planning",
        "Industry",
        "Economy",
        "Logistics",
        "Sustainability",
        "Innovation Policy",
        "Smart Grids",
        "Governance",
        "Public Policies",
        "Cybersecurity",
        "Living",
        "Multimodal Transport",
        "Traffic Management",
        "Citizens",
        "Emergency Safety",
        "Buildings",
        "Social Equity",
        "Lightning",
        "Mobility",
        "Learning and Teaching",
        "Renewable Energy",
        "Water Quality",
        "Air Quality",
        "Transportation Systems",
        "Finance",
        "People",
        "Electric Vehicles",
        "Public Transit",
        "Marketing",
        "Citizen Engagement",
        "Pedestrian",
        "Waste Management",
        "Green Spaces",
        "Pollution Control",
        "Housing",
        "Education",
        "Climate Change",
        "Bicycle",
        "Culture",
        "Tourism",
        "Healthcare"
      ],
      "scores": [
        0.6094965934753418,
        0.47064897418022156,
        0.10352446883916855,
        0.09220723062753677,
        0.07520890235900879,
        0.06561298668384552,
        0.0654592290520668,
        0.054044630378484726,
        0.031034838408231735,
        0.028092047199606895,
        0.0204243753105402,
        0.017942648380994797,
        0.014781247824430466,
        0.013950510881841183,
        0.010884822346270084,
        0.009577578864991665,
        0.00819320883601904,
        0.007573120296001434,
        0.004303703084588051,
        0.0030239426996558905,
        0.002559215761721134,
        0.00251940474845469,
        0.002312995959073305,
        0.002038826234638691,
        0.0018942378228530288,
        0.001004852238111198,
        0.0009209359996020794,
        0.0008547087199985981,
        0.000800112436991185,
        0.0007994513143785298,
        0.0007306662737391889,
        0.0007101418450474739,
        0.0006671229493804276,
        0.0006392074283212423,
        0.000633641320746392,
        0.000616825302131474,
        0.0005965817836113274,
        0.0005796867189928889,
        0.0005768956616520882,
        0.0005716996965929866,
        0.0005367192788980901,
        0.0005156625411473215,
        0.0005043955752626061,
        0.0004902607179246843,
        0.000485747994389385,
        0.00046926704817451537,
        0.0004518615605775267,
        0.0004228812758810818,
        0.000401700526708737
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Environment",
        "score": 0.6094965934753418
      }
    ]
  },
  {
    "abstract": "Highlights: What are the main findings? For smart city management, LLM-based multi-agent systems achieve 94â€“99% accuracy in routing urban queries and demonstrate significant improvements in response quality (G-Eval scores of 0.68â€“0.74) compared to standalone LLMs (0.30â€“0.38). Achievement of high scores in routing queries and response accuracy is possible with middle-size LLM models rather than the biggest LLM models. What is the implication of the main findings? The multi-agent LLM approach enables efficient processing of complex urban planning tasks while maintaining high relevance in responses, making it practical for real-world city management applications. LLM agents can effectively augment human decision making in urban planning by reducing task completion time from days to hours while maintaining accuracy and accountability in complex scenarios. This study investigates the implementation of LLM agents in smart city management, leveraging both the inherent language processing abilities of LLMs and the distributed problem solving capabilities of multi-agent systems for the improvement of urban decision making processes. A multi-agent system architecture combines LLMs with existing urban information systems to process complex queries and generate contextually relevant responses for urban planning and management. The research is focused on three main hypotheses testing: (1) LLM agentsâ€™ capability for effective routing and processing diverse urban queries, (2) the effectiveness of Retrieval-Augmented Generation (RAG) technology in improving response accuracy when working with local knowledge and regulations, and (3) the impact of integrating LLM agents with existing urban information systems. Our experimental results, based on a comprehensive validation dataset of 150 questionâ€“answer pairs, demonstrate significant improvements in decision support capabilities. The multi-agent system achieved pipeline selection accuracy of 94â€“99% across different models, while the integration of RAG technology improved response accuracy by 17% for strategic development queries and 55% for service accessibility questions. The combined use of document databases and service APIs resulted in the highest performance metrics (G-Eval scores of 0.68â€“0.74) compared to standalone LLM responses (0.30â€“0.38). Using St. Petersburgâ€™s Digital Urban Platform as a testbed, we demonstrate the practical applicability of this approach to create integrated city management systems with support complex urban decision making processes. This research contributes to the growing field of AI-enhanced urban management by providing empirical evidence of LLM agentsâ€™ effectiveness in processing heterogeneous urban data and supporting strategic planning decisions. Our findings suggest that LLM-based multi-agent systems can significantly enhance the efficiency and accuracy of urban decision making while maintaining high relevance in responses.",
    "doi": "10.3390/smartcities8010019",
    "author_keywords": [
      "data-driven management",
      "large language model",
      "LLM",
      "LLM agent",
      "multi-agent system",
      "smart city management",
      "strategic management"
    ],
    "contribution": "This study investigates the implementation of LLM agents in smart city management, leveraging both the inherent language processing abilities of LLMs and the distributed problem solving capabilities of multi-agent systems for the improvement of urban decision making processes. A multi-agent system architecture combines LLMs with existing urban information systems to process complex queries and generate contextually relevant responses for urban planning and management. The research is focused on three main hypotheses testing: (1) LLM agentsâ€™ capability for effective routing and processing diverse urban queries, (2) the effectiveness of Retrieval-Augmented Generation (RAG) technology in improving response accuracy when working with local knowledge and regulations, and (3) the impact of integrating LLM agents with existing urban information systems. Our experimental results, based on a comprehensive validation dataset of 150 questionâ€“answer pairs, demonstrate significant improvements in decision support capabilities. The multi-agent system achieved pipeline selection accuracy of 94â€“99% across different models, while the integration of RAG technology improved response accuracy by 17% for strategic development queries and 55% for service accessibility questions. The combined use of document databases and service APIs resulted in the highest performance metrics (G-Eval scores of 0.68â€“0.74) compared to standalone LLM responses (0.30â€“0.38). Using St. Petersburgâ€™s Digital Urban Platform as a testbed, we demonstrate the practical applicability of this approach to create integrated city management systems with support complex urban decision making processes. This research contributes to the growing field of AI-enhanced urban management by providing empirical evidence of LLM agentsâ€™ effectiveness in processing heterogeneous urban data and supporting strategic planning decisions. Our findings suggest that LLM-based multi-agent systems can significantly enhance the efficiency and accuracy of urban decision making while maintaining high relevance in responses.",
    "introduction": "Highlights: What are the main findings? For smart city management, LLM-based multi-agent systems achieve 94â€“99% accuracy in routing urban queries and demonstrate significant improvements in response quality (G-Eval scores of 0.68â€“0.74) compared to standalone LLMs (0.30â€“0.38). Achievement of high scores in routing queries and response accuracy is possible with middle-size LLM models rather than the biggest LLM models. What is the implication of the main findings? The multi-agent LLM approach enables efficient processing of complex urban planning tasks while maintaining high relevance in responses, making it practical for real-world city management applications. LLM agents can effectively augment human decision making in urban planning by reducing task completion time from days to hours while maintaining accuracy and accountability in complex scenarios.",
    "classification_result": {
      "labels": [
        "Urban Planning",
        "Public Services",
        "Public Policies",
        "Lightning",
        "Living",
        "Governance",
        "Learning and Teaching",
        "People",
        "Socioeconomics",
        "Logistics",
        "Environment",
        "Industry",
        "Business",
        "Citizen Engagement",
        "Innovation Policy",
        "Emergency Safety",
        "Mobility",
        "Multimodal Transport",
        "Buildings",
        "Power Distribution",
        "Resource Conservation",
        "Sustainability",
        "Citizens",
        "Economy",
        "Renewable Energy",
        "Economic Management",
        "Smart Grids",
        "Green Spaces",
        "Social Equity",
        "Education",
        "Energy Management",
        "Pedestrian",
        "Culture",
        "Air Quality",
        "Electric Vehicles",
        "Public Transit",
        "Climate Change",
        "Housing",
        "Transportation Systems",
        "Cybersecurity",
        "Pollution Control",
        "Marketing",
        "Water Quality",
        "Traffic Management",
        "Healthcare",
        "Tourism",
        "Finance",
        "Bicycle",
        "Waste Management"
      ],
      "scores": [
        0.5808879137039185,
        0.015489406883716583,
        0.014485472813248634,
        0.008476902730762959,
        0.004839146975427866,
        0.0043225460685789585,
        0.002772334963083267,
        0.002559969900175929,
        0.0021509418729692698,
        0.0021003014408051968,
        0.002017994411289692,
        0.001415339531376958,
        0.0013464507646858692,
        0.0012250259751453996,
        0.0009484737529419363,
        0.000875897821970284,
        0.0007674642838537693,
        0.0006166936946101487,
        0.0005818054778501391,
        0.0005817915662191808,
        0.0005720679182559252,
        0.0005664516938850284,
        0.000515369581989944,
        0.0005152978119440377,
        0.0004963945830240846,
        0.0004944513784721494,
        0.0004930332652293146,
        0.0004752535023726523,
        0.000470703758765012,
        0.00046563916839659214,
        0.00044071662705391645,
        0.000440710224211216,
        0.0004387908265925944,
        0.00043525462388060987,
        0.00043355542584322393,
        0.0004302969900891185,
        0.00041351767140440643,
        0.0003772967029362917,
        0.0003663978131953627,
        0.0003648793790489435,
        0.00036477664252743125,
        0.0003513903066050261,
        0.0003439886204432696,
        0.00033336892374791205,
        0.00032900398946367204,
        0.00032550853211432695,
        0.00032075901981443167,
        0.00031380352447740734,
        0.0003121090412605554
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Governance",
        "score": 0.5808879137039185
      }
    ]
  },
  {
    "abstract": "Highlights: What are the main findings? Smart Cities as Hyper-Connected Digital Environments generate large and diverse data streams and repositories that do not consistently translate into insights and decisions. A Responsible AI Hyper-Automation framework with Generative AI agents is developed and evaluated to address these complex challenges. What are the implications of the main findings? The developed AI framework is effective when grounded on five core technical capabilities with an independent cognitive engine for hyper-automated agentic AI that feeds into human-in-the-loop processes. The framework provides a prototypical setting for university cities of the future to provide direction, guidance, and standards for sustainable and safe smart cities of the future. Smart cities are Hyper-Connected Digital Environments (HCDEs) that transcend the boundaries of natural, human-made, social, virtual, and artificial environments. Human activities are no longer confined to a single environment as our presence and interactions are represented and interconnected across HCDEs. The data streams and repositories of HCDEs provide opportunities for the responsible application of Artificial Intelligence (AI) that generates unique insights into the constituent environments and the interplay across constituents. The translation of data into insights poses several complex challenges originating in data generation and then propagating through the computational layers to decision outcomes. To address these challenges, this article presents the design and development of a Hyper-Automated AI framework with Generative AI agents for sustainable smart cities. The framework is empirically evaluated in the living lab setting of a â€˜University City of the Futureâ€™. The developed AI framework is grounded on the core capabilities of acquisition, preparation, orchestration, dissemination, and retrospection, with an independent cognitive engine for hyper-automation of these AI capabilities using Generative AI. Hyper-automation output feeds into a human-in-the-loop process prior to decision-making outcomes. More broadly, this framework aims to provide a validated pathway for university cities of the future to take up the role of prototypes that deliver evidence-based guidelines for the development and management of sustainable smart cities.",
    "doi": "10.3390/smartcities8010034",
    "author_keywords": [
      "artificial intelligence",
      "generative AI",
      "hyper-automation",
      "smart cities",
      "university city of the future"
    ],
    "contribution": "To address these challenges, this article presents the design and development of a Hyper-Automated AI framework with Generative AI agents for sustainable smart cities. The framework is empirically evaluated in the living lab setting of a â€˜University City of the Futureâ€™. The developed AI framework is grounded on the core capabilities of acquisition, preparation, orchestration, dissemination, and retrospection, with an independent cognitive engine for hyper-automation of these AI capabilities using Generative AI. Hyper-automation output feeds into a human-in-the-loop process prior to decision-making outcomes. More broadly, this framework aims to provide a validated pathway for university cities of the future to take up the role of prototypes that deliver evidence-based guidelines for the development and management of sustainable smart cities.",
    "introduction": "Highlights: What are the main findings? Smart Cities as Hyper-Connected Digital Environments generate large and diverse data streams and repositories that do not consistently translate into insights and decisions. A Responsible AI Hyper-Automation framework with Generative AI agents is developed and evaluated to address these complex challenges. What are the implications of the main findings? The developed AI framework is effective when grounded on five core technical capabilities with an independent cognitive engine for hyper-automated agentic AI that feeds into human-in-the-loop processes. The framework provides a prototypical setting for university cities of the future to provide direction, guidance, and standards for sustainable and safe smart cities of the future. Smart cities are Hyper-Connected Digital Environments (HCDEs) that transcend the boundaries of natural, human-made, social, virtual, and artificial environments. Human activities are no longer confined to a single environment as our presence and interactions are represented and interconnected across HCDEs. The data streams and repositories of HCDEs provide opportunities for the responsible application of Artificial Intelligence (AI) that generates unique insights into the constituent environments and the interplay across constituents. The translation of data into insights poses several complex challenges originating in data generation and then propagating through the computational layers to decision outcomes.",
    "classification_result": {
      "labels": [
        "Public Services",
        "Environment",
        "Public Policies",
        "Urban Planning",
        "Business",
        "Governance",
        "Industry",
        "Learning and Teaching",
        "Innovation Policy",
        "Living",
        "Economic Management",
        "Socioeconomics",
        "People",
        "Citizen Engagement",
        "Economy",
        "Buildings",
        "Social Equity",
        "Multimodal Transport",
        "Energy Management",
        "Lightning",
        "Resource Conservation",
        "Citizens",
        "Water Quality",
        "Air Quality",
        "Emergency Safety",
        "Power Distribution",
        "Traffic Management",
        "Mobility",
        "Housing",
        "Cybersecurity",
        "Logistics",
        "Education",
        "Pedestrian",
        "Marketing",
        "Public Transit",
        "Renewable Energy",
        "Culture",
        "Pollution Control",
        "Transportation Systems",
        "Sustainability",
        "Waste Management",
        "Electric Vehicles",
        "Climate Change",
        "Smart Grids",
        "Green Spaces",
        "Tourism",
        "Bicycle",
        "Finance",
        "Healthcare"
      ],
      "scores": [
        0.03261012211441994,
        0.0260740015655756,
        0.016539189964532852,
        0.014663158915936947,
        0.007038810756057501,
        0.005032319575548172,
        0.0037006190977990627,
        0.0036145257763564587,
        0.003333834931254387,
        0.0025619983207434416,
        0.0023352429270744324,
        0.0019211634062230587,
        0.0018330567982047796,
        0.0017666546627879143,
        0.0015531423268839717,
        0.001497749355621636,
        0.0014408485731109977,
        0.0010707725305110216,
        0.001048397389240563,
        0.0010461818892508745,
        0.0010459007462486625,
        0.0009196320897899568,
        0.0008922694833017886,
        0.0008901728433556855,
        0.00086903793271631,
        0.0007853783899918199,
        0.0007319314172491431,
        0.0007288718479685485,
        0.0007080404320731759,
        0.0006929044029675424,
        0.000690835586283356,
        0.0006812206702306867,
        0.0006701273960061371,
        0.0006361734704114497,
        0.0006105966749601066,
        0.0005956419045105577,
        0.0005713373539038002,
        0.0005701239570043981,
        0.0005672986735589802,
        0.0005638368311338127,
        0.0005584876635111868,
        0.0005497590755112469,
        0.0005463752895593643,
        0.0005347657133825123,
        0.0004970754962414503,
        0.000485574419144541,
        0.00047137061483226717,
        0.0004581164103001356,
        0.0004124810511711985
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "With the trends of technology convergence and technology interdisciplinarity, technology-field (TF) resolution and classification of patents have gradually been challenged. Whether for patent applicants or for patent examiners, more precisely labeling the TF for a certain patent is important for technological searches. However, determining the TF of a patent may be difficult and may even involve the strategic behavior of patenting, which can cause noise in patent classification systems (PCSs). In addition, some specific patents could contain more TFs than claimed or be assigned questionable IPC codes; subsequently, in a regular search for technology/patents, information could be missed. Considering the advantages of deep learning compared with traditional machine learning algorithms in areas such as natural language processing (NLP), text classification and text sentiment analysis, this paper investigates several popular deep learning models and proposes a large-scale multilabel regression (MLR) model to handle specific patent analyses under situations of small sample learning. To verify the proposed MLR model for patent classification, the case study on smart cities and industrial Internet of Things (IIoT) is conducted. The MLR experiments on the TF resolution of smart cities and IIoT have yielded moderate results compared with those of the latest patent classification studies, which also rely on deep learning and the large language models (LLMs), which include RCNN, Bi-LSTM, BERT and GPT-4 etc. Therefore, the proposed MLR model with a customized loss function could be moderately effective for patent classification within a specific technology theme, could have implications for patent classification and the TF resolution of patents, and could further enrich methodologies for patent mining and informetrics based on artificial intelligence (AI).",
    "doi": "10.1016/j.joi.2024.101616",
    "author_keywords": [
      "Deep learning",
      "GPT-4",
      "Industrial Internet of Things",
      "Loss function",
      "Patent classification",
      "Semantic analysis",
      "Smart cities",
      "Technology-field resolution"
    ],
    "contribution": "Considering the advantages of deep learning compared with traditional machine learning algorithms in areas such as natural language processing (NLP), text classification and text sentiment analysis, this paper investigates several popular deep learning models and proposes a large-scale multilabel regression (MLR) model to handle specific patent analyses under situations of small sample learning. To verify the proposed MLR model for patent classification, the case study on smart cities and industrial Internet of Things (IIoT) is conducted. The MLR experiments on the TF resolution of smart cities and IIoT have yielded moderate results compared with those of the latest patent classification studies, which also rely on deep learning and the large language models (LLMs), which include RCNN, Bi-LSTM, BERT and GPT-4 etc. Therefore, the proposed MLR model with a customized loss function could be moderately effective for patent classification within a specific technology theme, could have implications for patent classification and the TF resolution of patents, and could further enrich methodologies for patent mining and informetrics based on artificial intelligence (AI).",
    "introduction": "With the trends of technology convergence and technology interdisciplinarity, technology-field (TF) resolution and classification of patents have gradually been challenged. Whether for patent applicants or for patent examiners, more precisely labeling the TF for a certain patent is important for technological searches. However, determining the TF of a patent may be difficult and may even involve the strategic behavior of patenting, which can cause noise in patent classification systems (PCSs). In addition, some specific patents could contain more TFs than claimed or be assigned questionable IPC codes; subsequently, in a regular search for technology/patents, information could be missed.",
    "classification_result": {
      "labels": [
        "Industry",
        "Electric Vehicles",
        "Renewable Energy",
        "Cybersecurity",
        "Power Distribution",
        "Smart Grids",
        "Energy Management",
        "Multimodal Transport",
        "Transportation Systems",
        "Innovation Policy",
        "Business",
        "Emergency Safety",
        "Lightning",
        "Public Transit",
        "Air Quality",
        "Pollution Control",
        "Learning and Teaching",
        "Mobility",
        "Sustainability",
        "Water Quality",
        "Public Policies",
        "Climate Change",
        "Resource Conservation",
        "Pedestrian",
        "Bicycle",
        "Green Spaces",
        "Environment",
        "Governance",
        "Public Services",
        "Waste Management",
        "Economy",
        "Buildings",
        "Citizens",
        "Housing",
        "Urban Planning",
        "People",
        "Education",
        "Socioeconomics",
        "Economic Management",
        "Social Equity",
        "Healthcare",
        "Logistics",
        "Citizen Engagement",
        "Traffic Management",
        "Living",
        "Tourism",
        "Finance",
        "Culture",
        "Marketing"
      ],
      "scores": [
        0.06157323345541954,
        0.01941153220832348,
        0.019258903339505196,
        0.01221739687025547,
        0.010031421668827534,
        0.009804373607039452,
        0.008616216480731964,
        0.007080880459398031,
        0.004167670849710703,
        0.003953265491873026,
        0.0031586503610014915,
        0.0028462910559028387,
        0.0026362722273916006,
        0.0018006470054388046,
        0.0017327953828498721,
        0.001479045138694346,
        0.0013102631783112884,
        0.001310143736191094,
        0.0012480104342103004,
        0.0011915006907656789,
        0.0011151297949254513,
        0.0010260868584737182,
        0.001009420957416296,
        0.0009508287766948342,
        0.0009038015850819647,
        0.0008755020680837333,
        0.0008578953566029668,
        0.00084688700735569,
        0.000732222746592015,
        0.0007172455079853535,
        0.0007080904324539006,
        0.0006228711572475731,
        0.0006138005992397666,
        0.0005673504201695323,
        0.0005310687120072544,
        0.0005117045948281884,
        0.0005112430662848055,
        0.0005085442680865526,
        0.0005058549577370286,
        0.0005023946869187057,
        0.0004901594365946949,
        0.00048799708019942045,
        0.0004773864638991654,
        0.00047610964975319803,
        0.0004603147099260241,
        0.00044248843914829195,
        0.0004142516409046948,
        0.0004061155195813626,
        0.00038802402559667826
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "Trajectory prediction of surrounding traffic participants is vital for the driving safety of Intelligent Connected Vehicles (ICVs). It has been enabled with the help of the availability of multi-sensor information collected by ICVs. For accurately predicting the future movements of traffic agents, it is crucial to subtlety model the inter-agent interaction. However, existing works focus on the correlations between agents and the map information while neglecting the importance of directly modeling the impact of map elements on inter-agent interactions, the direct modeling of which is beneficial for the representation of agent behaviors. Against this background, we propose to model the hyper-relational interaction, which incorporates map elements into the inter-agent interaction. To tackle the hyper-relational interaction, we propose a novel Hyper-relational Multi-modal Trajectory Prediction (HyperMTP) approach. Specifically, a hyper-relational driving graph is first constructed and the hyper-relational interaction is represented as the hyperedge, directly connecting to various nodes (i.e., agents and map elements). Then a structure-aware embedding initialization technique is developed to obtain unbiased initial embeddings. Afterward, hypergraph dual-attention networks are designed to capture correlations between graph elements while retaining the hyper-relational structure. Finally, a heterogeneous Transformer is devised to further capture the correlations between agentsâ€™ states and their corresponding hyper-relational interactions. Experimental results show that HyperMTP consistently outperforms the best-performing baseline with an average improvement of 4.8% across two real-world datasets. Moreover, HyperMTP also boosts the interpretability of trajectory prediction by quantifying the impact of map elements on inter-agent interactions.",
    "doi": "10.1016/j.inffus.2024.102682",
    "author_keywords": [
      "Hypergraph attention networks",
      "Intelligent connected vehicles",
      "Interaction modeling",
      "Multi-modal trajectory prediction"
    ],
    "contribution": "Against this background, we propose to model the hyper-relational interaction, which incorporates map elements into the inter-agent interaction. To tackle the hyper-relational interaction, we propose a novel Hyper-relational Multi-modal Trajectory Prediction (HyperMTP) approach. Specifically, a hyper-relational driving graph is first constructed and the hyper-relational interaction is represented as the hyperedge, directly connecting to various nodes (i.e., agents and map elements). Then a structure-aware embedding initialization technique is developed to obtain unbiased initial embeddings. Afterward, hypergraph dual-attention networks are designed to capture correlations between graph elements while retaining the hyper-relational structure. Finally, a heterogeneous Transformer is devised to further capture the correlations between agentsâ€™ states and their corresponding hyper-relational interactions. Experimental results show that HyperMTP consistently outperforms the best-performing baseline with an average improvement of 4.8% across two real-world datasets. Moreover, HyperMTP also boosts the interpretability of trajectory prediction by quantifying the impact of map elements on inter-agent interactions.",
    "introduction": "Trajectory prediction of surrounding traffic participants is vital for the driving safety of Intelligent Connected Vehicles (ICVs). It has been enabled with the help of the availability of multi-sensor information collected by ICVs. For accurately predicting the future movements of traffic agents, it is crucial to subtlety model the inter-agent interaction. However, existing works focus on the correlations between agents and the map information while neglecting the importance of directly modeling the impact of map elements on inter-agent interactions, the direct modeling of which is beneficial for the representation of agent behaviors.",
    "classification_result": {
      "labels": [
        "Transportation Systems",
        "Mobility",
        "Traffic Management",
        "Industry",
        "Logistics",
        "Environment",
        "Multimodal Transport",
        "Business",
        "Public Services",
        "Electric Vehicles",
        "Emergency Safety",
        "Innovation Policy",
        "Learning and Teaching",
        "Economic Management",
        "Citizens",
        "Urban Planning",
        "Living",
        "People",
        "Economy",
        "Socioeconomics",
        "Smart Grids",
        "Public Policies",
        "Resource Conservation",
        "Power Distribution",
        "Energy Management",
        "Cybersecurity",
        "Green Spaces",
        "Governance",
        "Education",
        "Renewable Energy",
        "Lightning",
        "Social Equity",
        "Citizen Engagement",
        "Bicycle",
        "Waste Management",
        "Public Transit",
        "Sustainability",
        "Climate Change",
        "Marketing",
        "Pedestrian",
        "Tourism",
        "Buildings",
        "Finance",
        "Pollution Control",
        "Water Quality",
        "Healthcare",
        "Air Quality",
        "Housing",
        "Culture"
      ],
      "scores": [
        0.978158175945282,
        0.9718919992446899,
        0.928299069404602,
        0.11613970249891281,
        0.10812007635831833,
        0.0622309073805809,
        0.021826937794685364,
        0.019504141062498093,
        0.014845401979982853,
        0.005398964509367943,
        0.003232327988371253,
        0.002523622242733836,
        0.0018600354669615626,
        0.001729649375192821,
        0.0014617455890402198,
        0.0013772007077932358,
        0.0013718392001464963,
        0.0013477880274876952,
        0.0010935140307992697,
        0.001030390034429729,
        0.0009160251938737929,
        0.0009045329061336815,
        0.0008035882492549717,
        0.0006896683480590582,
        0.000683448975905776,
        0.0006597884348593652,
        0.0006471275701187551,
        0.000626870896667242,
        0.0005948069738224149,
        0.0005878118681721389,
        0.0005720867193304002,
        0.0005340383504517376,
        0.0005319995689205825,
        0.0005289452383294702,
        0.0005048811435699463,
        0.000499213463626802,
        0.000497116707265377,
        0.0004949753638356924,
        0.0004832337435800582,
        0.0004826434305869043,
        0.00047196977538987994,
        0.00045857048826292157,
        0.0004461981588974595,
        0.0004273296217434108,
        0.00042151971138082445,
        0.00041432472062297165,
        0.0003968103264924139,
        0.0003873672103509307,
        0.000372821930795908
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Mobility",
        "score": 0.978158175945282
      }
    ]
  },
  {
    "abstract": "The infrared and visible fusion technology holds a pivotal position in smart city for cloud and fog computing, particularly in security system. By fusing infrared and visible image information, this technology enhances target identification, tracking and monitoring precision, bolstering overall system security. However, existing deep learning-based methods rely heavily on convolutional operations, which excel at extracting local features but have limited receptive fields, hampering global information capture. To overcome this difficulty, we introduce GRDATFusion, a novel end-to-end network comprising three key modules: transformer, gradient residual dense and attention residual. The gradient residual dense module extracts local complementary features, leveraging a dense-shaped network to retain potentially lost information. The attention residual module focuses on crucial input image details, while the transformer module captures global information and models long-range dependencies. Experiments on public datasets show that GRDATFusion outperforms state-of-the-art algorithms in qualitative and quantitative assessments. Ablation studies validate our approach's advantages, and efficiency comparisons demonstrate its computational efficiency. Therefore, our method makes the security systems in smart city with shorter delay and satisfies the real-time requirement.",
    "doi": "10.1111/exsy.13685",
    "author_keywords": [
      "AI",
      "cloud and fog computing",
      "image fusion",
      "security system",
      "transformer"
    ],
    "contribution": "To overcome this difficulty, we introduce GRDATFusion, a novel end-to-end network comprising three key modules: transformer, gradient residual dense and attention residual. The gradient residual dense module extracts local complementary features, leveraging a dense-shaped network to retain potentially lost information. The attention residual module focuses on crucial input image details, while the transformer module captures global information and models long-range dependencies. Experiments on public datasets show that GRDATFusion outperforms state-of-the-art algorithms in qualitative and quantitative assessments. Ablation studies validate our approach's advantages, and efficiency comparisons demonstrate its computational efficiency. Therefore, our method makes the security systems in smart city with shorter delay and satisfies the real-time requirement.",
    "introduction": "The infrared and visible fusion technology holds a pivotal position in smart city for cloud and fog computing, particularly in security system. By fusing infrared and visible image information, this technology enhances target identification, tracking and monitoring precision, bolstering overall system security. However, existing deep learning-based methods rely heavily on convolutional operations, which excel at extracting local features but have limited receptive fields, hampering global information capture.",
    "classification_result": {
      "labels": [
        "Industry",
        "Environment",
        "Cybersecurity",
        "Business",
        "Buildings",
        "Public Services",
        "Innovation Policy",
        "Urban Planning",
        "Multimodal Transport",
        "People",
        "Learning and Teaching",
        "Smart Grids",
        "Citizens",
        "Mobility",
        "Living",
        "Economy",
        "Economic Management",
        "Public Policies",
        "Lightning",
        "Air Quality",
        "Socioeconomics",
        "Emergency Safety",
        "Governance",
        "Pedestrian",
        "Sustainability",
        "Resource Conservation",
        "Electric Vehicles",
        "Transportation Systems",
        "Public Transit",
        "Power Distribution",
        "Social Equity",
        "Education",
        "Water Quality",
        "Climate Change",
        "Green Spaces",
        "Citizen Engagement",
        "Finance",
        "Renewable Energy",
        "Marketing",
        "Housing",
        "Energy Management",
        "Culture",
        "Pollution Control",
        "Healthcare",
        "Logistics",
        "Traffic Management",
        "Bicycle",
        "Tourism",
        "Waste Management"
      ],
      "scores": [
        0.568086564540863,
        0.20828787982463837,
        0.0846685990691185,
        0.060346346348524094,
        0.009906401857733727,
        0.004397729877382517,
        0.004217348527163267,
        0.001916861510835588,
        0.0019123791716992855,
        0.0014397145714610815,
        0.0013739465503022075,
        0.0011222036555409431,
        0.0008894221391528845,
        0.0008315184968523681,
        0.0006646489491686225,
        0.0005669204983860254,
        0.000548897369299084,
        0.0005404698895290494,
        0.0005289436667226255,
        0.0005235483404248953,
        0.0005019481759518385,
        0.0004902366199530661,
        0.00044723067549057305,
        0.00042589358054101467,
        0.0004242786963004619,
        0.0004229599144309759,
        0.000420242955442518,
        0.00040957951568998396,
        0.000403164274757728,
        0.0003990208497270942,
        0.000392801477573812,
        0.00039232042036019266,
        0.00038356619188562036,
        0.00038239231798797846,
        0.0003817611141130328,
        0.0003790785267483443,
        0.00037660234374925494,
        0.0003759979736059904,
        0.0003718469524756074,
        0.0003708371368702501,
        0.00035614639637060463,
        0.00035536399809643626,
        0.0003528123488649726,
        0.00035233100061304867,
        0.00035049530561082065,
        0.0003361520357429981,
        0.00031983572989702225,
        0.0003122139605693519,
        0.000289163610432297
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Economy",
        "score": 0.568086564540863
      }
    ]
  },
  {
    "abstract": "The development of vehicle re-identification technology has significantly enhanced the operational efficiency of intelligent transportation systems and smart cities, attributed to the advancement of artificial intelligence technologies such as deep learning and transformer models. By accurately tracking and identifying the same vehicle under different cameras, the technology not only greatly enhances the ability of urban safety monitoring, traffic management and accident investigation, but also provides powerful technical support for the development of intelligent transportation. This paper explores the shift from traditional to deep learning approaches in vehicle re-identification, highlighting the rise of Transformer models. We assess both non-visual and vision-based re-identification technologies, with a special focus on the deep feature-based methods across supervised, unsupervised, and semi-supervised learning. And we summarize the performance of supervised and unsupervised methods on the VeRi-776 and VehicleID datasets. Finally, this paper outlines six directions for the future development of vehicle Re-ID technology, highlighting its potential applications in various areas such as smart city traffic management.",
    "doi": "10.1016/j.neucom.2024.128745",
    "author_keywords": [
      "Semi-supervised learning",
      "Supervised learning",
      "Transformer",
      "Unsupervised learning",
      "Vehicle re-identification"
    ],
    "contribution": "This paper explores the shift from traditional to deep learning approaches in vehicle re-identification, highlighting the rise of Transformer models. We assess both non-visual and vision-based re-identification technologies, with a special focus on the deep feature-based methods across supervised, unsupervised, and semi-supervised learning. And we summarize the performance of supervised and unsupervised methods on the VeRi-776 and VehicleID datasets. Finally, this paper outlines six directions for the future development of vehicle Re-ID technology, highlighting its potential applications in various areas such as smart city traffic management.",
    "introduction": "The development of vehicle re-identification technology has significantly enhanced the operational efficiency of intelligent transportation systems and smart cities, attributed to the advancement of artificial intelligence technologies such as deep learning and transformer models. By accurately tracking and identifying the same vehicle under different cameras, the technology not only greatly enhances the ability of urban safety monitoring, traffic management and accident investigation, but also provides powerful technical support for the development of intelligent transportation.",
    "classification_result": {
      "labels": [
        "Transportation Systems",
        "Mobility",
        "Industry",
        "Traffic Management",
        "Public Services",
        "Logistics",
        "Business",
        "Multimodal Transport",
        "Public Transit",
        "Innovation Policy",
        "Environment",
        "Economy",
        "Urban Planning",
        "Emergency Safety",
        "Economic Management",
        "Citizens",
        "Living",
        "Cybersecurity",
        "Electric Vehicles",
        "Governance",
        "Public Policies",
        "Socioeconomics",
        "Lightning",
        "People",
        "Learning and Teaching",
        "Power Distribution",
        "Finance",
        "Sustainability",
        "Marketing",
        "Education",
        "Pollution Control",
        "Air Quality",
        "Resource Conservation",
        "Climate Change",
        "Citizen Engagement",
        "Energy Management",
        "Renewable Energy",
        "Tourism",
        "Green Spaces",
        "Social Equity",
        "Water Quality",
        "Culture",
        "Smart Grids",
        "Healthcare",
        "Buildings",
        "Waste Management",
        "Bicycle",
        "Pedestrian",
        "Housing"
      ],
      "scores": [
        0.9729651808738708,
        0.9215849041938782,
        0.24649207293987274,
        0.19126686453819275,
        0.1468200534582138,
        0.1338457316160202,
        0.12374341487884521,
        0.1037835031747818,
        0.08190570026636124,
        0.04153035208582878,
        0.013800950720906258,
        0.013191497884690762,
        0.011768952943384647,
        0.011005548760294914,
        0.007968496531248093,
        0.004423476289957762,
        0.00353951845318079,
        0.003102374728769064,
        0.002528232056647539,
        0.0019797529093921185,
        0.001936606247909367,
        0.001823202706873417,
        0.001723023015074432,
        0.0015426742611452937,
        0.0013818208826705813,
        0.0008370751165784895,
        0.0008194693364202976,
        0.00064552464755252,
        0.0005671082180924714,
        0.0005350520368665457,
        0.0005079258698970079,
        0.0005052325432188809,
        0.00048817857168614864,
        0.00048609808436594903,
        0.0004642641288228333,
        0.00045862243860028684,
        0.0004564200935419649,
        0.0004351267998572439,
        0.00042562521412037313,
        0.0004143949190620333,
        0.00040862776222638786,
        0.00040676083881407976,
        0.0004065017856191844,
        0.00039384554838761687,
        0.00038357885205186903,
        0.00037090765545144677,
        0.0003281434183008969,
        0.0003161672502756119,
        0.0003135681909043342
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Mobility",
        "score": 0.9729651808738708
      }
    ]
  },
  {
    "abstract": "Forecasting pedestrian trajectory is a vital area of research in smart urban mobility, which can be applied to intelligent transportation and intelligent surveillance. Current approaches employ conditional variational autoencoders to model future trajectory multimodality. However, these methods generate multi-modal trajectories for one single destination, ignoring the trajectory multimodality caused by the uncertainty of the pedestriansâ€™ destination intention. Besides, they can lead to mode collapse and training instability. To address this issue, we propose a novel destination intention estimation-based convolutional encoder-decoder framework for multimodal trajectory forecast. Specially, we design a destination intention estimator to forecast pedestrian future destination intentions at the last time step. Then, we devise a trajectory decoder module to forecast pedestrian trajectories at each time step with the assistance of the destination intentions. To evaluate our method, we perform experiments on publicly available benchmark datasets and demonstrate that our proposed method achieves the superior results compared with state-of-the-art approaches.",
    "doi": "10.1016/j.measurement.2024.115470",
    "author_keywords": [
      "Encoder-decoder",
      "Graph convolution",
      "Smart urban mobility",
      "Social interactions",
      "Trajectory multimodality"
    ],
    "contribution": "To address this issue, we propose a novel destination intention estimation-based convolutional encoder-decoder framework for multimodal trajectory forecast. Specially, we design a destination intention estimator to forecast pedestrian future destination intentions at the last time step. Then, we devise a trajectory decoder module to forecast pedestrian trajectories at each time step with the assistance of the destination intentions. To evaluate our method, we perform experiments on publicly available benchmark datasets and demonstrate that our proposed method achieves the superior results compared with state-of-the-art approaches.",
    "introduction": "Forecasting pedestrian trajectory is a vital area of research in smart urban mobility, which can be applied to intelligent transportation and intelligent surveillance. Current approaches employ conditional variational autoencoders to model future trajectory multimodality. However, these methods generate multi-modal trajectories for one single destination, ignoring the trajectory multimodality caused by the uncertainty of the pedestriansâ€™ destination intention. Besides, they can lead to mode collapse and training instability.",
    "classification_result": {
      "labels": [
        "Mobility",
        "Pedestrian",
        "Multimodal Transport",
        "Transportation Systems",
        "People",
        "Logistics",
        "Public Services",
        "Traffic Management",
        "Urban Planning",
        "Citizens",
        "Living",
        "Socioeconomics",
        "Public Transit",
        "Environment",
        "Public Policies",
        "Industry",
        "Business",
        "Economic Management",
        "Learning and Teaching",
        "Emergency Safety",
        "Economy",
        "Sustainability",
        "Resource Conservation",
        "Innovation Policy",
        "Governance",
        "Citizen Engagement",
        "Social Equity",
        "Smart Grids",
        "Green Spaces",
        "Energy Management",
        "Education",
        "Renewable Energy",
        "Lightning",
        "Electric Vehicles",
        "Climate Change",
        "Power Distribution",
        "Tourism",
        "Bicycle",
        "Marketing",
        "Finance",
        "Healthcare",
        "Cybersecurity",
        "Culture",
        "Buildings",
        "Water Quality",
        "Air Quality",
        "Pollution Control",
        "Waste Management",
        "Housing"
      ],
      "scores": [
        0.9937613010406494,
        0.9481187462806702,
        0.9367223381996155,
        0.926423192024231,
        0.26409849524497986,
        0.020261259749531746,
        0.010328932665288448,
        0.009692512452602386,
        0.005900305230170488,
        0.005631610751152039,
        0.00476357014849782,
        0.004309577867388725,
        0.002879267791286111,
        0.001809969311580062,
        0.0017378992633894086,
        0.0017157112015411258,
        0.0015850095078349113,
        0.0010055735474452376,
        0.0006993034621700644,
        0.0006082400213927031,
        0.0005493153003044426,
        0.0005398125504143536,
        0.0005138503038324416,
        0.0005129722994752228,
        0.0004947624984197319,
        0.0004692772636190057,
        0.00046322730486281216,
        0.0004251852515153587,
        0.0004247303877491504,
        0.0004237827379256487,
        0.000419548072386533,
        0.0003915721899829805,
        0.0003906455240212381,
        0.0003892281965818256,
        0.00038585884612984955,
        0.0003836196265183389,
        0.00037325196899473667,
        0.00037082945345900953,
        0.0003682142705656588,
        0.00036233814898878336,
        0.00036162303877063096,
        0.00035781963379122317,
        0.0003539466124493629,
        0.00035217386903241277,
        0.00034049691748805344,
        0.0003326126025058329,
        0.00033012035419233143,
        0.0003284314298070967,
        0.0003113621787633747
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Mobility",
        "score": 0.9937613010406494
      }
    ]
  },
  {
    "abstract": "Building type information indicates the functional properties of buildings and plays a crucial role in smart city development and urban socioeconomic activities. Existing methods for classifying building types often face challenges in accurately distinguishing buildings between types while maintaining well-delineated boundaries, especially in complex urban environments. This study introduces a novel framework, i.e., CNN-Transformer cross-attention feature fusion network (CTCFNet), for building type classification from very high resolution remote sensing images. CTCFNet integrates convolutional neural networks (CNNs) and Transformers using an interactive cross-encoder fusion module that enhances semantic feature learning and improves classification accuracy in complex scenarios. We develop an adaptive collaboration optimization module that applies human visual attention mechanisms to enhance the feature representation of building types and boundaries simultaneously. To address the scarcity of datasets in building type classification, we create two new datasets, i.e., the urban building type (UBT) dataset and the town building type (TBT) dataset, for model evaluation. Extensive experiments on these datasets demonstrate that CTCFNet outperforms popular CNNs, Transformers, and dual-encoder methods in identifying building types across various regions, achieving the highest mean intersection over union of 78.20% and 77.11%, F1 scores of 86.83% and 88.22%, and overall accuracy of 95.07% and 95.73% on the UBT and TBT datasets, respectively. We conclude that CTCFNet effectively addresses the challenges of high interclass similarity and intraclass inconsistency in complex scenes, yielding results with well-delineated building boundaries and accurate building types.",
    "doi": "10.1109/JSTARS.2024.3501678",
    "author_keywords": [
      "Building type classification",
      "CNN-transformer networks",
      "cross-encoder",
      "feature interaction",
      "very high resolution remote sensing"
    ],
    "contribution": "This study introduces a novel framework, i.e., CNN-Transformer cross-attention feature fusion network (CTCFNet), for building type classification from very high resolution remote sensing images. CTCFNet integrates convolutional neural networks (CNNs) and Transformers using an interactive cross-encoder fusion module that enhances semantic feature learning and improves classification accuracy in complex scenarios. We develop an adaptive collaboration optimization module that applies human visual attention mechanisms to enhance the feature representation of building types and boundaries simultaneously. To address the scarcity of datasets in building type classification, we create two new datasets, i.e., the urban building type (UBT) dataset and the town building type (TBT) dataset, for model evaluation. Extensive experiments on these datasets demonstrate that CTCFNet outperforms popular CNNs, Transformers, and dual-encoder methods in identifying building types across various regions, achieving the highest mean intersection over union of 78.20% and 77.11%, F1 scores of 86.83% and 88.22%, and overall accuracy of 95.07% and 95.73% on the UBT and TBT datasets, respectively. We conclude that CTCFNet effectively addresses the challenges of high interclass similarity and intraclass inconsistency in complex scenes, yielding results with well-delineated building boundaries and accurate building types.",
    "introduction": "Building type information indicates the functional properties of buildings and plays a crucial role in smart city development and urban socioeconomic activities. Existing methods for classifying building types often face challenges in accurately distinguishing buildings between types while maintaining well-delineated boundaries, especially in complex urban environments.",
    "classification_result": {
      "labels": [
        "Buildings",
        "Urban Planning",
        "Housing",
        "Environment",
        "Socioeconomics",
        "Business",
        "Economic Management",
        "Public Services",
        "Governance",
        "Public Policies",
        "Economy",
        "Learning and Teaching",
        "Living",
        "Logistics",
        "Power Distribution",
        "Industry",
        "Education",
        "Innovation Policy",
        "Resource Conservation",
        "Emergency Safety",
        "Sustainability",
        "Electric Vehicles",
        "Multimodal Transport",
        "Climate Change",
        "Energy Management",
        "Mobility",
        "Smart Grids",
        "Finance",
        "Renewable Energy",
        "Green Spaces",
        "Healthcare",
        "Citizens",
        "Lightning",
        "Waste Management",
        "Cybersecurity",
        "Tourism",
        "People",
        "Public Transit",
        "Culture",
        "Citizen Engagement",
        "Transportation Systems",
        "Air Quality",
        "Marketing",
        "Pollution Control",
        "Water Quality",
        "Social Equity",
        "Bicycle",
        "Pedestrian",
        "Traffic Management"
      ],
      "scores": [
        0.9996594190597534,
        0.7882084250450134,
        0.764795184135437,
        0.390646368265152,
        0.014640217646956444,
        0.004772151354700327,
        0.002011680044233799,
        0.0014132849173620343,
        0.0012596300803124905,
        0.0009702715906314552,
        0.0008766294340603054,
        0.0008462935220450163,
        0.0007598506635986269,
        0.0007215949590317905,
        0.0006343477871268988,
        0.0006266443524509668,
        0.0005910674808546901,
        0.0005900351679883897,
        0.0005450365715660155,
        0.0005357486079446971,
        0.0005266083171591163,
        0.0005239341990090907,
        0.0005129693308845162,
        0.0005108205368742347,
        0.0005015237256884575,
        0.00047538382932543755,
        0.0004646051675081253,
        0.0004578901862259954,
        0.0004482731455937028,
        0.00044300121953710914,
        0.00043365490273572505,
        0.00043235605699010193,
        0.00043115022708661854,
        0.000427514809416607,
        0.00041538028744980693,
        0.00041505484841763973,
        0.00041006391984410584,
        0.00040977358003146946,
        0.00040309992618858814,
        0.0004013935977127403,
        0.00039066115277819335,
        0.00038585043512284756,
        0.00037765977322123945,
        0.0003774672222789377,
        0.00035807667882181704,
        0.00035712134558707476,
        0.00035464786924421787,
        0.0003413013182580471,
        0.0003321759286336601
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Living",
        "score": 0.9996594190597534
      },
      {
        "domain": "Smart Governance",
        "score": 0.7882084250450134
      }
    ]
  },
  {
    "abstract": "Fire detection has held stringent importance in computer vision for over half a century. The development of early fire detection strategies is pivotal to the realization of safe and smart cities, inhabitable in the future. However, the development of optimal fire and smoke detection models is hindered by limitations like publicly available datasets, lack of diversity, and class imbalance. In this work, we explore the possible ways forward to overcome these challenges posed by available datasets. We study the impact of a class-balanced dataset to improve the fire detection capability of state-of-the-art (SOTA) vision-based models and propose the use of generative models for data augmentation, as a future work direction. First, a comparative analysis of two prominent object detection architectures, You Only Look Once version 7 (YOLOv7) and YOLOv8 has been carried out using a balanced dataset, where both models have been evaluated across various evaluation metrics including precision, recall, and mean Average Precision (mAP). The results are compared to other recent fire detection models, highlighting the superior performance and efficiency of the proposed YOLOv8 architecture as trained on our balanced dataset. Next, a fractal dimension analysis gives a deeper insight into the repetition of patterns in fire, and the effectiveness of the results has been demonstrated by a windowing-based inference approach. The proposed Slicing-Aided Hyper Inference (SAHI) improves the fire and smoke detection capability of YOLOv8 for real-life applications with a significantly improved mAP performance over a strict confidence threshold. YOLOv8 with SAHI inference gives a mAP:50-95 improvement of more than 25% compared to the base YOLOv8 model. The study also provides insights into future work direction by exploring the potential of generative models like deep convolutional generative adversarial network (DCGAN) and diffusion models like stable diffusion, for data augmentation.",
    "doi": "10.32604/cmc.2025.061466",
    "author_keywords": [
      "class-balanced dataset",
      "diffusion models",
      "Fire detection",
      "fractal dimension",
      "generative adversarial network (GAN)",
      "slicing-aided hyper inference (SAHI)",
      "smoke detection",
      "you only look once (YOLO)"
    ],
    "contribution": "In this work, we explore the possible ways forward to overcome these challenges posed by available datasets. We study the impact of a class-balanced dataset to improve the fire detection capability of state-of-the-art (SOTA) vision-based models and propose the use of generative models for data augmentation, as a future work direction. First, a comparative analysis of two prominent object detection architectures, You Only Look Once version 7 (YOLOv7) and YOLOv8 has been carried out using a balanced dataset, where both models have been evaluated across various evaluation metrics including precision, recall, and mean Average Precision (mAP). The results are compared to other recent fire detection models, highlighting the superior performance and efficiency of the proposed YOLOv8 architecture as trained on our balanced dataset. Next, a fractal dimension analysis gives a deeper insight into the repetition of patterns in fire, and the effectiveness of the results has been demonstrated by a windowing-based inference approach. The proposed Slicing-Aided Hyper Inference (SAHI) improves the fire and smoke detection capability of YOLOv8 for real-life applications with a significantly improved mAP performance over a strict confidence threshold. YOLOv8 with SAHI inference gives a mAP:50-95 improvement of more than 25% compared to the base YOLOv8 model. The study also provides insights into future work direction by exploring the potential of generative models like deep convolutional generative adversarial network (DCGAN) and diffusion models like stable diffusion, for data augmentation.",
    "introduction": "Fire detection has held stringent importance in computer vision for over half a century. The development of early fire detection strategies is pivotal to the realization of safe and smart cities, inhabitable in the future. However, the development of optimal fire and smoke detection models is hindered by limitations like publicly available datasets, lack of diversity, and class imbalance.",
    "classification_result": {
      "labels": [
        "Environment",
        "Emergency Safety",
        "Living",
        "Public Services",
        "Industry",
        "Citizens",
        "Business",
        "Public Policies",
        "Innovation Policy",
        "Air Quality",
        "People",
        "Sustainability",
        "Social Equity",
        "Urban Planning",
        "Buildings",
        "Socioeconomics",
        "Climate Change",
        "Learning and Teaching",
        "Healthcare",
        "Renewable Energy",
        "Governance",
        "Citizen Engagement",
        "Multimodal Transport",
        "Electric Vehicles",
        "Mobility",
        "Resource Conservation",
        "Economy",
        "Economic Management",
        "Housing",
        "Logistics",
        "Energy Management",
        "Smart Grids",
        "Cybersecurity",
        "Education",
        "Green Spaces",
        "Pedestrian",
        "Public Transit",
        "Transportation Systems",
        "Culture",
        "Power Distribution",
        "Finance",
        "Marketing",
        "Pollution Control",
        "Waste Management",
        "Traffic Management",
        "Bicycle",
        "Tourism",
        "Water Quality",
        "Lightning"
      ],
      "scores": [
        0.8174605965614319,
        0.6854941248893738,
        0.3700924217700958,
        0.18498489260673523,
        0.0911891981959343,
        0.0026833717711269855,
        0.0023523839190602303,
        0.0017294281860813498,
        0.000996928196400404,
        0.000671041605528444,
        0.0006598076433874667,
        0.0005854973569512367,
        0.0005637825815938413,
        0.000547435600310564,
        0.0005349941202439368,
        0.0005167934577912092,
        0.0004906068788841367,
        0.00046053575351834297,
        0.0004377345903776586,
        0.0004128560540266335,
        0.0004083203384652734,
        0.0004070938448421657,
        0.0004051571595482528,
        0.0003784111177083105,
        0.0003764358116313815,
        0.0003749811730813235,
        0.00037116152816452086,
        0.000368426350178197,
        0.00036681664641946554,
        0.0003607627295423299,
        0.0003418223059270531,
        0.0003383320290595293,
        0.00033685844391584396,
        0.0003178615588694811,
        0.0003107139782514423,
        0.00030923529993742704,
        0.00030780560337007046,
        0.0003050503437407315,
        0.0002977278782054782,
        0.00029500387609004974,
        0.0002940366684924811,
        0.0002900171384681016,
        0.0002896409132517874,
        0.00028509419644251466,
        0.0002814138715621084,
        0.0002785678079817444,
        0.00027668342227116227,
        0.000273795158136636,
        0.00026050861924886703
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Environment",
        "score": 0.8174605965614319
      },
      {
        "domain": "Smart Living",
        "score": 0.6854941248893738
      }
    ]
  },
  {
    "abstract": "Smart city mobility faces mounting challenges as urban mobility systems grow increasingly complex. Large language models (LLMs) have promise in interpreting and processing multi-modal urban data, but issues like model instability, computational inefficiency, and concerns about reliability hinder their implementations. In this Comment, we outline feasible LLM application scenarios, critically evaluate existing challenges, and highlight avenues for advancing LLM-based mobility systems through multi-modal data integration and developing robust, lightweight models.",
    "doi": "10.1007/s42524-025-4213-0",
    "author_keywords": [
      "large language model",
      "smart city mobility",
      "transportation",
      "urban computing"
    ],
    "contribution": "In this Comment, we outline feasible LLM application scenarios, critically evaluate existing challenges, and highlight avenues for advancing LLM-based mobility systems through multi-modal data integration and developing robust, lightweight models.",
    "introduction": "Smart city mobility faces mounting challenges as urban mobility systems grow increasingly complex. Large language models (LLMs) have promise in interpreting and processing multi-modal urban data, but issues like model instability, computational inefficiency, and concerns about reliability hinder their implementations.",
    "classification_result": {
      "labels": [
        "Mobility",
        "Multimodal Transport",
        "Transportation Systems",
        "Traffic Management",
        "Urban Planning",
        "Public Policies",
        "Business",
        "Public Services",
        "Innovation Policy",
        "Living",
        "Logistics",
        "Public Transit",
        "Industry",
        "Socioeconomics",
        "People",
        "Governance",
        "Lightning",
        "Economy",
        "Environment",
        "Citizens",
        "Learning and Teaching",
        "Economic Management",
        "Emergency Safety",
        "Pedestrian",
        "Smart Grids",
        "Finance",
        "Electric Vehicles",
        "Marketing",
        "Sustainability",
        "Cybersecurity",
        "Resource Conservation",
        "Power Distribution",
        "Citizen Engagement",
        "Social Equity",
        "Energy Management",
        "Climate Change",
        "Renewable Energy",
        "Bicycle",
        "Culture",
        "Education",
        "Air Quality",
        "Green Spaces",
        "Healthcare",
        "Buildings",
        "Water Quality",
        "Pollution Control",
        "Tourism",
        "Housing",
        "Waste Management"
      ],
      "scores": [
        0.9870635867118835,
        0.9645483493804932,
        0.8559128642082214,
        0.05811247229576111,
        0.04126789793372154,
        0.03432786092162132,
        0.00928562507033348,
        0.007230114657431841,
        0.0036694605369120836,
        0.0030912323854863644,
        0.0021862206049263477,
        0.0016657366650179029,
        0.0016376976855099201,
        0.0015237628249451518,
        0.001096897292882204,
        0.0008450887398794293,
        0.0007812263211235404,
        0.0006522767362184823,
        0.0006447731284424663,
        0.0005854812916368246,
        0.0005539749399758875,
        0.0005166347254998982,
        0.0004856722371187061,
        0.00044785195495933294,
        0.0004414338618516922,
        0.0004221182898618281,
        0.00042163266334682703,
        0.0004094933974556625,
        0.0004064819077029824,
        0.0004009091935586184,
        0.00039872751221992075,
        0.00039124017348513007,
        0.0003846724866889417,
        0.00038254738319665194,
        0.00037534479633904994,
        0.00037164866807870567,
        0.00036427206941880286,
        0.00035243044840171933,
        0.0003320530813653022,
        0.0003276506904512644,
        0.00032340895268134773,
        0.00032318165176548064,
        0.00032042869133874774,
        0.00031294094515033066,
        0.0003115205909125507,
        0.0003032978856936097,
        0.00029873420135118067,
        0.0002918353129643947,
        0.00028954751905985177
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Mobility",
        "score": 0.9870635867118835
      }
    ]
  },
  {
    "abstract": "Joint communication and sensing (JC&S) is emerging as a key component in 5G and 6G networks, enabling the dynamic adaptation to environmental changes and enhancing contextual awareness for optimized communication. By leveraging real-time environmental data, JC&S improves resource allocation, reduces latency, and enhancing power efficiency, while also supporting simulations and predictive modeling. This makes it a key technology for reactive systems and digital twins. These systems can respond to environmental events in real-time, offering transformative potential in sectors such as smart cities, healthcare, and Industry 5.0, where adaptive and multimodal interaction is critical to enhance real-time decision-making. In this work, we present a transformer-based architecture that processes temporal Channel State Information (CSI) data, specifically amplitude and phase, to generate 3D point clouds of indoor environments. The model utilizes multihead attention to capture complex spatio-temporal relationships in CSI data and is adaptable to different CSI configurations. We evaluate the architecture on the MM-Fi dataset, using two different protocols to capture human presence in indoor environments. The system demonstrates strong potential for accurate 3D reconstructions and effectively distinguishes between close and distant objects, advancing JC&S applications for spatial sensing in future wireless networks. The code is available at: https://github.com/Arritmic/csi2pointcloud.",
    "doi": "10.1109/JCS64661.2025.10880635",
    "author_keywords": [
      "6G",
      "Channel State Information (CSI)",
      "Joint Communication and Sensing",
      "Point Cloud Generation",
      "Transformer Networks",
      "WiFi"
    ],
    "contribution": "In this work, we present a transformer-based architecture that processes temporal Channel State Information (CSI) data, specifically amplitude and phase, to generate 3D point clouds of indoor environments. The model utilizes multihead attention to capture complex spatio-temporal relationships in CSI data and is adaptable to different CSI configurations. We evaluate the architecture on the MM-Fi dataset, using two different protocols to capture human presence in indoor environments. The system demonstrates strong potential for accurate 3D reconstructions and effectively distinguishes between close and distant objects, advancing JC&S applications for spatial sensing in future wireless networks. The code is available at: https://github.com/Arritmic/csi2pointcloud.",
    "introduction": "Joint communication and sensing (JC&S) is emerging as a key component in 5G and 6G networks, enabling the dynamic adaptation to environmental changes and enhancing contextual awareness for optimized communication. By leveraging real-time environmental data, JC&S improves resource allocation, reduces latency, and enhancing power efficiency, while also supporting simulations and predictive modeling. This makes it a key technology for reactive systems and digital twins. These systems can respond to environmental events in real-time, offering transformative potential in sectors such as smart cities, healthcare, and Industry 5.0, where adaptive and multimodal interaction is critical to enhance real-time decision-making.",
    "classification_result": {
      "labels": [
        "Mobility",
        "Environment",
        "Industry",
        "Business",
        "Emergency Safety",
        "Sustainability",
        "Multimodal Transport",
        "Public Services",
        "Economy",
        "Smart Grids",
        "Cybersecurity",
        "Living",
        "Climate Change",
        "Air Quality",
        "Transportation Systems",
        "Innovation Policy",
        "Citizens",
        "Economic Management",
        "Energy Management",
        "Traffic Management",
        "Urban Planning",
        "Logistics",
        "Healthcare",
        "Pollution Control",
        "Governance",
        "Water Quality",
        "Socioeconomics",
        "People",
        "Buildings",
        "Learning and Teaching",
        "Public Transit",
        "Renewable Energy",
        "Public Policies",
        "Power Distribution",
        "Finance",
        "Green Spaces",
        "Pedestrian",
        "Electric Vehicles",
        "Education",
        "Resource Conservation",
        "Marketing",
        "Lightning",
        "Social Equity",
        "Citizen Engagement",
        "Housing",
        "Waste Management",
        "Tourism",
        "Culture",
        "Bicycle"
      ],
      "scores": [
        0.3757363557815552,
        0.08091974258422852,
        0.06536120176315308,
        0.06174347922205925,
        0.018072428181767464,
        0.011808514595031738,
        0.007974877953529358,
        0.006720134988427162,
        0.00596553273499012,
        0.00452918978407979,
        0.003679563058540225,
        0.003405692521482706,
        0.0032044050749391317,
        0.002908435883000493,
        0.002555791987106204,
        0.002043296117335558,
        0.0015773843042552471,
        0.0015540618915110826,
        0.0013422224437817931,
        0.0013405719073489308,
        0.0013292510993778706,
        0.001162847620435059,
        0.0010435922304168344,
        0.0010375893907621503,
        0.0009314573835581541,
        0.0008974060765467584,
        0.0008751176646910608,
        0.000814871396869421,
        0.0007943600066937506,
        0.0007011471898294985,
        0.0006559744360856712,
        0.0005937302485108376,
        0.0005835815099999309,
        0.000559349253308028,
        0.0005571669316850603,
        0.0005408264696598053,
        0.0005280147888697684,
        0.0005246433429419994,
        0.0005066344165243208,
        0.00048554607201367617,
        0.0004740445001516491,
        0.00047267350601032376,
        0.0004510706348810345,
        0.0004384413769003004,
        0.00042013812344521284,
        0.0004070744616910815,
        0.0003961235051974654,
        0.0003792289935518056,
        0.00037781393621116877
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "In recent years, the rapid urbanization and development of the social economy have led to a growing focus on public safety issues. Governments across the world are increasingly promoting the construction of smart cities and intelligent security systems to safeguard the lives and property of citizens and maintain social stability. Person re-identification (ReID) is an essential technology for building smart cities, with significant implications for security monitoring and criminal investigation applications. The goal of person re-identification is to accurately identify specific individuals captured under different cameras. However, due to intra-class differences resulting from various factors such as illumination, viewpoint, occlusion, and pose, person re-identification remains a challenging task in the field of computer vision. Although existing fully supervised person re-identification methods have made significant progress, the scarcity of data and labels poses a bottleneck for further improving model performance. To address this challenge, we introduce a more complex and diverse synthetic dataset with easy-to-obtain labels for auxiliary training, and propose a novel camera-aware asymmetric adversarial learning (CAAL) method that overcomes intra-class variation among multiple cameras and the domain-shift between real data and synthetic data, enabling the learning of camera-invariant feature representations from diverse data sources. Furthermore, to mitigate the impact of misleading information carried by synthetic datasets and prevent the model from overfitting to synthetic data during adversarial training, we propose using an auxiliary network trained on real-world data to constrain the training of the backbone network. Finally, we conduct extensive experiments on two public datasets to demonstrate the effectiveness of the proposed method.",
    "doi": "10.7544/issn1000-1239.202330718",
    "author_keywords": [
      "adversarial learning",
      "computer vision",
      "image retrieval",
      "knowledge distillation",
      "person re-identification"
    ],
    "contribution": "To address this challenge, we introduce a more complex and diverse synthetic dataset with easy-to-obtain labels for auxiliary training, and propose a novel camera-aware asymmetric adversarial learning (CAAL) method that overcomes intra-class variation among multiple cameras and the domain-shift between real data and synthetic data, enabling the learning of camera-invariant feature representations from diverse data sources. Furthermore, to mitigate the impact of misleading information carried by synthetic datasets and prevent the model from overfitting to synthetic data during adversarial training, we propose using an auxiliary network trained on real-world data to constrain the training of the backbone network. Finally, we conduct extensive experiments on two public datasets to demonstrate the effectiveness of the proposed method.",
    "introduction": "In recent years, the rapid urbanization and development of the social economy have led to a growing focus on public safety issues. Governments across the world are increasingly promoting the construction of smart cities and intelligent security systems to safeguard the lives and property of citizens and maintain social stability. Person re-identification (ReID) is an essential technology for building smart cities, with significant implications for security monitoring and criminal investigation applications. The goal of person re-identification is to accurately identify specific individuals captured under different cameras. However, due to intra-class differences resulting from various factors such as illumination, viewpoint, occlusion, and pose, person re-identification remains a challenging task in the field of computer vision. Although existing fully supervised person re-identification methods have made significant progress, the scarcity of data and labels poses a bottleneck for further improving model performance.",
    "classification_result": {
      "labels": [
        "People",
        "Citizens",
        "Governance",
        "Public Services",
        "Living",
        "Public Policies",
        "Socioeconomics",
        "Cybersecurity",
        "Innovation Policy",
        "Emergency Safety",
        "Urban Planning",
        "Environment",
        "Pedestrian",
        "Lightning",
        "Buildings",
        "Economy",
        "Multimodal Transport",
        "Learning and Teaching",
        "Public Transit",
        "Mobility",
        "Transportation Systems",
        "Logistics",
        "Citizen Engagement",
        "Electric Vehicles",
        "Economic Management",
        "Business",
        "Power Distribution",
        "Resource Conservation",
        "Energy Management",
        "Social Equity",
        "Sustainability",
        "Climate Change",
        "Air Quality",
        "Industry",
        "Culture",
        "Healthcare",
        "Renewable Energy",
        "Marketing",
        "Smart Grids",
        "Traffic Management",
        "Green Spaces",
        "Water Quality",
        "Housing",
        "Finance",
        "Pollution Control",
        "Waste Management",
        "Bicycle",
        "Education",
        "Tourism"
      ],
      "scores": [
        0.9938597679138184,
        0.2933574616909027,
        0.17239314317703247,
        0.06982189416885376,
        0.06392520666122437,
        0.05580788850784302,
        0.012145365588366985,
        0.005288729909807444,
        0.004238885827362537,
        0.003120147157460451,
        0.0026770017575472593,
        0.0017090116161853075,
        0.0009706245618872344,
        0.0008881152025423944,
        0.0007755982805974782,
        0.0006244817632250488,
        0.0005515395314432681,
        0.0005175225087441504,
        0.0005077330861240625,
        0.0004964887630194426,
        0.000492136343382299,
        0.00045470966142602265,
        0.0004434976144693792,
        0.0004404718929436058,
        0.00043970279511995614,
        0.0004219690163154155,
        0.00041123907431028783,
        0.000406246428610757,
        0.00040191670996136963,
        0.0003941322793252766,
        0.0003939418529625982,
        0.00038902784581296146,
        0.0003856552066281438,
        0.0003835813549812883,
        0.00038291607052087784,
        0.0003775671939365566,
        0.000374743394786492,
        0.0003740125393960625,
        0.00036967004416510463,
        0.00036924195592291653,
        0.0003689006553031504,
        0.00036727177212014794,
        0.0003594850713852793,
        0.0003557516320142895,
        0.00035359690082259476,
        0.00034910469548776746,
        0.0003477184509392828,
        0.0003476102137938142,
        0.0003241014201194048
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart People",
        "score": 0.9938597679138184
      }
    ]
  },
  {
    "abstract": "The rapid evolution of cyber threats and the exponential growth of data-driven applications have necessitated the advancement of predictive analytics techniques in cybersecurity and data science. Machine learning (ML) and deep learning (DL) have emerged as powerful tools for detecting, analyzing, and mitigating cyber threats while also enhancing decision-making processes in data science applications. This paper explores state-of-the-art ML and DL methodologies for predictive analytics, emphasizing their role in proactive security measures and intelligent data analysis. Traditional security approaches often struggle to keep pace with the increasing complexity and volume of cyber threats. The integration of ML and DL offers dynamic, adaptive, and automated solutions that can identify anomalies, predict potential attacks, and strengthen defensive mechanisms. Supervised, unsupervised, and reinforcement learning models have been widely adopted for various cybersecurity applications, including intrusion detection, malware classification, fraud detection, and threat intelligence. Meanwhile, DL architectures such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers have demonstrated superior performance in feature extraction and pattern recognition, enabling advanced predictive analytics in cybersecurity. Beyond security applications, ML and DL play a crucial role in data science, enabling predictive modeling across diverse industries, such as healthcare, finance, and smart cities. Predictive analytics in data science leverages vast datasets to forecast trends, optimize decision-making, and drive innovation. However, challenges such as data privacy, model interpretability, adversarial attacks, and computational complexity must be addressed to ensure the reliability and ethical deployment of AI-driven solutions. This study presents a comprehensive review of the latest advancements in ML and DL for predictive analytics, examining their applications, benefits, and limitations. It also explores hybrid approaches that combine multiple techniques for enhanced accuracy and robustness. The paper further discusses emerging trends, including federated learning for privacy-preserving analytics, explainable AI (XAI) for model transparency, and quantum-enhanced ML for accelerated computations. Through extensive analysis and comparative evaluation, this research highlights the transformative potential of ML and DL in securing digital infrastructures and optimizing predictive analytics. The findings underscore the need for continuous innovation in algorithm design, data handling strategies, and cybersecurity frameworks to counter evolving cyber threats and maximize the utility of AI-driven predictive models. Ultimately, this study contributes to advancing the intersection of ML, DL, cybersecurity, and data science, paving the way for resilient, intelligent, and efficient digital ecosystems.",
    "doi": "10.52783/jisem.v10i9s.1236",
    "author_keywords": [
      "AI-Driven Data Science",
      "Cybersecurity Threat Detection",
      "Deep Learning Applications",
      "Machine Learning Models",
      "Predictive Analytics"
    ],
    "contribution": "This paper explores state-of-the-art ML and DL methodologies for predictive analytics, emphasizing their role in proactive security measures and intelligent data analysis. Traditional security approaches often struggle to keep pace with the increasing complexity and volume of cyber threats. The integration of ML and DL offers dynamic, adaptive, and automated solutions that can identify anomalies, predict potential attacks, and strengthen defensive mechanisms. Supervised, unsupervised, and reinforcement learning models have been widely adopted for various cybersecurity applications, including intrusion detection, malware classification, fraud detection, and threat intelligence. Meanwhile, DL architectures such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers have demonstrated superior performance in feature extraction and pattern recognition, enabling advanced predictive analytics in cybersecurity. Beyond security applications, ML and DL play a crucial role in data science, enabling predictive modeling across diverse industries, such as healthcare, finance, and smart cities. Predictive analytics in data science leverages vast datasets to forecast trends, optimize decision-making, and drive innovation. However, challenges such as data privacy, model interpretability, adversarial attacks, and computational complexity must be addressed to ensure the reliability and ethical deployment of AI-driven solutions. This study presents a comprehensive review of the latest advancements in ML and DL for predictive analytics, examining their applications, benefits, and limitations. It also explores hybrid approaches that combine multiple techniques for enhanced accuracy and robustness. The paper further discusses emerging trends, including federated learning for privacy-preserving analytics, explainable AI (XAI) for model transparency, and quantum-enhanced ML for accelerated computations. Through extensive analysis and comparative evaluation, this research highlights the transformative potential of ML and DL in securing digital infrastructures and optimizing predictive analytics. The findings underscore the need for continuous innovation in algorithm design, data handling strategies, and cybersecurity frameworks to counter evolving cyber threats and maximize the utility of AI-driven predictive models. Ultimately, this study contributes to advancing the intersection of ML, DL, cybersecurity, and data science, paving the way for resilient, intelligent, and efficient digital ecosystems.",
    "introduction": "The rapid evolution of cyber threats and the exponential growth of data-driven applications have necessitated the advancement of predictive analytics techniques in cybersecurity and data science. Machine learning (ML) and deep learning (DL) have emerged as powerful tools for detecting, analyzing, and mitigating cyber threats while also enhancing decision-making processes in data science applications.",
    "classification_result": {
      "labels": [
        "Cybersecurity",
        "Industry",
        "Business",
        "Environment",
        "Lightning",
        "Public Services",
        "Innovation Policy",
        "People",
        "Emergency Safety",
        "Public Policies",
        "Citizens",
        "Economy",
        "Governance",
        "Learning and Teaching",
        "Multimodal Transport",
        "Socioeconomics",
        "Economic Management",
        "Education",
        "Living",
        "Power Distribution",
        "Buildings",
        "Mobility",
        "Finance",
        "Smart Grids",
        "Urban Planning",
        "Public Transit",
        "Air Quality",
        "Electric Vehicles",
        "Transportation Systems",
        "Resource Conservation",
        "Social Equity",
        "Citizen Engagement",
        "Green Spaces",
        "Water Quality",
        "Bicycle",
        "Energy Management",
        "Renewable Energy",
        "Marketing",
        "Culture",
        "Logistics",
        "Pedestrian",
        "Sustainability",
        "Traffic Management",
        "Climate Change",
        "Tourism",
        "Pollution Control",
        "Healthcare",
        "Housing",
        "Waste Management"
      ],
      "scores": [
        0.9952947497367859,
        0.5299721956253052,
        0.0780852660536766,
        0.05230645462870598,
        0.005735492799431086,
        0.004226731136441231,
        0.004033144563436508,
        0.0029214967507869005,
        0.0015855737728998065,
        0.001417185296304524,
        0.0010462412610650063,
        0.0010012942366302013,
        0.0009224526002071798,
        0.0008209532825276256,
        0.0007440824410878122,
        0.0007220425759442151,
        0.0006770241889171302,
        0.0006756360526196659,
        0.0006224220851436257,
        0.0006207066471688449,
        0.0005430490127764642,
        0.0005234935088083148,
        0.000513383187353611,
        0.0005131906364113092,
        0.0005062325508333743,
        0.0005026384606026113,
        0.0004969020956195891,
        0.0004922231892123818,
        0.0004684995219577104,
        0.00046624033711850643,
        0.00046419043792411685,
        0.0004641084815375507,
        0.0004635683726519346,
        0.00046181483776308596,
        0.0004551073652692139,
        0.000450943160103634,
        0.0004467903636395931,
        0.0004413487040437758,
        0.0004336915444582701,
        0.0004299383726902306,
        0.0004276201070751995,
        0.00042472899076528847,
        0.0004191232437733561,
        0.0003917428257409483,
        0.00038441273500211537,
        0.00038397431490011513,
        0.0003772929485421628,
        0.00037629634607583284,
        0.0003446912451181561
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Governance",
        "score": 0.9952947497367859
      },
      {
        "domain": "Smart Economy",
        "score": 0.5299721956253052
      }
    ]
  },
  {
    "abstract": "One of the challenges of the Internet of Things and smart cities is energy consumption and energy theft. An accurate approach to predicting energy consumption and detecting energy theft in smart cities increases efficiency and energy efficiency. Forecasting energy consumption makes energy production based on the needs of consumers, and detecting energy theft makes energy consumption forecasting models more accurate. In this manuscript, in the first step, the data set is balanced using the generative adversarial network based on game theory and the synthetic minority oversampling based on sample density method. In the second step, the basic features of the samples are selected with the Namib beetle optimization (NBO) algorithm to reduce the input of the CNN-LSTM model. In the third step, the hyperparameters of the CNN-LSTM model are optimized to reduce the prediction and classification error rate with the NBO algorithm. In the Benin Electricity Company dataset, the proposed method has fewer errors in predicting energy consumption than the LSTM, GRU, ARIMA-LSTM, and ARIMA-GRU methods. On the Individual Household Electric-Power Consumption dataset, the proposed method provides lower energy consumption prediction errors than convolutional neural network (CNN), long short-term memory (LSTM), and CNN-LSTM. The NBO algorithm optimizer CNN-LSTM hyperparameters more accurately than Coati optimization algorithm, jellyfish search optimization, Harris hawks optimization (HHO), and African vultures optimization algorithm. Experiments on the State Grid Corporation of China dataset showed that the proposed method's accuracy, sensitivity, and precision in predicting energy theft are 98.93, 98.32, and 96.78%. The proposed method is more accurate than CNN, DeepCNN, CNN-LSTM, and the gated recurrent unit (GRU) method.",
    "doi": "10.1007/s11227-024-06811-5",
    "author_keywords": [
      "Convolutional neural networks",
      "Energy consumption",
      "Generative adversarial network",
      "Long short-term memory",
      "Namib beetle optimization algorithm",
      "Smart cities"
    ],
    "contribution": "In this manuscript, in the first step, the data set is balanced using the generative adversarial network based on game theory and the synthetic minority oversampling based on sample density method. In the second step, the basic features of the samples are selected with the Namib beetle optimization (NBO) algorithm to reduce the input of the CNN-LSTM model. In the third step, the hyperparameters of the CNN-LSTM model are optimized to reduce the prediction and classification error rate with the NBO algorithm. In the Benin Electricity Company dataset, the proposed method has fewer errors in predicting energy consumption than the LSTM, GRU, ARIMA-LSTM, and ARIMA-GRU methods. On the Individual Household Electric-Power Consumption dataset, the proposed method provides lower energy consumption prediction errors than convolutional neural network (CNN), long short-term memory (LSTM), and CNN-LSTM. The NBO algorithm optimizer CNN-LSTM hyperparameters more accurately than Coati optimization algorithm, jellyfish search optimization, Harris hawks optimization (HHO), and African vultures optimization algorithm. Experiments on the State Grid Corporation of China dataset showed that the proposed method's accuracy, sensitivity, and precision in predicting energy theft are 98.93, 98.32, and 96.78%. The proposed method is more accurate than CNN, DeepCNN, CNN-LSTM, and the gated recurrent unit (GRU) method.",
    "introduction": "One of the challenges of the Internet of Things and smart cities is energy consumption and energy theft. An accurate approach to predicting energy consumption and detecting energy theft in smart cities increases efficiency and energy efficiency. Forecasting energy consumption makes energy production based on the needs of consumers, and detecting energy theft makes energy consumption forecasting models more accurate.",
    "classification_result": {
      "labels": [
        "Energy Management",
        "Business",
        "Industry",
        "Environment",
        "Resource Conservation",
        "Economy",
        "Smart Grids",
        "Sustainability",
        "Economic Management",
        "Socioeconomics",
        "Public Services",
        "Innovation Policy",
        "Public Policies",
        "Power Distribution",
        "Logistics",
        "Urban Planning",
        "Living",
        "Finance",
        "Buildings",
        "Citizens",
        "Renewable Energy",
        "Governance",
        "Marketing",
        "Cybersecurity",
        "People",
        "Learning and Teaching",
        "Emergency Safety",
        "Multimodal Transport",
        "Climate Change",
        "Mobility",
        "Pollution Control",
        "Air Quality",
        "Transportation Systems",
        "Electric Vehicles",
        "Lightning",
        "Healthcare",
        "Social Equity",
        "Education",
        "Green Spaces",
        "Pedestrian",
        "Citizen Engagement",
        "Housing",
        "Bicycle",
        "Public Transit",
        "Culture",
        "Tourism",
        "Waste Management",
        "Water Quality",
        "Traffic Management"
      ],
      "scores": [
        0.9689298868179321,
        0.6072332859039307,
        0.509395182132721,
        0.44628003239631653,
        0.3397069573402405,
        0.3152807652950287,
        0.2714243531227112,
        0.2522816061973572,
        0.20654776692390442,
        0.15363481640815735,
        0.13358189165592194,
        0.09190268069505692,
        0.07321454584598541,
        0.056350745260715485,
        0.04216655343770981,
        0.03290748968720436,
        0.022212881594896317,
        0.02110551856458187,
        0.018410228192806244,
        0.007154003717005253,
        0.004331932868808508,
        0.003987053409218788,
        0.003746351459994912,
        0.0029813337605446577,
        0.0016495182644575834,
        0.0014402830274775624,
        0.001305718906223774,
        0.001275054644793272,
        0.0012703955871984363,
        0.0010755090042948723,
        0.0008273720741271973,
        0.0007495936006307602,
        0.0007310308865271509,
        0.0006760795949958265,
        0.0006153193535283208,
        0.0005876854411326349,
        0.0005385702825151384,
        0.0005221367464400828,
        0.0004976150230504572,
        0.00047662865836173296,
        0.0004710508219432086,
        0.00045185486669652164,
        0.00044139078818261623,
        0.0004385384963825345,
        0.00041495682671666145,
        0.0004060690989717841,
        0.00040537520544603467,
        0.0003989142132923007,
        0.0003670323349069804
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Environment",
        "score": 0.9689298868179321
      },
      {
        "domain": "Smart Economy",
        "score": 0.6072332859039307
      }
    ]
  },
  {
    "abstract": "High-resolution remote sensing images provide detailed surface information and are extensively utilized in urban planning, geographic monitoring, and smart city applications. Semantic segmentation, a crucial image analysis method, assigns pixel-level dense labels for scene understanding. However, this task faces challenges such as numerous small objects, complex shapes, detailed edge handling, and the effective fusion of multi-scale features. Existing methods often struggle to balance global information and local details, resulting in limited segmentation accuracy and efficiency. To address these challenges, we propose a novel network architecture named FAttFormer, which leverages the strengths of both Convolutional Neural Networks (CNNs) and Transformers. Within this architecture, we introduce two key modules: the Feature Attention Refinement Module (FARM) and the Multi-Scale Hybrid Attention (MSHA) module. The FAttFormer network is designed to significantly improve semantic segmentation accuracy and efficiency through multi-level and multi-scale feature fusion and refinement. Specifically, the FARM module focuses on effectively integrating encoder and decoder features to handle small objects and complex edges. The MSHA module enhances the ability to capture and integrate global and local information at different scales, further refining segmentation results. Extensive experiments on the ISPRS Vaihingen and Potsdam datasets demonstrate that FAttFormer outperforms existing models in segmenting impervious surfaces and buildings, showing significant improvements in accuracy and detail preservation.",
    "doi": "10.1117/12.3057505",
    "author_keywords": [
      "ISPRS Vaihingen dataset",
      "remote sensing image",
      "semantic segmentation",
      "Transformer"
    ],
    "contribution": "To address these challenges, we propose a novel network architecture named FAttFormer, which leverages the strengths of both Convolutional Neural Networks (CNNs) and Transformers. Within this architecture, we introduce two key modules: the Feature Attention Refinement Module (FARM) and the Multi-Scale Hybrid Attention (MSHA) module. The FAttFormer network is designed to significantly improve semantic segmentation accuracy and efficiency through multi-level and multi-scale feature fusion and refinement. Specifically, the FARM module focuses on effectively integrating encoder and decoder features to handle small objects and complex edges. The MSHA module enhances the ability to capture and integrate global and local information at different scales, further refining segmentation results. Extensive experiments on the ISPRS Vaihingen and Potsdam datasets demonstrate that FAttFormer outperforms existing models in segmenting impervious surfaces and buildings, showing significant improvements in accuracy and detail preservation.",
    "introduction": "High-resolution remote sensing images provide detailed surface information and are extensively utilized in urban planning, geographic monitoring, and smart city applications. Semantic segmentation, a crucial image analysis method, assigns pixel-level dense labels for scene understanding. However, this task faces challenges such as numerous small objects, complex shapes, detailed edge handling, and the effective fusion of multi-scale features. Existing methods often struggle to balance global information and local details, resulting in limited segmentation accuracy and efficiency.",
    "classification_result": {
      "labels": [
        "Environment",
        "Buildings",
        "Public Services",
        "Urban Planning",
        "Business",
        "Industry",
        "Living",
        "Green Spaces",
        "Pedestrian",
        "Housing",
        "Governance",
        "Lightning",
        "Mobility",
        "Waste Management",
        "Electric Vehicles",
        "Emergency Safety",
        "People",
        "Citizens",
        "Multimodal Transport",
        "Power Distribution",
        "Bicycle",
        "Logistics",
        "Innovation Policy",
        "Water Quality",
        "Climate Change",
        "Public Transit",
        "Education",
        "Transportation Systems",
        "Resource Conservation",
        "Learning and Teaching",
        "Renewable Energy",
        "Public Policies",
        "Healthcare",
        "Sustainability",
        "Energy Management",
        "Economy",
        "Social Equity",
        "Cybersecurity",
        "Economic Management",
        "Pollution Control",
        "Finance",
        "Socioeconomics",
        "Smart Grids",
        "Air Quality",
        "Culture",
        "Marketing",
        "Citizen Engagement",
        "Traffic Management",
        "Tourism"
      ],
      "scores": [
        0.8632633090019226,
        0.018192000687122345,
        0.016338810324668884,
        0.007837590761482716,
        0.003137103281915188,
        0.002930981572717428,
        0.0026806555688381195,
        0.002482467330992222,
        0.002250136574730277,
        0.0014865101547911763,
        0.0014831313164904714,
        0.0012941436143592,
        0.0009840630227699876,
        0.0009479888249188662,
        0.0009439315181225538,
        0.0009258267236873507,
        0.0009240114013664424,
        0.000860168831422925,
        0.0007858144235797226,
        0.0007618723320774734,
        0.0007456343155354261,
        0.0007303704041987658,
        0.0007217071834020317,
        0.0007210816256701946,
        0.0007207870949059725,
        0.0006795944646000862,
        0.0006750107859261334,
        0.0006699190707877278,
        0.0006416492396965623,
        0.0006192073924466968,
        0.0005967773031443357,
        0.0005965586169622838,
        0.000521013222169131,
        0.0005184331675991416,
        0.0004959279904142022,
        0.0004948643618263304,
        0.00047187780728563666,
        0.000471542589366436,
        0.0004648982430808246,
        0.0004645591543521732,
        0.0004636801313608885,
        0.00044850827543996274,
        0.00043987311073578894,
        0.00043620256474241614,
        0.00043091646512039006,
        0.00040643001557327807,
        0.0003874902322422713,
        0.00038577106897719204,
        0.000381881749490276
      ]
    },
    "macro_domains": [
      {
        "domain": "Smart Environment",
        "score": 0.8632633090019226
      }
    ]
  },
  {
    "abstract": "Artificial Intelligence (AI) technologies have enabled researchers to develop tools to monitor real-world events and user behavior using social media platforms. Twitter is particularly useful for gathering invaluable information related to diseases and public health to build real-time disease surveillance systems. Such systems offer a cost-effective and efficient alternative to the passive, expensive, and time-consuming process of using data from healthcare organizations and hospitals. In this paper, we propose a novel system of TepiSense to automatically perform disease surveillance of epidemic-prone diseases. Our system classifies tweets related to diseases and further identifies 'indication' tweets that highlight the presence of patients. Our system consists of four distinct modules of pre-processor, feature extractor, classifier, and evaluator. TepiSense compares the performance of 3 feature extraction techniques, 9 machine/deep learning models, and 3 Large Language Models (LLMs). To test the performance of our system, we build a dataset of Twitter Epidemic Surveillance Corpus (TESC) containing 23.9K English and 13K labelled Urdu tweets related to six diseases: COVID19, hepatitis, malaria, flu, dengue, and HIV/AIDS. Our results show that mBERT LLM achieves the highest F-measure values of 0.96 and 0.83 for topic and indication tweets classification, respectively. Furthermore, we compute the correlation of signals generated by our system with real-world cases to test the efficacy on COVID19 disease. We notice that real-world cases have a correlation of 0.58-0.63 with the indication category tweets. Finally, we develop an interactive and user-friendly dashboard to disseminate the analytics of our system. Overall, our system offers a powerful tool for real-time disease surveillance using social media with potential implications for public health policy and decision-making.",
    "doi": "10.1109/ACCESS.2025.3537168",
    "author_keywords": [
      "data mining",
      "e-health",
      "epidemic intelligence",
      "Natural language processing",
      "public health",
      "smart city"
    ],
    "contribution": "In this paper, we propose a novel system of TepiSense to automatically perform disease surveillance of epidemic-prone diseases. Our system classifies tweets related to diseases and further identifies 'indication' tweets that highlight the presence of patients. Our system consists of four distinct modules of pre-processor, feature extractor, classifier, and evaluator. TepiSense compares the performance of 3 feature extraction techniques, 9 machine/deep learning models, and 3 Large Language Models (LLMs). To test the performance of our system, we build a dataset of Twitter Epidemic Surveillance Corpus (TESC) containing 23.9K English and 13K labelled Urdu tweets related to six diseases: COVID19, hepatitis, malaria, flu, dengue, and HIV/AIDS. Our results show that mBERT LLM achieves the highest F-measure values of 0.96 and 0.83 for topic and indication tweets classification, respectively. Furthermore, we compute the correlation of signals generated by our system with real-world cases to test the efficacy on COVID19 disease. We notice that real-world cases have a correlation of 0.58-0.63 with the indication category tweets. Finally, we develop an interactive and user-friendly dashboard to disseminate the analytics of our system. Overall, our system offers a powerful tool for real-time disease surveillance using social media with potential implications for public health policy and decision-making.",
    "introduction": "Artificial Intelligence (AI) technologies have enabled researchers to develop tools to monitor real-world events and user behavior using social media platforms. Twitter is particularly useful for gathering invaluable information related to diseases and public health to build real-time disease surveillance systems. Such systems offer a cost-effective and efficient alternative to the passive, expensive, and time-consuming process of using data from healthcare organizations and hospitals.",
    "classification_result": {
      "labels": [
        "Healthcare",
        "Citizens",
        "Living",
        "Public Services",
        "Innovation Policy",
        "Citizen Engagement",
        "Industry",
        "Environment",
        "Business",
        "People",
        "Emergency Safety",
        "Public Policies",
        "Economy",
        "Governance",
        "Multimodal Transport",
        "Learning and Teaching",
        "Social Equity",
        "Economic Management",
        "Socioeconomics",
        "Urban Planning",
        "Mobility",
        "Air Quality",
        "Electric Vehicles",
        "Climate Change",
        "Sustainability",
        "Renewable Energy",
        "Cybersecurity",
        "Green Spaces",
        "Logistics",
        "Smart Grids",
        "Education",
        "Public Transit",
        "Water Quality",
        "Energy Management",
        "Resource Conservation",
        "Transportation Systems",
        "Culture",
        "Marketing",
        "Lightning",
        "Power Distribution",
        "Buildings",
        "Finance",
        "Pedestrian",
        "Tourism",
        "Housing",
        "Waste Management",
        "Pollution Control",
        "Bicycle",
        "Traffic Management"
      ],
      "scores": [
        0.18316851556301117,
        0.03836895525455475,
        0.0338548943400383,
        0.029853221029043198,
        0.013692021369934082,
        0.008101421408355236,
        0.006665803492069244,
        0.005572049878537655,
        0.0050581456162035465,
        0.003365113865584135,
        0.001914761494845152,
        0.0009352249326184392,
        0.0008828563150018454,
        0.0006918219150975347,
        0.0006759712123312056,
        0.0005713735590688884,
        0.0005159345455467701,
        0.000498626206535846,
        0.0004762787139043212,
        0.0004390968824736774,
        0.00041360806790180504,
        0.0004053398733958602,
        0.00040496265864931047,
        0.00040013485704548657,
        0.00039300709613598883,
        0.0003928521473426372,
        0.0003927682409994304,
        0.0003871839726343751,
        0.0003848662890959531,
        0.0003846269682981074,
        0.0003797221288550645,
        0.0003780857950914651,
        0.0003672946186270565,
        0.00036191174876876175,
        0.0003610250714700669,
        0.0003591981949284673,
        0.00035382198984734714,
        0.000353038078173995,
        0.0003490538219921291,
        0.0003478393773548305,
        0.000347193272318691,
        0.00034641052479855716,
        0.0003457091224845499,
        0.00031631573801860213,
        0.00031101173954084516,
        0.00031049223616719246,
        0.00031004336779005826,
        0.0002984919410664588,
        0.00028875251882709563
      ]
    },
    "macro_domains": []
  },
  {
    "abstract": "As urbanization accelerates, the rapid increase in urban populations and vehicle numbers poses unprecedented challenges to city traffic. The demand for intelligent transportation systems, a key component of smart city construction, is growing day by day. This system is a highly integrated interdisciplinary field that combines complex computer algorithms, which to some extent limits its extensive application. The emergence of large language middleware has reduced the deployment barriers for related applications. This article proposes an innovative intelligent transportation system that combines a large language model (LLM) with Amap API through LangGraph, providing strong support for urban traffic. This system not only assists users in making travel decisions through natural language dialogue based on the superior reasoning and planning capabilities of LLM, but also enhances the semantic understanding ability of LLM by constructing a graph structure through LangGraph,it improves the capture capability for urban traffic tasks and implements a self-feedback mechanism for the large language model.This innovative approach offers a more convenient and efficient method for the application of large language models in the field of Intelligent Traffic System.",
    "doi": "10.1117/12.3050639",
    "author_keywords": [
      "Amap",
      "ITS",
      "LangGraph",
      "Large Language Models"
    ],
    "contribution": "This system is a highly integrated interdisciplinary field that combines complex computer algorithms, which to some extent limits its extensive application. The emergence of large language middleware has reduced the deployment barriers for related applications. This article proposes an innovative intelligent transportation system that combines a large language model (LLM) with Amap API through LangGraph, providing strong support for urban traffic. This system not only assists users in making travel decisions through natural language dialogue based on the superior reasoning and planning capabilities of LLM, but also enhances the semantic understanding ability of LLM by constructing a graph structure through LangGraph,it improves the capture capability for urban traffic tasks and implements a self-feedback mechanism for the large language model.This innovative approach offers a more convenient and efficient method for the application of large language models in the field of Intelligent Traffic System.",
    "introduction": "As urbanization accelerates, the rapid increase in urban populations and vehicle numbers poses unprecedented challenges to city traffic. The demand for intelligent transportation systems, a key component of smart city construction, is growing day by day.",
    "macro_domains": []
  },
  {
    "abstract": "Intelligent Transportation Systems (ITS) are crucial for the development and operation of smart cities, addressing key challenges in efficiency, productivity, and environmental sustainability. This paper comprehensively reviews the transformative potential of Large Language Models (LLMs) in optimizing ITS. Initially, we provide an extensive overview of ITS, highlighting its components, operational principles, and overall effectiveness. We then delve into the theoretical background of various LLM techniques, such as GPT, T5, CTRL, and BERT, elucidating their relevance to ITS applications. Following this, we examine the wide-ranging applications of LLMs within ITS, including traffic flow prediction, vehicle detection and classification, autonomous driving, traffic sign recognition, and pedestrian detection. Our analysis reveals how these advanced models can significantly enhance traffic management and safety. Finally, we explore the challenges and limitations LLMs face in ITS, such as data availability, computational constraints, and ethical considerations. We also present several future research directions and potential innovations to address these challenges. This paper aims to guide researchers and practitioners through the complexities and opportunities of integrating LLMs in ITS, offering a roadmap to create more efficient, sustainable, and responsive next-generation transportation systems.",
    "doi": "10.1109/TITS.2025.3528116",
    "author_keywords": [
      "autonomous driving",
      "Intelligent transportation systems",
      "large language models",
      "traffic flow optimization",
      "traffic management"
    ],
    "contribution": "This paper comprehensively reviews the transformative potential of Large Language Models (LLMs) in optimizing ITS. Initially, we provide an extensive overview of ITS, highlighting its components, operational principles, and overall effectiveness. We then delve into the theoretical background of various LLM techniques, such as GPT, T5, CTRL, and BERT, elucidating their relevance to ITS applications. Following this, we examine the wide-ranging applications of LLMs within ITS, including traffic flow prediction, vehicle detection and classification, autonomous driving, traffic sign recognition, and pedestrian detection. Our analysis reveals how these advanced models can significantly enhance traffic management and safety. Finally, we explore the challenges and limitations LLMs face in ITS, such as data availability, computational constraints, and ethical considerations. We also present several future research directions and potential innovations to address these challenges. This paper aims to guide researchers and practitioners through the complexities and opportunities of integrating LLMs in ITS, offering a roadmap to create more efficient, sustainable, and responsive next-generation transportation systems.",
    "introduction": "Intelligent Transportation Systems (ITS) are crucial for the development and operation of smart cities, addressing key challenges in efficiency, productivity, and environmental sustainability.",
    "macro_domains": []
  },
  {
    "abstract": "Advanced deep learning algorithms play a key role in optimizing energy usage in smart cities, leveraging massive datasets to increase efficiency and sustainability. These algorithms analyze real-time data from sensors and IoT devices to predict energy demand, enabling dynamic load balancing and reducing waste. Reinforcement learning models optimize power distribution by learning from historical patterns and adapting to changes in energy usage in real time. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) facilitate detailed analysis of spatial and temporal data to better predict energy usage. Generative adversarial networks (GANs) are used to simulate energy usage scenarios, supporting strategic planning and anomaly detection. Federated learning ensures privacy-preserving data sharing in distributed energy systems, promoting collaboration without compromising security. These technologies are driving the transformation towards sustainable and energy-efficient urban environments, meeting the growing demands of modern smart cities. However, there is a view that if the pace of development is maintained with large amounts of data, the computational/energy costs may exceed the benefits. The article aims to conduct a comparative analysis and assess the development potential of this group of technologies, taking into account energy efficiency.",
    "doi": "10.3390/en18020407",
    "author_keywords": [
      "artificial intelligence",
      "deep learning",
      "energetic optimization",
      "energy management",
      "Internet of Things (IoT)",
      "smart buildings",
      "smart city"
    ],
    "contribution": "The article aims to conduct a comparative analysis and assess the development potential of this group of technologies, taking into account energy efficiency.",
    "introduction": "Advanced deep learning algorithms play a key role in optimizing energy usage in smart cities, leveraging massive datasets to increase efficiency and sustainability. These algorithms analyze real-time data from sensors and IoT devices to predict energy demand, enabling dynamic load balancing and reducing waste. Reinforcement learning models optimize power distribution by learning from historical patterns and adapting to changes in energy usage in real time. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) facilitate detailed analysis of spatial and temporal data to better predict energy usage. Generative adversarial networks (GANs) are used to simulate energy usage scenarios, supporting strategic planning and anomaly detection. Federated learning ensures privacy-preserving data sharing in distributed energy systems, promoting collaboration without compromising security. These technologies are driving the transformation towards sustainable and energy-efficient urban environments, meeting the growing demands of modern smart cities. However, there is a view that if the pace of development is maintained with large amounts of data, the computational/energy costs may exceed the benefits.",
    "macro_domains": []
  },
  {
    "abstract": "Unmanned aerial vehicles (UAVs), as the key Internet of Things (IoT) devices, play a dominant position in low-altitude environments. Semantic communication (SC), as the next-generation communication technology, serves as a bridge for surpassing the Shannon limit toward the 6G wireless network. Establishing air-ground SC to provide intelligent IoT services is a crucial initiative for building future smart cities. In this paper, we propose a UAV-based SC framework, named diffusion joint source-channel coding (D-JSCC). Abandoning traditional convolutional neural networks, we use transformers as the backbone and innovatively incorporate the diffusion model (DM) for image enhancement, achieving an optimal balance between image distortion and human perception. To accurately capture the numerical and perceptual loss induced by wireless channels and seamlessly amalgamate the DM with SC, we integrate channel states as strong prior information to refine the sampling process. Furthermore, we employ the gradient guidance strategy, which counteracts the randomness of sampling ensuring high robustness in harsh communication conditions. Additionally, we strike a balance between performance and sampling steps, ensuring both efficient computation and high-quality image enhancement. Comprehensive experiments demonstrate the advantages of D-JSCC across different communication environments.",
    "doi": "10.1109/JIOT.2025.3530462",
    "author_keywords": [
      "diffusion model",
      "generative artificial intelligence",
      "Semantic communication",
      "wireless image transmission"
    ],
    "contribution": "In this paper, we propose a UAV-based SC framework, named diffusion joint source-channel coding (D-JSCC). Abandoning traditional convolutional neural networks, we use transformers as the backbone and innovatively incorporate the diffusion model (DM) for image enhancement, achieving an optimal balance between image distortion and human perception. To accurately capture the numerical and perceptual loss induced by wireless channels and seamlessly amalgamate the DM with SC, we integrate channel states as strong prior information to refine the sampling process. Furthermore, we employ the gradient guidance strategy, which counteracts the randomness of sampling ensuring high robustness in harsh communication conditions. Additionally, we strike a balance between performance and sampling steps, ensuring both efficient computation and high-quality image enhancement. Comprehensive experiments demonstrate the advantages of D-JSCC across different communication environments.",
    "introduction": "Unmanned aerial vehicles (UAVs), as the key Internet of Things (IoT) devices, play a dominant position in low-altitude environments. Semantic communication (SC), as the next-generation communication technology, serves as a bridge for surpassing the Shannon limit toward the 6G wireless network. Establishing air-ground SC to provide intelligent IoT services is a crucial initiative for building future smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "With the rapid development of the internet of things and smart cities, the demand for effective spectrum collaboration has grown significantly. Radio maps play a crucial role in understanding the spatial radio environment, which is essential for wireless applications such as cell planning and radio resource management. However, generating radio maps is a resource-intensive task, as the construction process is complex and the distribution process consumes substantial bandwidth. This article proposes a method that combines semantic communication (SemCom) and generative artificial intelligence (GAI) to optimize the construction and distribution processes of radio maps. By incorporating SemCom, our method transmits only key semantic information during the distribution process, significantly reducing bandwidth usage while ensuring accurate and efficient information transfer. While the diverse generative capabilities of GAI introduce some instability, which could be a limitation in radio map construction, this article achieves precise content decoding through prompts based on multi-modal semantic information, enabling accurate construction and restoration of radio maps. By utilizing SemCom and GAI technologies, the cost of applications of radio maps can be significantly reduced, which is beneficial for stimulating the pace of intelligence evolution in future mobile networks.",
    "doi": "10.1109/MNET.2025.3529513",
    "author_keywords": [
      "diffusion models",
      "generative AI",
      "radio map",
      "semantic communication"
    ],
    "contribution": "This article proposes a method that combines semantic communication (SemCom) and generative artificial intelligence (GAI) to optimize the construction and distribution processes of radio maps. By incorporating SemCom, our method transmits only key semantic information during the distribution process, significantly reducing bandwidth usage while ensuring accurate and efficient information transfer. While the diverse generative capabilities of GAI introduce some instability, which could be a limitation in radio map construction, this article achieves precise content decoding through prompts based on multi-modal semantic information, enabling accurate construction and restoration of radio maps. By utilizing SemCom and GAI technologies, the cost of applications of radio maps can be significantly reduced, which is beneficial for stimulating the pace of intelligence evolution in future mobile networks.",
    "introduction": "With the rapid development of the internet of things and smart cities, the demand for effective spectrum collaboration has grown significantly. Radio maps play a crucial role in understanding the spatial radio environment, which is essential for wireless applications such as cell planning and radio resource management. However, generating radio maps is a resource-intensive task, as the construction process is complex and the distribution process consumes substantial bandwidth.",
    "macro_domains": []
  },
  {
    "abstract": "Video instance segmentation, a key technology for intelligent sensing in visual perception, plays a key role in automated surveillance, robotics, and smart cities. These scenarios rely on real-time and efficient target-tracking capabilities for accurate perception and intelligent analysis of dynamic environments. However, traditional video instance segmentation methods face complex models, high computational overheads, and slow segmentation speeds in time-series feature extraction, especially in resource-constrained environments. To address these challenges, a Dual-Channel and Frequency-Aware Approach for Lightweight Video Instance Segmentation (DCFA-LVIS) is proposed in this paper. In feature extraction, a DCEResNet backbone network structure based on a dual-channel feature enhancement mechanism is designed to improve the modelâ€™s accuracy by enhancing the feature extraction and representation capabilities. In instance tracking, a dual-frequency perceptual enhancement network structure is constructed, which uses an independent instance query mechanism to capture temporal information and combines with a frequency-aware attention mechanism to capture instance features on different attention layers of high and low frequencies, respectively, to effectively reduce the complexity of the model, decrease the number of parameters, and improve the segmentation efficiency. Experiments show that the model proposed in this paper achieves state-of-the-art segmentation performance with few parameters on the YouTube-VIS dataset, demonstrating its efficiency and practicality. This method significantly enhances the application efficiency and adaptability of visual perception intelligent sensing technology in video data acquisition and processing, providing strong support for its widespread deployment.",
    "doi": "10.3390/s25020459",
    "author_keywords": [
      "lightweight",
      "video instance segmentation",
      "video transformer",
      "video understanding",
      "visual perception intelligent sensing"
    ],
    "contribution": "To address these challenges, a Dual-Channel and Frequency-Aware Approach for Lightweight Video Instance Segmentation (DCFA-LVIS) is proposed in this paper. In feature extraction, a DCEResNet backbone network structure based on a dual-channel feature enhancement mechanism is designed to improve the modelâ€™s accuracy by enhancing the feature extraction and representation capabilities. In instance tracking, a dual-frequency perceptual enhancement network structure is constructed, which uses an independent instance query mechanism to capture temporal information and combines with a frequency-aware attention mechanism to capture instance features on different attention layers of high and low frequencies, respectively, to effectively reduce the complexity of the model, decrease the number of parameters, and improve the segmentation efficiency. Experiments show that the model proposed in this paper achieves state-of-the-art segmentation performance with few parameters on the YouTube-VIS dataset, demonstrating its efficiency and practicality. This method significantly enhances the application efficiency and adaptability of visual perception intelligent sensing technology in video data acquisition and processing, providing strong support for its widespread deployment.",
    "introduction": "Video instance segmentation, a key technology for intelligent sensing in visual perception, plays a key role in automated surveillance, robotics, and smart cities. These scenarios rely on real-time and efficient target-tracking capabilities for accurate perception and intelligent analysis of dynamic environments. However, traditional video instance segmentation methods face complex models, high computational overheads, and slow segmentation speeds in time-series feature extraction, especially in resource-constrained environments.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate bus arrival time prediction is crucial for enhancing passenger experience and optimizing smart city transit systems. Existing methods, typically based on single-route, sparse stop data, struggle with the complex spatiotemporal interactions present in dense stop areas and multi-route networks, resulting in lower prediction accuracy. In this paper, we propose a frontend-enhanced time-series prediction network, in which the Multi-Relational Modeling Graph Convolution (MRMGCN) as the frontend-enhanced module, called FEN-MRMGCN. The proposed module captures spatial relationships in dense, multi-route areas by using graph convolution layers based on multi-relational modeling to aggregate spatial information. The network then uses a conventional time-series model to capture temporal dynamics. Our approach effectively combines external factors, such as traffic congestion and weather conditions, particularly in dense bus route areas, thereby significantly enhancing bus arrival time prediction accuracy. Moreover, we compile and analyze a comprehensive dataset comprising passenger flow, traffic conditions, weather information, and arrival times for both densely populated bus stop areas and regular areas in Macao. Experimental results demonstrate that our frontend-enhanced network achieves a reduction in the Mean Absolute Percentage Error (MAPE) by 15.36%, 13.44%, and 19.07% compared to traditional time series forecasting models like CNN, LSTM, and Transformer, respectively. Future research will focus on leveraging additional data sources and exploring advanced graph convolutional architectures to further elevate prediction accuracy.",
    "doi": "10.1109/ACCESS.2024.3525357",
    "author_keywords": [
      "Bus arrival time prediction",
      "CNN",
      "frontend-enhanced network",
      "graph convolutional networks",
      "intelligent transportation for smart city",
      "LSTM",
      "multi-relational modeling",
      "transformer"
    ],
    "contribution": "In this paper, we propose a frontend-enhanced time-series prediction network, in which the Multi-Relational Modeling Graph Convolution (MRMGCN) as the frontend-enhanced module, called FEN-MRMGCN. The proposed module captures spatial relationships in dense, multi-route areas by using graph convolution layers based on multi-relational modeling to aggregate spatial information. The network then uses a conventional time-series model to capture temporal dynamics. Our approach effectively combines external factors, such as traffic congestion and weather conditions, particularly in dense bus route areas, thereby significantly enhancing bus arrival time prediction accuracy. Moreover, we compile and analyze a comprehensive dataset comprising passenger flow, traffic conditions, weather information, and arrival times for both densely populated bus stop areas and regular areas in Macao. Experimental results demonstrate that our frontend-enhanced network achieves a reduction in the Mean Absolute Percentage Error (MAPE) by 15.36%, 13.44%, and 19.07% compared to traditional time series forecasting models like CNN, LSTM, and Transformer, respectively. Future research will focus on leveraging additional data sources and exploring advanced graph convolutional architectures to further elevate prediction accuracy.",
    "introduction": "Accurate bus arrival time prediction is crucial for enhancing passenger experience and optimizing smart city transit systems. Existing methods, typically based on single-route, sparse stop data, struggle with the complex spatiotemporal interactions present in dense stop areas and multi-route networks, resulting in lower prediction accuracy.",
    "macro_domains": []
  },
  {
    "abstract": "Analyzing and comprehending check-in sequences is crucial for various applications in smart cities. However, publicly available check-in datasets are often limited in scale due to privacy concerns. This poses a significant obstacle to academic research and downstream applications. Thus, it is urgent to generate realistic check-in datasets. The denoising diffusion probabilistic model (DDPM) as one of the most capable generation methods is a good choice to achieve this goal. However, generating check-in sequences using DDPM is not an easy feat. The difficulties lie in handling check-in sequences of variable lengths and capturing the correlation from check-in sequencesâ€™ distinct characteristics. This paper addresses the challenges by proposing a Spatio-Temporal Contrastive Diffusion Model (STCDM). This model introduces a novel spatio-temporal lossless encoding method that effectively encodes check-in sequences into a suitable format with equal length. Furthermore, we capture the spatio-temporal correlations with two disentangled diffusion modules to reduce the impact of the difference between spatial and temporal characteristics. Finally, we incorporate contrastive learning to enhance the relationship between diffusion modules. We generate four realistic datasets in different scenarios using STCDM and design four metrics for comparison. Experiments demonstrate that our generated datasets are more realistic and free of privacy leakage.",
    "doi": "10.1109/TKDE.2025.3525718",
    "author_keywords": [
      "check-in sequence",
      "contrastive learning",
      "diffusion model",
      "sequence generation",
      "spatio-temporal data mining"
    ],
    "contribution": "This paper addresses the challenges by proposing a Spatio-Temporal Contrastive Diffusion Model (STCDM). This model introduces a novel spatio-temporal lossless encoding method that effectively encodes check-in sequences into a suitable format with equal length. Furthermore, we capture the spatio-temporal correlations with two disentangled diffusion modules to reduce the impact of the difference between spatial and temporal characteristics. Finally, we incorporate contrastive learning to enhance the relationship between diffusion modules. We generate four realistic datasets in different scenarios using STCDM and design four metrics for comparison. Experiments demonstrate that our generated datasets are more realistic and free of privacy leakage.",
    "introduction": "Analyzing and comprehending check-in sequences is crucial for various applications in smart cities. However, publicly available check-in datasets are often limited in scale due to privacy concerns. This poses a significant obstacle to academic research and downstream applications. Thus, it is urgent to generate realistic check-in datasets. The denoising diffusion probabilistic model (DDPM) as one of the most capable generation methods is a good choice to achieve this goal. However, generating check-in sequences using DDPM is not an easy feat. The difficulties lie in handling check-in sequences of variable lengths and capturing the correlation from check-in sequencesâ€™ distinct characteristics.",
    "macro_domains": []
  },
  {
    "abstract": "The construction of smart cities contributes to promoting residents' life convenience and sustainable energy development. Despite these advancements, the challenge of fully analyzing and understanding residents' energy usage behaviors leads to inefficient energy use and potential economic losses. Current resident anomaly detection technologies rely on single-source energy data, lacking detailed behavior pattern analysis. Hence, this paper proposes a method to detect abnormal residential water and electricity usage by incorporating multi-source information. Specifically, the correlation between water and electricity usage of residential customers is analyzed based on real metering data and the use of the Copula distribution function, followed by the integration of two innovative data mining techniques to form an anomaly detection framework. The distance correlation coefficient algorithm is used to measure the relevance of users' water and electricity usage data. Then, the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster the distance correlation coefficient for users and detect abnormal users whose distance correlation coefficient curves deviate from the normal user clusters. This multi-source approach avoids single-source bias by improving the data accuracy over one-dimensional methods. Experiments are implemented in a real low-voltage transformer area to prove the validity of the proposed method.",
    "doi": "10.1109/ACCESS.2025.3525726",
    "author_keywords": [
      "Advanced metering infrastructure",
      "behavior analysis",
      "distance correlation coefficient",
      "multi-source information",
      "smart cities"
    ],
    "contribution": "Hence, this paper proposes a method to detect abnormal residential water and electricity usage by incorporating multi-source information. Specifically, the correlation between water and electricity usage of residential customers is analyzed based on real metering data and the use of the Copula distribution function, followed by the integration of two innovative data mining techniques to form an anomaly detection framework. The distance correlation coefficient algorithm is used to measure the relevance of users' water and electricity usage data. Then, the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster the distance correlation coefficient for users and detect abnormal users whose distance correlation coefficient curves deviate from the normal user clusters. This multi-source approach avoids single-source bias by improving the data accuracy over one-dimensional methods. Experiments are implemented in a real low-voltage transformer area to prove the validity of the proposed method.",
    "introduction": "The construction of smart cities contributes to promoting residents' life convenience and sustainable energy development. Despite these advancements, the challenge of fully analyzing and understanding residents' energy usage behaviors leads to inefficient energy use and potential economic losses. Current resident anomaly detection technologies rely on single-source energy data, lacking detailed behavior pattern analysis.",
    "macro_domains": []
  },
  {
    "abstract": "With the development and widespread application of network information, new technologies led by 5G are emerging, resulting in an increasingly complex network security environment and more diverse attack methods. Unlike traditional networks, 5G networks feature higher connection density, faster data transmission speeds, and lower latency, which are widely applied in scenarios such as smart cities, the Internet of Things, and autonomous driving. The vast amounts of sensitive data generated by these applications become primary targets during the processes of collection and secure sharing, and unauthorized access or tampering could lead to severe data breaches and integrity issues. However, as 5G networks extensively employ encryption technologies to protect data transmission, attackers can hide malicious content within encrypted communication, rendering traditional content-based traffic detection methods ineffective for identifying malicious encrypted traffic. To address this challenge, this paper proposes a malicious encrypted traffic detection method based on reconstructive domain adaptation and adversarial hybrid neural networks. The proposed method integrates generative adversarial networks with ResNet, ResNeXt, and DenseNet to construct an adversarial hybrid neural network, aiming to tackle the challenges of encrypted traffic detection. On this basis, a reconstructive domain adaptation module is introduced to reduce the distribution discrepancy between the source domain and the target domain, thereby enhancing cross-domain detection capabilities. By preprocessing traffic data from public datasets, the proposed method is capable of extracting deep features from encrypted traffic without the need for decryption. The generator utilizes the adversarial hybrid neural network module to generate realistic malicious encrypted traffic samples, while the discriminator achieves sample classification through high-dimensional feature extraction. Additionally, the domain classifier within the reconstructive domain adaptation module further improves the modelâ€™s stability and generalization across different network environments and time periods. Experimental results demonstrate that the proposed method significantly improves the accuracy and efficiency of malicious encrypted traffic detection in 5G network environments, effectively enhancing the detection performance of malicious traffic in 5G networks.",
    "doi": "10.3390/electronics14010051",
    "author_keywords": [
      "adversarial generative networks",
      "deep learning",
      "domain adaptation",
      "encrypt malicious traffic",
      "hybrid neural networks"
    ],
    "contribution": "To address this challenge, this paper proposes a malicious encrypted traffic detection method based on reconstructive domain adaptation and adversarial hybrid neural networks. The proposed method integrates generative adversarial networks with ResNet, ResNeXt, and DenseNet to construct an adversarial hybrid neural network, aiming to tackle the challenges of encrypted traffic detection. On this basis, a reconstructive domain adaptation module is introduced to reduce the distribution discrepancy between the source domain and the target domain, thereby enhancing cross-domain detection capabilities. By preprocessing traffic data from public datasets, the proposed method is capable of extracting deep features from encrypted traffic without the need for decryption. The generator utilizes the adversarial hybrid neural network module to generate realistic malicious encrypted traffic samples, while the discriminator achieves sample classification through high-dimensional feature extraction. Additionally, the domain classifier within the reconstructive domain adaptation module further improves the modelâ€™s stability and generalization across different network environments and time periods. Experimental results demonstrate that the proposed method significantly improves the accuracy and efficiency of malicious encrypted traffic detection in 5G network environments, effectively enhancing the detection performance of malicious traffic in 5G networks.",
    "introduction": "With the development and widespread application of network information, new technologies led by 5G are emerging, resulting in an increasingly complex network security environment and more diverse attack methods. Unlike traditional networks, 5G networks feature higher connection density, faster data transmission speeds, and lower latency, which are widely applied in scenarios such as smart cities, the Internet of Things, and autonomous driving. The vast amounts of sensitive data generated by these applications become primary targets during the processes of collection and secure sharing, and unauthorized access or tampering could lead to severe data breaches and integrity issues. However, as 5G networks extensively employ encryption technologies to protect data transmission, attackers can hide malicious content within encrypted communication, rendering traditional content-based traffic detection methods ineffective for identifying malicious encrypted traffic.",
    "macro_domains": []
  },
  {
    "abstract": "Wireless Sensor Networks (WSNs) are extensively used in event monitoring and tracking, particularly in scenarios that require minimal human intervention. However, a key challenge in WSNs is the short lifespan of sensor nodes (SN), as continuous sensing leads to rapid battery depletion. In high-traffic areas, sensors located near the sink node exhaust their energy quickly, creating an energy-hole issue. As a result, optimizing energy usage is a significant challenge for WSN-assisted applications. To address this, this paper proposes an Energy-aware Routing and Cluster Head Selection in Wireless Sensor Network through an Attentive Dual Residual Generative Adversarial Network for Golden Search Optimization Algorithm in Wireless Sensor Network (EAR-WSN-ADRGAN-GSOA). This method involves selecting the Cluster Head (CH) using Attentive Dual Residual Generative Adversarial Network (ADRGAN), minimizing energy consumption, and reducing a number of dead sensor nodes. Subsequently, Golden Search Optimization Algorithm (GSOA) is employed to determine an optimal path for data transmission to the sink node, maximizing energy efficiency, and elongating sensor node lifespan. The proposed EAR-WSN-ADRGAN-GSOA method is simulated in MATLAB. The performance metrics, such as network lifetime, number of alive nodes, number of dead nodes, throughput, energy consumption, and packet delivery ratio is examined. The proposed EAR-WSN-ADRGAN-GSOA demonstrates improved performance, achieving a higher average throughput of 0.93 Mbps, and lower average energy consumption of 0.39 mJ compared with the existing methods. These improvements have significant real-world implications for enhancing the efficiency and longevity of WSNs in applications, such as environmental monitoring, smart cities, and industrial automation.",
    "doi": "10.1002/ett.70035",
    "author_keywords": [
      "Attentive Dual Residual Generative Adversarial Network",
      "cluster head",
      "Golden Search Optimization Algorithm",
      "nodes",
      "optimal routing and wireless sensor network"
    ],
    "contribution": "To address this, this paper proposes an Energy-aware Routing and Cluster Head Selection in Wireless Sensor Network through an Attentive Dual Residual Generative Adversarial Network for Golden Search Optimization Algorithm in Wireless Sensor Network (EAR-WSN-ADRGAN-GSOA). This method involves selecting the Cluster Head (CH) using Attentive Dual Residual Generative Adversarial Network (ADRGAN), minimizing energy consumption, and reducing a number of dead sensor nodes. Subsequently, Golden Search Optimization Algorithm (GSOA) is employed to determine an optimal path for data transmission to the sink node, maximizing energy efficiency, and elongating sensor node lifespan. The proposed EAR-WSN-ADRGAN-GSOA method is simulated in MATLAB. The performance metrics, such as network lifetime, number of alive nodes, number of dead nodes, throughput, energy consumption, and packet delivery ratio is examined. The proposed EAR-WSN-ADRGAN-GSOA demonstrates improved performance, achieving a higher average throughput of 0.93 Mbps, and lower average energy consumption of 0.39 mJ compared with the existing methods. These improvements have significant real-world implications for enhancing the efficiency and longevity of WSNs in applications, such as environmental monitoring, smart cities, and industrial automation.",
    "introduction": "Wireless Sensor Networks (WSNs) are extensively used in event monitoring and tracking, particularly in scenarios that require minimal human intervention. However, a key challenge in WSNs is the short lifespan of sensor nodes (SN), as continuous sensing leads to rapid battery depletion. In high-traffic areas, sensors located near the sink node exhaust their energy quickly, creating an energy-hole issue. As a result, optimizing energy usage is a significant challenge for WSN-assisted applications.",
    "macro_domains": []
  },
  {
    "abstract": "In recent years, intelligent transportation systems have played a pivotal role in the development of smart cities, with vehicle retrieval becoming a critical component of traffic management and surveillance. Traditional vehicle retrieval systems rely heavily on image-based matching techniques derived from vehicle re-identification (VReID) tasks. However, these approaches are limited by their dependency on image queries, which may not always be available in real-world scenarios. Natural language (NL)-based vehicle retrieval systems offer a more flexible and accessible alternative by enabling users to query vehicles using textual descriptions. Despite progress in NL-based retrieval, existing methods face challenges in fully capturing multi-granularity information and aligning heterogeneous visual and linguistic inputs. This paper addresses these limitations by proposing a robust Multimodal Vehicle Retrieval (MVR) model that integrates both visual and textual data through a dual-stream architecture. Our model captures complementary local features, alongside global information including motion and environmental context. We utilize InfoNCE and instance losses to align the visual and textual modalities within a shared feature space, while post-processing modules, including Granular Vehicle Feature Refinement and Spatial Relationship Modeling, further enhance retrieval performance by refining vehicle attributes and contextual relationships. Our experiments, conducted on the CityFlow-NL dataset, demonstrate that our model achieves a 35.6% improvement in Mean Reciprocal Rank (MRR), a 41.3% increase in recall at 5 (R@5), and a 22.9% improvement in recall at 10 (R@10) compared to the baseline, and overcomes the inherent challenges of cross-modal retrieval in improving real-world VReID.",
    "doi": "10.1109/ACCESS.2024.3524392",
    "author_keywords": [
      "intelligent transportation",
      "multimodal",
      "smart city",
      "Traffic surveillance",
      "vehicle tracking"
    ],
    "contribution": "This paper addresses these limitations by proposing a robust Multimodal Vehicle Retrieval (MVR) model that integrates both visual and textual data through a dual-stream architecture. Our model captures complementary local features, alongside global information including motion and environmental context. We utilize InfoNCE and instance losses to align the visual and textual modalities within a shared feature space, while post-processing modules, including Granular Vehicle Feature Refinement and Spatial Relationship Modeling, further enhance retrieval performance by refining vehicle attributes and contextual relationships. Our experiments, conducted on the CityFlow-NL dataset, demonstrate that our model achieves a 35.6% improvement in Mean Reciprocal Rank (MRR), a 41.3% increase in recall at 5 (R@5), and a 22.9% improvement in recall at 10 (R@10) compared to the baseline, and overcomes the inherent challenges of cross-modal retrieval in improving real-world VReID.",
    "introduction": "In recent years, intelligent transportation systems have played a pivotal role in the development of smart cities, with vehicle retrieval becoming a critical component of traffic management and surveillance. Traditional vehicle retrieval systems rely heavily on image-based matching techniques derived from vehicle re-identification (VReID) tasks. However, these approaches are limited by their dependency on image queries, which may not always be available in real-world scenarios. Natural language (NL)-based vehicle retrieval systems offer a more flexible and accessible alternative by enabling users to query vehicles using textual descriptions. Despite progress in NL-based retrieval, existing methods face challenges in fully capturing multi-granularity information and aligning heterogeneous visual and linguistic inputs.",
    "macro_domains": []
  },
  {
    "abstract": "In todayâ€™s smart cities, itâ€™s essential to combine advanced healthcare with education. Our research introduces a groundbreaking method for detecting skin cancer, using a new type of artificial intelligence called a Vision Transformer. This model analyzes a wide range of skin images from different people and accurately identifies skin cancer, especially melanoma and benign moles.Moving beyond traditional techniques like convolutional neural networks, our approach uses advanced attentionmechanisms to improve accuracy by focusing on key areas in the skin images. The model has been thoroughly tested with specific criteria to ensure it can reliably detect skin cancer while reducing errors. This research is particularly important as skin cancer rates are increasing worldwide, and early, accurate detection is vital for saving lives. Our study focuses on providing assistance to healthcare practitioners for skin disease diagnostics as well as to assist in providing training and education to healthcare researchers. The proposed method outperforms in terms of ROC curve analysis.",
    "doi": "10.1007/978-981-97-8345-8_28",
    "author_keywords": [
      "Dermoscopic Images",
      "Higher Education in Smart Cities",
      "Skin Cancer Detection",
      "Vision Transformers"
    ],
    "contribution": "Our research introduces a groundbreaking method for detecting skin cancer, using a new type of artificial intelligence called a Vision Transformer. This model analyzes a wide range of skin images from different people and accurately identifies skin cancer, especially melanoma and benign moles.Moving beyond traditional techniques like convolutional neural networks, our approach uses advanced attentionmechanisms to improve accuracy by focusing on key areas in the skin images. The model has been thoroughly tested with specific criteria to ensure it can reliably detect skin cancer while reducing errors. This research is particularly important as skin cancer rates are increasing worldwide, and early, accurate detection is vital for saving lives. Our study focuses on providing assistance to healthcare practitioners for skin disease diagnostics as well as to assist in providing training and education to healthcare researchers. The proposed method outperforms in terms of ROC curve analysis.",
    "introduction": "In todayâ€™s smart cities, itâ€™s essential to combine advanced healthcare with education.",
    "macro_domains": []
  },
  {
    "abstract": "Intelligent logistics relies on accurately predicting the service time, which is a part of time cost in the last-mile delivery. However, service time prediction (STP) is non-trivial given complex delivery circumstances, location heterogeneity, and skewed observations in space, which are not well-handled by existing solutions. In our prior work, we treat STP at each location as a learning task to keep the location heterogeneity, propose a prior knowledge-enhanced meta-learning to tackle skewed observations, and introduce a Transformer-based representation module to encode complex delivery circumstances. Maintaining the design principles of prior work, in this extended paper, we propose MetaSTP+. In addition to fusing the prior knowledge after the meta-learning process, MetaSTP+ also injects the prior knowledge before and during the meta-learning process to better tackle skewed observations. More specifically, MetaSTP+ completes the support set of tasks with scarce samples from other tasks based on prior knowledge and is equipped with a prior knowledge-aware historical observation encoding module to achieve those purposes accordingly. Experiments show MetaSTP+ outperforms the best baseline by 11.2% and 8.4% on two real-world datasets. Finally, an intelligent waybill assignment system based on MetaSTP+ is deployed in JD Logistics.",
    "doi": "10.1109/TKDE.2024.3512582",
    "author_keywords": [
      "Delivery data mining",
      "meta-learning",
      "urban computing"
    ],
    "contribution": "Maintaining the design principles of prior work, in this extended paper, we propose MetaSTP+. In addition to fusing the prior knowledge after the meta-learning process, MetaSTP+ also injects the prior knowledge before and during the meta-learning process to better tackle skewed observations. More specifically, MetaSTP+ completes the support set of tasks with scarce samples from other tasks based on prior knowledge and is equipped with a prior knowledge-aware historical observation encoding module to achieve those purposes accordingly. Experiments show MetaSTP+ outperforms the best baseline by 11.2% and 8.4% on two real-world datasets. Finally, an intelligent waybill assignment system based on MetaSTP+ is deployed in JD Logistics.",
    "introduction": "Intelligent logistics relies on accurately predicting the service time, which is a part of time cost in the last-mile delivery. However, service time prediction (STP) is non-trivial given complex delivery circumstances, location heterogeneity, and skewed observations in space, which are not well-handled by existing solutions. In our prior work, we treat STP at each location as a learning task to keep the location heterogeneity, propose a prior knowledge-enhanced meta-learning to tackle skewed observations, and introduce a Transformer-based representation module to encode complex delivery circumstances.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic flow prediction has emerged as a critical component in advancing smart cities. Nevertheless, precisely forecasting traffic flow remains a formidable challenge, attributable to the intricate and dynamic spatiotemporal interdependencies inherent within traffic data. Contemporary methodologies often overlook the different impacts exerted at each timestamp and treat temporal correlations, rendering them incapable of extracting temporal patterns at multiple scales. Furthermore, these approaches fail to account for the neighboring and functional relationships among nodes within the spatial module. In this work, we introduce an innovative Multiscale and Gated transFormer (MSGFormer) architecture, MSGFormer, to overcome the inherent limitations for accurate traffic flow estimation. We have introduced a multiscale sampling strategy wherein we sample from the original data at three scales: 1) recent; 2) daily; and 3) weekly. This approach enables the generation of corresponding subsequences that encapsulate temporal information across different granularities. Subsequently, each generated subsequence is projected into a latent space and systematically combined with positional, temporal, and spatial embeddings. The positional embedding comprises relative positional embedding and time stamp embedding corresponding to days and weeks, aiming at capturing the sequential and cyclical characteristics of the data. Furthermore, at the inception of the transformer encoder, a gated unit, composed of a neighboring mask and a functioning mask, is employed to capture both static and dynamic spatial correlations effectively. Comprehensive experiments have been conducted on four real-world traffic data sets. The experimental results robustly validate that our model attains significantly higher predictive accuracy in comparison to other baseline models.",
    "doi": "10.1109/JIOT.2024.3465559",
    "author_keywords": [
      "Data mining",
      "gated mechanism",
      "spatiotemporal sequence",
      "traffic flow prediction",
      "transformer"
    ],
    "contribution": "In this work, we introduce an innovative Multiscale and Gated transFormer (MSGFormer) architecture, MSGFormer, to overcome the inherent limitations for accurate traffic flow estimation. We have introduced a multiscale sampling strategy wherein we sample from the original data at three scales: 1) recent; 2) daily; and 3) weekly. This approach enables the generation of corresponding subsequences that encapsulate temporal information across different granularities. Subsequently, each generated subsequence is projected into a latent space and systematically combined with positional, temporal, and spatial embeddings. The positional embedding comprises relative positional embedding and time stamp embedding corresponding to days and weeks, aiming at capturing the sequential and cyclical characteristics of the data. Furthermore, at the inception of the transformer encoder, a gated unit, composed of a neighboring mask and a functioning mask, is employed to capture both static and dynamic spatial correlations effectively. Comprehensive experiments have been conducted on four real-world traffic data sets. The experimental results robustly validate that our model attains significantly higher predictive accuracy in comparison to other baseline models.",
    "introduction": "Traffic flow prediction has emerged as a critical component in advancing smart cities. Nevertheless, precisely forecasting traffic flow remains a formidable challenge, attributable to the intricate and dynamic spatiotemporal interdependencies inherent within traffic data. Contemporary methodologies often overlook the different impacts exerted at each timestamp and treat temporal correlations, rendering them incapable of extracting temporal patterns at multiple scales. Furthermore, these approaches fail to account for the neighboring and functional relationships among nodes within the spatial module.",
    "macro_domains": []
  },
  {
    "abstract": "As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.",
    "doi": "10.1016/j.inffus.2024.102606",
    "author_keywords": [
      "Data fusion",
      "Deep learning",
      "Large language models",
      "Multi-modal data",
      "Sustainable development",
      "Urban computing"
    ],
    "contribution": "To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.",
    "introduction": "As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse content intelligently and automatically. To support such artificial intelligence-generated content (AIGC) services, future communication systems must fulfill stringent requirements, including high data rates, throughput, and low latency, while efficiently utilizing limited spectrum resources. Semantic communication (SemCom) has been deemed as a revolutionary communication scheme to tackle this challenge by conveying the meaning of messages instead of bit reproduction. GAI algorithms serve as the foundation for enabling intelligent and efficient SemCom systems in terms of model pre-training and fine-tuning, knowledge base construction, and resource allocation. Conversely, SemCom can provide AIGC services with low latency and high reliability due to its ability to perform semantic-aware encoding and compression of data, as well as knowledge- and context-based reasoning. In this survey, we break new ground by investigating the architecture, wireless communication schemes, and network management of GAI-driven SemCom networks. We first introduce a novel architecture for GAI-driven SemCom networks, comprising the data plane, physical infrastructure, and network control plane. In turn, we provide an in-depth analysis of the transceiver design and semantic effectiveness calculation of end-to-end GAI-driven SemCom systems. Subsequently, we present innovative generation level and knowledge management strategies in the proposed networks, including knowledge construction, update, and sharing, ensuring accurate and timely knowledge-based reasoning. Finally, we explore several promising use cases, i.e., autonomous driving, smart cities, and the Metaverse, to provide a comprehensive understanding and future direction of GAI-driven SemCom networks.",
    "doi": "10.1109/TCCN.2024.3435524",
    "author_keywords": [
      "AIGC",
      "generative AI",
      "intelligent wireless networks",
      "knowledge management",
      "Semantic communication"
    ],
    "contribution": "In this survey, we break new ground by investigating the architecture, wireless communication schemes, and network management of GAI-driven SemCom networks. We first introduce a novel architecture for GAI-driven SemCom networks, comprising the data plane, physical infrastructure, and network control plane. In turn, we provide an in-depth analysis of the transceiver design and semantic effectiveness calculation of end-to-end GAI-driven SemCom systems. Subsequently, we present innovative generation level and knowledge management strategies in the proposed networks, including knowledge construction, update, and sharing, ensuring accurate and timely knowledge-based reasoning. Finally, we explore several promising use cases, i.e., autonomous driving, smart cities, and the Metaverse, to provide a comprehensive understanding and future direction of GAI-driven SemCom networks.",
    "introduction": "Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse content intelligently and automatically. To support such artificial intelligence-generated content (AIGC) services, future communication systems must fulfill stringent requirements, including high data rates, throughput, and low latency, while efficiently utilizing limited spectrum resources. Semantic communication (SemCom) has been deemed as a revolutionary communication scheme to tackle this challenge by conveying the meaning of messages instead of bit reproduction. GAI algorithms serve as the foundation for enabling intelligent and efficient SemCom systems in terms of model pre-training and fine-tuning, knowledge base construction, and resource allocation. Conversely, SemCom can provide AIGC services with low latency and high reliability due to its ability to perform semantic-aware encoding and compression of data, as well as knowledge- and context-based reasoning.",
    "macro_domains": []
  },
  {
    "abstract": "In the environmental security monitoring of smart cities, the infrared and visible image fusion method deployed on intelligent systems based on cloud and fog computing plays a vital role in providing enhanced images for target detection systems. However, the fusion quality can be significantly influenced by the illumination of the monitoring scenario in visible images. Therefore, conventional methods typically suffer a severe performance drop under the condition of insufficient illumination. To tackle this issue, we propose an illumination enhancement and target-aware fusion method-based on artificial intelligence, which breaks the boundaries between the task of illumination enhancement and image fusion and provide a fusion result with better visual perception in nighttime scene. Specifically, we use a light-weight contrast enhancement module restore the brightness of the visible image. Moreover, a Swin Transformer-based backbone network is utilized to facilitate information exchange between the source images and enhance the capabilities of target awareness. Finally, the fused images are reconstructed by the contrast-texture retention module and reconstructor. The extensive experiments indicate that the proposed approach achieves improved performance both in human perception and quantitative analysis compared with the state-of-the-art methods.",
    "doi": "10.1111/exsy.13538",
    "author_keywords": [
      "artificial intelligence",
      "cloud and fog computing",
      "image fusion",
      "smart city",
      "transformer"
    ],
    "contribution": "To tackle this issue, we propose an illumination enhancement and target-aware fusion method-based on artificial intelligence, which breaks the boundaries between the task of illumination enhancement and image fusion and provide a fusion result with better visual perception in nighttime scene. Specifically, we use a light-weight contrast enhancement module restore the brightness of the visible image. Moreover, a Swin Transformer-based backbone network is utilized to facilitate information exchange between the source images and enhance the capabilities of target awareness. Finally, the fused images are reconstructed by the contrast-texture retention module and reconstructor. The extensive experiments indicate that the proposed approach achieves improved performance both in human perception and quantitative analysis compared with the state-of-the-art methods.",
    "introduction": "In the environmental security monitoring of smart cities, the infrared and visible image fusion method deployed on intelligent systems based on cloud and fog computing plays a vital role in providing enhanced images for target detection systems. However, the fusion quality can be significantly influenced by the illumination of the monitoring scenario in visible images. Therefore, conventional methods typically suffer a severe performance drop under the condition of insufficient illumination.",
    "macro_domains": []
  },
  {
    "abstract": "Nowadays, as organisations and companies increasingly harness the power of artificial intelligence (AI), there is a growing need to ensure future professionals in fields such as business and management can possess relevant necessary knowledge, skills, and mindset for navigating the ethical and social implications of AI technologies. This study evaluated the effects of a specialised AI literacy course designed for business students at a university in Hong Kong. The course aimed to equip participants with a basic understanding of AI concepts via self-paced materials, hands-on activities, case study discussion, and design thinking activities. Through a mixed-methods approach involving evaluation surveys and student and teacher reflections, this case study examined how effectively the course developed the students' AI literacies as future business leaders and global digital citizens. AI competencies include understanding basic AI and generative AI (GenAI), using AI applications ethically, critically analysing AI-powered systems, identifying potential societal risks, and making data-driven decisions while upholding ethical principles. The findings provide valuable insights into the role of targeted AI education in preparing the next generation of business professionals for navigating the evolving data landscape and contributing to the responsible advancement of these transformative technologies.",
    "doi": "10.1108/978-1-83608-852-320241010",
    "author_keywords": [
      "AI competency",
      "AI literacy",
      "Business",
      "Digital citizenship",
      "Generative AI",
      "Smart city"
    ],
    "contribution": "This study evaluated the effects of a specialised AI literacy course designed for business students at a university in Hong Kong. The course aimed to equip participants with a basic understanding of AI concepts via self-paced materials, hands-on activities, case study discussion, and design thinking activities. Through a mixed-methods approach involving evaluation surveys and student and teacher reflections, this case study examined how effectively the course developed the students' AI literacies as future business leaders and global digital citizens. AI competencies include understanding basic AI and generative AI (GenAI), using AI applications ethically, critically analysing AI-powered systems, identifying potential societal risks, and making data-driven decisions while upholding ethical principles. The findings provide valuable insights into the role of targeted AI education in preparing the next generation of business professionals for navigating the evolving data landscape and contributing to the responsible advancement of these transformative technologies.",
    "introduction": "Nowadays, as organisations and companies increasingly harness the power of artificial intelligence (AI), there is a growing need to ensure future professionals in fields such as business and management can possess relevant necessary knowledge, skills, and mindset for navigating the ethical and social implications of AI technologies.",
    "macro_domains": []
  },
  {
    "abstract": "Customer satisfaction is not just a significant factor but a cornerstone for smart cities and their organizations that offer services to people. It enhances the organizationâ€™s reputation and profitability and drastically raises the chances of returning customers. Unfortunately, customer support service through online chat is often not rated by customers to help improve the service. This study employs artificial intelligence and data augmentation to predict customer satisfaction ratings from conversations by analyzing the responses of customers and service providers. For the study, the authors obtained actual conversations between customers and real agents from the call center database of Jeddah Municipality that were rated by customers on a scale of 1â€“5. They trained and tested five prediction models with approaches based on logistic regression, random forest, and ensemble-based deep learning, and fine-tuned two pre-trained recent models: ArabicT5 and SaudiBERT. Then, they repeated training and testing models after applying a data augmentation technique using the generative artificial intelligence, GPT-4, to improve the unbalance in customer conversation data. The study found that the ensemble-based deep learning approach best predicts the five-, three-, and two-class classifications. Moreover, data augmentation improved accuracy using the ensemble-based deep learning model with a 1.69% increase and the logistic regression model with a 3.84% increase. This study contributes to the advancement of Arabic opinion mining, as it is the first to report the performance of determining customer satisfaction levels using Arabic conversation data. The implications of this study are significant, as the findings can be applied to improve customer service in various organizations.",
    "doi": "10.3390/bdcc8120196",
    "author_keywords": [
      "Arabic conversation",
      "artificial intelligence",
      "automation",
      "customer satisfaction",
      "data analysis",
      "data augmentation",
      "opinion mining",
      "rating prediction",
      "sentiment analysis",
      "smart cities"
    ],
    "contribution": "This study employs artificial intelligence and data augmentation to predict customer satisfaction ratings from conversations by analyzing the responses of customers and service providers. For the study, the authors obtained actual conversations between customers and real agents from the call center database of Jeddah Municipality that were rated by customers on a scale of 1â€“5. They trained and tested five prediction models with approaches based on logistic regression, random forest, and ensemble-based deep learning, and fine-tuned two pre-trained recent models: ArabicT5 and SaudiBERT. Then, they repeated training and testing models after applying a data augmentation technique using the generative artificial intelligence, GPT-4, to improve the unbalance in customer conversation data. The study found that the ensemble-based deep learning approach best predicts the five-, three-, and two-class classifications. Moreover, data augmentation improved accuracy using the ensemble-based deep learning model with a 1.69% increase and the logistic regression model with a 3.84% increase. This study contributes to the advancement of Arabic opinion mining, as it is the first to report the performance of determining customer satisfaction levels using Arabic conversation data. The implications of this study are significant, as the findings can be applied to improve customer service in various organizations.",
    "introduction": "Customer satisfaction is not just a significant factor but a cornerstone for smart cities and their organizations that offer services to people. It enhances the organizationâ€™s reputation and profitability and drastically raises the chances of returning customers. Unfortunately, customer support service through online chat is often not rated by customers to help improve the service.",
    "macro_domains": []
  },
  {
    "abstract": "Semi-structured decisions, which fall between highly structured and unstructured decision types, rely on human intuition and experience for the final choice, while using data and analytical models to generate tentative solutions. These processes are traditionally iterative and time-consuming, requiring cycles of data gathering, analysis, and option evaluation. In this study, we propose a novel framework that integrates Large Language Models (LLMs) with optimization techniques to streamline such decision-making processes. In our approach, LLMs leverage their capabilities in data interpretation, common-sense reasoning, and mathematical modeling to assist decision makers by reducing cognitive load. They achieve this by automating aspects of information processing and option evaluation, while preserving human oversight as a crucial component of the final decision-making process. Another significant strength of our framework lies in its potential to drive the evolution of a new generation of decision support systems (DSSs). Unlike traditional systems that rely on rigid and inflexible interfaces, our approach enables users to express their preferences in a more natural, intuitive, and adaptable manner, substantially enhancing both usability and accessibility. A case study on last-mile delivery system design in a smart city demonstrates the practical application of this framework. The results suggest that our approach has the potential to simplify the decision-making process and improve efficiency by reducing cognitive load, enhancing user experience, and facilitating more intuitive interactions.",
    "doi": "10.3390/a17120582",
    "author_keywords": [
      "human-in-the-loop",
      "knowledge discovery",
      "large language models",
      "last-mile logistics",
      "semi-structured decisions"
    ],
    "contribution": "In this study, we propose a novel framework that integrates Large Language Models (LLMs) with optimization techniques to streamline such decision-making processes. In our approach, LLMs leverage their capabilities in data interpretation, common-sense reasoning, and mathematical modeling to assist decision makers by reducing cognitive load. They achieve this by automating aspects of information processing and option evaluation, while preserving human oversight as a crucial component of the final decision-making process. Another significant strength of our framework lies in its potential to drive the evolution of a new generation of decision support systems (DSSs). Unlike traditional systems that rely on rigid and inflexible interfaces, our approach enables users to express their preferences in a more natural, intuitive, and adaptable manner, substantially enhancing both usability and accessibility. A case study on last-mile delivery system design in a smart city demonstrates the practical application of this framework. The results suggest that our approach has the potential to simplify the decision-making process and improve efficiency by reducing cognitive load, enhancing user experience, and facilitating more intuitive interactions.",
    "introduction": "Semi-structured decisions, which fall between highly structured and unstructured decision types, rely on human intuition and experience for the final choice, while using data and analytical models to generate tentative solutions. These processes are traditionally iterative and time-consuming, requiring cycles of data gathering, analysis, and option evaluation.",
    "macro_domains": []
  },
  {
    "abstract": "Rapid urbanisation has intensified the need for sustainable solutions to address challenges in urban infrastructure, climate change, and resource constraints. This study reveals that Artificial Intelligence (AI)-enabled metaverse offers transformative potential for developing sustainable smart cities. AI techniques, such as machine learning, deep learning, generative AI (GAI), and large language models (LLMs), enhance the metaverseâ€™s capabilities in data analysis, urban decision making, and personalised user experiences. The study further examines how these advanced AI models facilitate key metaverse technologies such as big data analytics, natural language processing (NLP), computer vision, digital twins, Internet of Things (IoT), Edge AI, and 5G/6G networks. Applications across various smart city domainsâ€”environment, mobility, energy, health, governance, and economy, and real-world use cases of virtual cities like Singapore, Seoul, and Lisbon are presented, demonstrating AIâ€™s effectiveness in the metaverse for smart cities. However, AI-enabled metaverse in smart cities presents challenges related to data acquisition and management, privacy, security, interoperability, scalability, and ethical considerations. These challengesâ€™ societal and technological implications are discussed, highlighting the need for robust data governance frameworks and AI ethics guidelines. Future directions emphasise advancing AI model architectures and algorithms, enhancing privacy and security measures, promoting ethical AI practices, addressing performance measures, and fostering stakeholder collaboration. By addressing these challenges, the full potential of AI-enabled metaverse can be harnessed to enhance sustainability, adaptability, and livability in smart cities.",
    "doi": "10.3390/electronics13244874",
    "author_keywords": [
      "adaptive urban systems",
      "artificial intelligence",
      "digital twins",
      "generative AI",
      "large language models",
      "metaverse",
      "smart cities",
      "sustainable cities",
      "urban planning",
      "urban transformation"
    ],
    "contribution": "This study reveals that Artificial Intelligence (AI)-enabled metaverse offers transformative potential for developing sustainable smart cities. AI techniques, such as machine learning, deep learning, generative AI (GAI), and large language models (LLMs), enhance the metaverseâ€™s capabilities in data analysis, urban decision making, and personalised user experiences. The study further examines how these advanced AI models facilitate key metaverse technologies such as big data analytics, natural language processing (NLP), computer vision, digital twins, Internet of Things (IoT), Edge AI, and 5G/6G networks. Applications across various smart city domainsâ€”environment, mobility, energy, health, governance, and economy, and real-world use cases of virtual cities like Singapore, Seoul, and Lisbon are presented, demonstrating AIâ€™s effectiveness in the metaverse for smart cities. However, AI-enabled metaverse in smart cities presents challenges related to data acquisition and management, privacy, security, interoperability, scalability, and ethical considerations. These challengesâ€™ societal and technological implications are discussed, highlighting the need for robust data governance frameworks and AI ethics guidelines. Future directions emphasise advancing AI model architectures and algorithms, enhancing privacy and security measures, promoting ethical AI practices, addressing performance measures, and fostering stakeholder collaboration. By addressing these challenges, the full potential of AI-enabled metaverse can be harnessed to enhance sustainability, adaptability, and livability in smart cities.",
    "introduction": "Rapid urbanisation has intensified the need for sustainable solutions to address challenges in urban infrastructure, climate change, and resource constraints.",
    "macro_domains": []
  },
  {
    "abstract": "Efficient traffic flow is crucial for sustainable cities, as it directly impacts energy consumption, pollution levels, and overall quality of life. The integration of superficial intelligence, particularly transformer models, plays a significant role in enhancing the predictive capabilities for traffic management, thereby supporting sustainable urban development. In this survey, we explored the application of transformer models to predict and optimize traffic flow in sustainable cities. These models leverage advanced machine learning to capture intricate spatiotemporal patterns,thereby providing valuable insights for urban planners and traffic management centers. By systematically reviewing the literature, we emphasize the importance of transformer models in urban planning and sustainable resource use. Our study demonstrates how transformer models can learn complex spatiotemporal patterns from traffic data by incorporating both real-time and historical data to enhance prediction accuracy. This improved predictive capability aids the development of smart cities by reducing traffic congestion, facilitating smoother movement for city dwellers and tourists, and ultimately contributing to the sustainability goals of urban areas. This comprehensive review highlights the transformative potential of predictive modeling using transformer models, underscoring their critical role in optimizing urban infrastructure and promoting sustainable city development.",
    "doi": "10.1016/j.scs.2024.105882",
    "author_keywords": [
      "Predictive modeling",
      "Sustainable cities",
      "Traffic flow prediction",
      "Traffic management",
      "Transformer models",
      "Urban planning"
    ],
    "contribution": "In this survey, we explored the application of transformer models to predict and optimize traffic flow in sustainable cities. These models leverage advanced machine learning to capture intricate spatiotemporal patterns,thereby providing valuable insights for urban planners and traffic management centers. By systematically reviewing the literature, we emphasize the importance of transformer models in urban planning and sustainable resource use. Our study demonstrates how transformer models can learn complex spatiotemporal patterns from traffic data by incorporating both real-time and historical data to enhance prediction accuracy. This improved predictive capability aids the development of smart cities by reducing traffic congestion, facilitating smoother movement for city dwellers and tourists, and ultimately contributing to the sustainability goals of urban areas. This comprehensive review highlights the transformative potential of predictive modeling using transformer models, underscoring their critical role in optimizing urban infrastructure and promoting sustainable city development.",
    "introduction": "Efficient traffic flow is crucial for sustainable cities, as it directly impacts energy consumption, pollution levels, and overall quality of life. The integration of superficial intelligence, particularly transformer models, plays a significant role in enhancing the predictive capabilities for traffic management, thereby supporting sustainable urban development.",
    "macro_domains": []
  },
  {
    "abstract": "Emerging as a paradigmatic shift in urban development, smart cities harness the potential of advanced information and communication technologies to seamlessly integrate urban functions, optimize resource allocation, and improve the effectiveness of city management. Within the domain of smart education, the imperative application of Visual Question Answering (VQA) technology encounters significant limitations at the prevailing stage, particularly the absence of a robust Internet of Things (IoT) framework and the inadequate incorporation of large pre-trained language models (LLMs) within contemporary smart education paradigms, especially in addressing zero-shot VQA scenarios, which pose considerable challenges. In response to these constraints, this paper introduces an IoT-based smart city framework that is designed to refine the functionality and efficacy of educational systems. This framework is delineated into four cardinal layers: the data collection layer, data transmission layer, data management layer, and application layer. Furthermore, we introduce the innovative TeachVQA methodology at the application layer, synergizing VQA technology with extensive pre-trained language models, thereby considerably enhancing the dissemination and assimilation of educational content. Evaluative metrics in the VQAv2 and OKVQA datasets substantiate that the TeachVQA methodology not only outperforms existing VQA approaches, but also underscores its profound potential and practical relevance in the educational sector.",
    "doi": "10.1016/j.aej.2024.09.059",
    "author_keywords": [
      "IoT framework",
      "Large language models",
      "Smart cities",
      "Smart education technology",
      "Visual question answering"
    ],
    "contribution": "In response to these constraints, this paper introduces an IoT-based smart city framework that is designed to refine the functionality and efficacy of educational systems. This framework is delineated into four cardinal layers: the data collection layer, data transmission layer, data management layer, and application layer. Furthermore, we introduce the innovative TeachVQA methodology at the application layer, synergizing VQA technology with extensive pre-trained language models, thereby considerably enhancing the dissemination and assimilation of educational content. Evaluative metrics in the VQAv2 and OKVQA datasets substantiate that the TeachVQA methodology not only outperforms existing VQA approaches, but also underscores its profound potential and practical relevance in the educational sector.",
    "introduction": "Emerging as a paradigmatic shift in urban development, smart cities harness the potential of advanced information and communication technologies to seamlessly integrate urban functions, optimize resource allocation, and improve the effectiveness of city management. Within the domain of smart education, the imperative application of Visual Question Answering (VQA) technology encounters significant limitations at the prevailing stage, particularly the absence of a robust Internet of Things (IoT) framework and the inadequate incorporation of large pre-trained language models (LLMs) within contemporary smart education paradigms, especially in addressing zero-shot VQA scenarios, which pose considerable challenges.",
    "macro_domains": []
  },
  {
    "abstract": "In the intelligent transportation management of smart cities, traffic forecasting is crucial. The optimization of traffic flow, reduction of congestion, and improvement of the overall transportation system efficiency all depend on accurate traffic pattern projections. In order to overcome the difficulties caused by the complexity and diversity of urban traffic dynamics, this research suggests a unique method for multi-modal traffic forecasting combining Graph Neural Networks (GNNs) and Transformer-based multi-source visual fusion. GNNs are employed in this method to capture the spatial connections between various road segments and to properly reflect the basic structure of the road network. The model's ability to effectively analyse traffic dynamics and relationships between nearby locations is enhanced by graphs representing the road layout, which also increases the outcome of traffic predictions. Recursive Feature Elimination (RFE) is employed to improve the model's feature selection process and choose the most pertinent features for traffic prediction, producing forecasts that are more effective and precise. Utilizing real-time data, the performance of the suggested strategy was assessed, enabling it to adjust to shifting traffic patterns and deliver precise projections for intelligent transportation management. The empirical outcomes show exceptional results of performance metrics for the proposed approach, achieving an amazing accuracy of 99%. The results show that the suggested techniqueâ€™s findings have the ability to anticipate traffic and exhibit a superior level of reliability which supports efficient transportation management in smart cities.",
    "doi": "10.1007/s13177-024-00413-4",
    "author_keywords": [
      "Congestion forecasting",
      "Graph neural networks",
      "Multi-modal traffic forecasting",
      "Recursive feature elimination",
      "Smart cities",
      "Transformer-based multi-source visual fusion"
    ],
    "contribution": "In order to overcome the difficulties caused by the complexity and diversity of urban traffic dynamics, this research suggests a unique method for multi-modal traffic forecasting combining Graph Neural Networks (GNNs) and Transformer-based multi-source visual fusion. GNNs are employed in this method to capture the spatial connections between various road segments and to properly reflect the basic structure of the road network. The model's ability to effectively analyse traffic dynamics and relationships between nearby locations is enhanced by graphs representing the road layout, which also increases the outcome of traffic predictions. Recursive Feature Elimination (RFE) is employed to improve the model's feature selection process and choose the most pertinent features for traffic prediction, producing forecasts that are more effective and precise. Utilizing real-time data, the performance of the suggested strategy was assessed, enabling it to adjust to shifting traffic patterns and deliver precise projections for intelligent transportation management. The empirical outcomes show exceptional results of performance metrics for the proposed approach, achieving an amazing accuracy of 99%. The results show that the suggested techniqueâ€™s findings have the ability to anticipate traffic and exhibit a superior level of reliability which supports efficient transportation management in smart cities.",
    "introduction": "In the intelligent transportation management of smart cities, traffic forecasting is crucial. The optimization of traffic flow, reduction of congestion, and improvement of the overall transportation system efficiency all depend on accurate traffic pattern projections.",
    "macro_domains": []
  },
  {
    "abstract": "The Internet of Things (IoT) permeates various sectors, including healthcare, smart cities, and agriculture, alongside critical infrastructure management. However, its susceptibility to malware due to limited processing power and security protocols poses significant challenges. Traditional antimalware solutions fall short in combating evolving threats. To address this, the research work developed a feature selection-based classification model. At first stage, a preprocessing stage enhances dataset quality through data smoothing and consistency improvement. Feature selection via the Zebra Optimization Algorithm (ZOA) reduces dimensionality, while a classification phase integrates the Graph Attention Network (GAN), specifically the Dual-channel GAN (DGAN). DGAN incorporates Node Attention Networks and Semantic Attention Networks to capture intricate IoT device interactions and detect anomalous behaviors like botnet activity. The model's accuracy is further boosted by leveraging both structural and semantic data with the Sooty Tern Optimization Algorithm (STOA) for hyperparameter tuning. The proposed STOA-DGAN model achieves an impressive 99.87% accuracy in botnet activity classification, showcasing robustness and reliability compared to existing approaches.",
    "doi": "10.1038/s41598-024-67865-2",
    "author_keywords": [
      "Graph attention network",
      "Internet of things",
      "Node attention networks",
      "Sooty Tern optimization algorithm",
      "Zebra optimization algorithm"
    ],
    "contribution": "To address this, the research work developed a feature selection-based classification model. At first stage, a preprocessing stage enhances dataset quality through data smoothing and consistency improvement. Feature selection via the Zebra Optimization Algorithm (ZOA) reduces dimensionality, while a classification phase integrates the Graph Attention Network (GAN), specifically the Dual-channel GAN (DGAN). DGAN incorporates Node Attention Networks and Semantic Attention Networks to capture intricate IoT device interactions and detect anomalous behaviors like botnet activity. The model's accuracy is further boosted by leveraging both structural and semantic data with the Sooty Tern Optimization Algorithm (STOA) for hyperparameter tuning. The proposed STOA-DGAN model achieves an impressive 99.87% accuracy in botnet activity classification, showcasing robustness and reliability compared to existing approaches.",
    "introduction": "The Internet of Things (IoT) permeates various sectors, including healthcare, smart cities, and agriculture, alongside critical infrastructure management. However, its susceptibility to malware due to limited processing power and security protocols poses significant challenges. Traditional antimalware solutions fall short in combating evolving threats.",
    "macro_domains": []
  },
  {
    "abstract": "Industrial developments and consumption of massive amount of fossil fuels, vehicle pollution, and other calamities upsurges the AQI (Air Quality Index) of major cities in a drastic manner. Owing to these factors, it is important to take proactive measures for reducing the air pollution in order to avoid life- threatening consequence. Therefore, prediction of air quality is significant for improving the health of living beings as highly polluted regions have a higher concentration of pollutants mixed in the air, affecting the respiratory system and reducing the lifetime. To control pollution, AQI is used as a measure for estimating the pollutant content in the air. Even though many existing techniques have predicted AQI, enhancement is required in prediction algorithms with minimized loss. To address the challenges in traditional algorithms, the proposed smart cities-based AQI prediction intends to utilize the proposed regression algorithm in the dataset, namely Air- Quality-Data, which collected harmful pollutants on an hourly and daily basis from multiple cities in India between 2015 to 2020. To achieve prediction efficiency with reduced loss, pre-processing of input data is being performed using Deep GAN (Generative Adversarial Network). It performs the imputation of data in place of missing values to improve accurate prediction. Additionally, feature scaling normalizes independent real-data features to a fixed scale. With the processed data, regression is done through modified Stacked Attention GRU with KL divergence, which predicts Ernakulam, Chennai and Ahmedabad cities with higher, medium, and low levels of AQI in India. The performance of the proposed regression algorithm is measured using metrics such as MAE (Mean Absolute Error), MSE (Mean Square Error), R2 (Coefficient of determination), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Square Error) and better MAE, MSE, R2, MAPE and RMSE obtained by the model is 0.1013, 0.0134, 0.9479, 0.1152 and 0.1156. Internal assessment and comparative analysis performed with existing regression algorithms exhibit lower loss values obtained from the present research, which determines the efficacy of the proposed model.",
    "doi": "10.1007/s43621-024-00272-9",
    "author_keywords": [
      "Ahmedabad",
      "Air quality index",
      "Chennai",
      "Deep generative adversarial network",
      "Ernakulam",
      "Modified stacked attention GRU",
      "Pollutants",
      "Regression"
    ],
    "contribution": "",
    "introduction": "Industrial developments and consumption of massive amount of fossil fuels, vehicle pollution, and other calamities upsurges the AQI (Air Quality Index) of major cities in a drastic manner. Owing to these factors, it is important to take proactive measures for reducing the air pollution in order to avoid life- threatening consequence. Therefore, prediction of air quality is significant for improving the health of living beings as highly polluted regions have a higher concentration of pollutants mixed in the air, affecting the respiratory system and reducing the lifetime. To control pollution, AQI is used as a measure for estimating the pollutant content in the air. Even though many existing techniques have predicted AQI, enhancement is required in prediction algorithms with minimized loss. To address the challenges in traditional algorithms, the proposed smart cities-based AQI prediction intends to utilize the proposed regression algorithm in the dataset, namely Air- Quality-Data, which collected harmful pollutants on an hourly and daily basis from multiple cities in India between 2015 to 2020. To achieve prediction efficiency with reduced loss, pre-processing of input data is being performed using Deep GAN (Generative Adversarial Network). It performs the imputation of data in place of missing values to improve accurate prediction. Additionally, feature scaling normalizes independent real-data features to a fixed scale. With the processed data, regression is done through modified Stacked Attention GRU with KL divergence, which predicts Ernakulam, Chennai and Ahmedabad cities with higher, medium, and low levels of AQI in India. The performance of the proposed regression algorithm is measured using metrics such as MAE (Mean Absolute Error), MSE (Mean Square Error), R2 (Coefficient of determination), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Square Error) and better MAE, MSE, R2, MAPE and RMSE obtained by the model is 0.1013, 0.0134, 0.9479, 0.1152 and 0.1156. Internal assessment and comparative analysis performed with existing regression algorithms exhibit lower loss values obtained from the present research, which determines the efficacy of the proposed model.",
    "macro_domains": []
  },
  {
    "abstract": "Infrared (IR) human action recognition (AR) exhibits resilience against shifting illumination conditions, changes in appearance, and shadows. It has valuable applications in numerous areas of future sustainable and smart cities including robotics, intelligent systems, security, and transportation. However, current IR-based recognition approaches predominantly concentrate on spatial or local temporal information and often overlook the potential value of global temporal patterns. This oversight can lead to incomplete representations of body part movements and prevent accurate optimization of a network. Therefore, a contextual-motion coalescence network (CMCNet) is proposed that operates in a streamlined and end-to-end manner for robust action representation in darkness in a near-infrared (NIR) setting. Initially, data are preprocessed to separate foreground, normalized, and resized. The framework employs two parallel modules: the contextual visual features learning module (CVFLM) for local feature extraction, and the temporal optical flow learning module (TOFLM) for acquiring motion dynamics. These modules focus on action-relevant regions used shift window-based operations to ensure accurate interpretation of motion information. The coalescence block harmoniously integrates the contextual and motion features within a unified framework. Finally, the temporal decoder module discriminatively identifies the boundaries of the action sequence. This sequence of steps ensures the synergistic optimization of both CVFLM and TOFLM and thorough competent feature extraction for precise AR. Evaluations of CMCNet are carried out on publicly available datasets, InfAR and NTURGB-D, where superior performance is achieved. Our model yields the highest average precision of 89% and 85% on these datasets, respectively, representing an improvement of 2.25% (on InfAR) compared to conventional methods operating at spatial and optical flow levels which underscores its efficacy.",
    "doi": "10.1016/j.knosys.2024.112480",
    "author_keywords": [
      "Computer vision",
      "Deep learning",
      "Human activity recognition",
      "Networks fusion",
      "Transformer network"
    ],
    "contribution": "",
    "introduction": "Infrared (IR) human action recognition (AR) exhibits resilience against shifting illumination conditions, changes in appearance, and shadows. It has valuable applications in numerous areas of future sustainable and smart cities including robotics, intelligent systems, security, and transportation. However, current IR-based recognition approaches predominantly concentrate on spatial or local temporal information and often overlook the potential value of global temporal patterns. This oversight can lead to incomplete representations of body part movements and prevent accurate optimization of a network. Therefore, a contextual-motion coalescence network (CMCNet) is proposed that operates in a streamlined and end-to-end manner for robust action representation in darkness in a near-infrared (NIR) setting. Initially, data are preprocessed to separate foreground, normalized, and resized. The framework employs two parallel modules: the contextual visual features learning module (CVFLM) for local feature extraction, and the temporal optical flow learning module (TOFLM) for acquiring motion dynamics. These modules focus on action-relevant regions used shift window-based operations to ensure accurate interpretation of motion information. The coalescence block harmoniously integrates the contextual and motion features within a unified framework. Finally, the temporal decoder module discriminatively identifies the boundaries of the action sequence. This sequence of steps ensures the synergistic optimization of both CVFLM and TOFLM and thorough competent feature extraction for precise AR. Evaluations of CMCNet are carried out on publicly available datasets, InfAR and NTURGB-D, where superior performance is achieved. Our model yields the highest average precision of 89% and 85% on these datasets, respectively, representing an improvement of 2.25% (on InfAR) compared to conventional methods operating at spatial and optical flow levels which underscores its efficacy.",
    "macro_domains": []
  },
  {
    "abstract": "Equitable urban transportation applications require high-fidelity digital representations of the built environment (streets, crossings, curb ramps and more). Direct inspections and manual annotations are costly at scale, while conventional machine learning methods require substantial annotated training data for adequate performance. This study explores vision language models as a tool for annotating diverse urban features from satellite images, reducing the dependence on human annotation. Although these models excel at describing common objects in human-centric images, their training sets may lack signals for esoteric built environment features, making their performance uncertain. We demonstrate a proof-of-concept using a vision language model and a visual prompting strategy that considers segmented image elements. Experiments on two urban features - stop lines and raised tables - show that while zero-shot prompting rarely works, the segmentation and visual prompting strategies achieve nearly 40% intersection-over-union accuracy. We describe how these results motivate further research in automatic annotation of the built environment to improve equity, accessibility, and safety at scale and in diverse environments.",
    "doi": "10.1145/3678717.3691296",
    "author_keywords": [
      "Image Segmentation",
      "Large Language Model",
      "Urban Computing",
      "Urban Data Annotation",
      "Vision Language Model"
    ],
    "contribution": "This study explores vision language models as a tool for annotating diverse urban features from satellite images, reducing the dependence on human annotation. Although these models excel at describing common objects in human-centric images, their training sets may lack signals for esoteric built environment features, making their performance uncertain. We demonstrate a proof-of-concept using a vision language model and a visual prompting strategy that considers segmented image elements. Experiments on two urban features - stop lines and raised tables - show that while zero-shot prompting rarely works, the segmentation and visual prompting strategies achieve nearly 40% intersection-over-union accuracy. We describe how these results motivate further research in automatic annotation of the built environment to improve equity, accessibility, and safety at scale and in diverse environments.",
    "introduction": "Equitable urban transportation applications require high-fidelity digital representations of the built environment (streets, crossings, curb ramps and more). Direct inspections and manual annotations are costly at scale, while conventional machine learning methods require substantial annotated training data for adequate performance.",
    "macro_domains": []
  },
  {
    "abstract": "Understanding and predicting Origin-Destination (OD) flows is crucial for urban planning and transportation management. Traditional OD prediction models, while effective within single cities, often face limitations when applied across different cities due to varied traffic conditions, urban layouts, and socio-economic factors. In this paper, by employing Large Language Models (LLMs), we introduce a new method for cross-city OD flow prediction. Our approach leverages the advanced semantic understanding and contextual learning capabilities of LLMs to bridge the gap between cities with different characteristics, providing a robust and adaptable solution for accurate OD flow prediction that can be transferred from one city to another. Our novel framework involves four major components: collecting OD training datasets from a source city, instruction-tuning the LLMs, predicting destination POIs in a target city, and identifying the locations that best match the predicted destination POIs. We introduce a new loss function that integrates POI semantics and trip distance during training. By extracting high-quality semantic features from human mobility and POI data, the model understands spatial and functional relationships within urban spaces and captures interactions between individuals and various POIs. Extensive experimental results demonstrate the superiority of our approach over the state-of-the-art learning-based methods in cross-city OD flow prediction.",
    "doi": "10.1145/3678717.3691308",
    "author_keywords": [
      "Cross-City Transferability",
      "Large Language Models(LLMs)",
      "origin-destination",
      "Urban Computing"
    ],
    "contribution": "In this paper, by employing Large Language Models (LLMs), we introduce a new method for cross-city OD flow prediction. Our approach leverages the advanced semantic understanding and contextual learning capabilities of LLMs to bridge the gap between cities with different characteristics, providing a robust and adaptable solution for accurate OD flow prediction that can be transferred from one city to another. Our novel framework involves four major components: collecting OD training datasets from a source city, instruction-tuning the LLMs, predicting destination POIs in a target city, and identifying the locations that best match the predicted destination POIs. We introduce a new loss function that integrates POI semantics and trip distance during training. By extracting high-quality semantic features from human mobility and POI data, the model understands spatial and functional relationships within urban spaces and captures interactions between individuals and various POIs. Extensive experimental results demonstrate the superiority of our approach over the state-of-the-art learning-based methods in cross-city OD flow prediction.",
    "introduction": "Understanding and predicting Origin-Destination (OD) flows is crucial for urban planning and transportation management. Traditional OD prediction models, while effective within single cities, often face limitations when applied across different cities due to varied traffic conditions, urban layouts, and socio-economic factors.",
    "macro_domains": []
  },
  {
    "abstract": "Intelligent analysis of user generated content (UGC) plays an important role in ensuring urban natural gas safety and controlling process risks. However, most existing analysis methods are single-task driven and ignore the spatio-temporal information of gas sensing data. To address these problems, we propose a Transformer-based cyber-physical social security system (CPSS) for UGC analysis. Specifically, this unified system integrates multiple tasks, i.e. quality assessment and control of gas data, security factors of user consumption, and spatio-temporal abnormal gas signal detection. In the developed Transformer-based model, a time-space cross-attention module is embedded for combining the long-range spatio-temporal dependences of gas data. Moreover, a feature memory block module is introduced for abnormal feature enhancement and high-level representation of gas quality. Experimental results on related gas datasets demonstrate that this Transformer-based method achieves state-of-the-art performance, and the security system significantly improves the safety factor of natural gas use in smart cities, providing a robust framework for risk management and safety enhancement.",
    "doi": "10.1016/j.apenergy.2024.123947",
    "author_keywords": [
      "CPSS",
      "Security system",
      "Transformer",
      "Urban natural gas",
      "User generated content"
    ],
    "contribution": "To address these problems, we propose a Transformer-based cyber-physical social security system (CPSS) for UGC analysis. Specifically, this unified system integrates multiple tasks, i.e. quality assessment and control of gas data, security factors of user consumption, and spatio-temporal abnormal gas signal detection. In the developed Transformer-based model, a time-space cross-attention module is embedded for combining the long-range spatio-temporal dependences of gas data. Moreover, a feature memory block module is introduced for abnormal feature enhancement and high-level representation of gas quality. Experimental results on related gas datasets demonstrate that this Transformer-based method achieves state-of-the-art performance, and the security system significantly improves the safety factor of natural gas use in smart cities, providing a robust framework for risk management and safety enhancement.",
    "introduction": "Intelligent analysis of user generated content (UGC) plays an important role in ensuring urban natural gas safety and controlling process risks. However, most existing analysis methods are single-task driven and ignore the spatio-temporal information of gas sensing data.",
    "macro_domains": []
  },
  {
    "abstract": "The exponential increase in urban population necessitates the emergence of transportation systems that are both effective and sustainable, using the potential modern technology. The issue of dynamic traffic flow significantly impedes the movement of vehicles. Traffic congestion is a critical issue affecting urban mobility and efficiency in cities worldwide, with Bangalore no exception. This study addresses the challenge of leveraging advanced predictive analytics and intelligent transport systems to manage traffic congestion. The proposed research aims to address the limitations of traditional traffic management strategies by integrating the Temporal Fusion Transformer (TFT) model into an Intelligent Transport System (ITS) framework. The research employs rigorous data preprocessing techniques to leverage extensive data from multiple online map service providers and traffic monitoring platforms, spanning from January 1, 2019, to December 31, 2023. The TFT model forecasts traffic congestion with notable precision, achieving a Mean Absolute Error (MAE) of 0.39, Mean Squared Error (MSE) of 0.30, Root Mean Squared Error (RMSE) of 0.55, Mean Absolute Percentage Error (MAPE) of 7.2%, and an R-squared (RÂ²) value of 0.87. The outcomes obtained clearly illustrate the modelâ€™s superior accuracy and efficacy. Integrating TFT predictions into the ITS framework enhances real-time traffic control by improving the timings of traffic signals, recommending alternative routes, and improving incident management. This proactive approach significantly reduces traffic congestion and enhances travel efficiency, substantially advancing urban traffic management solutions.",
    "doi": "10.14445/23488549/IJECE-V11I11P117",
    "author_keywords": [
      "Intelligent Transport System",
      "Smart city",
      "Temporal Fusion Transformer",
      "Traffic congestion",
      "Traffic volume"
    ],
    "contribution": "This study addresses the challenge of leveraging advanced predictive analytics and intelligent transport systems to manage traffic congestion. The proposed research aims to address the limitations of traditional traffic management strategies by integrating the Temporal Fusion Transformer (TFT) model into an Intelligent Transport System (ITS) framework. The research employs rigorous data preprocessing techniques to leverage extensive data from multiple online map service providers and traffic monitoring platforms, spanning from January 1, 2019, to December 31, 2023. The TFT model forecasts traffic congestion with notable precision, achieving a Mean Absolute Error (MAE) of 0.39, Mean Squared Error (MSE) of 0.30, Root Mean Squared Error (RMSE) of 0.55, Mean Absolute Percentage Error (MAPE) of 7.2%, and an R-squared (RÂ²) value of 0.87. The outcomes obtained clearly illustrate the modelâ€™s superior accuracy and efficacy. Integrating TFT predictions into the ITS framework enhances real-time traffic control by improving the timings of traffic signals, recommending alternative routes, and improving incident management. This proactive approach significantly reduces traffic congestion and enhances travel efficiency, substantially advancing urban traffic management solutions.",
    "introduction": "The exponential increase in urban population necessitates the emergence of transportation systems that are both effective and sustainable, using the potential modern technology. The issue of dynamic traffic flow significantly impedes the movement of vehicles. Traffic congestion is a critical issue affecting urban mobility and efficiency in cities worldwide, with Bangalore no exception.",
    "macro_domains": []
  },
  {
    "abstract": "The United Nations 2030 Agenda defines the priorities and aspirations for global development based on seventeen ambitious sustainable development goals encompassing economic, environmental, and social dimensions. Tourism plays a vital role in the list of actions for the people and the planet. While the tourism industry drives economic growth, its environmental and social impact is equally high. Sustainable tourism aims to reduce the damage caused by the tourism industry, protect communities, and guarantee the industryâ€™s long-term future. These changes require touristsâ€™ collective and concerted effort. The question arises whether tourists are willing to be more demanding about sustainability when looking for a destination. This study uses artificial intelligence to classify a new trend in European citizensâ€™ search for sustainable destinations and to generate intelligent recommendations. Using data from the Flash Eurobarometer 499, we use a tree-based algorithm, random forest, to obtain intelligent citizens classification systems supported by machine learning. The classification system explores the predisposition of citizens to contribute to the three pillars of sustainability when choosing a destination to visit based on gender, age, and the region of living. We found that European citizens place little emphasis on the social sustainability pillar. While they care about preserving the environment, this competes with the cultural offerings and availability of activities at the destination. Additionally, we found that the willingness to contribute to the three pillars of sustainability varies by gender, age, and European region.",
    "doi": "10.3390/su16229844",
    "author_keywords": [
      "economic sustainability",
      "environmental sustainability",
      "generative artificial intelligence",
      "machine learning",
      "social sustainability",
      "sustainable destinations",
      "sustainable development",
      "tourism sustainability"
    ],
    "contribution": "This study uses artificial intelligence to classify a new trend in European citizensâ€™ search for sustainable destinations and to generate intelligent recommendations. Using data from the Flash Eurobarometer 499, we use a tree-based algorithm, random forest, to obtain intelligent citizens classification systems supported by machine learning. The classification system explores the predisposition of citizens to contribute to the three pillars of sustainability when choosing a destination to visit based on gender, age, and the region of living. We found that European citizens place little emphasis on the social sustainability pillar. While they care about preserving the environment, this competes with the cultural offerings and availability of activities at the destination. Additionally, we found that the willingness to contribute to the three pillars of sustainability varies by gender, age, and European region.",
    "introduction": "The United Nations 2030 Agenda defines the priorities and aspirations for global development based on seventeen ambitious sustainable development goals encompassing economic, environmental, and social dimensions. Tourism plays a vital role in the list of actions for the people and the planet. While the tourism industry drives economic growth, its environmental and social impact is equally high. Sustainable tourism aims to reduce the damage caused by the tourism industry, protect communities, and guarantee the industryâ€™s long-term future. These changes require touristsâ€™ collective and concerted effort. The question arises whether tourists are willing to be more demanding about sustainability when looking for a destination.",
    "macro_domains": []
  },
  {
    "abstract": "Fire and smoke detection technologies face challenges in complex and dynamic environments. Traditional detectors are vulnerable to background noise, lighting changes, and similar objects (e.g., clouds, steam, dust), leading to high false alarm rates. Additionally, they struggle with detecting small objects, limiting their effectiveness in early fire warnings and rapid responses. As real-time monitoring demands grow, traditional methods often fall short in smart city and drone applications. To address these issues, we propose FireNet, integrating a simplified Vision Transformer (RepViT) to enhance global feature learning while reducing computational overhead. Dynamic snake convolution (DSConv) captures fine boundary details of flames and smoke, especially in complex curved edges. A lightweight decoupled detection head optimizes classification and localization, ideal for high inter-class similarity and small targets. FireNet outperforms YOLOv8 on the Fire Scene dataset (FSD) with a mAP@0.5 of 80.2%, recall of 78.4%, and precision of 82.6%, with an inference time of 26.7 ms. It also excels on the FSD dataset, addressing current fire detection challenges.",
    "doi": "10.3390/rs16214112",
    "author_keywords": [
      "decoupled detection head",
      "DSConv",
      "fire and smoke detection",
      "RepVit",
      "YOLO"
    ],
    "contribution": "To address these issues, we propose FireNet, integrating a simplified Vision Transformer (RepViT) to enhance global feature learning while reducing computational overhead. Dynamic snake convolution (DSConv) captures fine boundary details of flames and smoke, especially in complex curved edges. A lightweight decoupled detection head optimizes classification and localization, ideal for high inter-class similarity and small targets. FireNet outperforms YOLOv8 on the Fire Scene dataset (FSD) with a mAP@0.5 of 80.2%, recall of 78.4%, and precision of 82.6%, with an inference time of 26.7 ms. It also excels on the FSD dataset, addressing current fire detection challenges.",
    "introduction": "Fire and smoke detection technologies face challenges in complex and dynamic environments. Traditional detectors are vulnerable to background noise, lighting changes, and similar objects (e.g., clouds, steam, dust), leading to high false alarm rates. Additionally, they struggle with detecting small objects, limiting their effectiveness in early fire warnings and rapid responses. As real-time monitoring demands grow, traditional methods often fall short in smart city and drone applications.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic flow forecasting is integral to the advancement of intelligent transportation systems and the development of smart cities. This paper introduces a novel model, the Spatialâ€“Temporal Similarity Fusion Graphs Adversarial Convolutional Networks (STSF-GACN), which leverages advanced data preprocessing techniques to enhance the predictive accuracy and efficiency of traffic flow forecasting. The innovation of our approach lies in the meticulous construction of the spatialâ€“temporal similarity matrix through the precise calculation of temporal and spatial similarities. This matrix forms the backbone of our model, serving as the generator in the integrated Generative Adversarial Network (GAN) architecture. The Spatialâ€“Temporal Similarity Fusion Adaptive Graph Convolutional Network, developed as part of our GAN's generator, utilizes cutting-edge techniques such as the Wasserstein distance and Dynamic Time Warping to optimize the adaptive adjacency matrix, enabling the model to capture latent spatialâ€“temporal correlations with unprecedented depth and precision. The discriminator of the GAN further refines the model by evaluating the accuracy of the traffic predictions, ensuring that the generative model produces results that are not only accurate but also robust against varying traffic conditions. This cohesive integration of GAN into the model architecture allows for a significant improvement in prediction accuracy and convergence speed, moving beyond traditional forecasting methods.",
    "doi": "10.1016/j.jfranklin.2024.107299",
    "author_keywords": [
      "Graph Convolutional Neural Network",
      "Similarity measure",
      "Traffic flow forecasting"
    ],
    "contribution": "This paper introduces a novel model, the Spatialâ€“Temporal Similarity Fusion Graphs Adversarial Convolutional Networks (STSF-GACN), which leverages advanced data preprocessing techniques to enhance the predictive accuracy and efficiency of traffic flow forecasting. The innovation of our approach lies in the meticulous construction of the spatialâ€“temporal similarity matrix through the precise calculation of temporal and spatial similarities. This matrix forms the backbone of our model, serving as the generator in the integrated Generative Adversarial Network (GAN) architecture. The Spatialâ€“Temporal Similarity Fusion Adaptive Graph Convolutional Network, developed as part of our GAN's generator, utilizes cutting-edge techniques such as the Wasserstein distance and Dynamic Time Warping to optimize the adaptive adjacency matrix, enabling the model to capture latent spatialâ€“temporal correlations with unprecedented depth and precision. The discriminator of the GAN further refines the model by evaluating the accuracy of the traffic predictions, ensuring that the generative model produces results that are not only accurate but also robust against varying traffic conditions. This cohesive integration of GAN into the model architecture allows for a significant improvement in prediction accuracy and convergence speed, moving beyond traditional forecasting methods.",
    "introduction": "Traffic flow forecasting is integral to the advancement of intelligent transportation systems and the development of smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "The integration of large-scale solar photovoltaic (PV) systems in urban environments requires careful consideration of network planning to ensure a reliable power supply and mitigate challenges. This study focuses on the impact of urban network planning such as wide solar-battery integration and demand response strategy on smart cities. Specifically, it investigates the effects of urban network planning on medium-voltage (MV) networks, with a case study conducted in Malaysia. The substation considered in the research consists of two parallel transformers, 13 lines, and 38 connection points. Each urban load connection point is equipped with 500 kW of solar PV capacity and 1 kWh of battery Energy Storage (BES) to store excess power generated from solar injecting it into the urban network during peak periods. The demand response strategy in this study mainly focuses on the Time of Use (ToU) strategy, encouraging customers to reduce usage during peak load periods and shift it to off-peak periods. Dynamic simulations using Power Factory software are performed to evaluate the effectiveness of the proposed mitigation techniques. The results indicate that each of the demand response and wide solar-battery integration strategies technique significantly improves the performance of the urban network by reducing voltage fluctuations and minimizing power losses. However, the study reveals that integrating these two techniques dramatically improves the system's performance. This study highlights the importance of incorporating urban network planning in smart cities. It enables reliable and efficient utilization of solar energy while maintaining grid stability.",
    "doi": "10.1016/j.est.2024.113789",
    "author_keywords": [
      "Demand response planning",
      "Energy storage",
      "Large-scale solar",
      "Solar energy",
      "Time of use",
      "Urban network planning"
    ],
    "contribution": "This study focuses on the impact of urban network planning such as wide solar-battery integration and demand response strategy on smart cities. Specifically, it investigates the effects of urban network planning on medium-voltage (MV) networks, with a case study conducted in Malaysia. The substation considered in the research consists of two parallel transformers, 13 lines, and 38 connection points. Each urban load connection point is equipped with 500 kW of solar PV capacity and 1 kWh of battery Energy Storage (BES) to store excess power generated from solar injecting it into the urban network during peak periods. The demand response strategy in this study mainly focuses on the Time of Use (ToU) strategy, encouraging customers to reduce usage during peak load periods and shift it to off-peak periods. Dynamic simulations using Power Factory software are performed to evaluate the effectiveness of the proposed mitigation techniques. The results indicate that each of the demand response and wide solar-battery integration strategies technique significantly improves the performance of the urban network by reducing voltage fluctuations and minimizing power losses. However, the study reveals that integrating these two techniques dramatically improves the system's performance. This study highlights the importance of incorporating urban network planning in smart cities. It enables reliable and efficient utilization of solar energy while maintaining grid stability.",
    "introduction": "The integration of large-scale solar photovoltaic (PV) systems in urban environments requires careful consideration of network planning to ensure a reliable power supply and mitigate challenges.",
    "macro_domains": []
  },
  {
    "abstract": "In smart cities, sustainable development depends on energy load prediction since it directs utilities in effectively planning, distributing and generating energy. This work presents a novel hybrid deep learning model including components of the Improved-convolutional neural network (CNN), bidirectional long short-term memory (Bi-LSTM), Graph neural network (GNN), Transformer and Fusion Layer architectures for precise energy load forecasting. Better feature extraction results from the Improved-CNN's dilated convolution and residual block accommodation of wide receptive fields reduced the vanishing gradient problem. By capturing temporal links in both directions, Bi-LSTM networks help to better grasp complicated energy use patterns. Graph neural networks improve predictive capacities across linked systems by characterizing the spatial relationships between energy-consuming units in smart cities. Emphasizing critical trends to guarantee reliable forecasts, transformer models use attention methods to manage long-term dependencies in energy consumption data. Combining CNN, Bi-LSTM, Transformer and GNN component predictions in a Fusion Layer synthesizes numerous data representations to increase accuracy. With Root Mean Square Error of 5.7532 Wh, Mean Absolute Percentage Error of 3.5001%, Mean Absolute Error of 6.7532 Wh and R2 of 0.9701, the hybrid model fared better than other models on the â€˜Electric Power Consumptionâ€™ Kaggle dataset. This work develops a realistic model that helps informed decision-making and enhances energy efficiency techniques, promoting energy load forecasting in smart cities.",
    "doi": "10.1177/01445987241267822",
    "author_keywords": [
      "Bi-LSTM",
      "deep learning",
      "Energy load prediction",
      "GNN",
      "improved-CNN",
      "sustainable development"
    ],
    "contribution": "This work presents a novel hybrid deep learning model including components of the Improved-convolutional neural network (CNN), bidirectional long short-term memory (Bi-LSTM), Graph neural network (GNN), Transformer and Fusion Layer architectures for precise energy load forecasting. Better feature extraction results from the Improved-CNN's dilated convolution and residual block accommodation of wide receptive fields reduced the vanishing gradient problem. By capturing temporal links in both directions, Bi-LSTM networks help to better grasp complicated energy use patterns. Graph neural networks improve predictive capacities across linked systems by characterizing the spatial relationships between energy-consuming units in smart cities. Emphasizing critical trends to guarantee reliable forecasts, transformer models use attention methods to manage long-term dependencies in energy consumption data. Combining CNN, Bi-LSTM, Transformer and GNN component predictions in a Fusion Layer synthesizes numerous data representations to increase accuracy. With Root Mean Square Error of 5.7532 Wh, Mean Absolute Percentage Error of 3.5001%, Mean Absolute Error of 6.7532 Wh and R2 of 0.9701, the hybrid model fared better than other models on the â€˜Electric Power Consumptionâ€™ Kaggle dataset. This work develops a realistic model that helps informed decision-making and enhances energy efficiency techniques, promoting energy load forecasting in smart cities.",
    "introduction": "In smart cities, sustainable development depends on energy load prediction since it directs utilities in effectively planning, distributing and generating energy.",
    "macro_domains": []
  },
  {
    "abstract": "In the context of rapidly urbanizing smart cities reliant on IoT networks, efficient load management is critical for sustainable energy use. This paper proposes an AI-enhanced Multi-Stage Learning-to-Learning (MSLL) approach tailored for secure load management in IoT networks. The proposed approach leverages MMStransformer, a transformer-based model designed to handle multivariate, correlated data, and to capture long-range dependencies inherent in load forecasting. MMStransformer employs a multi-mask learning-to-learning strategy, optimizing computational efficiency without compromising prediction accuracy. The study addresses the dynamic and complex nature of smart city data by integrating diverse environmental and operational variables. Security and privacy concerns inherent in IoT networks are also addressed, ensuring secure data handling and communication. Experimental results demonstrate the efficacy of the proposed approach, achieving competitive performance compared to traditional methods and baseline models. The findings highlight the potential of AI-driven solutions in enhancing load forecasting accuracy while ensuring robust security measures in smart city infrastructures. This research contributes to advancing the state-of-the-art in AI applications for sustainable urban development and energy management.",
    "doi": "10.1016/j.adhoc.2024.103628",
    "author_keywords": [
      "AI-enhanced",
      "IoT networks",
      "Load management",
      "MMStransformer",
      "Smart cities"
    ],
    "contribution": "This paper proposes an AI-enhanced Multi-Stage Learning-to-Learning (MSLL) approach tailored for secure load management in IoT networks. The proposed approach leverages MMStransformer, a transformer-based model designed to handle multivariate, correlated data, and to capture long-range dependencies inherent in load forecasting. MMStransformer employs a multi-mask learning-to-learning strategy, optimizing computational efficiency without compromising prediction accuracy. The study addresses the dynamic and complex nature of smart city data by integrating diverse environmental and operational variables. Security and privacy concerns inherent in IoT networks are also addressed, ensuring secure data handling and communication. Experimental results demonstrate the efficacy of the proposed approach, achieving competitive performance compared to traditional methods and baseline models. The findings highlight the potential of AI-driven solutions in enhancing load forecasting accuracy while ensuring robust security measures in smart city infrastructures. This research contributes to advancing the state-of-the-art in AI applications for sustainable urban development and energy management.",
    "introduction": "In the context of rapidly urbanizing smart cities reliant on IoT networks, efficient load management is critical for sustainable energy use.",
    "macro_domains": []
  },
  {
    "abstract": "The Internet of Things (IoT) is an evolving paradigm that has dramatically transformed the traditional style of living into a smart lifestyle. IoT devices have recently attained great attention due to their wide range of applications in various sectors, such as healthcare, smart home devices, smart industries, smart cities, and so forth. However, security is still a challenging issue in the IoT environment. Because of the disparate nature of IoT devices, it is hard to detect the different kinds of attacks available in IoT. Various existing works aim to provide a reliable intrusion detection system (IDS) technique. But they failed to work because of several security issues. Thus, the proposed study presents a blockchain-based deep learning model for IDS. Initially, the input data are preprocessed using min-max normalization, converting the raw input data into improved quality. In order to detect the presented attacks in the provided dataset, the proposed work introduced Gaussian mixtureâ€“fully convolutional variational autoencoder (GM-FCVAE) model. The implementation is performed in Python, and the performance of the proposed GM-FCVAE model is analyzed by evaluating several metrics. The proposed GM-FCVAE model is tested on three datasets and attained superior accuracy of 99.18%, 98.81%, and 98.4% with UNSW-NB15, CICIDS 2019, and N_BaIoT datasets, respectively. The comparison reveals that the proposed GM-FCVAE model obtained higher results than the other deep learning techniques. The outperformance shows the efficacy of the proposed study in identifying security attacks.",
    "doi": "10.1002/nem.2295",
    "author_keywords": [
      "blockchain",
      "improved proof of work (I-PoW)",
      "Internet of Things (IoT)",
      "intrusion detection system (IDS)",
      "preprocessing",
      "variational autoencoder (VAE)"
    ],
    "contribution": "",
    "introduction": "The Internet of Things (IoT) is an evolving paradigm that has dramatically transformed the traditional style of living into a smart lifestyle. IoT devices have recently attained great attention due to their wide range of applications in various sectors, such as healthcare, smart home devices, smart industries, smart cities, and so forth. However, security is still a challenging issue in the IoT environment. Because of the disparate nature of IoT devices, it is hard to detect the different kinds of attacks available in IoT. Various existing works aim to provide a reliable intrusion detection system (IDS) technique. But they failed to work because of several security issues. Thus, the proposed study presents a blockchain-based deep learning model for IDS. Initially, the input data are preprocessed using min-max normalization, converting the raw input data into improved quality. In order to detect the presented attacks in the provided dataset, the proposed work introduced Gaussian mixtureâ€“fully convolutional variational autoencoder (GM-FCVAE) model. The implementation is performed in Python, and the performance of the proposed GM-FCVAE model is analyzed by evaluating several metrics. The proposed GM-FCVAE model is tested on three datasets and attained superior accuracy of 99.18%, 98.81%, and 98.4% with UNSW-NB15, CICIDS 2019, and N_BaIoT datasets, respectively. The comparison reveals that the proposed GM-FCVAE model obtained higher results than the other deep learning techniques. The outperformance shows the efficacy of the proposed study in identifying security attacks.",
    "macro_domains": []
  },
  {
    "abstract": "Weapon detection is the process of identifying handheld weapons such as guns, knives, etc., and creating a bounding box around them to highlight the spatial locations. Weapon detection is one of the key building blocks of the intelligent video surveillance system for security applications in smart cities. However, detecting handheld weapons from surveillance videos is quite challenging due to small object size, occlusion, illumination variation, model complexity, and latency. Hence, an efficient, novel, robust, and lightweight YOLOv8-based weapon detector with GhostNet backbone and C3 module with transformer block (C3TR) neck (YOLO-GTWDNet model) is proposed for detecting the weapons either from stored images or from the live video streams. The proposed model is trained using a weapon dataset named â€œWeapon7,â€ which is developed by collecting various weapon classes, such as Axe, Bow and arrow, Gun, Knife, Lathi, Pistol, and Sword, from various publicly available datasets, Internet, and own camera capture. Extensive experimental analysis is carried out to demonstrate the effectiveness of the proposed YOLO-GTWDNet model. The proposed model outperforms the state-of-the-art models when compared using both quantitative and qualitative performance metrics. The deployment of the proposed model is expected to bolster public safety significantly, providing city authorities with a powerful tool to mitigate risks and swiftly address potential threats.",
    "doi": "10.1007/s11760-024-03458-w",
    "author_keywords": [
      "C3TR",
      "Deep learning",
      "GhostNet",
      "Weapon detection",
      "Weapon7 dataset",
      "YOLO-GTWDNet model",
      "YOLOv8"
    ],
    "contribution": "",
    "introduction": "Weapon detection is the process of identifying handheld weapons such as guns, knives, etc., and creating a bounding box around them to highlight the spatial locations. Weapon detection is one of the key building blocks of the intelligent video surveillance system for security applications in smart cities. However, detecting handheld weapons from surveillance videos is quite challenging due to small object size, occlusion, illumination variation, model complexity, and latency. Hence, an efficient, novel, robust, and lightweight YOLOv8-based weapon detector with GhostNet backbone and C3 module with transformer block (C3TR) neck (YOLO-GTWDNet model) is proposed for detecting the weapons either from stored images or from the live video streams. The proposed model is trained using a weapon dataset named â€œWeapon7,â€ which is developed by collecting various weapon classes, such as Axe, Bow and arrow, Gun, Knife, Lathi, Pistol, and Sword, from various publicly available datasets, Internet, and own camera capture. Extensive experimental analysis is carried out to demonstrate the effectiveness of the proposed YOLO-GTWDNet model. The proposed model outperforms the state-of-the-art models when compared using both quantitative and qualitative performance metrics. The deployment of the proposed model is expected to bolster public safety significantly, providing city authorities with a powerful tool to mitigate risks and swiftly address potential threats.",
    "macro_domains": []
  },
  {
    "abstract": "Inferring the fine-grained urban flows based on the coarse-grained flow observations is practically important to many smart city-related applications. Adequate data is usually a prerequisite for existing machine learning methods, especially most deep learning models. However, many cities still suffer from the data scarcity issue due to the unbalanced city development levels. To mitigate this issue, we propose a novel cross-city fine-grained urban flow inference model named FGITrans, which aims to effectively transfer the knowledge from the data-rich cities to the data-scarce cities. Specifically, we design a weight-sharing triple-branch transformer framework which adopts self-attention and cross-attention for source/target city feature learning and domain alignment, respectively. Then, we propose a novel spatio-temporal adaptive embedding (STAE) layer for our transformer framework, and introduce a cross-city knowledge distillation (CKD) loss to narrow the cross-city disparities. The CKD loss explicitly enforces the framework to learn the discriminative domain-specific and domain-invariant representations simultaneously. Extensive experiments conducted on four large real-world datasets validate the effectiveness of FGITrans compared with the state-of-the-art baselines.",
    "doi": "10.1145/3627673.3679855",
    "author_keywords": [
      "spatial-temporal data mining",
      "transfer learning",
      "urban flow inference"
    ],
    "contribution": "To mitigate this issue, we propose a novel cross-city fine-grained urban flow inference model named FGITrans, which aims to effectively transfer the knowledge from the data-rich cities to the data-scarce cities. Specifically, we design a weight-sharing triple-branch transformer framework which adopts self-attention and cross-attention for source/target city feature learning and domain alignment, respectively. Then, we propose a novel spatio-temporal adaptive embedding (STAE) layer for our transformer framework, and introduce a cross-city knowledge distillation (CKD) loss to narrow the cross-city disparities. The CKD loss explicitly enforces the framework to learn the discriminative domain-specific and domain-invariant representations simultaneously. Extensive experiments conducted on four large real-world datasets validate the effectiveness of FGITrans compared with the state-of-the-art baselines.",
    "introduction": "Inferring the fine-grained urban flows based on the coarse-grained flow observations is practically important to many smart city-related applications. Adequate data is usually a prerequisite for existing machine learning methods, especially most deep learning models. However, many cities still suffer from the data scarcity issue due to the unbalanced city development levels.",
    "macro_domains": []
  },
  {
    "abstract": "Inferring the fine-grained urban traffic flows based on the coarse-grained traffic flow observations is practically important to many real applications for smart city. Existing approaches mostly rely on a large number of high quality urban flow data, but neglect the data sparsity issue which is common in real-world scenarios. Therefore, the performance of existing methods may not be promising towards cities that lack sufficient traffic flow data. How to design a more generalizable urban flow inference model that is able to effectively transfer knowledge across multiple cities is challenging and remains as an open research problem. In this paper, we propose a novel fine-grained urban flow inference model named AdaTM, which leverages the city-specific and city-invariant knowledge extracted from multiple cities. Specifically, we first propose a transformer-based urban feature extraction network named UBFormer to comprehensively extract the spatial-temporal features of multiple source cities. Then, we incorporate a learnable integrator to fuse the city-invariant and city-specific feature representations for the target city with sparse traffic flow data. Finally, we construct the feature representation of the target city through adaptive feature fusion and infer its fine-grained urban flows through the designed urban flow upsampler. Extensive experiments conducted on four large real-world datasets demonstrate the effectiveness of our approach.",
    "doi": "10.1145/3627673.3679856",
    "author_keywords": [
      "domain generalization",
      "spatial-temporal data mining",
      "urban flow inference"
    ],
    "contribution": "In this paper, we propose a novel fine-grained urban flow inference model named AdaTM, which leverages the city-specific and city-invariant knowledge extracted from multiple cities. Specifically, we first propose a transformer-based urban feature extraction network named UBFormer to comprehensively extract the spatial-temporal features of multiple source cities. Then, we incorporate a learnable integrator to fuse the city-invariant and city-specific feature representations for the target city with sparse traffic flow data. Finally, we construct the feature representation of the target city through adaptive feature fusion and infer its fine-grained urban flows through the designed urban flow upsampler. Extensive experiments conducted on four large real-world datasets demonstrate the effectiveness of our approach.",
    "introduction": "Inferring the fine-grained urban traffic flows based on the coarse-grained traffic flow observations is practically important to many real applications for smart city. Existing approaches mostly rely on a large number of high quality urban flow data, but neglect the data sparsity issue which is common in real-world scenarios. Therefore, the performance of existing methods may not be promising towards cities that lack sufficient traffic flow data. How to design a more generalizable urban flow inference model that is able to effectively transfer knowledge across multiple cities is challenging and remains as an open research problem.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate spatio-temporal prediction is crucial for the sustainable development of smart cities. However, current approaches often struggle to capture important spatio-temporal relationships, particularly overlooking global relations among distant city regions. Most existing techniques predominantly rely on Convolutional Neural Networks (CNNs) to capture global relations. However, CNNs exhibit neighbourhood bias, making them insufficient for capturing distant relations. To address this limitation, we propose ST-SAMPLENET, a novel transformer-based architecture that combines CNNs with self-attention mechanisms to capture both local and global relations effectively. Moreover, as the number of regions increases, the quadratic complexity of self-attention becomes a challenge. To tackle this issue, we introduce a lightweight region sampling strategy that prunes non-essential regions and enhances the efficiency of our approach. Furthermore, we introduce a spatially constrained position embedding that incorporates spatial neighbourhood information into the self-attention mechanism, aiding in semantic interpretation and improving the performance of ST-SAMPLENET. Our experimental evaluation on three real-world datasets demonstrates the effectiveness of ST-SAMPLENET. Additionally, our efficient variant achieves a 40% reduction in computational costs with only a marginal compromise in performance, approximately 1%.",
    "doi": "10.3233/FAIA240813",
    "author_keywords": null,
    "contribution": "To address this limitation, we propose ST-SAMPLENET, a novel transformer-based architecture that combines CNNs with self-attention mechanisms to capture both local and global relations effectively. Moreover, as the number of regions increases, the quadratic complexity of self-attention becomes a challenge. To tackle this issue, we introduce a lightweight region sampling strategy that prunes non-essential regions and enhances the efficiency of our approach. Furthermore, we introduce a spatially constrained position embedding that incorporates spatial neighbourhood information into the self-attention mechanism, aiding in semantic interpretation and improving the performance of ST-SAMPLENET. Our experimental evaluation on three real-world datasets demonstrates the effectiveness of ST-SAMPLENET. Additionally, our efficient variant achieves a 40% reduction in computational costs with only a marginal compromise in performance, approximately 1%.",
    "introduction": "Accurate spatio-temporal prediction is crucial for the sustainable development of smart cities. However, current approaches often struggle to capture important spatio-temporal relationships, particularly overlooking global relations among distant city regions. Most existing techniques predominantly rely on Convolutional Neural Networks (CNNs) to capture global relations. However, CNNs exhibit neighbourhood bias, making them insufficient for capturing distant relations.",
    "macro_domains": []
  },
  {
    "abstract": "Spatio-temporal prediction tasks play a crucial role in facilitating informed decision-making through anticipatory insights. By accurately predicting future outcomes, the ability to strategize, preemptively address risks, and minimize their potential impact is enhanced. The precision in forecasting spatial and temporal patterns holds significant potential for optimizing resource allocation, land utilization, and infrastructure development. While existing review and survey papers predominantly focus on specific forecasting domains such as intelligent transportation, urban planning, pandemics, disease prediction, climate and weather forecasting, environmental data prediction, and agricultural yield projection, limited attention has been devoted to comprehensive surveys encompassing multiple objects concurrently. This article addresses this gap by comprehensively analyzing techniques employed in traffic, pandemics, disease forecasting, climate and weather prediction, agricultural yield estimation, and environmental data prediction. Furthermore, it elucidates challenges inherent in spatio-temporal forecasting and outlines potential avenues for future research exploration.",
    "doi": "10.1145/3696661",
    "author_keywords": [
      "Agricultural Datasets",
      "Forecasting",
      "Graph Neural Networks",
      "Pandemic Datasets",
      "Spatio-Temporal Data",
      "Transformers",
      "Transportation",
      "Urban Computing",
      "Weather/Climate Datasets"
    ],
    "contribution": "This article addresses this gap by comprehensively analyzing techniques employed in traffic, pandemics, disease forecasting, climate and weather prediction, agricultural yield estimation, and environmental data prediction. Furthermore, it elucidates challenges inherent in spatio-temporal forecasting and outlines potential avenues for future research exploration.",
    "introduction": "Spatio-temporal prediction tasks play a crucial role in facilitating informed decision-making through anticipatory insights. By accurately predicting future outcomes, the ability to strategize, preemptively address risks, and minimize their potential impact is enhanced. The precision in forecasting spatial and temporal patterns holds significant potential for optimizing resource allocation, land utilization, and infrastructure development. While existing review and survey papers predominantly focus on specific forecasting domains such as intelligent transportation, urban planning, pandemics, disease prediction, climate and weather forecasting, environmental data prediction, and agricultural yield projection, limited attention has been devoted to comprehensive surveys encompassing multiple objects concurrently.",
    "macro_domains": []
  },
  {
    "abstract": "Automatic road interpretation using remote sensing images is crucial for intelligent city construction and is widely applied in various domains such as automatic driving navigation, cartography, and urban planning. Recently, deep learning algorithms, especially for convolutional neural networks (CNNs) and Transformers, have been utilized with large-scale remote sensing datasets to extract abundant semantic features, significantly improving the accuracy and efficiency of road extraction. However, these models ignore the correlation between multiscale local context and global semantics, which could cause fragmentary prediction in complex remote sensing environments. In addition, the edge features of roads often cannot be accurately constructed due to the lack of semantic guidance. To address the aforementioned issues, this study developed a hybrid deep neural network integrating CNN and Transformer structures. In the encoder, a multiscale global attention pyramid (MGAP) is constructed to enhance the overall semantic representation of the road with a local context. The road edge perceptron is designed in the decoder to improve edge prediction accuracy by establishing hierarchical spatial attention. Quantitative experiments and visual analysis on two public road datasets have confirmed that the proposed network architecture and modules can improve road extraction accuracy with high efficiency (achieving an average 71% IOU and 83% F1 score).",
    "doi": "10.1109/LGRS.2024.3478847",
    "author_keywords": [
      "Convolutional neural network (CNN)",
      "deep learning",
      "remote sensing image",
      "road extraction",
      "transformer"
    ],
    "contribution": "To address the aforementioned issues, this study developed a hybrid deep neural network integrating CNN and Transformer structures. In the encoder, a multiscale global attention pyramid (MGAP) is constructed to enhance the overall semantic representation of the road with a local context. The road edge perceptron is designed in the decoder to improve edge prediction accuracy by establishing hierarchical spatial attention. Quantitative experiments and visual analysis on two public road datasets have confirmed that the proposed network architecture and modules can improve road extraction accuracy with high efficiency (achieving an average 71% IOU and 83% F1 score).",
    "introduction": "Automatic road interpretation using remote sensing images is crucial for intelligent city construction and is widely applied in various domains such as automatic driving navigation, cartography, and urban planning. Recently, deep learning algorithms, especially for convolutional neural networks (CNNs) and Transformers, have been utilized with large-scale remote sensing datasets to extract abundant semantic features, significantly improving the accuracy and efficiency of road extraction. However, these models ignore the correlation between multiscale local context and global semantics, which could cause fragmentary prediction in complex remote sensing environments. In addition, the edge features of roads often cannot be accurately constructed due to the lack of semantic guidance.",
    "macro_domains": []
  },
  {
    "abstract": "This editorial for issue 11.2 of the Journal of Urban Cultural Studies follows from a reading of Richard Sennettâ€™s book Building and Dwelling (2018), in which the urban thinker discusses the user-friendly city, among other topics. Following first The Craftsman (2008) and second Together (2012), Building and Dwelling is the third volume in his Homo Faber series, a reflection on the relationship between head and hand. Here Sennettâ€™s remarks on user-friendliness and technology serve as a launching point for assessing what is at stake in the rise of generative artificial intelligence for long-form writing.",
    "doi": "10.1386/jucs_00085_2",
    "author_keywords": [
      "artificial intelligence",
      "editing",
      "libraries",
      "smart city",
      "urban planning",
      "writing"
    ],
    "contribution": "",
    "introduction": "This editorial for issue 11.2 of the Journal of Urban Cultural Studies follows from a reading of Richard Sennettâ€™s book Building and Dwelling (2018), in which the urban thinker discusses the user-friendly city, among other topics. Following first The Craftsman (2008) and second Together (2012), Building and Dwelling is the third volume in his Homo Faber series, a reflection on the relationship between head and hand. Here Sennettâ€™s remarks on user-friendliness and technology serve as a launching point for assessing what is at stake in the rise of generative artificial intelligence for long-form writing.",
    "macro_domains": []
  },
  {
    "abstract": "The advancement to Urban 4.0 requires urban digitization and predictive maintenance of infrastructure to improve efficiency, durability, and quality of life. This study aims to integrate intelligent technologies for the predictive maintenance of photovoltaic panel systems, which serve as essential smart city renewable energy sources. In addition, we employ vision transformers (ViT), a deep learning architecture devoted to evolving image analysis, to detect anomalies in PV systems. The ViT model is pre-trained on ImageNet to exploit a comprehensive set of relevant visual features from the PV images and classify the input PV panel. Furthermore, the developed system was integrated into a web application that allows users to upload PV images, automatically detect anomalies, and provide detailed panel information, such as PV panel type, defect probability, and anomaly status. A comparative study using several convolutional neural network architectures (VGG, ResNet, and AlexNet) and the ViT transformer was conducted. Therefore, the adopted ViT model performs excellently in anomaly detection, where the ViT achieves an AUC of 0.96. Finally, the proposed approach excels at the prompt identification of potential defects detection, reducing maintenance costs, advancing equipment lifetime, and optimizing PV system implementation.",
    "doi": "10.3390/technologies12100192",
    "author_keywords": [
      "anomalies detection",
      "computer vision",
      "deep transformer",
      "predictive maintenance",
      "software application",
      "Urban 4.0"
    ],
    "contribution": "This study aims to integrate intelligent technologies for the predictive maintenance of photovoltaic panel systems, which serve as essential smart city renewable energy sources. In addition, we employ vision transformers (ViT), a deep learning architecture devoted to evolving image analysis, to detect anomalies in PV systems. The ViT model is pre-trained on ImageNet to exploit a comprehensive set of relevant visual features from the PV images and classify the input PV panel. Furthermore, the developed system was integrated into a web application that allows users to upload PV images, automatically detect anomalies, and provide detailed panel information, such as PV panel type, defect probability, and anomaly status. A comparative study using several convolutional neural network architectures (VGG, ResNet, and AlexNet) and the ViT transformer was conducted. Therefore, the adopted ViT model performs excellently in anomaly detection, where the ViT achieves an AUC of 0.96. Finally, the proposed approach excels at the prompt identification of potential defects detection, reducing maintenance costs, advancing equipment lifetime, and optimizing PV system implementation.",
    "introduction": "The advancement to Urban 4.0 requires urban digitization and predictive maintenance of infrastructure to improve efficiency, durability, and quality of life.",
    "macro_domains": []
  },
  {
    "abstract": "Person and vehicle re-identification has been a popular subject in the field of the computer vision technologies. Existing closed-set re-identification surpasses human-level accuracies on commonly used benchmarks, and the research focus for re-identification is shifting to the open world-setting. The latter setting is more suitable for practical applications, however, is less developed due to its challenges. On the other hand, existing research is more focused on person re-identification, even though both, person and vehicle, are important components for smart city applications. This review attempts to combine for the first time the problem of person and vehicle re-identification under closed and open settings, its challenges, and the existing research. Specifically, we start from the origin of the re-identification task and then summarize state-of-the-art research based on deep learning in different scenarios: person or vehicle or unified re-identification in closed- and open-world settings. Additionally, we analyse a new method for solving the re-identification task using the Transformer, a model architecture that relies entirely on an attention mechanism, which shows promising results. This survey facilitates future research by providing a summary on past and present trends, and aids to improve the usability of re-ID techniques.",
    "doi": "10.1007/s42979-024-03271-9",
    "author_keywords": [
      "Closed-world re-identification",
      "Open-set re-identification",
      "Open-world re-identification",
      "Person re-identification",
      "Vehicle re-identification"
    ],
    "contribution": "Existing closed-set re-identification surpasses human-level accuracies on commonly used benchmarks, and the research focus for re-identification is shifting to the open world-setting. The latter setting is more suitable for practical applications, however, is less developed due to its challenges. On the other hand, existing research is more focused on person re-identification, even though both, person and vehicle, are important components for smart city applications. This review attempts to combine for the first time the problem of person and vehicle re-identification under closed and open settings, its challenges, and the existing research. Specifically, we start from the origin of the re-identification task and then summarize state-of-the-art research based on deep learning in different scenarios: person or vehicle or unified re-identification in closed- and open-world settings. Additionally, we analyse a new method for solving the re-identification task using the Transformer, a model architecture that relies entirely on an attention mechanism, which shows promising results. This survey facilitates future research by providing a summary on past and present trends, and aids to improve the usability of re-ID techniques.",
    "introduction": "Person and vehicle re-identification has been a popular subject in the field of the computer vision technologies.",
    "macro_domains": []
  },
  {
    "abstract": "The development of smart cities holds immense significance in shaping a nation's urban fabric and effectively addressing urban challenges that profoundly impact the economy. Among these challenges, road accidents pose a significant obstacle to urban progress, affecting lives, supply chain efficiency, and socioeconomic well-being. To address this issue effectively, accurate forecasting of road accidents is crucial for policy formulation and enhancing safety measures. Time series forecasting of road accidents provides invaluable insights for devising strategies, enabling swift actions in the short term to reduce accident rates, and informing well-informed road design and safety management policies for the long term, including the implementation of flyovers, and the enhancement of road quality to withstand all weather conditions. Deep Learning's exceptional pattern recognition capabilities have made it a favored approach for accident forecasting. The study comprehensively evaluates deep learning models, such as RNN, LSTM, CNN+LSTM, GRU, Transformer, and MLP, using a ten-year dataset from the esteemed Smart Road Accident Database in Hubballi-Dharwad. The findings unequivocally underscore LSTM's superiority, exhibiting lower errors in both yearly (RMSE: 0.291, MAE: 0.271, MAPE: 6.674%) and monthly (RMSE: 0.186, MAE: 0.176, MAPE: 5.850%) variations. Based on these compelling findings, the study provides strategic recommendations to urban development authorities, emphasizing comprehensive policy frameworks encompassing short-term and long-term measures to reduce accident rates alongside meticulous safety measures and infrastructure planning. By leveraging insights from deep learning models, urban development authorities can adeptly shape the urban landscape, fostering safer environments and contributing to global safety and prosperity.",
    "doi": "10.22115/scce.2023.399598.1654",
    "author_keywords": [
      "Accident",
      "Deep Learning (DL)",
      "Policy-making",
      "Time Series Forecasting (TSF)"
    ],
    "contribution": "The study comprehensively evaluates deep learning models, such as RNN, LSTM, CNN+LSTM, GRU, Transformer, and MLP, using a ten-year dataset from the esteemed Smart Road Accident Database in Hubballi-Dharwad. The findings unequivocally underscore LSTM's superiority, exhibiting lower errors in both yearly (RMSE: 0.291, MAE: 0.271, MAPE: 6.674%) and monthly (RMSE: 0.186, MAE: 0.176, MAPE: 5.850%) variations. Based on these compelling findings, the study provides strategic recommendations to urban development authorities, emphasizing comprehensive policy frameworks encompassing short-term and long-term measures to reduce accident rates alongside meticulous safety measures and infrastructure planning. By leveraging insights from deep learning models, urban development authorities can adeptly shape the urban landscape, fostering safer environments and contributing to global safety and prosperity.",
    "introduction": "The development of smart cities holds immense significance in shaping a nation's urban fabric and effectively addressing urban challenges that profoundly impact the economy. Among these challenges, road accidents pose a significant obstacle to urban progress, affecting lives, supply chain efficiency, and socioeconomic well-being. To address this issue effectively, accurate forecasting of road accidents is crucial for policy formulation and enhancing safety measures. Time series forecasting of road accidents provides invaluable insights for devising strategies, enabling swift actions in the short term to reduce accident rates, and informing well-informed road design and safety management policies for the long term, including the implementation of flyovers, and the enhancement of road quality to withstand all weather conditions. Deep Learning's exceptional pattern recognition capabilities have made it a favored approach for accident forecasting.",
    "macro_domains": []
  },
  {
    "abstract": "One of the crucial issues for power grids in strengthening the urbanization around the world is imbalance between supply and demand, which leads the users to consume electricity in an anomalous manner without paying for it. Electricity theft plays a pivotal role in cutting down on the electricity bills. The existing data-oriented approaches for electricity theft detection (ETD) in the smart cities have limited ability to handle noisy high-dimensional data and featuresâ€™ associations. These limitations raise the misclassification rate, which makes some of the approaches unacceptable for electric utilities. A new twofold end-to-end methodology is proposed for ETD. In the first fold, it groups the similar electricity consumption (EC) cases through grey wolf optimization (GWO)-based clustering mechanism; clustering by fast search and find of density peaks (CFSFDP), we named it GC. In the second fold, a new relational stacked denoising autoencoder (RSDAE)-based semi-supervised generative adversarial network (GAN), termed as RGAN, is used for ETD. The combined methodology is named as GC-RGAN. In the methodology, RSDAE acts as both feature extraction technique and generator sub-model of the proposed RGAN. The proposed methodology utilizes the advantages of clustering, adversarial learning and semi-supervised EC data. Besides, to validate the effectiveness of the proposed solution, extensive simulations are performed using smart meter data. Simulation results validate the excellent ETD performance of the proposed GC-RGAN against existing ETD schemes, such as random forest and semi-supervised support vector machine. In comparison, GC-RGAN covers the ETD score of 98% that shows its suitability for real-world scenarios. The proposed solution has extraordinary performance for ETD as compared to traditional solutions, which shows its superiority and usefulness for real-world applications.",
    "doi": "10.1007/s00202-024-02362-3",
    "author_keywords": [
      "Anomalous electricity consumption",
      "Electricity theft detection",
      "Grey wolf optimization",
      "Relational stacked denoising autoencoder",
      "Semi-supervised GAN",
      "Smart cities",
      "Urban planning"
    ],
    "contribution": "",
    "introduction": "One of the crucial issues for power grids in strengthening the urbanization around the world is imbalance between supply and demand, which leads the users to consume electricity in an anomalous manner without paying for it. Electricity theft plays a pivotal role in cutting down on the electricity bills. The existing data-oriented approaches for electricity theft detection (ETD) in the smart cities have limited ability to handle noisy high-dimensional data and featuresâ€™ associations. These limitations raise the misclassification rate, which makes some of the approaches unacceptable for electric utilities. A new twofold end-to-end methodology is proposed for ETD. In the first fold, it groups the similar electricity consumption (EC) cases through grey wolf optimization (GWO)-based clustering mechanism; clustering by fast search and find of density peaks (CFSFDP), we named it GC. In the second fold, a new relational stacked denoising autoencoder (RSDAE)-based semi-supervised generative adversarial network (GAN), termed as RGAN, is used for ETD. The combined methodology is named as GC-RGAN. In the methodology, RSDAE acts as both feature extraction technique and generator sub-model of the proposed RGAN. The proposed methodology utilizes the advantages of clustering, adversarial learning and semi-supervised EC data. Besides, to validate the effectiveness of the proposed solution, extensive simulations are performed using smart meter data. Simulation results validate the excellent ETD performance of the proposed GC-RGAN against existing ETD schemes, such as random forest and semi-supervised support vector machine. In comparison, GC-RGAN covers the ETD score of 98% that shows its suitability for real-world scenarios. The proposed solution has extraordinary performance for ETD as compared to traditional solutions, which shows its superiority and usefulness for real-world applications.",
    "macro_domains": []
  },
  {
    "abstract": "The integration of smart buildings (SBs) into smart cities (SCs) is critical to urban development, with the potential to improve SCsâ€™ performance. Artificial intelligence (AI) applications have emerged as a promising tool to enhance SB and SC development. The authors apply an AI-based methodology, particularly Large Language Models of OpenAI ChatGPT-3 and Google Bard as AI experts, to uniquely evaluate 26 criteria that represent SB services across five SC infrastructure domains (energy, mobility, water, waste management, and security), emphasizing their contributions to the integration of SB into SC and quantifying their impact on the efficiency, resilience, and environmental sustainability of SC. The framework was then validated through two rounds of the Delphi method, leveraging human expert knowledge and an iterative consensus-building process. The frameworkâ€™s efficiency in analyzing complicated information and generating important insights is demonstrated via five case studies. These findings contribute to a deeper understanding of the effects of SB services on SC infrastructure domains, highlighting the intricate nature of SC, as well as revealing areas that require further integration to realize the SC performance objectives.",
    "doi": "10.3390/su16188032",
    "author_keywords": [
      "artificial intelligence",
      "evaluation framework",
      "Google Bard",
      "OpenAI ChatGPT-3",
      "smart building",
      "smart city"
    ],
    "contribution": "",
    "introduction": "The integration of smart buildings (SBs) into smart cities (SCs) is critical to urban development, with the potential to improve SCsâ€™ performance. Artificial intelligence (AI) applications have emerged as a promising tool to enhance SB and SC development. The authors apply an AI-based methodology, particularly Large Language Models of OpenAI ChatGPT-3 and Google Bard as AI experts, to uniquely evaluate 26 criteria that represent SB services across five SC infrastructure domains (energy, mobility, water, waste management, and security), emphasizing their contributions to the integration of SB into SC and quantifying their impact on the efficiency, resilience, and environmental sustainability of SC. The framework was then validated through two rounds of the Delphi method, leveraging human expert knowledge and an iterative consensus-building process. The frameworkâ€™s efficiency in analyzing complicated information and generating important insights is demonstrated via five case studies. These findings contribute to a deeper understanding of the effects of SB services on SC infrastructure domains, highlighting the intricate nature of SC, as well as revealing areas that require further integration to realize the SC performance objectives.",
    "macro_domains": []
  },
  {
    "abstract": "Cybercriminals have become an imperative threat because they target the most valuable resource on earth, data. Organizations prepare against cyber attacks by creating Cyber Security Incident Response Teams (CSIRTs) that use various technologies to monitor and detect threats and to help perform forensics on machines and networks. Testing the limits of defense technologies and the skill of a CSIRT can be performed through adversary emulation performed by so-called â€œred teamsâ€. The red teamâ€™s work is primarily manual and requires high skill. We propose SpecRep, a system to ease the testing of the detection capabilities of defenses in complex, heterogeneous infrastructures. SpecRep uses previously known attack specifications to construct attack scenarios based on attacker objectives instead of the traditional attack graphs or a list of actions. We create a metalanguage to describe objectives to be achieved in an attack together with a compiler that can build multiple attack scenarios that achieve the objectives. We use text processing tools aided by large language models to extract information from freely available white papers and convert them to plausible attack specifications that can then be emulated by SpecRep. We show how our system can emulate attacks against a smart home, a large enterprise, and an industrial control system.",
    "doi": "10.3390/s24175601",
    "author_keywords": [
      "adversary emulation",
      "attacks against complex infrastructures",
      "cyber security for the smart city",
      "formal languages",
      "large language models used for knowledge extraction"
    ],
    "contribution": "We propose SpecRep, a system to ease the testing of the detection capabilities of defenses in complex, heterogeneous infrastructures. SpecRep uses previously known attack specifications to construct attack scenarios based on attacker objectives instead of the traditional attack graphs or a list of actions. We create a metalanguage to describe objectives to be achieved in an attack together with a compiler that can build multiple attack scenarios that achieve the objectives. We use text processing tools aided by large language models to extract information from freely available white papers and convert them to plausible attack specifications that can then be emulated by SpecRep. We show how our system can emulate attacks against a smart home, a large enterprise, and an industrial control system.",
    "introduction": "Cybercriminals have become an imperative threat because they target the most valuable resource on earth, data. Organizations prepare against cyber attacks by creating Cyber Security Incident Response Teams (CSIRTs) that use various technologies to monitor and detect threats and to help perform forensics on machines and networks. Testing the limits of defense technologies and the skill of a CSIRT can be performed through adversary emulation performed by so-called â€œred teamsâ€. The red teamâ€™s work is primarily manual and requires high skill.",
    "macro_domains": []
  },
  {
    "abstract": "In the realm of India's smart cities, precise meter readings are essential for effectively managing domestic energy and water systems. Nevertheless, meter reading employing conventional techniques prove to be both costly and time-consuming, especially considering the vast user base and deficit of everyday consumption analysis. To cope with this challenge, the proposed solution introduces a novel unified wireless smart metering system for measuring energy and water usage. This prototype harnesses the smart, advanced metering technology to manage energy and water resources. The presence of data and remote control capabilities in smart distribution transformers offers distribution operators the chance to optimize system operation and control. The innovative system proposed utilizes smart metering technology and incorporates a distribution system self-healing mechanism against power outages, revolutionizing the way utilities manage water and energy consumption. The system not only offers real-time consumption statistics to the utility provider but also provides the flexibility to remotely control the system's turn-on and turn-off functions. The system effectively captures real-time data, transmits it via LoRa to Telegram application. The system automatically re-establishes remote connections in the event of disconnections caused by emergency conditions or non-payment of the bill, once the relevant issue has been resolved. Additionally, the system promptly notifies authorities on overload, over-temperature, and instances of electricity theft. The system proficiently generates bills based on the consumed data and seamlessly transmits the consumed units to the authorities. The innovative system proposed has proven its ability to communicate effectively, yielding results that align with the given circumstances.",
    "doi": "10.1016/j.rineng.2024.102687",
    "author_keywords": [
      "Integrated smart water and energy meter",
      "Internet of Things (IoT)",
      "Long range (LoRa)",
      "Smart city",
      "Smart distribution transformer"
    ],
    "contribution": "",
    "introduction": "In the realm of India's smart cities, precise meter readings are essential for effectively managing domestic energy and water systems. Nevertheless, meter reading employing conventional techniques prove to be both costly and time-consuming, especially considering the vast user base and deficit of everyday consumption analysis. To cope with this challenge, the proposed solution introduces a novel unified wireless smart metering system for measuring energy and water usage. This prototype harnesses the smart, advanced metering technology to manage energy and water resources. The presence of data and remote control capabilities in smart distribution transformers offers distribution operators the chance to optimize system operation and control. The innovative system proposed utilizes smart metering technology and incorporates a distribution system self-healing mechanism against power outages, revolutionizing the way utilities manage water and energy consumption. The system not only offers real-time consumption statistics to the utility provider but also provides the flexibility to remotely control the system's turn-on and turn-off functions. The system effectively captures real-time data, transmits it via LoRa to Telegram application. The system automatically re-establishes remote connections in the event of disconnections caused by emergency conditions or non-payment of the bill, once the relevant issue has been resolved. Additionally, the system promptly notifies authorities on overload, over-temperature, and instances of electricity theft. The system proficiently generates bills based on the consumed data and seamlessly transmits the consumed units to the authorities. The innovative system proposed has proven its ability to communicate effectively, yielding results that align with the given circumstances.",
    "macro_domains": []
  },
  {
    "abstract": "Generating trajectory data is among promising solutions to addressing privacy concerns, collection costs, and proprietary restrictions usually associated with human mobility analyses. However, existing trajectory generation methods are still in their infancy due to the inherent diversity and unpredictability of human activities, grappling with issues such as fidelity, flexibility, and generalizability. To overcome these obstacles, we propose ControlTraj, a Controllable Trajectory generation framework with the topology-constrained diffusion model. Distinct from prior approaches, ControlTraj utilizes a diffusion model to generate high-fidelity trajectories while integrating the structural constraints of road network topology to guide the geographical outcomes. Specifically, we develop a novel road segment autoencoder to extract fine-grained road segment embedding. The encoded features, along with trip attributes, are subsequently merged into the proposed geographic denoising UNet architecture, named GeoUNet, to synthesize geographic trajectories from white noise. Through experimentation across three real-world data settings, ControlTraj demonstrates its ability to produce human-directed, high-fidelity trajectory generation with adaptability to unexplored geographical contexts.",
    "doi": "10.1145/3637528.3671866",
    "author_keywords": [
      "diffusion model",
      "gps trajectory",
      "urban computing"
    ],
    "contribution": "To overcome these obstacles, we propose ControlTraj, a Controllable Trajectory generation framework with the topology-constrained diffusion model. Distinct from prior approaches, ControlTraj utilizes a diffusion model to generate high-fidelity trajectories while integrating the structural constraints of road network topology to guide the geographical outcomes. Specifically, we develop a novel road segment autoencoder to extract fine-grained road segment embedding. The encoded features, along with trip attributes, are subsequently merged into the proposed geographic denoising UNet architecture, named GeoUNet, to synthesize geographic trajectories from white noise. Through experimentation across three real-world data settings, ControlTraj demonstrates its ability to produce human-directed, high-fidelity trajectory generation with adaptability to unexplored geographical contexts.",
    "introduction": "Generating trajectory data is among promising solutions to addressing privacy concerns, collection costs, and proprietary restrictions usually associated with human mobility analyses. However, existing trajectory generation methods are still in their infancy due to the inherent diversity and unpredictability of human activities, grappling with issues such as fidelity, flexibility, and generalizability.",
    "macro_domains": []
  },
  {
    "abstract": "Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. In certain cases, it becomes challenging to collect any labeled data from downstream scenarios, intensifying the problem further. Consequently, it becomes necessary to build a spatio-temporal model that can exhibit strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce. The code and data are available at: https://github.com/HKUDS/UrbanGPT.",
    "doi": "10.1145/3637528.3671578",
    "author_keywords": [
      "generative ai",
      "large language models",
      "smart cities",
      "spatial-temporal data mining",
      "urban computing"
    ],
    "contribution": "Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce. The code and data are available at: https://github.com/HKUDS/UrbanGPT.",
    "introduction": "Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. In certain cases, it becomes challenging to collect any labeled data from downstream scenarios, intensifying the problem further. Consequently, it becomes necessary to build a spatio-temporal model that can exhibit strong generalization capabilities across diverse spatio-temporal learning scenarios.",
    "macro_domains": []
  },
  {
    "abstract": "Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Graph intelligence is rapidly becoming a crucial aspect of understanding and exploiting the intricate interconnections within graph data. Recently, large language models (LLMs) and prompt learning techniques have pushed graph intelligence forward, outperforming traditional Graph Neural Network (GNN) pre-training methods and setting new benchmarks for performance. In this tutorial, we begin by offering a comprehensive review and analysis of existing methods that integrate LLMs with graphs. We introduce existing works based on a novel taxonomy that classifies them into three distinct categories according to the roles of LLMs in graph tasks: as enhancers, predictors, or alignment components. Secondly, we introduce a new learning method that utilizes prompting on graphs, offering substantial potential to enhance graph transfer capabilities across diverse tasks and domains. We discuss existing works on graph prompting within a unified framework and introduce our developed tool for executing a variety of graph prompting tasks. Additionally, we discuss the applications of combining Graphs, LLMs, and prompt learning across various tasks, such as urban computing, recommendation systems, and anomaly detection. This lecture-style tutorial is an extension of our original work published in IJCAI 2024[44] and arXiv[77] with the invitation of KDD24.",
    "doi": "10.1145/3637528.3671456",
    "author_keywords": [
      "graph learning",
      "graph prompting",
      "large language model"
    ],
    "contribution": "We introduce existing works based on a novel taxonomy that classifies them into three distinct categories according to the roles of LLMs in graph tasks: as enhancers, predictors, or alignment components. Secondly, we introduce a new learning method that utilizes prompting on graphs, offering substantial potential to enhance graph transfer capabilities across diverse tasks and domains. We discuss existing works on graph prompting within a unified framework and introduce our developed tool for executing a variety of graph prompting tasks. Additionally, we discuss the applications of combining Graphs, LLMs, and prompt learning across various tasks, such as urban computing, recommendation systems, and anomaly detection. This lecture-style tutorial is an extension of our original work published in IJCAI 2024[44] and arXiv[77] with the invitation of KDD24.",
    "introduction": "Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Graph intelligence is rapidly becoming a crucial aspect of understanding and exploiting the intricate interconnections within graph data. Recently, large language models (LLMs) and prompt learning techniques have pushed graph intelligence forward, outperforming traditional Graph Neural Network (GNN) pre-training methods and setting new benchmarks for performance. In this tutorial, we begin by offering a comprehensive review and analysis of existing methods that integrate LLMs with graphs.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate power load forecasting is critical to achieving the sustainability of energy management systems. However, conventional prediction methods suffer from low precision and stability because of crude modules for predicting short-term and medium-term loads. To solve such a problem, a Combined Modeling Power Load-Forecasting (CMPLF) method is proposed in this work. The CMPLF comprises two modules to deal with short-term and medium-term load forecasting, respectively. Each module consists of four essential parts including initial forecasting, decomposition and denoising, nonlinear optimization, and evaluation. Especially, to break through bottlenecks in hierarchical model optimization, we effectively fuse the Nonlinear Autoregressive model with Exogenous Inputs (NARX) and Long-Short Term Memory (LSTM) networks into the Autoregressive Integrated Moving Average (ARIMA) model. The experiment results based on real-world datasets from Queensland and China mainland show that our CMPLF has significant performance superiority compared with the state-of-the-art (SOTA) methods. CMPLF achieves a goodness-of-fit value of 97.174% in short-term load prediction and 97.162% in medium-term prediction. Our approach will be of great significance in promoting the sustainable development of smart cities.",
    "doi": "10.3390/su16166903",
    "author_keywords": [
      "ARIMA",
      "deep learning",
      "hierarchical optimization models",
      "LSTM",
      "NARX",
      "power load forecasting"
    ],
    "contribution": "To solve such a problem, a Combined Modeling Power Load-Forecasting (CMPLF) method is proposed in this work. The CMPLF comprises two modules to deal with short-term and medium-term load forecasting, respectively. Each module consists of four essential parts including initial forecasting, decomposition and denoising, nonlinear optimization, and evaluation. Especially, to break through bottlenecks in hierarchical model optimization, we effectively fuse the Nonlinear Autoregressive model with Exogenous Inputs (NARX) and Long-Short Term Memory (LSTM) networks into the Autoregressive Integrated Moving Average (ARIMA) model. The experiment results based on real-world datasets from Queensland and China mainland show that our CMPLF has significant performance superiority compared with the state-of-the-art (SOTA) methods. CMPLF achieves a goodness-of-fit value of 97.174% in short-term load prediction and 97.162% in medium-term prediction. Our approach will be of great significance in promoting the sustainable development of smart cities.",
    "introduction": "Accurate power load forecasting is critical to achieving the sustainability of energy management systems. However, conventional prediction methods suffer from low precision and stability because of crude modules for predicting short-term and medium-term loads.",
    "macro_domains": []
  },
  {
    "abstract": "Designing effective cybersecurity visualization has become a crucial component of cyber defense strategies in many domains and industrial environments. Human behaviour, modeling and input are major aspects of designing visualization systems. Yet, the task of evaluating these developed visualization systems is both time-consuming and challenging, and it is often prone to cases where user evaluation is limited owing to a lack of different stakeholders and end users during the design process. Recognizing the potential of advanced Generative Artificial Intelligence and Large Language Models (LLMs), our study aims to explore their capabilities in evaluating web-based security visualization tools and dashboards, particularly in the context of smart cities and buildings. We study and compare the feasibility of using various LLMs available today, for conducting usability testing, serving as an additional resource given the limited availability of human participants. In particular, we focus on three different LLMs: Bing Chat, ChatGPT-4 and ChatGPT-4o. While each had its strengths and drawbacks, our findings revealed that the results obtained had a strong correlation with human test subjects. LLMs can be a valuable aid during evaluation, by offering in-depth insights and evaluations, tailored to the specific requirements of smart buildings, cities and automation cybersecurity. Moreover, our research and findings also reveal that LLMs can similarly be used for the evaluation of a wide range of other visual systems for industrial environments.",
    "doi": "10.1145/3664476.3670943",
    "author_keywords": [
      "LLM",
      "Security Visualization",
      "Smart City",
      "Usability Testing"
    ],
    "contribution": "Recognizing the potential of advanced Generative Artificial Intelligence and Large Language Models (LLMs), our study aims to explore their capabilities in evaluating web-based security visualization tools and dashboards, particularly in the context of smart cities and buildings. We study and compare the feasibility of using various LLMs available today, for conducting usability testing, serving as an additional resource given the limited availability of human participants. In particular, we focus on three different LLMs: Bing Chat, ChatGPT-4 and ChatGPT-4o. While each had its strengths and drawbacks, our findings revealed that the results obtained had a strong correlation with human test subjects. LLMs can be a valuable aid during evaluation, by offering in-depth insights and evaluations, tailored to the specific requirements of smart buildings, cities and automation cybersecurity. Moreover, our research and findings also reveal that LLMs can similarly be used for the evaluation of a wide range of other visual systems for industrial environments.",
    "introduction": "Designing effective cybersecurity visualization has become a crucial component of cyber defense strategies in many domains and industrial environments. Human behaviour, modeling and input are major aspects of designing visualization systems. Yet, the task of evaluating these developed visualization systems is both time-consuming and challenging, and it is often prone to cases where user evaluation is limited owing to a lack of different stakeholders and end users during the design process.",
    "macro_domains": []
  },
  {
    "abstract": "As cities transform, disrupting citizens' lives, their participation in urban development is often undervalued despite its importance. Citizen complaint systems exist but are often limited in fostering meaningful dialogue with municipalities. Meanwhile, smart cities aim to improve living standards, efficiency, and sustainability by integrating digital twins with physical infrastructures, potentially enhancing transparency and enriching communication between cities and their inhabitants with real-time data. Complementing these developments, technologies realizing Conversational User Interfaces (CUIs) are becoming more capable in providing a conversational and feedback-oriented approach such as complaint management processes. The improvement of CUIs for citizen complaint management through enhanced contextual feedback is explored in this work. The term contextual feedback has been developed and defined as all information (for example, background, conditions, explanations, timelines, and the existence of similar complaints) related to a complaint and or the underlying problem that could potentially be relevant for the user. The solution proposed in this paper gathers data from users about their issues via a CUI, which subsequently queries various data sources to obtain relevant contextual information. Following this, a Large Language Model processes the collected data to produce the corresponding feedback. In the study, a static CUI without contextual data as the baseline has been compared to a CUI that includes contextual data, analyzing their impact on pragmatic and hedonic quality, reuse intention, and potential influence on the citizens' trust in their municipality. The study has been conducted in cooperation with the German municipality of Wadgassen. The good performance of the baseline system shows the general potential of LLMs in the citizen complaint domain even without data sources. The results show that contextual feedback performed better overall, with significant improvements in the pragmatic and hedonic quality, attractiveness, reuse intention, feeling that the complaint is taken seriously, and the citizens' trust in their municipality.",
    "doi": "10.1145/3640794.3665562",
    "author_keywords": [
      "Citizen Engagement",
      "Context Information",
      "Conversational UI",
      "Smart City"
    ],
    "contribution": "The improvement of CUIs for citizen complaint management through enhanced contextual feedback is explored in this work. The term contextual feedback has been developed and defined as all information (for example, background, conditions, explanations, timelines, and the existence of similar complaints) related to a complaint and or the underlying problem that could potentially be relevant for the user. The solution proposed in this paper gathers data from users about their issues via a CUI, which subsequently queries various data sources to obtain relevant contextual information. Following this, a Large Language Model processes the collected data to produce the corresponding feedback. In the study, a static CUI without contextual data as the baseline has been compared to a CUI that includes contextual data, analyzing their impact on pragmatic and hedonic quality, reuse intention, and potential influence on the citizens' trust in their municipality. The study has been conducted in cooperation with the German municipality of Wadgassen. The good performance of the baseline system shows the general potential of LLMs in the citizen complaint domain even without data sources. The results show that contextual feedback performed better overall, with significant improvements in the pragmatic and hedonic quality, attractiveness, reuse intention, feeling that the complaint is taken seriously, and the citizens' trust in their municipality.",
    "introduction": "As cities transform, disrupting citizens' lives, their participation in urban development is often undervalued despite its importance. Citizen complaint systems exist but are often limited in fostering meaningful dialogue with municipalities. Meanwhile, smart cities aim to improve living standards, efficiency, and sustainability by integrating digital twins with physical infrastructures, potentially enhancing transparency and enriching communication between cities and their inhabitants with real-time data. Complementing these developments, technologies realizing Conversational User Interfaces (CUIs) are becoming more capable in providing a conversational and feedback-oriented approach such as complaint management processes.",
    "macro_domains": []
  },
  {
    "abstract": "Semantic segmentation of large-scale point clouds is crucial for advancing smart city infrastructure and supporting autonomous driving technology. However, existing semantic segmentation techniques designed for indoor environments often struggle to adapt to vast outdoor scenes. Moreover, networks for large-scale scenes face challenges such as limited receptive fields and computational complexity, hindering their ability to accurately perceive small target features. To address these challenges, we propose PVCFormer, a novel cross-attention architecture that leverages both point and voxel representations. By feeding concurrently sampled data at varying voxel resolutions into the network, PVCFormer enhances the segmentation of small-scale features while expanding the receptive field. Additionally, the cross-transformer block facilitates better fusion of point and voxel features, and the introduction of CosFormer improves the computational efficiency of the network.Simultaneously, we introduce SYSU9, a new dataset labeled with 9 categories covering an area of over 7 square kilometers, to serve as a benchmark for evaluating point cloud semantic segmentation algorithms. We proposed two model versions, PVCFormer-CA and PVCFormer-SA. PVCFormer-CA achieves an overall accuracy of 92.4 % on SensatUrban, 94.6 % on DALES, and 91.1 % on SYSU9. For semantic segmentation, PVCFormer-CA achieves 61.5 % mIoU on SensatUrban, 73.6 % mIoU on DALES, and 62.4 % mIoU on SYSU9.Our experiments demonstrated promising results in large-scale outdoor point cloud semantic segmentation and introduce novel methodologies leveraging attention mechanisms for handling large-scale point clouds.",
    "doi": "10.1016/j.jag.2024.103951",
    "author_keywords": [
      "CosFormer",
      "Cross attention",
      "Multi-scale integration",
      "Outdoor scene semantic segmentation"
    ],
    "contribution": "To address these challenges, we propose PVCFormer, a novel cross-attention architecture that leverages both point and voxel representations. By feeding concurrently sampled data at varying voxel resolutions into the network, PVCFormer enhances the segmentation of small-scale features while expanding the receptive field. Additionally, the cross-transformer block facilitates better fusion of point and voxel features, and the introduction of CosFormer improves the computational efficiency of the network.Simultaneously, we introduce SYSU9, a new dataset labeled with 9 categories covering an area of over 7 square kilometers, to serve as a benchmark for evaluating point cloud semantic segmentation algorithms. We proposed two model versions, PVCFormer-CA and PVCFormer-SA. PVCFormer-CA achieves an overall accuracy of 92.4 % on SensatUrban, 94.6 % on DALES, and 91.1 % on SYSU9. For semantic segmentation, PVCFormer-CA achieves 61.5 % mIoU on SensatUrban, 73.6 % mIoU on DALES, and 62.4 % mIoU on SYSU9.Our experiments demonstrated promising results in large-scale outdoor point cloud semantic segmentation and introduce novel methodologies leveraging attention mechanisms for handling large-scale point clouds.",
    "introduction": "Semantic segmentation of large-scale point clouds is crucial for advancing smart city infrastructure and supporting autonomous driving technology. However, existing semantic segmentation techniques designed for indoor environments often struggle to adapt to vast outdoor scenes. Moreover, networks for large-scale scenes face challenges such as limited receptive fields and computational complexity, hindering their ability to accurately perceive small target features.",
    "macro_domains": []
  },
  {
    "abstract": "The transportation Metaverse, by integrating real and virtual vehicular networks, brings significant benefits to the development of smart cities. However, the difficulty and high cost of conducting large-scale traffic and driving simulations in the transportation Metaverse via realistic data collection and fusion from the physical world directly result in the lack of spatialâ€“temporal traffic data and privacy concerns, which significantly hinder the development of the transportation Metaverse. Hence, in these situations, it becomes essential to produce high-quality, large-scale trajectory data to support relevant applications. However, the deficiency of data-driven method is the heavy dependence on high-quality historical data. Prior knowledge can help reduce learning difficulties and overfitting problems with small amounts of data. In our study, we use a hybrid framework, the Travel Demand Conditioning Generative Adversarial Network (TD-GAN), which combines data-driven and knowledge-driven approaches to address the issue of traffic trajectory generation. First, we employ a conditional mechanism to incorporate prior knowledge of travel demand to reduce learning difficulties. Second, non-standard convolutional module and multi-headed self-attention module are developed to capture spatialâ€“temporal correlations. The experimental results show that our model outperforms the baseline models.",
    "doi": "10.1016/j.asoc.2024.111690",
    "author_keywords": [
      "Conditional adversarial generative networks",
      "Prior knowledge",
      "Spatialâ€“temporal data",
      "Traffic trajectory generation",
      "Transportation metaverse"
    ],
    "contribution": "In our study, we use a hybrid framework, the Travel Demand Conditioning Generative Adversarial Network (TD-GAN), which combines data-driven and knowledge-driven approaches to address the issue of traffic trajectory generation. First, we employ a conditional mechanism to incorporate prior knowledge of travel demand to reduce learning difficulties. Second, non-standard convolutional module and multi-headed self-attention module are developed to capture spatialâ€“temporal correlations. The experimental results show that our model outperforms the baseline models.",
    "introduction": "The transportation Metaverse, by integrating real and virtual vehicular networks, brings significant benefits to the development of smart cities. However, the difficulty and high cost of conducting large-scale traffic and driving simulations in the transportation Metaverse via realistic data collection and fusion from the physical world directly result in the lack of spatialâ€“temporal traffic data and privacy concerns, which significantly hinder the development of the transportation Metaverse. Hence, in these situations, it becomes essential to produce high-quality, large-scale trajectory data to support relevant applications. However, the deficiency of data-driven method is the heavy dependence on high-quality historical data. Prior knowledge can help reduce learning difficulties and overfitting problems with small amounts of data.",
    "macro_domains": []
  },
  {
    "abstract": "Effective disaster response is critical for communities to remain resilient and advance the development of smart cities. Responders and decision-makers would benefit from reliable, timely measures of the issues impacting their communities during a disaster, and social media offers a potentially rich data source. Social media can reflect public concerns and behaviors during a disaster, offering valuable insights for decision-makers to understand evolving situations and optimize resource allocation. We used Bidirectional Encoder Representations from Transformers (BERT) topic modeling to cluster topics from Twitter data. Then, we conducted a temporal-spatial analysis to examine the distribution of these topics across different regions during the 2020 western U.S. wildfire season. Our results show that Twitter users mainly focused on three topics: â€œhealth impact,â€ â€œdamage,â€ and â€œevacuation.â€ We used the Susceptible-Infected-Recovered (SIR) theory to explore the magnitude and velocity of topic diffusion on Twitter. The results displayed a clear relationship between topic trends and wildfire propagation patterns. The estimated parameters obtained from the SIR model in selected cities revealed that residents exhibited a high level of several concerns during the wildfire. Our study offers a quantitative approach to measure disaster response and support community resilience enhancement.",
    "doi": "10.1016/j.scs.2024.105362",
    "author_keywords": [
      "BERT topic modeling",
      "Community resilience",
      "SIR model",
      "Social media",
      "Wildfire response"
    ],
    "contribution": "Our study offers a quantitative approach to measure disaster response and support community resilience enhancement.",
    "introduction": "Effective disaster response is critical for communities to remain resilient and advance the development of smart cities. Responders and decision-makers would benefit from reliable, timely measures of the issues impacting their communities during a disaster, and social media offers a potentially rich data source. Social media can reflect public concerns and behaviors during a disaster, offering valuable insights for decision-makers to understand evolving situations and optimize resource allocation. We used Bidirectional Encoder Representations from Transformers (BERT) topic modeling to cluster topics from Twitter data. Then, we conducted a temporal-spatial analysis to examine the distribution of these topics across different regions during the 2020 western U.S. wildfire season. Our results show that Twitter users mainly focused on three topics: â€œhealth impact,â€ â€œdamage,â€ and â€œevacuation.â€ We used the Susceptible-Infected-Recovered (SIR) theory to explore the magnitude and velocity of topic diffusion on Twitter. The results displayed a clear relationship between topic trends and wildfire propagation patterns. The estimated parameters obtained from the SIR model in selected cities revealed that residents exhibited a high level of several concerns during the wildfire.",
    "macro_domains": []
  },
  {
    "abstract": "Multispectral image fusion plays a crucial role in smart city environment safety. In the domain of visible and infrared image fusion, object vanishment after fusion is a key problem which restricts the fusion performance. To address this problem, a novel Salient Regional Generative Adversarial Network GAN (SaReGAN) is presented for infrared and VIS image fusion. The SaReGAN consists of three parts. In the first part, the salient regions of infrared image are extracted by visual saliency map and the information of these regions is preserved. In the second part, the VIS image, infrared image and salient information are merged thoroughly in the generator to gain a pre-fused image. In the third part, the discriminator attempts to differentiate the pre-fused image and VIS image, in order to learn details from VIS image based on the adversarial mechanism. Experimental results verify that the SaReGAN outperforms other state-of-the-art methods in quantitative and qualitative evaluations.",
    "doi": "10.1007/s11042-023-14393-2",
    "author_keywords": [
      "Generative adversarial network",
      "Image fusion",
      "Salient region",
      "Smart city",
      "Visible and infrared image"
    ],
    "contribution": "",
    "introduction": "Multispectral image fusion plays a crucial role in smart city environment safety. In the domain of visible and infrared image fusion, object vanishment after fusion is a key problem which restricts the fusion performance. To address this problem, a novel Salient Regional Generative Adversarial Network GAN (SaReGAN) is presented for infrared and VIS image fusion. The SaReGAN consists of three parts. In the first part, the salient regions of infrared image are extracted by visual saliency map and the information of these regions is preserved. In the second part, the VIS image, infrared image and salient information are merged thoroughly in the generator to gain a pre-fused image. In the third part, the discriminator attempts to differentiate the pre-fused image and VIS image, in order to learn details from VIS image based on the adversarial mechanism. Experimental results verify that the SaReGAN outperforms other state-of-the-art methods in quantitative and qualitative evaluations.",
    "macro_domains": []
  },
  {
    "abstract": "Taipei City has been experimenting with the use of Artificial Intelligence (AI) tools to enhance its smart capabilities, aiming to increase citizen satisfaction. This initiative is part of the cityâ€™s Smart City Proof of Concept (PoC) projects, which have been progressively rolled out since 2015. Most of these projects incorporate AI tools or algorithms, such as the combination of the Internet of Things (IoT) with AI to form AIoT, or the application of Large Language Models (LLMs). The objective is to leverage the latest technological developments to achieve a smarter Taipei. This study analyzes the execution of 302 PoC projects, categorizing them into 22 technological segments that together form an AI framework for smart city construction applications. This framework corresponds to 15 major issues of concern to Taipeiâ€™s residents, with the potential to address or mitigate 13 of them. According to the IMD Smart City Index Report 2023, Taipeiâ€™s smart city rating improved from a B in 2021 to an A in 2023, indicating progress. The results demonstrate that the AI framework derived from dissecting multiple PoC projects can effectively enhance the cityâ€™s smart construction ratings. This framework, aligned with major municipal concerns, proposes solutions driven by AI, guiding Taipeiâ€™s digital transformation into a smarter city and enabling its citizens to enjoy an improved quality of life.",
    "doi": "10.1145/3657054.3657065",
    "author_keywords": [
      "AI",
      "AIoT",
      "Implementation framework",
      "IoT",
      "LLM",
      "PoC"
    ],
    "contribution": "This study analyzes the execution of 302 PoC projects, categorizing them into 22 technological segments that together form an AI framework for smart city construction applications. This framework corresponds to 15 major issues of concern to Taipeiâ€™s residents, with the potential to address or mitigate 13 of them. According to the IMD Smart City Index Report 2023, Taipeiâ€™s smart city rating improved from a B in 2021 to an A in 2023, indicating progress. The results demonstrate that the AI framework derived from dissecting multiple PoC projects can effectively enhance the cityâ€™s smart construction ratings. This framework, aligned with major municipal concerns, proposes solutions driven by AI, guiding Taipeiâ€™s digital transformation into a smarter city and enabling its citizens to enjoy an improved quality of life.",
    "introduction": "Taipei City has been experimenting with the use of Artificial Intelligence (AI) tools to enhance its smart capabilities, aiming to increase citizen satisfaction. This initiative is part of the cityâ€™s Smart City Proof of Concept (PoC) projects, which have been progressively rolled out since 2015. Most of these projects incorporate AI tools or algorithms, such as the combination of the Internet of Things (IoT) with AI to form AIoT, or the application of Large Language Models (LLMs). The objective is to leverage the latest technological developments to achieve a smarter Taipei.",
    "macro_domains": []
  },
  {
    "abstract": "Predictive analytics technologies like machine learning, AI and Generative AI models like Large Language Models (LLMs), have garnered enthusiasm for their potential to improve healthcare services in smart cities. However, these rapidly developing intelligent agents that guides the healthcare decisions may also risk exacerbating health inequities along racial, ethnic, gender, and socioeconomic lines, reflecting systemic discrimination ingrained within healthcare practices. Flawed or injudiciously applied AI systems could improperly restrict opportunities and provide substandard care for minority groups by propagating historical patterns of prejudice encoded within limited training datasets. These advanced intelligent technologies can hinder the sustainable health solutions for smart cities. This study examines intelligent AI models and applications in healthcare settings, with a focus on assessing impacts on marginalized and disadvantaged populations. Comprehensive scholarly database searches identified 45 relevant studies investigating issues on algorithmic bias, lack of diverse training data, and discrimination risks linked to healthcare AI systems. The review finds most applications still lack adequate safeguards to prevent discrimination against vulnerable populations. Through the review of these systems, we propose an integrated inclusive smart health model that considers both technical interventions as well as broader participatory and ethical approaches. Realizing AIâ€™s fullest potential to meaningfully advance health justice requires not only algorithmic adjustments to mitigate bias, and efforts to improve diversity of training data, transparent analysis frameworks, and best practices for ensuring just AI systems in healthcare, but also a human-centered commitment to thoughtful, inclusive development approaches that center the needs and priorities of communities impacted by health disparities from the outset.",
    "doi": "10.1145/3657054.3657152",
    "author_keywords": [
      "AI and healthcare",
      "Algorithmic Bias",
      "Health Equity",
      "Machine Learning in health decision support",
      "Trustworthy AI"
    ],
    "contribution": "This study examines intelligent AI models and applications in healthcare settings, with a focus on assessing impacts on marginalized and disadvantaged populations. Comprehensive scholarly database searches identified 45 relevant studies investigating issues on algorithmic bias, lack of diverse training data, and discrimination risks linked to healthcare AI systems. The review finds most applications still lack adequate safeguards to prevent discrimination against vulnerable populations. Through the review of these systems, we propose an integrated inclusive smart health model that considers both technical interventions as well as broader participatory and ethical approaches. Realizing AIâ€™s fullest potential to meaningfully advance health justice requires not only algorithmic adjustments to mitigate bias, and efforts to improve diversity of training data, transparent analysis frameworks, and best practices for ensuring just AI systems in healthcare, but also a human-centered commitment to thoughtful, inclusive development approaches that center the needs and priorities of communities impacted by health disparities from the outset.",
    "introduction": "Predictive analytics technologies like machine learning, AI and Generative AI models like Large Language Models (LLMs), have garnered enthusiasm for their potential to improve healthcare services in smart cities. However, these rapidly developing intelligent agents that guides the healthcare decisions may also risk exacerbating health inequities along racial, ethnic, gender, and socioeconomic lines, reflecting systemic discrimination ingrained within healthcare practices. Flawed or injudiciously applied AI systems could improperly restrict opportunities and provide substandard care for minority groups by propagating historical patterns of prejudice encoded within limited training datasets. These advanced intelligent technologies can hinder the sustainable health solutions for smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Building extraction is one of the important research directions that has attracted great attention in the field of remote sensing image processing. It refers to the process of accurately extracting building information such as the location and shape of buildings by analyzing and processing remote sensing images. This technology plays an irreplaceable and important role in urban planning, disaster management, map production, smart city construction, and other fields. In recent years, with the advancement of science and technology, especially the continuous evolution of earth observation technology and the rapid development of deep learning algorithms, Convolutional Neural Networks (CNNs) have become an emerging solution for extracting buildings from remote sensing images because of their powerful feature extraction capability. The aim of this paper is to provide a comprehensive and systematic overview and analysis of building extraction methods based on convolutional neural networks. We conduct a comprehensive literature review to summarize the building extraction methods from perspectives of model structure, multi-scale feature differences, lack of boundary information, and model complexity. This will help researchers to better understand the advantages and disadvantages of different methods and the applicable scenarios. In addition, several typical building datasets in this field are described in detail, as well as the potential issues associated with these datasets. Subsequently, by collecting experimental results of relevant algorithms on these typical datasets, a detailed discussion on the accuracy and parameter quantities of various methods is conducted, aiming to provide a comprehensive assessment of performance and applicability of these methods. Finally, based on the current research status of this field and looking forward to the new era of high-quality development in artificial intelligence, the future directions for building extraction are prospected. Specifically, this paper discusses the combination of Transformers and CNNs, the combination of deep learning and reinforcement learning, multi-modal data fusion, unsupervised or semi-supervised learning methods, real-time extraction based on large-scale remote sensing model, building instance segmentation, and building contour vector extraction. In conclusion, our review can provide some valuable references and inspirations for future related research, so as to promote the practical application and innovation of building extraction from remote sensing images. This will fulfill the demand for efficient and precise map information in remote sensing technology and other related fields, contributing to the sustainable and high-quality development of human society.",
    "doi": "10.12082/dqxxkx.2024.240057",
    "author_keywords": [
      "asymmetric network structure",
      "boundary optimization",
      "building extraction",
      "convolutional neural network",
      "deep learning",
      "lightweight network structure",
      "multi-scale feature fusion",
      "remote sensing image"
    ],
    "contribution": "The aim of this paper is to provide a comprehensive and systematic overview and analysis of building extraction methods based on convolutional neural networks. We conduct a comprehensive literature review to summarize the building extraction methods from perspectives of model structure, multi-scale feature differences, lack of boundary information, and model complexity. This will help researchers to better understand the advantages and disadvantages of different methods and the applicable scenarios. In addition, several typical building datasets in this field are described in detail, as well as the potential issues associated with these datasets. Subsequently, by collecting experimental results of relevant algorithms on these typical datasets, a detailed discussion on the accuracy and parameter quantities of various methods is conducted, aiming to provide a comprehensive assessment of performance and applicability of these methods. Finally, based on the current research status of this field and looking forward to the new era of high-quality development in artificial intelligence, the future directions for building extraction are prospected. Specifically, this paper discusses the combination of Transformers and CNNs, the combination of deep learning and reinforcement learning, multi-modal data fusion, unsupervised or semi-supervised learning methods, real-time extraction based on large-scale remote sensing model, building instance segmentation, and building contour vector extraction. In conclusion, our review can provide some valuable references and inspirations for future related research, so as to promote the practical application and innovation of building extraction from remote sensing images. This will fulfill the demand for efficient and precise map information in remote sensing technology and other related fields, contributing to the sustainable and high-quality development of human society.",
    "introduction": "Building extraction is one of the important research directions that has attracted great attention in the field of remote sensing image processing. It refers to the process of accurately extracting building information such as the location and shape of buildings by analyzing and processing remote sensing images. This technology plays an irreplaceable and important role in urban planning, disaster management, map production, smart city construction, and other fields. In recent years, with the advancement of science and technology, especially the continuous evolution of earth observation technology and the rapid development of deep learning algorithms, Convolutional Neural Networks (CNNs) have become an emerging solution for extracting buildings from remote sensing images because of their powerful feature extraction capability.",
    "macro_domains": []
  },
  {
    "abstract": "With the artificial intelligence technology development boom, large language models are demonstrating their potential in comprehension and creativity. Large language models such as GPT-4 and Gemini have been able to powerfully study for various professional-level exams. However, as a language model itself, its powerful comprehension can only be reflected in text sequences. Currently, although videos can be generated through the connection between 3D point clouds and large language models, there is currently no prompt project that directly interacts with one-dimensional through attribute calculation results. The point cloud data is also rich in information that can support various tasks of urban construction. For scene-level point cloud data, there has been a lot of research done on semantic segmentation, target detection, and other tasks. However, it is usually difficult to provide direct help to scene construction from the perception results. This paper presents a method for applying large language models to urban ecological construction by combining the results of 3D point cloud semantic segmentation. The objective is to integrate the prior knowledge and creative capabilities of Large Language Models (LLMs) within urban development with the outcomes derived from point cloud semantic segmentation results. This integration aims to establish an interactive point cloud intelligent analysis system, tailored for aiding decision-making processes in urban ecological civilization construction, thus presenting innovative perspectives for the advancement of smart city development.",
    "doi": "10.1016/j.isprsjprs.2024.04.024",
    "author_keywords": [
      "Large language model interact",
      "Point cloud understanding",
      "Prompt engineering",
      "Thought chain",
      "Urban ecological construction"
    ],
    "contribution": "This paper presents a method for applying large language models to urban ecological construction by combining the results of 3D point cloud semantic segmentation. The objective is to integrate the prior knowledge and creative capabilities of Large Language Models (LLMs) within urban development with the outcomes derived from point cloud semantic segmentation results. This integration aims to establish an interactive point cloud intelligent analysis system, tailored for aiding decision-making processes in urban ecological civilization construction, thus presenting innovative perspectives for the advancement of smart city development.",
    "introduction": "With the artificial intelligence technology development boom, large language models are demonstrating their potential in comprehension and creativity. Large language models such as GPT-4 and Gemini have been able to powerfully study for various professional-level exams. However, as a language model itself, its powerful comprehension can only be reflected in text sequences. Currently, although videos can be generated through the connection between 3D point clouds and large language models, there is currently no prompt project that directly interacts with one-dimensional through attribute calculation results. The point cloud data is also rich in information that can support various tasks of urban construction. For scene-level point cloud data, there has been a lot of research done on semantic segmentation, target detection, and other tasks. However, it is usually difficult to provide direct help to scene construction from the perception results.",
    "macro_domains": []
  },
  {
    "abstract": "Integrating Embodied Robots into a smart city's networked system can significantly enhance the city's operational efficiency. These robots can be connected to the city's network, receiving and transmitting data in real time for enhancing humanâ€“robot communications. Language-conditioned robot behavior plays a vital role in executing complex tasks by associating human commands or instructions with perception and actions. However, most language-conditioned policy-related research is limited to specific datasets and cannot generalize across different environments. In this study, we propose a novel imitation learning framework tailored for language-conditioned robotic tasks. Our framework includes specialized encoders designed for various benchmarks and utilizes two distinct models: the Transformer and Diffusion models. We rigorously evaluate this framework in three different robotic environments. Our findings indicate that the framework consistently delivers superior performance across multiple domains. Notably, we observe that the Transformer model is particularly effective in managing tasks with long trajectories, whereas the Diffusion model demonstrates enhanced proficiency in generating trajectories from limited training datasets. Our approach showcases remarkable generalization capabilities across a range of tasks and achieves significantly higher success rates in task completion.",
    "doi": "10.1016/j.comcom.2024.04.029",
    "author_keywords": [
      "Embodied robot",
      "Humanâ€“robot communication",
      "Imitation learning",
      "Neural network",
      "Smart city"
    ],
    "contribution": "In this study, we propose a novel imitation learning framework tailored for language-conditioned robotic tasks. Our framework includes specialized encoders designed for various benchmarks and utilizes two distinct models: the Transformer and Diffusion models. We rigorously evaluate this framework in three different robotic environments. Our findings indicate that the framework consistently delivers superior performance across multiple domains. Notably, we observe that the Transformer model is particularly effective in managing tasks with long trajectories, whereas the Diffusion model demonstrates enhanced proficiency in generating trajectories from limited training datasets. Our approach showcases remarkable generalization capabilities across a range of tasks and achieves significantly higher success rates in task completion.",
    "introduction": "Integrating Embodied Robots into a smart city's networked system can significantly enhance the city's operational efficiency. These robots can be connected to the city's network, receiving and transmitting data in real time for enhancing humanâ€“robot communications. Language-conditioned robot behavior plays a vital role in executing complex tasks by associating human commands or instructions with perception and actions. However, most language-conditioned policy-related research is limited to specific datasets and cannot generalize across different environments.",
    "macro_domains": []
  },
  {
    "abstract": "Artificial intelligence (AI) engines, such as ChatGPT, InferKit, and DeepAI, are very popular today and new AI engines, such as Google Bard, Chinchilla AI DeepMind, and GPT-4, constantly emerge. However, question remains how these new data management tools can assist scholars in improving the research design and implementation. In an attempt to answer this question, we focus on one particular research field â€“ definition and identification of smart cities (SCs), â€“ and compare the answers provided by different AI engines with the answers given in a sequence of research papers, prepared without the use of AI and recently published by these authors. In particular, the following aspects of the original studies were re-analysed here using the AI input: a) problem definition; b) summary of current knowledge; c) identification of unknowns; d) research strategy, and e) recommendations for research and practice. As the study reveals, the recommendations of AI engines are, at times, inconsistent and data sources cited are often inaccurate. However, as such engines scan multiple open sources and retrieve relevant information, they can help to bridge gaps in the summary of background studies and streamline the research design, by supplementing missing or overlooked information.",
    "doi": "10.1016/j.techsoc.2024.102555",
    "author_keywords": [
      "Artificial intelligence (AI)",
      "Research design",
      "Smart cities (SCs)"
    ],
    "contribution": "However, question remains how these new data management tools can assist scholars in improving the research design and implementation. In an attempt to answer this question, we focus on one particular research field â€“ definition and identification of smart cities (SCs), â€“ and compare the answers provided by different AI engines with the answers given in a sequence of research papers, prepared without the use of AI and recently published by these authors. In particular, the following aspects of the original studies were re-analysed here using the AI input: a) problem definition; b) summary of current knowledge; c) identification of unknowns; d) research strategy, and e) recommendations for research and practice. As the study reveals, the recommendations of AI engines are, at times, inconsistent and data sources cited are often inaccurate. However, as such engines scan multiple open sources and retrieve relevant information, they can help to bridge gaps in the summary of background studies and streamline the research design, by supplementing missing or overlooked information.",
    "introduction": "Artificial intelligence (AI) engines, such as ChatGPT, InferKit, and DeepAI, are very popular today and new AI engines, such as Google Bard, Chinchilla AI DeepMind, and GPT-4, constantly emerge.",
    "macro_domains": []
  },
  {
    "abstract": "Urban function detection plays a significant role in urban complex system recognition and smart city construction. The location big data obtained from human activities, which is cohesive with urban functions, provides valuable insights into human mobility patterns. However, as urban functions become highly mixed, existing feature representation structures struggle to explicitly depict the latent human activity features, limiting their applicability for detecting mixed urban functions in a supervised manner. To close the gap, this study analogizes the latent human activity features to the shape, texture, and color semantics of images, with a contrastive learning framework being introduced to extract image-based crowd mobility features for detecting mixed urban functions. Firstly, by translating human activity features into image semantics, a novel feature representation structure termed the Trajectory Temporal Image (TTI) is proposed to explicitly represent human activity features. Secondly, the Vision Transformer (ViT) model is employed to extract image-based semantics in a self-supervised manner. Lastly, based on urban dynamics, a mathematical model is developed to represent mixed urban functions, and the decomposition of mixed urban functions is achieved using the theory of fuzzy sets. A case study is conducted using taxi trajectory data in three cities in China. Experimental results indicate the high discriminability of our proposed method, especially in areas with weak activity intensity, and reveal the relationship between the mixture index and the trip distance. The proposed method is promising to establish a solid scientific foundation for comprehending the urban complex system.",
    "doi": "10.1016/j.compenvurbsys.2024.102113",
    "author_keywords": [
      "Contrastive learning",
      "FCM",
      "Human activity",
      "Location big data",
      "Mixed urban functions",
      "Trajectory temporal image"
    ],
    "contribution": "To close the gap, this study analogizes the latent human activity features to the shape, texture, and color semantics of images, with a contrastive learning framework being introduced to extract image-based crowd mobility features for detecting mixed urban functions. Firstly, by translating human activity features into image semantics, a novel feature representation structure termed the Trajectory Temporal Image (TTI) is proposed to explicitly represent human activity features. Secondly, the Vision Transformer (ViT) model is employed to extract image-based semantics in a self-supervised manner. Lastly, based on urban dynamics, a mathematical model is developed to represent mixed urban functions, and the decomposition of mixed urban functions is achieved using the theory of fuzzy sets. A case study is conducted using taxi trajectory data in three cities in China. Experimental results indicate the high discriminability of our proposed method, especially in areas with weak activity intensity, and reveal the relationship between the mixture index and the trip distance. The proposed method is promising to establish a solid scientific foundation for comprehending the urban complex system.",
    "introduction": "Urban function detection plays a significant role in urban complex system recognition and smart city construction. The location big data obtained from human activities, which is cohesive with urban functions, provides valuable insights into human mobility patterns. However, as urban functions become highly mixed, existing feature representation structures struggle to explicitly depict the latent human activity features, limiting their applicability for detecting mixed urban functions in a supervised manner.",
    "macro_domains": []
  },
  {
    "abstract": "Point of Interest (POI) is an important intermediary connecting geo data and text data in smart cities, widely used to extract and identify urban functional areas. While computer uses numerical coordinates, human uses places names or addresses to find location, leading to spatial-semantic ambiguities. However, traditional methods of extracting POIs are time-consuming and costly, and has the limitation of the lack of integration of functionalities such as information extraction(IE), information searching. Also, previous models have low accessibility and high barriers for users. With the advent of Large Language Models(LLMs) we propose a method that connects LLM models and POI information based on social media text data. By employing two steps, named entities recognition(NER) and POI information searching, we introduce POI GPT, the specialized model for providing precise location of POIs in social media text data. We compared its results with those obtained by human experts, NER model and zero-shot prompts. The findings show that our model effectively found the POI and precise location from social media text data. In result, POI GPT is a effective model that solves the existing POI extraction problems. We provide new extraction technique of POI GPT which is a new paradigm in traditional urban research methodologies and be actively utilized in urban studies in the future.",
    "doi": "10.5194/isprs-archives-XLVIII-4-W10-2024-113-2024",
    "author_keywords": [
      "ChatGPT",
      "Large Language Model(LLM)",
      "Named Entity Recognition(NER)",
      "Point of Interest(POI)",
      "Social Media"
    ],
    "contribution": "With the advent of Large Language Models(LLMs) we propose a method that connects LLM models and POI information based on social media text data. By employing two steps, named entities recognition(NER) and POI information searching, we introduce POI GPT, the specialized model for providing precise location of POIs in social media text data. We compared its results with those obtained by human experts, NER model and zero-shot prompts. The findings show that our model effectively found the POI and precise location from social media text data. In result, POI GPT is a effective model that solves the existing POI extraction problems. We provide new extraction technique of POI GPT which is a new paradigm in traditional urban research methodologies and be actively utilized in urban studies in the future.",
    "introduction": "Point of Interest (POI) is an important intermediary connecting geo data and text data in smart cities, widely used to extract and identify urban functional areas. While computer uses numerical coordinates, human uses places names or addresses to find location, leading to spatial-semantic ambiguities. However, traditional methods of extracting POIs are time-consuming and costly, and has the limitation of the lack of integration of functionalities such as information extraction(IE), information searching. Also, previous models have low accessibility and high barriers for users.",
    "macro_domains": []
  },
  {
    "abstract": "In smart cities, generative artificial intelligence (AI) models such as ChatGPT have become revolutionary tools in many respects, chiefly due to their ability to process and communicate natural language. These artificial intelligence (AI) systems have greatly enhanced communication and problem-solving skills, leading to increased productivity and efficiency in a variety of fields, including healthcare, education, environmental monitoring, public health, smart grid management, traffic management, citizen engagement, environmental monitoring, and environmental monitoring. This study looks at ChatGPT's and similar Generative AI's changing role in smartcity contexts. It highlights the need for ethical frameworks and regulatory rules by examining the difficulties in putting them into practice. Concurrently, it highlights the enormous potential these technologies provide, from promoting inclusivity to igniting innovation, forming a future in which artificial intelligence augments human capabilities and fosters peaceful coexistence between sentient machines and people.",
    "doi": "10.4018/979-8-3693-6824-4.ch010",
    "author_keywords": null,
    "contribution": "This study looks at ChatGPT's and similar Generative AI's changing role in smartcity contexts. It highlights the need for ethical frameworks and regulatory rules by examining the difficulties in putting them into practice. Concurrently, it highlights the enormous potential these technologies provide, from promoting inclusivity to igniting innovation, forming a future in which artificial intelligence augments human capabilities and fosters peaceful coexistence between sentient machines and people.",
    "introduction": "In smart cities, generative artificial intelligence (AI) models such as ChatGPT have become revolutionary tools in many respects, chiefly due to their ability to process and communicate natural language. These artificial intelligence (AI) systems have greatly enhanced communication and problem-solving skills, leading to increased productivity and efficiency in a variety of fields, including healthcare, education, environmental monitoring, public health, smart grid management, traffic management, citizen engagement, environmental monitoring, and environmental monitoring.",
    "macro_domains": []
  },
  {
    "abstract": "As intelligent urban centers continue to evolve, the reliance on wireless type sensory networks (WSNs) for data samples collections and message interaction will become paramount. However, the increasingly complexity of the networks may demand robust security measures to safeguarding against potential intrusions. In response, this chapter introduces IntelligentGuard, a novelistic intrusion identification system leverages generative based adversarial networks (GANs) for enhancement in security in WSNs within intelligent urban centers. IntelligentGuard will employs machine learning-driven techniques, including supervises learning algorithms such as support vector supportive machines (SVMs) and decision-based trees, to discern normal network behavior from anomalous patterns, thus fortifying the WSN against various intrusion scenarios. The proposed system's GAN-based architecture not only enhances identification accuracy but also adapts dynamically to evolving threat landscapes.",
    "doi": "10.4018/9798369335970.ch012",
    "author_keywords": null,
    "contribution": "In response, this chapter introduces IntelligentGuard, a novelistic intrusion identification system leverages generative based adversarial networks (GANs) for enhancement in security in WSNs within intelligent urban centers. IntelligentGuard will employs machine learning-driven techniques, including supervises learning algorithms such as support vector supportive machines (SVMs) and decision-based trees, to discern normal network behavior from anomalous patterns, thus fortifying the WSN against various intrusion scenarios. The proposed system's GAN-based architecture not only enhances identification accuracy but also adapts dynamically to evolving threat landscapes.",
    "introduction": "As intelligent urban centers continue to evolve, the reliance on wireless type sensory networks (WSNs) for data samples collections and message interaction will become paramount. However, the increasingly complexity of the networks may demand robust security measures to safeguarding against potential intrusions.",
    "macro_domains": []
  },
  {
    "abstract": "As the demand for data security intensifies, the vulnerabilities become glaring, exposing sensitive information to potential threats. In this tumultuous landscape, Generative Adversarial Networks (GANs) emerge as a groundbreaking solution, transcending their initial role as image generators to become indispensable guardians of data security. Within the pages of Enhancing Security in Public Spaces Through Generative Adversarial Networks (GANs), readers are guided through the intricate world of GANs, unraveling their unique design and dynamic adversarial training. The book presents GANs not merely as a technical marvel but as a strategic asset for organizations, offering a comprehensive solution to fortify cybersecurity, protect data privacy, and mitigate the risks associated with evolving cyber threats. It navigates the ethical considerations surrounding GANs, emphasizing the delicate balance between technological advancement and responsible use. Tailored for a diverse audience, the book speaks directly to organizations, researchers, government agencies, cybersecurity professionals, data privacy advocates, AI specialists, educational institutions, regulatory bodies, cybersecurity solution providers, and the general public. It provides actionable insights on integrating GANs into various sectors, offering a roadmap for leveraging their capabilities in healthcare, finance, smart cities, and beyond. Dive into the future of data security, armed with the knowledge and practical applications presented in this transformative book, as it unfolds the potential of GANs to safeguard our digital infrastructure in an era of unprecedented challenges.",
    "doi": "10.4018/9798369335970",
    "author_keywords": null,
    "contribution": "",
    "introduction": "As the demand for data security intensifies, the vulnerabilities become glaring, exposing sensitive information to potential threats. In this tumultuous landscape, Generative Adversarial Networks (GANs) emerge as a groundbreaking solution, transcending their initial role as image generators to become indispensable guardians of data security. Within the pages of Enhancing Security in Public Spaces Through Generative Adversarial Networks (GANs), readers are guided through the intricate world of GANs, unraveling their unique design and dynamic adversarial training. The book presents GANs not merely as a technical marvel but as a strategic asset for organizations, offering a comprehensive solution to fortify cybersecurity, protect data privacy, and mitigate the risks associated with evolving cyber threats. It navigates the ethical considerations surrounding GANs, emphasizing the delicate balance between technological advancement and responsible use. Tailored for a diverse audience, the book speaks directly to organizations, researchers, government agencies, cybersecurity professionals, data privacy advocates, AI specialists, educational institutions, regulatory bodies, cybersecurity solution providers, and the general public. It provides actionable insights on integrating GANs into various sectors, offering a roadmap for leveraging their capabilities in healthcare, finance, smart cities, and beyond. Dive into the future of data security, armed with the knowledge and practical applications presented in this transformative book, as it unfolds the potential of GANs to safeguard our digital infrastructure in an era of unprecedented challenges.",
    "macro_domains": []
  },
  {
    "abstract": "Smart cities have emerged as a promising solution to the problems associated with urbanization. However, research that holistically considers diverse stakeholders in smart cities is scarce. This study utilizes data from four types of collaborators (academia, public sector, industry, and civil society actors) to identify key topics and suggest research areas for developing smart cities. We used latent Dirichlet allocation and Bidirectional Encoder Representations from Transformers for topic extraction and analysis. The analysis reveals that sustainability and digital platform have received similar levels of interest from academia, industry, and government, whereas governance, resource, and green space are less frequently mentioned than technology-related topics. Hype cycle analysis, which considers public and media expectations, reveals that smart cities experienced rapid growth from 2015 to 2021, but the growth rate has slowed since 2022. This means that a breakthrough improvement in the current situation is required. Accordingly, we propose resolving the unbalanced distribution of topic interests among collaborators, especially in the areas of governance, environment, economy, and healthcare. We expect that our findings will help researchers, policymakers, and industry stakeholders in understanding which topics are underdeveloped in their fields and taking active measures for the future development of smart cities.",
    "doi": "10.1016/j.heliyon.2024.e30367",
    "author_keywords": [
      "BERT",
      "Google trends",
      "Hype cycle",
      "LDA",
      "Quadruple helix",
      "Smart city"
    ],
    "contribution": "This study utilizes data from four types of collaborators (academia, public sector, industry, and civil society actors) to identify key topics and suggest research areas for developing smart cities. We used latent Dirichlet allocation and Bidirectional Encoder Representations from Transformers for topic extraction and analysis. The analysis reveals that sustainability and digital platform have received similar levels of interest from academia, industry, and government, whereas governance, resource, and green space are less frequently mentioned than technology-related topics. Hype cycle analysis, which considers public and media expectations, reveals that smart cities experienced rapid growth from 2015 to 2021, but the growth rate has slowed since 2022. This means that a breakthrough improvement in the current situation is required. Accordingly, we propose resolving the unbalanced distribution of topic interests among collaborators, especially in the areas of governance, environment, economy, and healthcare. We expect that our findings will help researchers, policymakers, and industry stakeholders in understanding which topics are underdeveloped in their fields and taking active measures for the future development of smart cities.",
    "introduction": "Smart cities have emerged as a promising solution to the problems associated with urbanization. However, research that holistically considers diverse stakeholders in smart cities is scarce.",
    "macro_domains": []
  },
  {
    "abstract": "With the tremendous success of large language models such as ChatGPT, artificial intelligence has entered a new era of large models. Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains. In this paper, we tackle the problem of building large vision-language intelligent models for specific industrial domains by leveraging the general large models and federated learning. We compare the challenges faced by federated learning in the era of small models and large models from different dimensions, and propose a technical framework for federated learning in the era of large models.Specifically, our framework mainly considers three aspects: heterogeneous model fusion, flexible aggregation methods, and data quality improvement. Based on this framework, we conduct a case study of leading enterprises contributing vision-language data and expert knowledge to city safety operation management. The preliminary experiments show that enterprises can enhance and accumulate their intelligence capabilities through federated learning, and jointly create an intelligent city model that provides high-quality intelligent services covering energy infrastructure security, residential community security and urban operation management.",
    "doi": "10.1145/3589335.3651939",
    "author_keywords": [
      "Federated learning",
      "Large model",
      "Multimodal model"
    ],
    "contribution": "In this paper, we tackle the problem of building large vision-language intelligent models for specific industrial domains by leveraging the general large models and federated learning. We compare the challenges faced by federated learning in the era of small models and large models from different dimensions, and propose a technical framework for federated learning in the era of large models.Specifically, our framework mainly considers three aspects: heterogeneous model fusion, flexible aggregation methods, and data quality improvement. Based on this framework, we conduct a case study of leading enterprises contributing vision-language data and expert knowledge to city safety operation management. The preliminary experiments show that enterprises can enhance and accumulate their intelligence capabilities through federated learning, and jointly create an intelligent city model that provides high-quality intelligent services covering energy infrastructure security, residential community security and urban operation management.",
    "introduction": "With the tremendous success of large language models such as ChatGPT, artificial intelligence has entered a new era of large models. Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains.",
    "macro_domains": []
  },
  {
    "abstract": "Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.",
    "doi": "10.1145/3589334.3645378",
    "author_keywords": [
      "language-image pretraining",
      "spatio-temporal data",
      "urban computing"
    ],
    "contribution": "",
    "introduction": "Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.",
    "macro_domains": []
  },
  {
    "abstract": "Group detection, especially for large-scale scenes, has many potential applications for public safety and smart cities. Existing methods fail to cope with frequent occlusions in large-scale scenes with multiple people, and are difficult to effectively utilize spatio-temporal information. In this paper, we propose an end-to-end framework, GroupTransformer, for group detection in large-scale scenes. To deal with the frequent occlusions caused by multiple people, we design an occlusion encoder to detect and suppress severely occluded person crops. To explore the potential spatio-temporal relationship, we propose spatio-temporal transformers to simultaneously extract trajectory information and fuse inter-person features in a hierarchical manner. Experimental results on both large-scale and small-scale scenes demonstrate that our method achieves better performance compared with state-of-the-art methods. On large-scale scenes, our method significantly boosts the performance in terms of precision and F1 score by more than 10%. On small-scale scenes, our method still improves the performance of F1 score by more than 5%. We will release the code for research purposes.",
    "doi": "10.1109/TCSVT.2023.3324868",
    "author_keywords": [
      "Group detection",
      "large-scale scenes",
      "spatio-temporal transformers"
    ],
    "contribution": "In this paper, we propose an end-to-end framework, GroupTransformer, for group detection in large-scale scenes. To deal with the frequent occlusions caused by multiple people, we design an occlusion encoder to detect and suppress severely occluded person crops. To explore the potential spatio-temporal relationship, we propose spatio-temporal transformers to simultaneously extract trajectory information and fuse inter-person features in a hierarchical manner. Experimental results on both large-scale and small-scale scenes demonstrate that our method achieves better performance compared with state-of-the-art methods. On large-scale scenes, our method significantly boosts the performance in terms of precision and F1 score by more than 10%. On small-scale scenes, our method still improves the performance of F1 score by more than 5%. We will release the code for research purposes.",
    "introduction": "Group detection, especially for large-scale scenes, has many potential applications for public safety and smart cities. Existing methods fail to cope with frequent occlusions in large-scale scenes with multiple people, and are difficult to effectively utilize spatio-temporal information.",
    "macro_domains": []
  },
  {
    "abstract": "ChatGPT plays significant roles in the third decade of the 21st Century. Smart cities applications can be integrated with ChatGPT in various fields. This research proposes an approach for developing large language models using generative artificial intelligence models suitable for small- and medium-sized enterprises with limited hardware resources. There are many generative AI systems in operation and in development. However, the technological, human, and financial resources required to develop generative AI systems are impractical for small- and medium-sized enterprises. In this study, we present a proposed approach to reduce training time and computational cost that is designed to automate questionâ€“response interactions for specific domains in smart cities. The proposed model utilises the BLOOM approach as its backbone for using generative AI to maximum the effectiveness of small- and medium-sized enterprises. We have conducted a set of experiments on several datasets associated with specific domains to validate the effectiveness of the proposed model. Experiments using datasets for the English and Vietnamese languages have been combined with model training using low-rank adaptation to reduce training time and computational cost. In comparative experimental testing, the proposed model outperformed the â€˜Phoenixâ€™ multilingual chatbot model by achieving a 92% performance compared to â€˜ChatGPTâ€™ for the English benchmark.",
    "doi": "10.3390/app14073036",
    "author_keywords": [
      "chatbot",
      "ChatGPT",
      "generative AI",
      "language comprehension",
      "large language models",
      "multilingual language models",
      "support systems",
      "technological determinism"
    ],
    "contribution": "This research proposes an approach for developing large language models using generative artificial intelligence models suitable for small- and medium-sized enterprises with limited hardware resources. There are many generative AI systems in operation and in development. However, the technological, human, and financial resources required to develop generative AI systems are impractical for small- and medium-sized enterprises. In this study, we present a proposed approach to reduce training time and computational cost that is designed to automate questionâ€“response interactions for specific domains in smart cities. The proposed model utilises the BLOOM approach as its backbone for using generative AI to maximum the effectiveness of small- and medium-sized enterprises. We have conducted a set of experiments on several datasets associated with specific domains to validate the effectiveness of the proposed model. Experiments using datasets for the English and Vietnamese languages have been combined with model training using low-rank adaptation to reduce training time and computational cost. In comparative experimental testing, the proposed model outperformed the â€˜Phoenixâ€™ multilingual chatbot model by achieving a 92% performance compared to â€˜ChatGPTâ€™ for the English benchmark.",
    "introduction": "ChatGPT plays significant roles in the third decade of the 21st Century. Smart cities applications can be integrated with ChatGPT in various fields.",
    "macro_domains": []
  },
  {
    "abstract": "In the dynamic evolution of smart cities, the collaboration between generative artificial intelligence (AI) and internet of things (IoT) technologies is reshaping urban experiences and fostering sustainable urban development. This collaborative explores the intricate balance of dynamic resource allocation and optimization facilitated by generative AI algorithms within intelligent city IoT networks. It unfolds the transformative potential of generative design for smart city infrastructure, offering insights into energy efficiency and advanced AI processes. The chapter underscores the pivotal role of predictive analytics, behavior prediction, and cybersecurity measures in steering decision-making for optimal urban funcÂ¬tioning. Real-world case studies illuminate successful generative AI-IoT integrations, providing tangible lessons for stakeholders, and conclude by urging ongoing collaborative research to address evolving challenges and chart future directions for a more interconnected and resilient urban future. This chapter serves as a valuable contribution, providing a comprehensive exploration of the transformative potential of this collaborative paradigm.",
    "doi": "10.4018/979-8-3693-2373-1.ch011",
    "author_keywords": null,
    "contribution": "This chapter serves as a valuable contribution, providing a comprehensive exploration of the transformative potential of this collaborative paradigm.",
    "introduction": "In the dynamic evolution of smart cities, the collaboration between generative artificial intelligence (AI) and internet of things (IoT) technologies is reshaping urban experiences and fostering sustainable urban development. This collaborative explores the intricate balance of dynamic resource allocation and optimization facilitated by generative AI algorithms within intelligent city IoT networks. It unfolds the transformative potential of generative design for smart city infrastructure, offering insights into energy efficiency and advanced AI processes. The chapter underscores the pivotal role of predictive analytics, behavior prediction, and cybersecurity measures in steering decision-making for optimal urban funcÂ¬tioning. Real-world case studies illuminate successful generative AI-IoT integrations, providing tangible lessons for stakeholders, and conclude by urging ongoing collaborative research to address evolving challenges and chart future directions for a more interconnected and resilient urban future.",
    "macro_domains": []
  },
  {
    "abstract": "A crucial natural resource that directly affects the ecology is forests. Forest fires have become a noteworthy problem recently as a result of both natural and man-made climatic changes. A smart city application that uses a forest fire discovery technology based on artificial intelligence is provided in order to prevent significant catastrophes. A major danger to the environment, animals, and human lives is posed by forest fires. The early detection and suppression of these fires is crucial. This work offers a thorough method for detecting forest fires using advanced deep learning (DL) algorithms. Preprocessing the forest fire dataset is the initial step in order to improve its relevance and quality. Then, to enable the model to capture the dynamic character of forest fire data, long short-term memory (LSTM) networks are used to extract useful feature from the dataset. In this work, weight optimisation in LSTM is performed using a Modified Firefly Algorithm (MFFA), which enhances the model's performance and convergence. The Variational Autoencoder Generative Adversarial Networks (VAEGAN) model is used to classify the retrieved features. Furthermore, every DL model's success depends heavily on hyperparameter optimisation. The hyperparameters of an VAEGAN model are tuned in this research using the Waterwheel Plant Optimisation Algorithm (WWPA), an optimisation technique inspired by nature. WPPA uses the idea of plant growth to properly tune the VAEGAN's parameters, assuring the network's peak fire detection performance. The outstanding accuracy (ACC) of 97.8%, precision (PR) of 97.7%, recall (RC) of 96.26%, F1-score (F1) of 97.3%, and specificity (SPEC) of 97.5% of the suggested model beats all other existing models, which is probably owing to its improved architecture and training techniques.",
    "doi": "10.18280/ijsse.140202",
    "author_keywords": [
      "forest fire",
      "long short term memory",
      "modified firefly algorithm",
      "variational autoencoder",
      "waterwheel plant optimization"
    ],
    "contribution": "This work offers a thorough method for detecting forest fires using advanced deep learning (DL) algorithms. Preprocessing the forest fire dataset is the initial step in order to improve its relevance and quality. Then, to enable the model to capture the dynamic character of forest fire data, long short-term memory (LSTM) networks are used to extract useful feature from the dataset. In this work, weight optimisation in LSTM is performed using a Modified Firefly Algorithm (MFFA), which enhances the model's performance and convergence. The Variational Autoencoder Generative Adversarial Networks (VAEGAN) model is used to classify the retrieved features. Furthermore, every DL model's success depends heavily on hyperparameter optimisation. The hyperparameters of an VAEGAN model are tuned in this research using the Waterwheel Plant Optimisation Algorithm (WWPA), an optimisation technique inspired by nature. WPPA uses the idea of plant growth to properly tune the VAEGAN's parameters, assuring the network's peak fire detection performance. The outstanding accuracy (ACC) of 97.8%, precision (PR) of 97.7%, recall (RC) of 96.26%, F1-score (F1) of 97.3%, and specificity (SPEC) of 97.5% of the suggested model beats all other existing models, which is probably owing to its improved architecture and training techniques.",
    "introduction": "A crucial natural resource that directly affects the ecology is forests. Forest fires have become a noteworthy problem recently as a result of both natural and man-made climatic changes. A smart city application that uses a forest fire discovery technology based on artificial intelligence is provided in order to prevent significant catastrophes. A major danger to the environment, animals, and human lives is posed by forest fires. The early detection and suppression of these fires is crucial.",
    "macro_domains": []
  },
  {
    "abstract": "Bike-sharing systems (BSS) have emerged as an increasingly important form of transportation in smart cities, playing a pivotal role in the evolving landscape of urban mobility. As cities worldwide strive to promote sustainable and efficient transportation options, BSS offer a flexible, eco-friendly alternative that complements traditional public transport systems. These systems, however, are complex and influenced by a myriad of endogenous and exogenous factors. This complexity poses challenges in predicting BSS activity and optimizing its usage and effectiveness. This study delves into the dynamics of the BSS in Hamburg, Germany, focusing on system stability and activity prediction. We propose an interpretable attention-based Temporal Fusion Transformer (TFT) model and compare its performance with the state-of-the-art Long Short-Term Memory (LSTM) model. The proposed TFT model outperforms the LSTM model with a 36.8% improvement in RMSE and overcomes current black-box models via interpretability. Via detailed analysis, key factors influencing bike-sharing activity, especially in terms of temporal and spatial contexts, are identified, examined, and evaluated. Based on the results, we propose interventions and a deployed TFT model that can improve the effectiveness of BSS. This research contributes to the evolving field of sustainable urban mobility via data analysis for data-informed decision-making.",
    "doi": "10.3390/su16083230",
    "author_keywords": [
      "bike-sharing activity",
      "bike-sharing system",
      "demand prediction",
      "Long Short-Term Memory",
      "machine learning",
      "Temporal Fusion Transformer"
    ],
    "contribution": "This study delves into the dynamics of the BSS in Hamburg, Germany, focusing on system stability and activity prediction. We propose an interpretable attention-based Temporal Fusion Transformer (TFT) model and compare its performance with the state-of-the-art Long Short-Term Memory (LSTM) model. The proposed TFT model outperforms the LSTM model with a 36.8% improvement in RMSE and overcomes current black-box models via interpretability. Via detailed analysis, key factors influencing bike-sharing activity, especially in terms of temporal and spatial contexts, are identified, examined, and evaluated. Based on the results, we propose interventions and a deployed TFT model that can improve the effectiveness of BSS. This research contributes to the evolving field of sustainable urban mobility via data analysis for data-informed decision-making.",
    "introduction": "Bike-sharing systems (BSS) have emerged as an increasingly important form of transportation in smart cities, playing a pivotal role in the evolving landscape of urban mobility. As cities worldwide strive to promote sustainable and efficient transportation options, BSS offer a flexible, eco-friendly alternative that complements traditional public transport systems. These systems, however, are complex and influenced by a myriad of endogenous and exogenous factors. This complexity poses challenges in predicting BSS activity and optimizing its usage and effectiveness.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic flow prediction is essential for smart city management and planning, aiding in optimizing traffic scheduling and improving overall traffic conditions. However, due to the correlation and heterogeneity of traffic data, effectively integrating the captured temporal and spatial features remains a significant challenge. This paper proposes a model spatialâ€“temporal fusion gated transformer network (STFGTN), which is based on an attention mechanism that integrates temporal and spatial features. This paper proposes an attention mechanism-based model to address these issues and model complex spatialâ€“temporal dependencies in road networks. The self-attention mechanism enables the model to achieve long-term dependency modeling and global representation of time series data. Regarding temporal features, we incorporate a time embedding layer and a time transformer to learn temporal dependencies. This capability contributes to a more comprehensive and accurate understanding of spatialâ€“temporal dynamic patterns throughout the entire time series. As for spatial features, we utilize DGCN and spatial transformers to capture both global and local spatial dependencies, respectively. Additionally, we propose two fusion gate mechanisms to effectively accommodate to the complex correlation and heterogeneity of spatialâ€“temporal information, resulting in a more accurate reflection of the actual traffic flow. Our experiments on three real-world datasets illustrate the superior performance of our approach.",
    "doi": "10.3390/electronics13081594",
    "author_keywords": [
      "attention mechanism",
      "fusion gate",
      "smart city",
      "traffic flow prediction",
      "transformer"
    ],
    "contribution": "This paper proposes a model spatialâ€“temporal fusion gated transformer network (STFGTN), which is based on an attention mechanism that integrates temporal and spatial features. This paper proposes an attention mechanism-based model to address these issues and model complex spatialâ€“temporal dependencies in road networks. The self-attention mechanism enables the model to achieve long-term dependency modeling and global representation of time series data. Regarding temporal features, we incorporate a time embedding layer and a time transformer to learn temporal dependencies. This capability contributes to a more comprehensive and accurate understanding of spatialâ€“temporal dynamic patterns throughout the entire time series. As for spatial features, we utilize DGCN and spatial transformers to capture both global and local spatial dependencies, respectively. Additionally, we propose two fusion gate mechanisms to effectively accommodate to the complex correlation and heterogeneity of spatialâ€“temporal information, resulting in a more accurate reflection of the actual traffic flow. Our experiments on three real-world datasets illustrate the superior performance of our approach.",
    "introduction": "Traffic flow prediction is essential for smart city management and planning, aiding in optimizing traffic scheduling and improving overall traffic conditions. However, due to the correlation and heterogeneity of traffic data, effectively integrating the captured temporal and spatial features remains a significant challenge.",
    "macro_domains": []
  },
  {
    "abstract": "With the prevalence of the Internet of Things (IoT) systems, smart cities comprise complex networks, including sensors, actuators, appliances, and cyber services. The complexity and heterogeneity of smart cities have become vulnerable to sophisticated cyber-attacks, especially privacy-related attacks such as inference and data poisoning ones. Federated Learning (FL) has been regarded as a hopeful method to enable distributed learning with privacy-preserved intelligence in IoT applications. Even though the significance of developing privacy-preserving FL has drawn as a great research interest, the current research only concentrates on FL with independent identically distributed (i.i.d) data and few studies have addressed the non-i. i.d setting. FL is known to be vulnerable to Generative Adversarial Network (GAN) attacks, where an adversary can presume to act as a contributor participating in the training process to acquire the private data of other contributors. This paper proposes an innovative Privacy Protection-based Federated Deep Learning (PP-FDL) framework, which accomplishes data protection against privacy-related GAN attacks, along with high classification rates from non-i. i.d data. PP-FDL is designed to enable fog nodes to cooperate to train the FDL model in a way that ensures contributors have no access to the data of each other, where class probabilities are protected utilizing a private identifier generated for each class. The PP-FDL framework is evaluated for image classification using simple convolutional networks which are trained using MNIST and CIFAR-10 datasets. The empirical results have revealed that PF-DFL can achieve data protection and the framework outperforms the other three state-of-the-art models with 3%â€“8% as accuracy improvements.",
    "doi": "10.1016/j.dcan.2022.12.013",
    "author_keywords": [
      "Deep learning",
      "Federated learning",
      "Fog computing",
      "Privacy preservation",
      "Smart cities"
    ],
    "contribution": "This paper proposes an innovative Privacy Protection-based Federated Deep Learning (PP-FDL) framework, which accomplishes data protection against privacy-related GAN attacks, along with high classification rates from non-i. i.d data. PP-FDL is designed to enable fog nodes to cooperate to train the FDL model in a way that ensures contributors have no access to the data of each other, where class probabilities are protected utilizing a private identifier generated for each class. The PP-FDL framework is evaluated for image classification using simple convolutional networks which are trained using MNIST and CIFAR-10 datasets. The empirical results have revealed that PF-DFL can achieve data protection and the framework outperforms the other three state-of-the-art models with 3%â€“8% as accuracy improvements.",
    "introduction": "With the prevalence of the Internet of Things (IoT) systems, smart cities comprise complex networks, including sensors, actuators, appliances, and cyber services. The complexity and heterogeneity of smart cities have become vulnerable to sophisticated cyber-attacks, especially privacy-related attacks such as inference and data poisoning ones. Federated Learning (FL) has been regarded as a hopeful method to enable distributed learning with privacy-preserved intelligence in IoT applications. Even though the significance of developing privacy-preserving FL has drawn as a great research interest, the current research only concentrates on FL with independent identically distributed (i.i.d) data and few studies have addressed the non-i. i.d setting. FL is known to be vulnerable to Generative Adversarial Network (GAN) attacks, where an adversary can presume to act as a contributor participating in the training process to acquire the private data of other contributors.",
    "macro_domains": []
  },
  {
    "abstract": "Security in smart cities is a challenging issue in urban environments as they depend upon interconnected technologies and data for effective services. To address security challenges, smart cities implement robust cybersecurity measures, including network monitoring, encryption, and intrusion detection systems. Detecting and mitigating possible security risks in drone network B5G is a crucial aspect of ensuring reliable and safe drone operation. It is necessary to establish sophisticated and robust attack detection techniques to defend against security threats as the use of drones becomes increasingly widespread and their applications diversify. This is due to the lack of privacy and security consideration in the drone's system, including an inadequate computation capability and unsecured wireless channels to perform advanced cryptographic algorithms. Intrusion detection systems (IDS) and anomaly detection systems can identify suspicious activities and monitor network traffic, such as anomalous communication patterns or unauthorized access attempts. Therefore, the study presents an enhanced dwarf mongoose optimization algorithm with deep learning-based attack detection (EDMOA-DLAD) in Networks B5G for the purpose of Drones technique. The presented EDMOA-DLAD technique aims to recognize the attacks and classifies them on the drone network B5G. Primarily, the EDMOA-DLAD technique designs a feature selection (FS) approach using EDMOA. To detect attacks, the EDMOA-DLAD technique uses a deep variational autoencoder (DVAE) classifier. Finally, the EDMOA-DLAD technique applies the beetle antenna search (BAS) technique for the optimum hyperparameter part of DVAE model. The outcome of EDMOA-DLAD approach can be verified on benchmark datasets. A wide range of simulations inferred that the EDMOA-DLAD method obtains enhanced performance of 99.79% over other classification techniques.",
    "doi": "10.1016/j.aej.2024.02.048",
    "author_keywords": [
      "Deep learning",
      "Dwarf mongoose optimization algorithm",
      "Security",
      "Smart cities attacks"
    ],
    "contribution": "Therefore, the study presents an enhanced dwarf mongoose optimization algorithm with deep learning-based attack detection (EDMOA-DLAD) in Networks B5G for the purpose of Drones technique. The presented EDMOA-DLAD technique aims to recognize the attacks and classifies them on the drone network B5G. Primarily, the EDMOA-DLAD technique designs a feature selection (FS) approach using EDMOA. To detect attacks, the EDMOA-DLAD technique uses a deep variational autoencoder (DVAE) classifier. Finally, the EDMOA-DLAD technique applies the beetle antenna search (BAS) technique for the optimum hyperparameter part of DVAE model. The outcome of EDMOA-DLAD approach can be verified on benchmark datasets. A wide range of simulations inferred that the EDMOA-DLAD method obtains enhanced performance of 99.79% over other classification techniques.",
    "introduction": "Security in smart cities is a challenging issue in urban environments as they depend upon interconnected technologies and data for effective services. To address security challenges, smart cities implement robust cybersecurity measures, including network monitoring, encryption, and intrusion detection systems. Detecting and mitigating possible security risks in drone network B5G is a crucial aspect of ensuring reliable and safe drone operation. It is necessary to establish sophisticated and robust attack detection techniques to defend against security threats as the use of drones becomes increasingly widespread and their applications diversify. This is due to the lack of privacy and security consideration in the drone's system, including an inadequate computation capability and unsecured wireless channels to perform advanced cryptographic algorithms. Intrusion detection systems (IDS) and anomaly detection systems can identify suspicious activities and monitor network traffic, such as anomalous communication patterns or unauthorized access attempts.",
    "macro_domains": []
  },
  {
    "abstract": "In the subjective evaluation process, the hesitant fuzzy set (HFS), as a convenient and robust presentation tool, cannot only suitably address the decision makersâ€™ (DMsâ€™) or expertsâ€™ hesitant and uncertain issues but also can arise the dimension curse puzzle. Furthermore, the decision-making result is just derived according to the given objective and subjective information, without considering the DM's subjective evaluation and the environment's dynamic influence. Unlike the previous studies, this paper tries to address them from the deep learning viewpoint. To this end, we first define the non-equidimensional HFS (NHFS) and then introduce the equidimensional and classification characters into the NHFS to further develop the equidimensional HFS (EHFS) and the EHFS with the optimal classification result. Then, the equidimensional hesitant fuzzy-generative adversarial network (EHF-GAN) model is proposed to transform the hesitant fuzzy information from the non-equidimensional to the equidimensional form. The generalization and the convergence of the new model are proven to show the modelsâ€™ reasonability. In addition, the double-learning algorithm of the EHF-GAN model is designed, which can fuse the DMsâ€™ dynamic judgments and derive the optimal decision-making results. Lastly, this paper applies the proposed model and algorithm to an illustrative example of the new smart city enterprises and then shows their feasibility and effectiveness.",
    "doi": "10.1016/j.ins.2024.120307",
    "author_keywords": [
      "Classification label",
      "Double-learning algorithm",
      "Generative adversarial network",
      "Hesitant fuzzy set",
      "New smart city",
      "Non-equidimensional information"
    ],
    "contribution": "Unlike the previous studies, this paper tries to address them from the deep learning viewpoint. To this end, we first define the non-equidimensional HFS (NHFS) and then introduce the equidimensional and classification characters into the NHFS to further develop the equidimensional HFS (EHFS) and the EHFS with the optimal classification result. Then, the equidimensional hesitant fuzzy-generative adversarial network (EHF-GAN) model is proposed to transform the hesitant fuzzy information from the non-equidimensional to the equidimensional form. The generalization and the convergence of the new model are proven to show the modelsâ€™ reasonability. In addition, the double-learning algorithm of the EHF-GAN model is designed, which can fuse the DMsâ€™ dynamic judgments and derive the optimal decision-making results. Lastly, this paper applies the proposed model and algorithm to an illustrative example of the new smart city enterprises and then shows their feasibility and effectiveness.",
    "introduction": "In the subjective evaluation process, the hesitant fuzzy set (HFS), as a convenient and robust presentation tool, cannot only suitably address the decision makersâ€™ (DMsâ€™) or expertsâ€™ hesitant and uncertain issues but also can arise the dimension curse puzzle. Furthermore, the decision-making result is just derived according to the given objective and subjective information, without considering the DM's subjective evaluation and the environment's dynamic influence.",
    "macro_domains": []
  },
  {
    "abstract": "Given the pervasive use of deep learning models across various domains, ensuring model security has emerged as a critical concern. This paper examines backdoor attacks, a form of security threat that compromises model output by poisoning the training data. Our investigation specifically addresses backdoor attacks on object detection models, vital for security-sensitive applications like autonomous driving and smart city systems. Consequently, such attacks on object detection models could pose significant risks to human life and property. Consequently, backdoor attacks on object detection could pose serious threats to human life and property. To elucidate this security risk, we propose and experimentally evaluate five backdoor attack methods for object detection models. The key findings are: (1) Unnecessary Object Generation: a globally embedded trigger creating false objects in the target class; (2) Partial Misclassification: a trigger causing specific class misclassification; (3) Global Misclassification: a trigger reclassifying all objects into the target class; (4) Specific Object Vanishing: a trigger causing non-detection of certain objects; (5) Object Position Shifting: a trigger causing bounding box shifts for a specific class. To assess attack effectiveness, we introduced the Attack Success Rate (ASR), which can surpass 1 in object detection tasks, thus providing a more accurate reflection of the attack impact. Experimental outcomes indicate that the ASR values of these varied backdoor attacks frequently approach or surpass 1, demonstrating our method's capacity to impact multiple objects simultaneously. Additionally, to augment trigger stealth, we introduce Backdoor Attack with Wavelet Embedding (BAWE), which discreetly embeds triggers as image watermarks in training data. This embedding method yields more natural triggers with enhanced stealth. Highly stealthy triggers are less detectable, significantly increasing the likelihood of attack success and efficacy. We have developed a Transformer-based network architecture, diverging from traditional neural network frameworks. Our experiments across various object detection datasets highlight the susceptibility of these models and the high success rate of our approaches. This vulnerability poses significant risks to digital twin systems utilizing object detection technology. Our methodology not only enhances trigger stealth but also suits dense predictive tasks and circumvents current neural network backdoor attack detection methods. The experimental findings expose key challenges in the security of object detection models, particularly when integrated with digital twins, offering new avenues for backdoor attack research and foundational insights for devising defense strategies against these attacks.",
    "doi": "10.1016/j.aei.2024.102355",
    "author_keywords": [
      "Autonomous driving",
      "Backdoor attack",
      "Deep learning model",
      "Global Misclassification",
      "Object detection",
      "Object Position Shifting",
      "Partial Misclassification",
      "Specific Object Vanishing",
      "Trigger",
      "Unnecessary Object Generation",
      "Wavelet embedding"
    ],
    "contribution": "This paper examines backdoor attacks, a form of security threat that compromises model output by poisoning the training data. Our investigation specifically addresses backdoor attacks on object detection models, vital for security-sensitive applications like autonomous driving and smart city systems. Consequently, such attacks on object detection models could pose significant risks to human life and property. Consequently, backdoor attacks on object detection could pose serious threats to human life and property. To elucidate this security risk, we propose and experimentally evaluate five backdoor attack methods for object detection models. The key findings are: (1) Unnecessary Object Generation: a globally embedded trigger creating false objects in the target class; (2) Partial Misclassification: a trigger causing specific class misclassification; (3) Global Misclassification: a trigger reclassifying all objects into the target class; (4) Specific Object Vanishing: a trigger causing non-detection of certain objects; (5) Object Position Shifting: a trigger causing bounding box shifts for a specific class. To assess attack effectiveness, we introduced the Attack Success Rate (ASR), which can surpass 1 in object detection tasks, thus providing a more accurate reflection of the attack impact. Experimental outcomes indicate that the ASR values of these varied backdoor attacks frequently approach or surpass 1, demonstrating our method's capacity to impact multiple objects simultaneously. Additionally, to augment trigger stealth, we introduce Backdoor Attack with Wavelet Embedding (BAWE), which discreetly embeds triggers as image watermarks in training data. This embedding method yields more natural triggers with enhanced stealth. Highly stealthy triggers are less detectable, significantly increasing the likelihood of attack success and efficacy. We have developed a Transformer-based network architecture, diverging from traditional neural network frameworks. Our experiments across various object detection datasets highlight the susceptibility of these models and the high success rate of our approaches. This vulnerability poses significant risks to digital twin systems utilizing object detection technology. Our methodology not only enhances trigger stealth but also suits dense predictive tasks and circumvents current neural network backdoor attack detection methods. The experimental findings expose key challenges in the security of object detection models, particularly when integrated with digital twins, offering new avenues for backdoor attack research and foundational insights for devising defense strategies against these attacks.",
    "introduction": "Given the pervasive use of deep learning models across various domains, ensuring model security has emerged as a critical concern.",
    "macro_domains": []
  },
  {
    "abstract": "Road extraction is a crucial task that requires high-resolution remote sensing images with wide-ranging applications in urban planning, navigation, and autonomous vehicles. However, this task is challenged by complex road structures and the need to capture long-range dependencies. RoadTransNet is a new road extraction architecture that aims to solve these problems that making the power of the Swin Transformer and Feature Pyramid Network (FPN) while introducing Transformer-like attention mechanisms. RoadTransNet combines a robust convolutional backbone, inspired by the Swin Transformer, with an FPN to capture multi-scale features effectively. The Transformer-like attention mechanisms, including multi-head self-attention and cross-attention, enable the network to represent context information on a local and global scale, ensuring accurate road extraction. The skip connections facilitate gradient flow, preserving fine details, and decoding layers transform extracted features into precise road predictions. Our experiments are conducted using the RoadTransNet, which is subject to rigorous assessment on the following datasets: the DeepGlobe road extraction challenge Dataset and the CHN6-cUG roads dataset. The outcomes indicate its superior performance in achieving high-level metrics of precision and recall, as well as achieving high F1 scores and IoU. The comparative evaluations performed against traditional methods showcase RoadTransNet's ability to capture complex road structures and long-range dependencies. The RoadTransNet stands as a comprehensive solution for the extraction of roads in high-resolution remote sensing images, offering promising opportunities for improving urban planning, navigation systems, and autonomous vehicle technologies. Its success lies in the synergy of convolutional and transformer-based architectures, paving the way for advanced remote sensing applications in smart cities and others.",
    "doi": "10.1007/s11760-023-02916-1",
    "author_keywords": [
      "Cross-attention",
      "Decoder",
      "Feature pyramid network",
      "Road extraction",
      "RoadTransNet",
      "Self-attention",
      "Skip connections",
      "Swin transformer"
    ],
    "contribution": "",
    "introduction": "Road extraction is a crucial task that requires high-resolution remote sensing images with wide-ranging applications in urban planning, navigation, and autonomous vehicles. However, this task is challenged by complex road structures and the need to capture long-range dependencies. RoadTransNet is a new road extraction architecture that aims to solve these problems that making the power of the Swin Transformer and Feature Pyramid Network (FPN) while introducing Transformer-like attention mechanisms. RoadTransNet combines a robust convolutional backbone, inspired by the Swin Transformer, with an FPN to capture multi-scale features effectively. The Transformer-like attention mechanisms, including multi-head self-attention and cross-attention, enable the network to represent context information on a local and global scale, ensuring accurate road extraction. The skip connections facilitate gradient flow, preserving fine details, and decoding layers transform extracted features into precise road predictions. Our experiments are conducted using the RoadTransNet, which is subject to rigorous assessment on the following datasets: the DeepGlobe road extraction challenge Dataset and the CHN6-cUG roads dataset. The outcomes indicate its superior performance in achieving high-level metrics of precision and recall, as well as achieving high F1 scores and IoU. The comparative evaluations performed against traditional methods showcase RoadTransNet's ability to capture complex road structures and long-range dependencies. The RoadTransNet stands as a comprehensive solution for the extraction of roads in high-resolution remote sensing images, offering promising opportunities for improving urban planning, navigation systems, and autonomous vehicle technologies. Its success lies in the synergy of convolutional and transformer-based architectures, paving the way for advanced remote sensing applications in smart cities and others.",
    "macro_domains": []
  },
  {
    "abstract": "As a fundamental spatiotemporal sequence forecasting problem, traffic prediction is pivotal in transportation management and urban computing. Nonetheless, the intricate and dynamic nature of spatiotemporal correlations presents significant obstacles in acquiring precise forecasts. Existing techniques utilize graph convolutional networks in conjunction with temporal modules, such as recurrent neural networks or transformer-based structures, to effectively extract spatiotemporal features. Unfortunately, current approaches struggle with outliers and fail to capture potential global correlations between different timestamps. In this study, we propose an innovative Spatio-Temporal Graph Convolution Network with Embedded location and time features (STEGCN) for traffic prediction problems, which can generate precise and prompt predictions. STEGCN effectively captures the complex interdependencies among location, time, and traffic volume by leveraging the TransD algorithm to embed their representations. For each timestamp, a graph convolution module is exploited to capture the spatial features, merged with the embeddings of location and time that serve as global external information. Then, we leverage a temporal module composed of 1-D convolutions to capture the spatiotemporal patterns. The traffic volume embedding is employed to constrain predictions within a reasonable range. Extensive experiments and rigorous analysis show that our STEGCN model outperforms state-of-the-art baselines, demonstrating exceptional performance and potential for practical application.",
    "doi": "10.1016/j.eswa.2023.122449",
    "author_keywords": [
      "Embedding",
      "Graph Convolutional Network",
      "Spatiotemporal Sequence",
      "Traffic Prediction",
      "TransD Algorithm"
    ],
    "contribution": "In this study, we propose an innovative Spatio-Temporal Graph Convolution Network with Embedded location and time features (STEGCN) for traffic prediction problems, which can generate precise and prompt predictions. STEGCN effectively captures the complex interdependencies among location, time, and traffic volume by leveraging the TransD algorithm to embed their representations. For each timestamp, a graph convolution module is exploited to capture the spatial features, merged with the embeddings of location and time that serve as global external information. Then, we leverage a temporal module composed of 1-D convolutions to capture the spatiotemporal patterns. The traffic volume embedding is employed to constrain predictions within a reasonable range. Extensive experiments and rigorous analysis show that our STEGCN model outperforms state-of-the-art baselines, demonstrating exceptional performance and potential for practical application.",
    "introduction": "As a fundamental spatiotemporal sequence forecasting problem, traffic prediction is pivotal in transportation management and urban computing. Nonetheless, the intricate and dynamic nature of spatiotemporal correlations presents significant obstacles in acquiring precise forecasts. Existing techniques utilize graph convolutional networks in conjunction with temporal modules, such as recurrent neural networks or transformer-based structures, to effectively extract spatiotemporal features. Unfortunately, current approaches struggle with outliers and fail to capture potential global correlations between different timestamps.",
    "macro_domains": []
  },
  {
    "abstract": "Mobile Crowdsensing (MCS) is a sensing paradigm that enables large-scale smart city applications, such as environmental sensing and traffic monitoring. However, traditional MCS often suffers from performance degradation due to the limited spatiotemporal coverage of collected data. In this context, Sparse MCS has been proposed, which utilizes data inference algorithms to recover full data from sparse data collected by users. However, existing Sparse MCS approaches often overlook spatiotemporal fractures, where no data is observed either for a sensing subarea across all sensing time slots (temporal fracture), or for a sensing time slot in all sensing subarea (spatial fracture). Such spatiotemporal fractures pose great challenges to the data inference algorithms, as it is difficult to capture the complex spatiotemporal correlations of the sensing data from very limited observations. To address this issue, we propose a Graph- and Attention-based Matrix Completion (GAMC) method for the spatiotemporal fracture data inference problem in Sparse MCS. Specifically, we first pre-fill the general missing values using the classical Matrix Factorization (MF) technique. Then, we propose a neural network architecture based on Graph Attention Networks (GAT) and Transformer to capture complex spatiotemporal dependencies in the sensing data. Finally, we recover the complete data with a projection layer. We conduct extensive experiments on three real-world urban sensing datasets. The experimental results show the effectiveness of the proposed method.",
    "doi": "10.1109/TNET.2023.3323522",
    "author_keywords": [
      "graph attention networks",
      "Mobile crowdsensing",
      "spatiotemporal fracture data inference",
      "transformer"
    ],
    "contribution": "To address this issue, we propose a Graph- and Attention-based Matrix Completion (GAMC) method for the spatiotemporal fracture data inference problem in Sparse MCS. Specifically, we first pre-fill the general missing values using the classical Matrix Factorization (MF) technique. Then, we propose a neural network architecture based on Graph Attention Networks (GAT) and Transformer to capture complex spatiotemporal dependencies in the sensing data. Finally, we recover the complete data with a projection layer. We conduct extensive experiments on three real-world urban sensing datasets. The experimental results show the effectiveness of the proposed method.",
    "introduction": "Mobile Crowdsensing (MCS) is a sensing paradigm that enables large-scale smart city applications, such as environmental sensing and traffic monitoring. However, traditional MCS often suffers from performance degradation due to the limited spatiotemporal coverage of collected data. In this context, Sparse MCS has been proposed, which utilizes data inference algorithms to recover full data from sparse data collected by users. However, existing Sparse MCS approaches often overlook spatiotemporal fractures, where no data is observed either for a sensing subarea across all sensing time slots (temporal fracture), or for a sensing time slot in all sensing subarea (spatial fracture). Such spatiotemporal fractures pose great challenges to the data inference algorithms, as it is difficult to capture the complex spatiotemporal correlations of the sensing data from very limited observations.",
    "macro_domains": []
  },
  {
    "abstract": "In recent years, the application of the internet of things (IoT) in areas such as intelligent transportation, smart cities, and the industrial internet has become increasingly widespread. As a crucial supporting infrastructure, IoT devices are utilized in various fields to construct IoT networks. However, due to the inherent limitations of IoT devices, such as limited computing resources and low memory capacity, security concerns have become increasingly prominent. Among these concerns are Denial-of-Service (DoS) and botnet attacks, which are difficult to prevent due to their large-scale and covert nature. To address these challenges, this paper proposes a Hybrid DoS Attack Intrusion Detection System (HDA-IDS) that combines signature-based detection with anomaly-based detection to effectively identify both known and unknown DoS/botnet attacks. Additionally, this paper introduces a novel anomaly-based detection model called CL-GAN. It integrates CNN-LSTM with GAN to establish a baseline for normal behavior and detect malicious traffic. In contrast to other semi-supervised models, the CL-GAN exhibits superior accuracy, as well as shorter training and testing times, in detecting DoS and botnet attacks. In addition, experimental results demonstrate that the HDA-IDS outperforms other IDSs in detecting DoS and botnet attacks. When tested on datasets such as NSL-KDD, CICIDS2018, and Bot-IoT, the HDA-IDS achieved an average of 5% overall improvement superior performance in terms of accuracy, precision, recall, and F1-Score compared to other works. These results highlight the effectiveness of the proposed system in addressing security issues in IoT networks, and presents a general framework that addresses the challenge of large-scale attacks constructed through the dissemination of false information.",
    "doi": "10.1016/j.eswa.2023.122198",
    "author_keywords": [
      "Generative adversarial network",
      "Internet of Things",
      "Intrusion Detection System",
      "Machine learning"
    ],
    "contribution": "To address these challenges, this paper proposes a Hybrid DoS Attack Intrusion Detection System (HDA-IDS) that combines signature-based detection with anomaly-based detection to effectively identify both known and unknown DoS/botnet attacks. Additionally, this paper introduces a novel anomaly-based detection model called CL-GAN. It integrates CNN-LSTM with GAN to establish a baseline for normal behavior and detect malicious traffic. In contrast to other semi-supervised models, the CL-GAN exhibits superior accuracy, as well as shorter training and testing times, in detecting DoS and botnet attacks. In addition, experimental results demonstrate that the HDA-IDS outperforms other IDSs in detecting DoS and botnet attacks. When tested on datasets such as NSL-KDD, CICIDS2018, and Bot-IoT, the HDA-IDS achieved an average of 5% overall improvement superior performance in terms of accuracy, precision, recall, and F1-Score compared to other works. These results highlight the effectiveness of the proposed system in addressing security issues in IoT networks, and presents a general framework that addresses the challenge of large-scale attacks constructed through the dissemination of false information.",
    "introduction": "In recent years, the application of the internet of things (IoT) in areas such as intelligent transportation, smart cities, and the industrial internet has become increasingly widespread. As a crucial supporting infrastructure, IoT devices are utilized in various fields to construct IoT networks. However, due to the inherent limitations of IoT devices, such as limited computing resources and low memory capacity, security concerns have become increasingly prominent. Among these concerns are Denial-of-Service (DoS) and botnet attacks, which are difficult to prevent due to their large-scale and covert nature.",
    "macro_domains": []
  },
  {
    "abstract": "Identifying violent activities is important for ensuring the safety of society. Although the Transformer model contributes significantly to the field of behavior recognition, it often requires a substantial volume of data to perform well. Since existing datasets on violent behavior are currently lacking, it will be a challenge for Transformers to identify violent behavior with insufficient datasets. Additionally, Transformers are known to be computationally heavy and can sometimes overlook temporal features. To overcome these issues, an architecture named MLP-Mixer can be used to achieve comparable results with a smaller dataset. In this research, a special type of dataset to be fed into the MLP-Mixer called a sequential image collage (SIC) is proposed. This dataset is created by aggregating frames of video clips into image collages sequentially for the model to better understand the temporal features of violent behavior in videos. Three different public datasets, namely, the dataset of National Hockey League hockey fights, the dataset of smart-city CCTV violence detection, and the dataset of real-life violence situations were used to train the model. The results of the experiments proved that the model trained using the proposed SIC is capable of achieving high performance in violent behavior recognition with fewer parameters and FLOPs needed compared to other state-of-the-art models.",
    "doi": "10.3390/s24061844",
    "author_keywords": [
      "behavioral sciences",
      "computer architecture",
      "image recognition",
      "multilayer perceptrons",
      "neurons",
      "training",
      "Transformers"
    ],
    "contribution": "In this research, a special type of dataset to be fed into the MLP-Mixer called a sequential image collage (SIC) is proposed. This dataset is created by aggregating frames of video clips into image collages sequentially for the model to better understand the temporal features of violent behavior in videos. Three different public datasets, namely, the dataset of National Hockey League hockey fights, the dataset of smart-city CCTV violence detection, and the dataset of real-life violence situations were used to train the model. The results of the experiments proved that the model trained using the proposed SIC is capable of achieving high performance in violent behavior recognition with fewer parameters and FLOPs needed compared to other state-of-the-art models.",
    "introduction": "Identifying violent activities is important for ensuring the safety of society. Although the Transformer model contributes significantly to the field of behavior recognition, it often requires a substantial volume of data to perform well. Since existing datasets on violent behavior are currently lacking, it will be a challenge for Transformers to identify violent behavior with insufficient datasets. Additionally, Transformers are known to be computationally heavy and can sometimes overlook temporal features. To overcome these issues, an architecture named MLP-Mixer can be used to achieve comparable results with a smaller dataset.",
    "macro_domains": []
  },
  {
    "abstract": "In smart cities, effective traffic congestion management hinges on adept pedestrian and vehicle detection. Unmanned Aerial Vehicles (UAVs) offer a solution with mobility, cost-effectiveness, and a wide field of view, and yet, optimizing recognition models is crucial to surmounting challenges posed by small and occluded objects. To address these issues, we utilize the YOLOv8s model and a Swin Transformer block and introduce the PVswin-YOLOv8s model for pedestrian and vehicle detection based on UAVs. Firstly, the backbone network of YOLOv8s incorporates the Swin Transformer model for global feature extraction for small object detection. Secondly, to address the challenge of missed detections, we opt to integrate the CBAM into the neck of the YOLOv8. Both the channel and the spatial attention modules are used in this addition because of how well they extract feature information flow across the network. Finally, we employ Soft-NMS to improve the accuracy of pedestrian and vehicle detection in occlusion situations. Soft-NMS increases performance and manages overlapped boundary boxes well. The proposed network reduced the fraction of small objects overlooked and enhanced model detection performance. Performance comparisons with different YOLO versions (for example YOLOv3 extremely small, YOLOv5, YOLOv6, and YOLOv7), YOLOv8 variants (YOLOv8n, YOLOv8s, YOLOv8m, and YOLOv8l), and classical object detectors (Faster-RCNN, Cascade R-CNN, RetinaNet, and CenterNet) were used to validate the superiority of the proposed PVswin-YOLOv8s model. The efficiency of the PVswin-YOLOv8s model was confirmed by the experimental findings, which showed a 4.8% increase in average detection accuracy (mAP) compared to YOLOv8s on the VisDrone2019 dataset.",
    "doi": "10.3390/drones8030084",
    "author_keywords": [
      "CBAM",
      "pedestrian and vehicle detection",
      "soft-NMS",
      "swin transformer",
      "UAVs",
      "YOLOv8"
    ],
    "contribution": "",
    "introduction": "In smart cities, effective traffic congestion management hinges on adept pedestrian and vehicle detection. Unmanned Aerial Vehicles (UAVs) offer a solution with mobility, cost-effectiveness, and a wide field of view, and yet, optimizing recognition models is crucial to surmounting challenges posed by small and occluded objects. To address these issues, we utilize the YOLOv8s model and a Swin Transformer block and introduce the PVswin-YOLOv8s model for pedestrian and vehicle detection based on UAVs. Firstly, the backbone network of YOLOv8s incorporates the Swin Transformer model for global feature extraction for small object detection. Secondly, to address the challenge of missed detections, we opt to integrate the CBAM into the neck of the YOLOv8. Both the channel and the spatial attention modules are used in this addition because of how well they extract feature information flow across the network. Finally, we employ Soft-NMS to improve the accuracy of pedestrian and vehicle detection in occlusion situations. Soft-NMS increases performance and manages overlapped boundary boxes well. The proposed network reduced the fraction of small objects overlooked and enhanced model detection performance. Performance comparisons with different YOLO versions (for example YOLOv3 extremely small, YOLOv5, YOLOv6, and YOLOv7), YOLOv8 variants (YOLOv8n, YOLOv8s, YOLOv8m, and YOLOv8l), and classical object detectors (Faster-RCNN, Cascade R-CNN, RetinaNet, and CenterNet) were used to validate the superiority of the proposed PVswin-YOLOv8s model. The efficiency of the PVswin-YOLOv8s model was confirmed by the experimental findings, which showed a 4.8% increase in average detection accuracy (mAP) compared to YOLOv8s on the VisDrone2019 dataset.",
    "macro_domains": []
  },
  {
    "abstract": "In the modern world, human safety and crime control are daunting tasks. Each year the number of street crime cases has been increasing. In many cases, the culprit is unknown, in which the challenging task is to identify the right culprit possibly among hundreds of options in contexts of densely populated public spaces like target killing, vehicle snatching, etc. Often, in these situations, a sketch artist, working for the police forensic department, produces a drawing of the culpritâ€™s face based on guidelines from the victims or witnesses to the crime. However, hand-drawn sketches can be an inefficient means for matching facial photographs of the culprit, particularly in cases where the software is designed around using images of real faces. In this research work, a novel technique is proposed to generate hyperreal high-definition (H-HD) face images of the culprit from a single hand-drawn face sketch. â€™Hyperrealâ€™ is used here in the way it is used in the Arts, as in making the image, albeit based on a personâ€™s thoughts, truer to reality through a deep understanding of how the real subject would appear. To produce this image translation from sketch to H-HD face, two techniques are presented in this article, namely cycle generative adversarial network (CGAN) and multistage cycle generative adversarial network (MS-CGAN). MS-CGAN has multiple layers as stages and produces minimum cycle consistency and generative adversarial losses. CGAN uses paired data for training whereas MS-CGAN uses unpaired data. The training results show that the MSE loss of the proposed technique is found to be less than CGANs. GANs can be evaluated in three ways, namely qualitative, quantitative, and observational. In this paper, a quantitative comparison is made by the evaluation of CGAN and MS-CGAN based on the pixel-to-pixel comparison. An observational analysis is performed on the feedback from the observers. According to the evaluations, 54% of participants voted for the MS-CGAN whereas 46% rated CGAN to be the better performer. Two types of pixel-to-pixel comparisons are performed: color-to-color comparison and sketch-to-sketch comparison in terms of mean square error (MSE) and root mean square error (RMSE). For color-to-color image comparison, CGAN achieved an MSE of 2.312 and RMSE of 1.521 whereas MS-CGAN achieved an MSE of 2.232 and RMSE of 1.494. For sketch-to-sketch pixel comparison, CGAN achieved an MSE of 1.901 and RMSE of 1.379 whereas MS-CGAN achieved an MSE of 1.81 and 1.345 RMSE. The development of MS-CGAN and the research of this article are aimed at the police forensic department to generate a true-to-life H-HD face of a culprit and thereby contribute toward the overarching goal of maintaining a peaceful society.",
    "doi": "10.1007/s13369-023-08193-x",
    "author_keywords": [
      "Face sketch",
      "Generative adversarial network",
      "Image forensic",
      "Image translation",
      "Multistage cycle generative adversarial network",
      "Smart cities"
    ],
    "contribution": "In this research work, a novel technique is proposed to generate hyperreal high-definition (H-HD) face images of the culprit from a single hand-drawn face sketch. â€™Hyperrealâ€™ is used here in the way it is used in the Arts, as in making the image, albeit based on a personâ€™s thoughts, truer to reality through a deep understanding of how the real subject would appear. To produce this image translation from sketch to H-HD face, two techniques are presented in this article, namely cycle generative adversarial network (CGAN) and multistage cycle generative adversarial network (MS-CGAN). MS-CGAN has multiple layers as stages and produces minimum cycle consistency and generative adversarial losses. CGAN uses paired data for training whereas MS-CGAN uses unpaired data. The training results show that the MSE loss of the proposed technique is found to be less than CGANs. GANs can be evaluated in three ways, namely qualitative, quantitative, and observational. In this paper, a quantitative comparison is made by the evaluation of CGAN and MS-CGAN based on the pixel-to-pixel comparison. An observational analysis is performed on the feedback from the observers. According to the evaluations, 54% of participants voted for the MS-CGAN whereas 46% rated CGAN to be the better performer. Two types of pixel-to-pixel comparisons are performed: color-to-color comparison and sketch-to-sketch comparison in terms of mean square error (MSE) and root mean square error (RMSE). For color-to-color image comparison, CGAN achieved an MSE of 2.312 and RMSE of 1.521 whereas MS-CGAN achieved an MSE of 2.232 and RMSE of 1.494. For sketch-to-sketch pixel comparison, CGAN achieved an MSE of 1.901 and RMSE of 1.379 whereas MS-CGAN achieved an MSE of 1.81 and 1.345 RMSE. The development of MS-CGAN and the research of this article are aimed at the police forensic department to generate a true-to-life H-HD face of a culprit and thereby contribute toward the overarching goal of maintaining a peaceful society.",
    "introduction": "In the modern world, human safety and crime control are daunting tasks. Each year the number of street crime cases has been increasing. In many cases, the culprit is unknown, in which the challenging task is to identify the right culprit possibly among hundreds of options in contexts of densely populated public spaces like target killing, vehicle snatching, etc. Often, in these situations, a sketch artist, working for the police forensic department, produces a drawing of the culpritâ€™s face based on guidelines from the victims or witnesses to the crime. However, hand-drawn sketches can be an inefficient means for matching facial photographs of the culprit, particularly in cases where the software is designed around using images of real faces.",
    "macro_domains": []
  },
  {
    "abstract": "Violent attacks have been one of the hot issues in recent years. In the presence of closed-circuit televisions (CCTVs) in smart cities, there is an emerging challenge in apprehending criminals, leading to a need for innovative solutions. In this paper, the propose a model aimed at enhancing real-time emergency response capabilities and swiftly identifying criminals. This initiative aims to foster a safer environment and better manage criminal activity within smart cities. The proposed architecture combines an image-to-image stable diffusion model with violence detection and pose estimation approaches. The diffusion model generates synthetic data while the object detection approach uses YOLO v7 to identify violent objects like baseball bats, knives, and pistols, complemented by MediaPipe for action detection. Further, a long short-term memory (LSTM) network classifies the action attacks involving violent objects. Subsequently, an ensemble consisting of an edge device and the entire proposed model is deployed onto the edge device for real-time data testing using a dash camera. Thus, this study can handle violent attacks and send alerts in emergencies. As a result, our proposed YOLO model achieves a mean average precision (MAP) of 89.5% for violent attack detection, and the LSTM classifier model achieves an accuracy of 88.33% for violent action classification. The results highlight the modelâ€™s enhanced capability to accurately detect violent objects, particularly in effectively identifying violence through the implemented artificial intelligence system.",
    "doi": "10.3390/fi16020050",
    "author_keywords": [
      "artificial intelligence",
      "edge computing",
      "expert system",
      "image-to-image stable diffusion",
      "LSTM",
      "MediaPipe",
      "real-time application",
      "smart city",
      "violence detection",
      "YOLO v7"
    ],
    "contribution": "In this paper, the propose a model aimed at enhancing real-time emergency response capabilities and swiftly identifying criminals. This initiative aims to foster a safer environment and better manage criminal activity within smart cities. The proposed architecture combines an image-to-image stable diffusion model with violence detection and pose estimation approaches. The diffusion model generates synthetic data while the object detection approach uses YOLO v7 to identify violent objects like baseball bats, knives, and pistols, complemented by MediaPipe for action detection. Further, a long short-term memory (LSTM) network classifies the action attacks involving violent objects. Subsequently, an ensemble consisting of an edge device and the entire proposed model is deployed onto the edge device for real-time data testing using a dash camera. Thus, this study can handle violent attacks and send alerts in emergencies. As a result, our proposed YOLO model achieves a mean average precision (MAP) of 89.5% for violent attack detection, and the LSTM classifier model achieves an accuracy of 88.33% for violent action classification. The results highlight the modelâ€™s enhanced capability to accurately detect violent objects, particularly in effectively identifying violence through the implemented artificial intelligence system.",
    "introduction": "Violent attacks have been one of the hot issues in recent years. In the presence of closed-circuit televisions (CCTVs) in smart cities, there is an emerging challenge in apprehending criminals, leading to a need for innovative solutions.",
    "macro_domains": []
  },
  {
    "abstract": "In Internet of Things-based smart grids, smart meters record and report a massive number of power consumption data at certain intervals to the data center of the utility for load monitoring and energy management. Energy theft is a big problem for smart meters and causes non-technical losses. Energy theft attacks can be launched by malicious consumers by compromising the smart meters to report manipulated consumption data for less billing. It is a global issue causing technical and financial damage to governments and operators. Deep learning-based techniques can effectively identify consumers involved in energy theft through power consumption data. In this study, a hybrid convolutional neural network (CNN)-based energy-theft-detection system is proposed to detect data-tampering cyber-attack vectors. CNN is a commonly employed method that automates the extraction of features and the classification process. We employed CNN for feature extraction and traditional machine learning algorithms for classification. In this work, honest data were obtained from a real dataset. Six attack vectors causing data tampering were utilized. Tampered data were synthetically generated through these attack vectors. Six separate datasets were created for each attack vector to design a specialized detector tailored for that specific attack. Additionally, a dataset containing all attack vectors was also generated for the purpose of designing a general detector. Furthermore, the imbalanced dataset problem was addressed through the application of the generative adversarial network (GAN) method. GAN was chosen due to its ability to generate new data closely resembling real data, and its application in this field has not been extensively explored. The data generated with GAN ensured better training for the hybrid CNN-based detector on honest and malicious consumption patterns. Finally, the results indicate that the proposed general detector could classify both honest and malicious users with satisfactory accuracy.",
    "doi": "10.3390/s24041148",
    "author_keywords": [
      "convolutional neural network",
      "cyber security",
      "deep learning",
      "energy theft",
      "generative adversarial network",
      "Internet of Things",
      "smart grid"
    ],
    "contribution": "In this study, a hybrid convolutional neural network (CNN)-based energy-theft-detection system is proposed to detect data-tampering cyber-attack vectors. CNN is a commonly employed method that automates the extraction of features and the classification process. We employed CNN for feature extraction and traditional machine learning algorithms for classification. In this work, honest data were obtained from a real dataset. Six attack vectors causing data tampering were utilized. Tampered data were synthetically generated through these attack vectors. Six separate datasets were created for each attack vector to design a specialized detector tailored for that specific attack. Additionally, a dataset containing all attack vectors was also generated for the purpose of designing a general detector. Furthermore, the imbalanced dataset problem was addressed through the application of the generative adversarial network (GAN) method. GAN was chosen due to its ability to generate new data closely resembling real data, and its application in this field has not been extensively explored. The data generated with GAN ensured better training for the hybrid CNN-based detector on honest and malicious consumption patterns. Finally, the results indicate that the proposed general detector could classify both honest and malicious users with satisfactory accuracy.",
    "introduction": "In Internet of Things-based smart grids, smart meters record and report a massive number of power consumption data at certain intervals to the data center of the utility for load monitoring and energy management. Energy theft is a big problem for smart meters and causes non-technical losses. Energy theft attacks can be launched by malicious consumers by compromising the smart meters to report manipulated consumption data for less billing. It is a global issue causing technical and financial damage to governments and operators. Deep learning-based techniques can effectively identify consumers involved in energy theft through power consumption data.",
    "macro_domains": []
  },
  {
    "abstract": "Due to emerging concerns about public and private privacy issues in smart cities, many countries and organizations are establishing laws and regulations (e.g., GPDR) to protect the data security. One of the most important items is the so-called The Right to be Forgotten, which means that these data should be forgotten by all inappropriate use. To truly forget these data, they should be deleted from all databases that cover them, and also be removed from all machine learning models that are trained on them. The second one is called machine unlearning. One naive method for machine unlearning is to retrain a new model after data removal. However, in the current big data era, this will take a very long time. In this paper, we borrow the idea of Generative Adversarial Network (GAN), and propose a fast machine unlearning method that unlearns data in an adversarial way. Experimental results show that our method produces significant improvement in terms of the forgotten performance, model accuracy, and time cost.",
    "doi": "10.1007/s12243-023-00960-z",
    "author_keywords": [
      "Generative adversarial network",
      "Machine unlearning",
      "Membership inference attack",
      "Privacy protection"
    ],
    "contribution": "In this paper, we borrow the idea of Generative Adversarial Network (GAN), and propose a fast machine unlearning method that unlearns data in an adversarial way. Experimental results show that our method produces significant improvement in terms of the forgotten performance, model accuracy, and time cost.",
    "introduction": "Due to emerging concerns about public and private privacy issues in smart cities, many countries and organizations are establishing laws and regulations (e.g., GPDR) to protect the data security. One of the most important items is the so-called The Right to be Forgotten, which means that these data should be forgotten by all inappropriate use. To truly forget these data, they should be deleted from all databases that cover them, and also be removed from all machine learning models that are trained on them. The second one is called machine unlearning. One naive method for machine unlearning is to retrain a new model after data removal. However, in the current big data era, this will take a very long time.",
    "macro_domains": []
  },
  {
    "abstract": "Understanding the behavior of human motion in social environments is important for various domains of a smart city, e.g, smart transportation, automatic navigation of service robots, efficient navigation of autonomous cars and surveillance systems. Examining past trajectories or environmental factors alone are not enough to address this problem. We propose a novel methodology to predict future motion trajectories of humans based on past attitude of individuals, crowd attitude and environmental context. Many researchers have proposed different techniques based on different features extraction and features fusion to predict the future motion trajectory. They used traditional machine learning algorithms like SVM,social forces, probabilistic models and LSTM to analyze the heuristic motion trajectories but they didnâ€™t consider the other environmental factors e.g relative positions of other humans present in environment and positions of objects present in environment which can affect the motion trajectories of humans. We intend to achieve this goal by employing Long Short Term Memory(LSTM) units to analyze motion histories, convolution neural networks to environmental facts e.g. human-human, human-object interaction and relative positioning of 80 different objects including pedestrians and generative adversarial networks(GANs) to predict possible future motion paths. Our proposed method achieved 70% lower Average Displacement Error(ADE) and 41% lower Final Displacement Error(FDE) in comparison to other state of the art techniques.",
    "doi": "10.1007/s11042-021-11457-z",
    "author_keywords": [
      "Future motion trajectories",
      "GAN",
      "Human re-identification",
      "LSTM",
      "Object detection",
      "Path planning"
    ],
    "contribution": "We propose a novel methodology to predict future motion trajectories of humans based on past attitude of individuals, crowd attitude and environmental context. Many researchers have proposed different techniques based on different features extraction and features fusion to predict the future motion trajectory. They used traditional machine learning algorithms like SVM,social forces, probabilistic models and LSTM to analyze the heuristic motion trajectories but they didnâ€™t consider the other environmental factors e.g relative positions of other humans present in environment and positions of objects present in environment which can affect the motion trajectories of humans. We intend to achieve this goal by employing Long Short Term Memory(LSTM) units to analyze motion histories, convolution neural networks to environmental facts e.g. human-human, human-object interaction and relative positioning of 80 different objects including pedestrians and generative adversarial networks(GANs) to predict possible future motion paths. Our proposed method achieved 70% lower Average Displacement Error(ADE) and 41% lower Final Displacement Error(FDE) in comparison to other state of the art techniques.",
    "introduction": "Understanding the behavior of human motion in social environments is important for various domains of a smart city, e.g, smart transportation, automatic navigation of service robots, efficient navigation of autonomous cars and surveillance systems. Examining past trajectories or environmental factors alone are not enough to address this problem.",
    "macro_domains": []
  },
  {
    "abstract": "The hill state of Uttarakhand located in north India where 70% area falls in hilly regions and 30% area under plain region. Being a hill state, several challenges are faced by peoples in their daily life. The water body and resources in this state is high however 15% of total hydro potential is derived in Electricity Generation. Being a capital of state, the Dehradun city has selected as Smart City in year 2018 by the Government of India. The need of electricity recorded to cater the demand is 55 MU wherein 85% is taken from State and Centre Generation Stations of Uttarakhand and remaining 15% electricity is taken from Energy Exchange, Energy Banking or Short-Term Power Purchase Agreements. In this study, the ten-year electricity load required for charging the electric vehicle is calculated using Artificial Neural Network tool. The scaled conjugate method is used in this research to calculate the required load demand in future. The developed model is trained, validated and tested on the input data and future load is predicted. The results showing the extra load provisions to be arranged for electric vehicle charging in domestic and commercial places which including capacity upgradation of transmission network and transformers.",
    "doi": "10.1063/5.0194312",
    "author_keywords": [
      "Artificial Neural Network",
      "Electric Vehicle",
      "Scaled Conjugate Method."
    ],
    "contribution": "In this study, the ten-year electricity load required for charging the electric vehicle is calculated using Artificial Neural Network tool. The scaled conjugate method is used in this research to calculate the required load demand in future. The developed model is trained, validated and tested on the input data and future load is predicted. The results showing the extra load provisions to be arranged for electric vehicle charging in domestic and commercial places which including capacity upgradation of transmission network and transformers.",
    "introduction": "The hill state of Uttarakhand located in north India where 70% area falls in hilly regions and 30% area under plain region. Being a hill state, several challenges are faced by peoples in their daily life. The water body and resources in this state is high however 15% of total hydro potential is derived in Electricity Generation. Being a capital of state, the Dehradun city has selected as Smart City in year 2018 by the Government of India. The need of electricity recorded to cater the demand is 55 MU wherein 85% is taken from State and Centre Generation Stations of Uttarakhand and remaining 15% electricity is taken from Energy Exchange, Energy Banking or Short-Term Power Purchase Agreements.",
    "macro_domains": []
  },
  {
    "abstract": "Road extraction from remote sensing images has gradually become a prominent research hotspot in the field of autonomous driving and smart city construction. In recent years, with the developments of computing power, deep learning has been widely used in this field and convolution neural networks are usually used to extract roads. However, since the roads in the remote sensing images are easy to be occluded by trees and buildings, the roads extracted by these methods are usually fragmented. In this paper, a U-shaped Neural Network based on Pyramid Vision Transformer (PVT-Unet) is designed. This network combines Transformer's long term learning capability with U-shaped network multi-scale feature extraction capability to predict the roads well. Experimental results show that PVT-Unet outperforms the state-of-the-art methods in all evaluation metrics on the Istanbul City Road Dataset. The source code has been made publicly available at: https://github.com/XYQ1517/PVT-Unet.",
    "doi": "10.1145/3647649.3647682",
    "author_keywords": [
      "Deep learning",
      "Multiscale feature extraction",
      "Pyramid Vision Transformer",
      "Road extraction"
    ],
    "contribution": "In this paper, a U-shaped Neural Network based on Pyramid Vision Transformer (PVT-Unet) is designed. This network combines Transformer's long term learning capability with U-shaped network multi-scale feature extraction capability to predict the roads well. Experimental results show that PVT-Unet outperforms the state-of-the-art methods in all evaluation metrics on the Istanbul City Road Dataset. The source code has been made publicly available at: https://github.com/XYQ1517/PVT-Unet.",
    "introduction": "Road extraction from remote sensing images has gradually become a prominent research hotspot in the field of autonomous driving and smart city construction. In recent years, with the developments of computing power, deep learning has been widely used in this field and convolution neural networks are usually used to extract roads. However, since the roads in the remote sensing images are easy to be occluded by trees and buildings, the roads extracted by these methods are usually fragmented.",
    "macro_domains": []
  },
  {
    "abstract": "Trajectory forecasting of multiple agents is a fundamental task that has applications in various fields, such as autonomous driving, physical system modeling and smart cities. It is challenging because agent interactions and underlying continuous dynamics jointly affect its behavior. Existing approaches often rely on Graph Neural Networks (GNNs) or Transformers to extract agent interaction features. However, they tend to neglect how the distance and velocity information between agents impact their interactions dynamically. Moreover, previous methods use RNNs or first-order Ordinary Differential Equations (ODEs) to model temporal dynamics, which may lack interpretability with respect to how each agent is driven by interactions. To address these challenges, this paper proposes the Agent Graph ODE, a novel approach that models agent interactions and continuous second-order dynamics explicitly. Our method utilizes a variational autoencoder architecture, incorporating spatial-temporal Transformers with distance information and dynamic interaction graph construction in the encoder module. In the decoder module, we employ GNNs with distance information to model agent interactions, and use coupled second-order ODEs to capture the underlying continuous dynamics by modeling the relationship between acceleration and agent interactions. Experimental results show that our proposed Agent Graph ODE outperforms state-of-the-art methods in prediction accuracy. Moreover, our method performs well in sudden situations not seen in the training dataset.",
    "doi": "10.1109/WACV57701.2024.00501",
    "author_keywords": [
      "3D",
      "Algorithms",
      "Algorithms",
      "Algorithms",
      "and algorithms",
      "etc.",
      "formulations",
      "Generative models for image",
      "Machine learning architectures",
      "video",
      "Video recognition and understanding"
    ],
    "contribution": "To address these challenges, this paper proposes the Agent Graph ODE, a novel approach that models agent interactions and continuous second-order dynamics explicitly. Our method utilizes a variational autoencoder architecture, incorporating spatial-temporal Transformers with distance information and dynamic interaction graph construction in the encoder module. In the decoder module, we employ GNNs with distance information to model agent interactions, and use coupled second-order ODEs to capture the underlying continuous dynamics by modeling the relationship between acceleration and agent interactions. Experimental results show that our proposed Agent Graph ODE outperforms state-of-the-art methods in prediction accuracy. Moreover, our method performs well in sudden situations not seen in the training dataset.",
    "introduction": "Trajectory forecasting of multiple agents is a fundamental task that has applications in various fields, such as autonomous driving, physical system modeling and smart cities. It is challenging because agent interactions and underlying continuous dynamics jointly affect its behavior. Existing approaches often rely on Graph Neural Networks (GNNs) or Transformers to extract agent interaction features. However, they tend to neglect how the distance and velocity information between agents impact their interactions dynamically. Moreover, previous methods use RNNs or first-order Ordinary Differential Equations (ODEs) to model temporal dynamics, which may lack interpretability with respect to how each agent is driven by interactions.",
    "macro_domains": []
  },
  {
    "abstract": "The rapid proliferation of the Internet of Things (IoT) has revolutionized industries through interconnected devices and smart decision-making. However, this expansion has also introduced significant security challenges, as IoT networks are characterized by heterogeneity, resource constraints, and evolving threats. Intrusion Detection Systems (IDS) have emerged as essential mechanisms to complement preventive measures, yet existing solutions fall short of addressing the full spectrum of IoT-specific vulnerabilities. This paper critically reviews state-of-the-art IDS techniques, including advanced methods such as machine learning, federated learning, blockchain, and hybrid detection. Additionally, emerging approaches like Generative Adversarial Networks (GANs), reinforcement learning, and bio-inspired algorithms are explored for their potential to enhance IDS adaptability and scalability. The role of complementary security techniques, such as penetration testing, is highlighted in validating and strengthening IDS implementations. Applications in critical areas such as smart cities are discussed, emphasizing the need for robust and efficient security mechanisms. Key challenges such as interoperability, real-time detection, and resource efficiency are analyzed, and future research directions are proposed to develop comprehensive IDS frameworks tailored to the dynamic and diverse IoT ecosystem.",
    "doi": "10.1109/SDS64317.2024.10883899",
    "author_keywords": [
      "Intrusion detection systems (IDS)",
      "IoT security",
      "Smart Cities",
      "wireless sensor networks"
    ],
    "contribution": "This paper critically reviews state-of-the-art IDS techniques, including advanced methods such as machine learning, federated learning, blockchain, and hybrid detection. Additionally, emerging approaches like Generative Adversarial Networks (GANs), reinforcement learning, and bio-inspired algorithms are explored for their potential to enhance IDS adaptability and scalability. The role of complementary security techniques, such as penetration testing, is highlighted in validating and strengthening IDS implementations. Applications in critical areas such as smart cities are discussed, emphasizing the need for robust and efficient security mechanisms. Key challenges such as interoperability, real-time detection, and resource efficiency are analyzed, and future research directions are proposed to develop comprehensive IDS frameworks tailored to the dynamic and diverse IoT ecosystem.",
    "introduction": "The rapid proliferation of the Internet of Things (IoT) has revolutionized industries through interconnected devices and smart decision-making. However, this expansion has also introduced significant security challenges, as IoT networks are characterized by heterogeneity, resource constraints, and evolving threats. Intrusion Detection Systems (IDS) have emerged as essential mechanisms to complement preventive measures, yet existing solutions fall short of addressing the full spectrum of IoT-specific vulnerabilities.",
    "macro_domains": []
  },
  {
    "abstract": "Digital Twins represent virtual replicas of real-world objects, processes, or systems, enabling continuous real-time monitoring, dynamic adaptation, and predictive analytics. Their integration has become central in industrial, urban, and transportation domains under the paradigms of Industry 4.0, the Industrial Internet of Things (IIoT), and smart cities. However, effectively harnessing the torrents of time-series data and complex system states integral to Digital Twins (DTs) requires advanced analytical tools. Machine learning (ML) methodsâ€”ranging from classical ensemble models to deep learning architectures and reinforcement learningâ€”provide powerful mechanisms for anomaly detection, failure prediction, operational optimization, and scenario modeling. This review explores the essential ML algorithms, their application contexts, and the supportive infrastructures required for implementing ML-driven DT solutions. We also discuss interpretability techniques, address security and concept drift challenges, examine the role of MLOps in ensuring reliable deployment, and highlight future research directions, including physics-informed ML, multimodal data integration, and advanced transformers for time-series forecasting.",
    "doi": "10.1109/ICNGN63705.2024.10871832",
    "author_keywords": [
      "Anomaly Detection",
      "Digital Twin",
      "IIoT",
      "Industry 4.0",
      "Machine Learning",
      "Predictive Maintenance",
      "Process Optimization",
      "Reinforcement Learning",
      "Scenario Modeling",
      "Time-Series Analysis"
    ],
    "contribution": "This review explores the essential ML algorithms, their application contexts, and the supportive infrastructures required for implementing ML-driven DT solutions. We also discuss interpretability techniques, address security and concept drift challenges, examine the role of MLOps in ensuring reliable deployment, and highlight future research directions, including physics-informed ML, multimodal data integration, and advanced transformers for time-series forecasting.",
    "introduction": "Digital Twins represent virtual replicas of real-world objects, processes, or systems, enabling continuous real-time monitoring, dynamic adaptation, and predictive analytics. Their integration has become central in industrial, urban, and transportation domains under the paradigms of Industry 4.0, the Industrial Internet of Things (IIoT), and smart cities. However, effectively harnessing the torrents of time-series data and complex system states integral to Digital Twins (DTs) requires advanced analytical tools. Machine learning (ML) methodsâ€”ranging from classical ensemble models to deep learning architectures and reinforcement learningâ€”provide powerful mechanisms for anomaly detection, failure prediction, operational optimization, and scenario modeling.",
    "macro_domains": []
  },
  {
    "abstract": "Drone imagery analysis is an essential part of smart city construction and management. Object detection in UAV images has been a popular research topic recently. The images captured by drones usually have huge scale changes due to the flying and shooting at different altitudes, which puts a burden on traditional deep learning networks. The Transformer-based network has proven successful in computer vision tasks due to its strong long sequence memory analysis capabilities. This article will design a network for object detection and analysis of drone images based on the Transformer structure. The main challenge with using transformers is the high computational cost of processing image sequences, so the common method is to use local attention instead of global attention and a hierarchical structure to compensate for the loss of global vision. However, the large amount of information lost caused by using local attention can not be made up for with this action simply. This paper analyzes the ideas of multiscale and hierarchical structure concepts and attention mechanisms, and embeds multiscale concepts into the local attention structure to further make up for the global view information lost. In order to achieve this, we used the pooling concept to build multiscale pooling layers combined with a pyramid structure and applied it to the multi-head self-attention module. At the same time, we precut the image features entering the pooling block to reduce the length of the image token sequence. While reducing the calculation amount of the vision transformer, the global visual field information is increased as much as possible to obtain better contextual features. On VisDrone dataset, MRPVT as a backbone achieves 47.98% AP50 and 25.20% AP75 accuracy and on UAVDT's car category achieves 98.84% AP50 and 89.27% AP75 accuracy. As expected, MRPVT delivers great performance on drone-captured images' object detection and visual aesthetic assessment.",
    "doi": "10.1109/ICCVIT63928.2024.10872469",
    "author_keywords": [
      "drone-captured",
      "efficient attention",
      "multiscale pooling",
      "object detection",
      "Transformer"
    ],
    "contribution": "This article will design a network for object detection and analysis of drone images based on the Transformer structure. The main challenge with using transformers is the high computational cost of processing image sequences, so the common method is to use local attention instead of global attention and a hierarchical structure to compensate for the loss of global vision. However, the large amount of information lost caused by using local attention can not be made up for with this action simply. This paper analyzes the ideas of multiscale and hierarchical structure concepts and attention mechanisms, and embeds multiscale concepts into the local attention structure to further make up for the global view information lost. In order to achieve this, we used the pooling concept to build multiscale pooling layers combined with a pyramid structure and applied it to the multi-head self-attention module. At the same time, we precut the image features entering the pooling block to reduce the length of the image token sequence. While reducing the calculation amount of the vision transformer, the global visual field information is increased as much as possible to obtain better contextual features. On VisDrone dataset, MRPVT as a backbone achieves 47.98% AP50 and 25.20% AP75 accuracy and on UAVDT's car category achieves 98.84% AP50 and 89.27% AP75 accuracy. As expected, MRPVT delivers great performance on drone-captured images' object detection and visual aesthetic assessment.",
    "introduction": "Drone imagery analysis is an essential part of smart city construction and management. Object detection in UAV images has been a popular research topic recently. The images captured by drones usually have huge scale changes due to the flying and shooting at different altitudes, which puts a burden on traditional deep learning networks. The Transformer-based network has proven successful in computer vision tasks due to its strong long sequence memory analysis capabilities.",
    "macro_domains": []
  },
  {
    "abstract": "The growing demand for data-driven applications requires AI solutions that are both efficient and scalable to support big data analytics across diverse industries. Large Language Models (LLMs), such as GPT-4, offer advanced performance but incur high computational costs, latency, and energy demands, making them less suitable for real-time analytics or edge computing. Small Language Models (SLMs), like LLaMA 2 and Mistral 7B, have been developed to address these challenges by reducing cost and power consumption while retaining high task-specific performance. This paper explores how SLMs integrate within hybrid AI architectures, handling sub-tasks like pre-processing and localized inference, while LLMs perform complex analytics in cloud environments. Such hybrid architectures present scalable, efficient solutions for sectors including finance, healthcare, and smart cities. The challenges of SLM integration, such as reduced contextual understanding and accuracy tradeoffs, are also addressed. Further, we propose future directions to mitigate these issues, including AutoML frameworks, federated learning, and quantization techniques to enhance model efficiency. This paper discusses deployment strategies for SLMs within hybrid architectures to achieve balanced performance, scalability, and efficiency in big data applications.",
    "doi": "10.1109/ICSCNA63714.2024.10863995",
    "author_keywords": [
      "Big data analytics",
      "Edge computing",
      "Federated learning",
      "Hybrid AI architectures",
      "Small Language Models (SLMs)"
    ],
    "contribution": "This paper explores how SLMs integrate within hybrid AI architectures, handling sub-tasks like pre-processing and localized inference, while LLMs perform complex analytics in cloud environments. Such hybrid architectures present scalable, efficient solutions for sectors including finance, healthcare, and smart cities. The challenges of SLM integration, such as reduced contextual understanding and accuracy tradeoffs, are also addressed. Further, we propose future directions to mitigate these issues, including AutoML frameworks, federated learning, and quantization techniques to enhance model efficiency. This paper discusses deployment strategies for SLMs within hybrid architectures to achieve balanced performance, scalability, and efficiency in big data applications.",
    "introduction": "The growing demand for data-driven applications requires AI solutions that are both efficient and scalable to support big data analytics across diverse industries. Large Language Models (LLMs), such as GPT-4, offer advanced performance but incur high computational costs, latency, and energy demands, making them less suitable for real-time analytics or edge computing. Small Language Models (SLMs), like LLaMA 2 and Mistral 7B, have been developed to address these challenges by reducing cost and power consumption while retaining high task-specific performance.",
    "macro_domains": []
  },
  {
    "abstract": "The combination of Generative AI and IoT technologies has created opportunities to improve the capabilities and efficiency of Healthcare Systems. This integration has the capacity to transform several sectors, such as healthcare, manufacturing, transportation, and smart cities. Generative AI systems give machines with tangible existence and independent decision-making powers, while IoT enables effortless connection and data interchange between physical objects and digital systems. This research examines the difficulties and potential advantages of incorporating Generative artificial intelligence systems into internet of things-based Healthcare systems. The study first examines the structure and elements of Generative AI systems and IoT-based Healthcare Systems, emphasizing their individual functions and interconnections. Subsequently, it analyzes the advantages of integrating various technologies, including improved perception of the surrounding circumstances, immediate and informed decision-making, and flexible responses in ever-changing settings. Furthermore, the study discusses the difficulties linked to this integration, including interoperability, security, privacy, and ethical issues. In addition, the paper showcases several instances and uses where the combination of Generative AI systems with IoT-based Healthcare Systems has shown notable progress. These include self-governing robotic systems in advanced manufacturing, intelligent gadgets for healthcare monitoring, self-driving automobiles, and systems for managing smart infrastructure. In addition, the study explores forthcoming areas of research and upcoming developments in this domain, including edge computing, swarm robotics, humanâ€“robot cooperation, and decentralized AI. Furthermore, it underscores the need of multidisciplinary cooperation among specialists in AI, IoT, robotics, cybersecurity, and domain-specific businesses to tackle intricate obstacles and fully unlock the potential of integrated Generative AI systems in IoT-based Healthcare Systems. Ultimately, the incorporation of Generative AI systems into IoT-based Healthcare Systems shows great potential for developing highly intelligent, adaptable, and effective Healthcare systems in several fields. Nevertheless, it necessitates meticulous examination of technological, ethical, and sociological ramifications to guarantee responsible implementation and optimize the advantages for mankind.",
    "doi": "10.1007/978-3-031-75771-6_14",
    "author_keywords": [
      "Cybersecurity",
      "Generative AI",
      "Healthcare systems",
      "Industrial 5.0",
      "IoT"
    ],
    "contribution": "This research examines the difficulties and potential advantages of incorporating Generative artificial intelligence systems into internet of things-based Healthcare systems. The study first examines the structure and elements of Generative AI systems and IoT-based Healthcare Systems, emphasizing their individual functions and interconnections. Subsequently, it analyzes the advantages of integrating various technologies, including improved perception of the surrounding circumstances, immediate and informed decision-making, and flexible responses in ever-changing settings. Furthermore, the study discusses the difficulties linked to this integration, including interoperability, security, privacy, and ethical issues. In addition, the paper showcases several instances and uses where the combination of Generative AI systems with IoT-based Healthcare Systems has shown notable progress. These include self-governing robotic systems in advanced manufacturing, intelligent gadgets for healthcare monitoring, self-driving automobiles, and systems for managing smart infrastructure. In addition, the study explores forthcoming areas of research and upcoming developments in this domain, including edge computing, swarm robotics, humanâ€“robot cooperation, and decentralized AI. Furthermore, it underscores the need of multidisciplinary cooperation among specialists in AI, IoT, robotics, cybersecurity, and domain-specific businesses to tackle intricate obstacles and fully unlock the potential of integrated Generative AI systems in IoT-based Healthcare Systems. Ultimately, the incorporation of Generative AI systems into IoT-based Healthcare Systems shows great potential for developing highly intelligent, adaptable, and effective Healthcare systems in several fields. Nevertheless, it necessitates meticulous examination of technological, ethical, and sociological ramifications to guarantee responsible implementation and optimize the advantages for mankind.",
    "introduction": "The combination of Generative AI and IoT technologies has created opportunities to improve the capabilities and efficiency of Healthcare Systems. This integration has the capacity to transform several sectors, such as healthcare, manufacturing, transportation, and smart cities. Generative AI systems give machines with tangible existence and independent decision-making powers, while IoT enables effortless connection and data interchange between physical objects and digital systems.",
    "macro_domains": []
  },
  {
    "abstract": "The rapid emergence of IoT-powered smart cities has generated substantial apprehensions regarding energy efficiency and security. Current technologies frequently fail to adequately address these concerns in a comprehensive manner. This study presents a hybrid framework that combines GAN with ICA to improve energy efficiency and security in smart city infrastructures. The design of the model utilizes GANs to generate synthetic data and ICA to extract independent characteristics, resulting in improved accuracy and security of IoT systems. The accuracy of our model surpassed that of previous technologies, reaching 97.5%. Additionally, our model achieved a precision of 95.0% and an F1 score of 95.6%. As a result, our model has established a new benchmark in smart city research. The results showcase the model's capacity to enhance smart city operations, rendering it a worthwhile addition to the field.",
    "doi": "10.1109/GCCIT63234.2024.10862065",
    "author_keywords": [
      "Data Preprocessing",
      "Energy Efficiency",
      "Feature Extraction",
      "Generative Adversarial Networks",
      "Hybrid GAN-ICA",
      "Independent Component Analysis",
      "Internet of Things (IoT) Security",
      "Model Training",
      "Performance Metrics",
      "Smart Cities"
    ],
    "contribution": "This study presents a hybrid framework that combines GAN with ICA to improve energy efficiency and security in smart city infrastructures. The design of the model utilizes GANs to generate synthetic data and ICA to extract independent characteristics, resulting in improved accuracy and security of IoT systems. The accuracy of our model surpassed that of previous technologies, reaching 97.5%. Additionally, our model achieved a precision of 95.0% and an F1 score of 95.6%. As a result, our model has established a new benchmark in smart city research. The results showcase the model's capacity to enhance smart city operations, rendering it a worthwhile addition to the field.",
    "introduction": "The rapid emergence of IoT-powered smart cities has generated substantial apprehensions regarding energy efficiency and security. Current technologies frequently fail to adequately address these concerns in a comprehensive manner.",
    "macro_domains": []
  },
  {
    "abstract": "The integration of Internet of Things (IoT) technologies with advanced analytics has become critical in extracting valuable insights from continuous data streams in real-time. This paper explores the application of Large Language Models (LLMs) as a transformative approach to enhancing IoT data analytics. We present a novel framework that leverages LLMs for the real-time interpretation and processing of vast, diverse IoT data sets. Our methodology involves the adaptation of transformer-based architectures to handle structured and unstructured data from IoT sources, enabling immediate decision-making and actionable insights. Through rigorous experimentation, we demonstrate how LLMs can significantly improve the accuracy and speed of data analytics in IoT environments compared to traditional methods. The results underscore the potential of LLMs to revolutionize real-time data processing tasks across various industries, from smart cities to healthcare. Our study not only reinforces the applicability of LLMs in real-time analytics but also outlines future research directions for integrating AI with IoT infrastructure to achieve scalable and efficient solutions.",
    "doi": "10.1109/GCCIT63234.2024.10862622",
    "author_keywords": [
      "Data Engineering",
      "Data Science",
      "IoT Data Analytics",
      "Large language models (LLMs)",
      "Real-Time Processing"
    ],
    "contribution": "This paper explores the application of Large Language Models (LLMs) as a transformative approach to enhancing IoT data analytics. We present a novel framework that leverages LLMs for the real-time interpretation and processing of vast, diverse IoT data sets. Our methodology involves the adaptation of transformer-based architectures to handle structured and unstructured data from IoT sources, enabling immediate decision-making and actionable insights. Through rigorous experimentation, we demonstrate how LLMs can significantly improve the accuracy and speed of data analytics in IoT environments compared to traditional methods. The results underscore the potential of LLMs to revolutionize real-time data processing tasks across various industries, from smart cities to healthcare. Our study not only reinforces the applicability of LLMs in real-time analytics but also outlines future research directions for integrating AI with IoT infrastructure to achieve scalable and efficient solutions.",
    "introduction": "The integration of Internet of Things (IoT) technologies with advanced analytics has become critical in extracting valuable insights from continuous data streams in real-time.",
    "macro_domains": []
  },
  {
    "abstract": "In recent years, Smart Cities (SC), Traffic Flow (TF) refers to the optimized movement of vehicles, pedestrians, and other road users by progressive technologies. Predicting traffic flow is dynamic to ease congestion, enhance traffic management, and to improve emergency response. Previously, many methods were proposed to enhance the prediction of traffic flow, although the existing methods have overfitting, computational complexity, and generalizability problems. To overcome these problems, a Graph Convolutional Network based Graph Long Short-Term Memory (GCN-GLSTM) model is considered to predict traffic flow. Initially, Urban Traffic Density in Cities (UTDC) dataset is employed to optimize the flow of traffic. The preprocessing is performed with Data cleaning, to remove outliers and missing values, Data filtering to remove data points with low GPS accuracy, Z-Score normalization to normalize data, and Data transformation to Converted data into suitable formats. Feature extraction is performed by employing Graph Attention Network (GAN) to handle complexity. For classification, GCN-GLSTM is used to handle high-dimensionality, and to enhance generalizability. The proposed GCN-GLSTM method gained high performance metrics such as accuracy, MSE, MAE, and RMSE of 98.34%, 1.72, 1.14, and 1.35 compared to existing methods like Graph Neural Network (GNN).",
    "doi": "10.1109/ICIICS63763.2024.10860256",
    "author_keywords": [
      "graph attention network",
      "graph convolutional network with graph long short-term memory",
      "smart cities",
      "traffic flow",
      "urban traffic density in cities"
    ],
    "contribution": "",
    "introduction": "In recent years, Smart Cities (SC), Traffic Flow (TF) refers to the optimized movement of vehicles, pedestrians, and other road users by progressive technologies. Predicting traffic flow is dynamic to ease congestion, enhance traffic management, and to improve emergency response. Previously, many methods were proposed to enhance the prediction of traffic flow, although the existing methods have overfitting, computational complexity, and generalizability problems. To overcome these problems, a Graph Convolutional Network based Graph Long Short-Term Memory (GCN-GLSTM) model is considered to predict traffic flow. Initially, Urban Traffic Density in Cities (UTDC) dataset is employed to optimize the flow of traffic. The preprocessing is performed with Data cleaning, to remove outliers and missing values, Data filtering to remove data points with low GPS accuracy, Z-Score normalization to normalize data, and Data transformation to Converted data into suitable formats. Feature extraction is performed by employing Graph Attention Network (GAN) to handle complexity. For classification, GCN-GLSTM is used to handle high-dimensionality, and to enhance generalizability. The proposed GCN-GLSTM method gained high performance metrics such as accuracy, MSE, MAE, and RMSE of 98.34%, 1.72, 1.14, and 1.35 compared to existing methods like Graph Neural Network (GNN).",
    "macro_domains": []
  },
  {
    "abstract": "In the context of smart cities, there is a growing demand for risk-free navigation systems that help citizens avoid congestion and enjoy outdoor activities in clean environments. Such systems require the ability to predict traffic and environmental hotspots by analyzing spatial-temporal big data from various sources, including IoT devices, stations, CCTV, and personal device networks. However, analyzing and forecasting spatial-temporal data presents significant challenges due to the complex interplay of spatial and temporal dependencies. To address these challenges, we introduce a novel dual attention mechanism graph transformer that leverages both spatial and temporal information to capture intricate patterns in spatial-temporal data. We evaluate our model on two forecasting tasks: air pollution and traffic flow. Our results demonstrate superior performance compared to other graph neural network models. Consequently, this model has been integrated into a traffic-risk navigator application, which will be evaluated in Yokohama, Japan, using real data collected from air pollution stations and traffic monitors.",
    "doi": "10.1109/BigData62323.2024.10825469",
    "author_keywords": [
      "Air Pollution Forecasting",
      "Graph Big Data",
      "Graph Transformer",
      "Spatial-temporal Big Data",
      "Traffic Flow Forecasting"
    ],
    "contribution": "To address these challenges, we introduce a novel dual attention mechanism graph transformer that leverages both spatial and temporal information to capture intricate patterns in spatial-temporal data. We evaluate our model on two forecasting tasks: air pollution and traffic flow. Our results demonstrate superior performance compared to other graph neural network models. Consequently, this model has been integrated into a traffic-risk navigator application, which will be evaluated in Yokohama, Japan, using real data collected from air pollution stations and traffic monitors.",
    "introduction": "In the context of smart cities, there is a growing demand for risk-free navigation systems that help citizens avoid congestion and enjoy outdoor activities in clean environments. Such systems require the ability to predict traffic and environmental hotspots by analyzing spatial-temporal big data from various sources, including IoT devices, stations, CCTV, and personal device networks. However, analyzing and forecasting spatial-temporal data presents significant challenges due to the complex interplay of spatial and temporal dependencies.",
    "macro_domains": []
  },
  {
    "abstract": "Digital twins are increasingly being implemented in smart cities, where they are designed to provide 3D digital representations for near-real time interactivity and status feedback of the twinned physical assets. The ability to provide accurate predictions in what-if scenarios plays a key role in driving the advances in resources optimization and risk mitigation. To this end, prediction models require large datasets to train, and such datasets are usually scarce at local level. In this paper, we propose a generative AI-based workflow to infer domestic photovoltaic energy production data, based on a process that uses Generative Adversarial Networks to generate an enriched meteorological dataset. The generated meteorological data captures essential statistical properties of real data that can be later used to infer realistic energy production data points. The resulting output dataset is validated against a real photovoltaic system, highlighting the ability to deliver high-fidelity time series out of scarce input datasets.",
    "doi": "10.1109/BigData62323.2024.10825752",
    "author_keywords": [
      "data augmentation",
      "data scarcity",
      "digital twin",
      "Generative Adversarial Networks",
      "smart city"
    ],
    "contribution": "In this paper, we propose a generative AI-based workflow to infer domestic photovoltaic energy production data, based on a process that uses Generative Adversarial Networks to generate an enriched meteorological dataset. The generated meteorological data captures essential statistical properties of real data that can be later used to infer realistic energy production data points. The resulting output dataset is validated against a real photovoltaic system, highlighting the ability to deliver high-fidelity time series out of scarce input datasets.",
    "introduction": "Digital twins are increasingly being implemented in smart cities, where they are designed to provide 3D digital representations for near-real time interactivity and status feedback of the twinned physical assets. The ability to provide accurate predictions in what-if scenarios plays a key role in driving the advances in resources optimization and risk mitigation. To this end, prediction models require large datasets to train, and such datasets are usually scarce at local level.",
    "macro_domains": []
  },
  {
    "abstract": "Anomalous event classification automatically identifies anomalous events using the videos in an intelligent video surveillance system. However, anomalous event classification is challenging due to inherent research challenges such as the requirement of high-end computational infrastructure, data imbalances, and data scarcity. Typically, a combination of Convolution Neural Networks (CNNs) and Long-Short-Term-Memory (LSTM) are used to model the spatiotemporal dynamics of the videos for video classification. However, these models have no attention mechanism to boost the relevant spatiotemporal features and discard the irrelevant features. Hence, a Space-Time Attention Model (STAM)-based anomalous event classifier is proposed. The model is trained and validated on the \"Anomalous Event Classification 22,\"i.e., the \"AEC22 dataset\"comprising twenty-two anomalous event classes such as abuse, arrest, arson, assault, etc. The STAM is a combined spatial and temporal transformer that takes a series of frames extracted from the input video and predicts corresponding video-level classification as the output. Subsequently, the proposed model provides 92.84% classification accuracy, which is compared with the two state-of-the-art video classification methods to validate its superiority. The proposed model has huge potential for classifying anomalous events in smart city applications.",
    "doi": "10.1109/ICEC59683.2024.10837247",
    "author_keywords": [
      "3D-CNN",
      "Anomalous event classification",
      "Convolutional LSTM",
      "DenseNet",
      "LSTM",
      "ResNet",
      "Space-Time Attention Module",
      "Video classification"
    ],
    "contribution": "",
    "introduction": "Anomalous event classification automatically identifies anomalous events using the videos in an intelligent video surveillance system. However, anomalous event classification is challenging due to inherent research challenges such as the requirement of high-end computational infrastructure, data imbalances, and data scarcity. Typically, a combination of Convolution Neural Networks (CNNs) and Long-Short-Term-Memory (LSTM) are used to model the spatiotemporal dynamics of the videos for video classification. However, these models have no attention mechanism to boost the relevant spatiotemporal features and discard the irrelevant features. Hence, a Space-Time Attention Model (STAM)-based anomalous event classifier is proposed. The model is trained and validated on the \"Anomalous Event Classification 22,\"i.e., the \"AEC22 dataset\"comprising twenty-two anomalous event classes such as abuse, arrest, arson, assault, etc. The STAM is a combined spatial and temporal transformer that takes a series of frames extracted from the input video and predicts corresponding video-level classification as the output. Subsequently, the proposed model provides 92.84% classification accuracy, which is compared with the two state-of-the-art video classification methods to validate its superiority. The proposed model has huge potential for classifying anomalous events in smart city applications.",
    "macro_domains": []
  },
  {
    "abstract": "Precipitation nowcasting is an important spatiotemporal prediction task to predict the radar echoes sequences based on current observations, which can serve both meteorological science and smart city applications. Due to the chaotic evolution nature of the precipitation systems, it is a very challenging problem. Previous studies address the problem either from the perspectives of deterministic modeling or probabilistic modeling. However, their predictions suffer from the blurry, high-value echoes fading away and position inaccurate issues. The root reason of these issues is that the chaotic evolutionary precipitation systems are not appropriately modeled. Inspired by the nature of the systems, we propose to decompose and model them from the perspective of global deterministic motion and local stochastic variations with residual mechanism. A unified and flexible framework that can equip any type of spatio-temporal models is proposed based on residual diffusion, which effectively tackles the shortcomings of previous methods. Extensive experimental results on four publicly available radar datasets demonstrate the effectiveness and superiority of the proposed framework, compared to state-of-the-art techniques.",
    "doi": "10.1109/CVPR52733.2024.02622",
    "author_keywords": [
      "Diffusion Model",
      "Precipitation Nowcasting",
      "Spatio-Temporal Prediction"
    ],
    "contribution": "Inspired by the nature of the systems, we propose to decompose and model them from the perspective of global deterministic motion and local stochastic variations with residual mechanism. A unified and flexible framework that can equip any type of spatio-temporal models is proposed based on residual diffusion, which effectively tackles the shortcomings of previous methods. Extensive experimental results on four publicly available radar datasets demonstrate the effectiveness and superiority of the proposed framework, compared to state-of-the-art techniques.",
    "introduction": "Precipitation nowcasting is an important spatiotemporal prediction task to predict the radar echoes sequences based on current observations, which can serve both meteorological science and smart city applications. Due to the chaotic evolution nature of the precipitation systems, it is a very challenging problem. Previous studies address the problem either from the perspectives of deterministic modeling or probabilistic modeling. However, their predictions suffer from the blurry, high-value echoes fading away and position inaccurate issues. The root reason of these issues is that the chaotic evolutionary precipitation systems are not appropriately modeled.",
    "macro_domains": []
  },
  {
    "abstract": "Autonomous Vehicle (AV) decision-making in ur-ban environments is inherently challenging due to the dynamic interactions with surrounding vehicles. For safe planning, AV/ego must understand the weightage of various spatiotemporal interactions in a scene. Contemporary works use colos-sal transformer architectures to encode interactions mainly for trajectory prediction, resulting in increased computational complexity. To address this issue without compromising spatiotemporal understanding and performance, we propose the simple Deep Attention Driven Reinforcement Learning (DAD-RL) framework, which dynamically assigns and incorporates the significance of surrounding vehicles into the ego's RL-driven decision-making process. We introduce an AV-centric spatiotemporal attention encoding (STAE) mechanism for learning the dynamic interactions with different surrounding vehicles. To understand map and route context, we employ a context encoder to extract features from context maps. The spatiotemporal representations combined with contextual encoding provide a comprehensive state representation. The resulting model is trained using the Soft-Actor Critic (SAC) algorithm. We evaluate the proposed framework on the SMARTS urban benchmarking scenarios without traffic signals to demonstrate that DAD-RL outperforms recent state-of-the-art methods. Furthermore, an ablation study underscores the importance of the context-encoder and spatiotemporal attention encoder in achieving superior performance.",
    "doi": "10.1109/SMC54092.2024.10832016",
    "author_keywords": null,
    "contribution": "To address this issue without compromising spatiotemporal understanding and performance, we propose the simple Deep Attention Driven Reinforcement Learning (DAD-RL) framework, which dynamically assigns and incorporates the significance of surrounding vehicles into the ego's RL-driven decision-making process. We introduce an AV-centric spatiotemporal attention encoding (STAE) mechanism for learning the dynamic interactions with different surrounding vehicles. To understand map and route context, we employ a context encoder to extract features from context maps. The spatiotemporal representations combined with contextual encoding provide a comprehensive state representation. The resulting model is trained using the Soft-Actor Critic (SAC) algorithm. We evaluate the proposed framework on the SMARTS urban benchmarking scenarios without traffic signals to demonstrate that DAD-RL outperforms recent state-of-the-art methods. Furthermore, an ablation study underscores the importance of the context-encoder and spatiotemporal attention encoder in achieving superior performance.",
    "introduction": "Autonomous Vehicle (AV) decision-making in ur-ban environments is inherently challenging due to the dynamic interactions with surrounding vehicles. For safe planning, AV/ego must understand the weightage of various spatiotemporal interactions in a scene. Contemporary works use colos-sal transformer architectures to encode interactions mainly for trajectory prediction, resulting in increased computational complexity.",
    "macro_domains": []
  },
  {
    "abstract": "Person re-identification (ReID) is increasingly important due to the expansion of surveillance cameras. ReID can effectively operate in various conditions, making it suitable for security, retail analytics, and smart city applications. We propose a transformer-based model, DeepChangeVIT-ReID, fine-tuned with triplet loss, using the DeepChange dataset. We address long-term ReID challenges, including pose variations, camera angle differences, and clothing alterations. DeepChangeVIT-ReID achieves state-of-the-art performance, significantly improving Rank-1 accuracy compared to existing methods on the DeepChange dataset.",
    "doi": "10.1109/TELFOR63250.2024.10819135",
    "author_keywords": [
      "Computer Vision",
      "Image Processing",
      "Person Re-identification",
      "Surveillance Systems",
      "Transformers"
    ],
    "contribution": "We propose a transformer-based model, DeepChangeVIT-ReID, fine-tuned with triplet loss, using the DeepChange dataset. We address long-term ReID challenges, including pose variations, camera angle differences, and clothing alterations. DeepChangeVIT-ReID achieves state-of-the-art performance, significantly improving Rank-1 accuracy compared to existing methods on the DeepChange dataset.",
    "introduction": "Person re-identification (ReID) is increasingly important due to the expansion of surveillance cameras. ReID can effectively operate in various conditions, making it suitable for security, retail analytics, and smart city applications.",
    "macro_domains": []
  },
  {
    "abstract": "The rapid acceleration of urbanization underscores the urgent need for developing intelligent transportation systems (ITS) to enhance the efficiency, safety, and sustainability of urban mobility. Within this context, accurately predicting vehicle trajectories is paramount for facilitating superior traffic management and control. To this end, the paper presents an innovative architecture that combines a Long Short-Term Memory (LSTM) module with a generative artificial intelligence (Gen-AI) component, specifically the RoBERTa Transformer model. By leveraging these sophisticated architecture, the LSTM network with a recursive decoder outperforms the teacher forcing decoder on clean datasets, showing higher robustness in time-series predictions. When video data was partially missing, performance decreased, but using the RoBERTa model to reconstruct the missing data significantly improved results for both decoders (from 37% up to 92%). The reconstructed data notably enhanced the performance of the LSTM models, particularly when larger portions of the video data were absent. These findings highlight the effectiveness of data reconstruction techniques in mitigating the challenges posed by uncontrollable events (common in real ITS scenarios) which can bear to incomplete information.",
    "doi": "10.1109/WF-IoT62078.2024.10811280",
    "author_keywords": [
      "Generative-AI",
      "Internet of Things",
      "ITS",
      "LSTM",
      "Smart cities",
      "Transformers",
      "Vehicle trajectory prediction"
    ],
    "contribution": "To this end, the paper presents an innovative architecture that combines a Long Short-Term Memory (LSTM) module with a generative artificial intelligence (Gen-AI) component, specifically the RoBERTa Transformer model. By leveraging these sophisticated architecture, the LSTM network with a recursive decoder outperforms the teacher forcing decoder on clean datasets, showing higher robustness in time-series predictions. When video data was partially missing, performance decreased, but using the RoBERTa model to reconstruct the missing data significantly improved results for both decoders (from 37% up to 92%). The reconstructed data notably enhanced the performance of the LSTM models, particularly when larger portions of the video data were absent. These findings highlight the effectiveness of data reconstruction techniques in mitigating the challenges posed by uncontrollable events (common in real ITS scenarios) which can bear to incomplete information.",
    "introduction": "The rapid acceleration of urbanization underscores the urgent need for developing intelligent transportation systems (ITS) to enhance the efficiency, safety, and sustainability of urban mobility. Within this context, accurately predicting vehicle trajectories is paramount for facilitating superior traffic management and control.",
    "macro_domains": []
  },
  {
    "abstract": "Person re-identification aims to recognize a target pedestrian across non-overlapping camera views based on source information. The Internet of Things (IoT) provides a wide range of application scenarios for pedestrian re-identification technology-smart city management, resource optimization, and multi-source data fusion. It is crucial for IoT applications like intelligent video surveillance but remains challenging due to factors like low image resolution, varying angles, lighting changes, and occlusion. In this paper, we propose a multi-task learning approach that integrates text information to enhance recognition accuracy. Using a dual-stream Transformer encoder, we extract both image and text features. To improve feature interaction and learning, we perform multimodal interaction for fine-grained alignment and share feature for modality-invariant feature representation and learning. Our method, TFTI, outperforms state-of-the-art techniques in person re-identification, as validated on the CUHK-PEDES dataset.",
    "doi": "10.1109/SmartIoT62235.2024.00081",
    "author_keywords": [
      "Internet of Things(IoT)",
      "Multi-task Learning",
      "Person Re-identification",
      "Text Information-aided"
    ],
    "contribution": "In this paper, we propose a multi-task learning approach that integrates text information to enhance recognition accuracy. Using a dual-stream Transformer encoder, we extract both image and text features. To improve feature interaction and learning, we perform multimodal interaction for fine-grained alignment and share feature for modality-invariant feature representation and learning. Our method, TFTI, outperforms state-of-the-art techniques in person re-identification, as validated on the CUHK-PEDES dataset.",
    "introduction": "Person re-identification aims to recognize a target pedestrian across non-overlapping camera views based on source information. The Internet of Things (IoT) provides a wide range of application scenarios for pedestrian re-identification technology-smart city management, resource optimization, and multi-source data fusion. It is crucial for IoT applications like intelligent video surveillance but remains challenging due to factors like low image resolution, varying angles, lighting changes, and occlusion.",
    "macro_domains": []
  },
  {
    "abstract": "The advent of Digital Twin (DT) technology represents a significant milestone in the evolution of smart city management, introducing virtual models and data-driven simulations that enhance our understanding, planning, and management of urban environments. Generative Artificial Intelligence (GenAI) integration enriches digital twins by boosting their predictive capabilities and simulating more realistic and interactive scenarios. By leveraging generative algorithms, digital twins can create synthetic data, to simulate a wide range of potential outcomes. These additional capabilities enable more accurate modeling of complex systems, predicting variations and potential issues. Moreover, Generative AI can contribute to creating high-quality simulations, improving the accuracy and reliability of digital twins in representing real-world environments and processes. This chapter provides an exploration of the synergies between GenAI and digital twins in the context of disaster management and smart cities. The chapter begins with an introduction, offering a contextual background integrating generative AI and digital twins for simulating disaster and emergency scenarios. It then delves into the foundations of generative AI, discussing its principles, applications, and success stories across various domains, with a specific focus on its relevance to urban disaster management. The subsequent sections clarify the evolution of digital twins and their pivotal role in predicting and mitigating disasters and emergency response. The chapter then navigates the intersection between generative AI and digital twins and the functionalities that GenAI brings to improving the simulation process, providing examples of successful integrations while addressing potential challenges and proposing solutions. Furthermore, it explores how smart cities contribute to disaster resilience, detailing the technologies and strategies employed for disaster preparedness. The chapter concludes with an in-depth analysis of specific GenAI-enhanced digital twinsâ€™ applications in disaster management, anticipating future challenges and developments in the field, and emphasizing emerging trends and potential directions.",
    "doi": "10.1007/978-981-97-8483-7_5",
    "author_keywords": [
      "Data synthesis",
      "Digital twin",
      "Disaster and emergency management",
      "Generative AI",
      "Scenario generation",
      "Smart cities",
      "Urban intelligence",
      "Urban resilience"
    ],
    "contribution": "This chapter provides an exploration of the synergies between GenAI and digital twins in the context of disaster management and smart cities. The chapter begins with an introduction, offering a contextual background integrating generative AI and digital twins for simulating disaster and emergency scenarios. It then delves into the foundations of generative AI, discussing its principles, applications, and success stories across various domains, with a specific focus on its relevance to urban disaster management. The subsequent sections clarify the evolution of digital twins and their pivotal role in predicting and mitigating disasters and emergency response. The chapter then navigates the intersection between generative AI and digital twins and the functionalities that GenAI brings to improving the simulation process, providing examples of successful integrations while addressing potential challenges and proposing solutions. Furthermore, it explores how smart cities contribute to disaster resilience, detailing the technologies and strategies employed for disaster preparedness. The chapter concludes with an in-depth analysis of specific GenAI-enhanced digital twinsâ€™ applications in disaster management, anticipating future challenges and developments in the field, and emphasizing emerging trends and potential directions.",
    "introduction": "The advent of Digital Twin (DT) technology represents a significant milestone in the evolution of smart city management, introducing virtual models and data-driven simulations that enhance our understanding, planning, and management of urban environments. Generative Artificial Intelligence (GenAI) integration enriches digital twins by boosting their predictive capabilities and simulating more realistic and interactive scenarios. By leveraging generative algorithms, digital twins can create synthetic data, to simulate a wide range of potential outcomes. These additional capabilities enable more accurate modeling of complex systems, predicting variations and potential issues. Moreover, Generative AI can contribute to creating high-quality simulations, improving the accuracy and reliability of digital twins in representing real-world environments and processes.",
    "macro_domains": []
  },
  {
    "abstract": "Rapid urbanization and population growth have created significant challenges in urban mobility management, including traffic congestion, inefficient public transportation, and environmental pollution. This paper presents the development and implementation of a Digital Twin (DT) for smart mobility, designed to address these issues. The DT platform integrates a diverse range of historical and real-time data, providing a comprehensive view of urban mobility conditions. Descriptive statistics are employed to identify patterns in parking occupancy and violation frequencies, while Machine Learning and Deep Learning algorithms enhance predictive and generative analytics for forecasting parking needs and simulating scenarios with other mobility aspects. Advanced analytics uncover hidden patterns and behaviors, and visualization tools map data onto the urban layout to facilitate spatial planning and resource allocation. Scenario simulation enables urban planners to assess the impact of different strategies in a virtual environment prior to real-world implementation. The integration of Generative Artificial Intel- ligence (GenAl) models further enhances predictive capabilities and scenario generation. Preliminary results demonstrate the DT platform's potential in improving urban mobility management, particularly in optimizing parking meter placement and enhancing user experience. Although limited data availability affects long-term prediction accuracy, the model exhibits robustness and adaptability for extended forecasting horizons.",
    "doi": "10.1109/CyberSciTech64112.2024.00032",
    "author_keywords": [
      "Data-Driven Decision Making",
      "Digital Twin",
      "Generative AI",
      "Smart Cities",
      "Urban Mobility Management"
    ],
    "contribution": "This paper presents the development and implementation of a Digital Twin (DT) for smart mobility, designed to address these issues. The DT platform integrates a diverse range of historical and real-time data, providing a comprehensive view of urban mobility conditions. Descriptive statistics are employed to identify patterns in parking occupancy and violation frequencies, while Machine Learning and Deep Learning algorithms enhance predictive and generative analytics for forecasting parking needs and simulating scenarios with other mobility aspects. Advanced analytics uncover hidden patterns and behaviors, and visualization tools map data onto the urban layout to facilitate spatial planning and resource allocation. Scenario simulation enables urban planners to assess the impact of different strategies in a virtual environment prior to real-world implementation. The integration of Generative Artificial Intel- ligence (GenAl) models further enhances predictive capabilities and scenario generation. Preliminary results demonstrate the DT platform's potential in improving urban mobility management, particularly in optimizing parking meter placement and enhancing user experience. Although limited data availability affects long-term prediction accuracy, the model exhibits robustness and adaptability for extended forecasting horizons.",
    "introduction": "Rapid urbanization and population growth have created significant challenges in urban mobility management, including traffic congestion, inefficient public transportation, and environmental pollution.",
    "macro_domains": []
  },
  {
    "abstract": "Human mobility prediction is fundamental to designing intelligent cities and forecasting how people move during disasters and health emergencies, specifically in emergency responses. However, the existing method for human mobility prediction is mainly designed for normal scenarios and is incapable of handling the case of a pandemic. The COVID-19 pandemic has presented challenges over the past few years: the powerful pandemic has a fundamental and long-lasting influence on mobility, which is hard to model. Inspired by recent progress in the Large Language Model, we present the Human Mobility Prediction-Large Language Model (HMP-LLM), which utilizes LLMs with understanding and reasoning abilities to do human mobility prediction tasks. Especially to adapt LLMs to intervened time series prediction, we propose the following critical designs: 1) Seasonal Decompose. 2) Two-stage Prompts Designing. We convert the input data into textual prototypes so LLMs can understand it, then we use two-stage prompts to guide the language model in reasoning. Extensive experiments on real-world datasets confirm the superiority of HMP-LLM over existing methods. Besides, due to the zero-shot nature and the expansibility of our two-stage design, HMP-LLM is expected to be used in other public safety incidents.",
    "doi": "10.1109/DTPI61353.2024.10778764",
    "author_keywords": [
      "Human Mobility Prediction",
      "Large Language Models",
      "Smart Cities"
    ],
    "contribution": "Inspired by recent progress in the Large Language Model, we present the Human Mobility Prediction-Large Language Model (HMP-LLM), which utilizes LLMs with understanding and reasoning abilities to do human mobility prediction tasks. Especially to adapt LLMs to intervened time series prediction, we propose the following critical designs: 1) Seasonal Decompose. 2) Two-stage Prompts Designing. We convert the input data into textual prototypes so LLMs can understand it, then we use two-stage prompts to guide the language model in reasoning. Extensive experiments on real-world datasets confirm the superiority of HMP-LLM over existing methods. Besides, due to the zero-shot nature and the expansibility of our two-stage design, HMP-LLM is expected to be used in other public safety incidents.",
    "introduction": "Human mobility prediction is fundamental to designing intelligent cities and forecasting how people move during disasters and health emergencies, specifically in emergency responses. However, the existing method for human mobility prediction is mainly designed for normal scenarios and is incapable of handling the case of a pandemic. The COVID-19 pandemic has presented challenges over the past few years: the powerful pandemic has a fundamental and long-lasting influence on mobility, which is hard to model.",
    "macro_domains": []
  },
  {
    "abstract": "The rapid urbanization and the need for sustainable city management have driven the demand for intelligent and efficient smart city planning solutions. This paper explores an innovative approach to automated smart city planning using a personalized large language model (LLM) combined with Retrieval Augmented Generation (RAG). Our proposed system leverages the personalized mistral7b model, enabling the ingestion and analysis of multiple documents, including smart city master plans and government regulations. This methodology ensures tailored urban planning recommendations while maintaining data privacy by running the system locally. In light of the dangers of cyberattacks and the inherent risks associated with using foreign-run services, our approach provides a secure and autonomous solution for urban development planning.",
    "doi": "10.1109/ICITCOM62788.2024.10762118",
    "author_keywords": [
      "chatbot",
      "large language models",
      "retrieval augmented generation",
      "smart city"
    ],
    "contribution": "This paper explores an innovative approach to automated smart city planning using a personalized large language model (LLM) combined with Retrieval Augmented Generation (RAG). Our proposed system leverages the personalized mistral7b model, enabling the ingestion and analysis of multiple documents, including smart city master plans and government regulations. This methodology ensures tailored urban planning recommendations while maintaining data privacy by running the system locally. In light of the dangers of cyberattacks and the inherent risks associated with using foreign-run services, our approach provides a secure and autonomous solution for urban development planning.",
    "introduction": "The rapid urbanization and the need for sustainable city management have driven the demand for intelligent and efficient smart city planning solutions.",
    "macro_domains": []
  },
  {
    "abstract": "The fifth-generation (5G) offers advanced services, supporting applications such as intelligent transportation, con-nected healthcare, and smart cities within the Internet of Things (IoT). However, these advancements introduce significant security challenges, with increasingly sophisticated cyber-attacks. This paper proposes a robust intrusion detection system (IDS) using federated learning and large language models (LLMs). The core of our IDS is based on BERT, a transformer model adapted to identify malicious network flows. We modified this transformer to optimize performance on edge devices with limited resources. Experiments were conducted in both centralized and federated learning contexts. In the centralized setup, the model achieved an inference accuracy of 97.79 %. In a federated learning context, the model was trained across multiple devices using both IID (Independent and Identically Distributed) and non-IID data, based on various scenarios, ensuring data privacy and compliance with regulations. We also leveraged linear quantization to com-press the model for deployment on edge devices. This reduction resulted in a slight decrease of 0.02 % in accuracy for a model size reduction of 28.74 %. The results underscore the viability of LLMs for deployment in IoT ecosystems, highlighting their ability to operate on devices with constrained computational and storage resources.",
    "doi": "10.1109/WiMob61911.2024.10770340",
    "author_keywords": [
      "5G",
      "Cybersecurity",
      "Data privacy",
      "Federated Learning",
      "Internet of Things",
      "Intrusion detection system",
      "Large Language Models"
    ],
    "contribution": "This paper proposes a robust intrusion detection system (IDS) using federated learning and large language models (LLMs). The core of our IDS is based on BERT, a transformer model adapted to identify malicious network flows. We modified this transformer to optimize performance on edge devices with limited resources. Experiments were conducted in both centralized and federated learning contexts. In the centralized setup, the model achieved an inference accuracy of 97.79 %. In a federated learning context, the model was trained across multiple devices using both IID (Independent and Identically Distributed) and non-IID data, based on various scenarios, ensuring data privacy and compliance with regulations. We also leveraged linear quantization to com-press the model for deployment on edge devices. This reduction resulted in a slight decrease of 0.02 % in accuracy for a model size reduction of 28.74 %. The results underscore the viability of LLMs for deployment in IoT ecosystems, highlighting their ability to operate on devices with constrained computational and storage resources.",
    "introduction": "The fifth-generation (5G) offers advanced services, supporting applications such as intelligent transportation, con-nected healthcare, and smart cities within the Internet of Things (IoT). However, these advancements introduce significant security challenges, with increasingly sophisticated cyber-attacks.",
    "macro_domains": []
  },
  {
    "abstract": "Our book, Future of Tech Startups and Innovations in the Age of AI, mainly focuses on artificial intelligence (AI) tools, AI-based startups, AI-enabled innovations, Autonomous AI Agents (Auto-GPT), AI-based marketing startups, machine learning for organizations, AI-internet of things (IoT) for new tech companies, AI-enabled drones for agriculture industry, machine learning (ML)/deep learning (DL)-based drip farming, AI-based driverless cars, AI-based weather prediction startups, AI tools for personal branding, AI-based teaching, AI-based doctor/hospital startups, AI for game companies, AI-based finance tools, AI for human resource management, AI-powered management tools, AI tools for future pandemics, AI/ML-based transportation companies, AI for media, AI for carrier counseling, AI for customer care, AI for next generation businesses, and many more applications. AI tools and techniques will revolutionize startups all over the world. Entrepreneurs, engineers, and practitioners have already moved toward AI-based solutions to reshape businesses. AI/ML will create possibilities and opportunities for improving human lifestyles. AI-enabled startups will work on cost-effective solutions to solve difficult problems. Recently, many research companies are interested in providing solutions and investing a lot in AI-based startups. AI-driven products will revolutionize the â€œsmart world.â€ AI computing tech companies will help to model human speech recognition systems. Also, AI-based startups will focus on perception and reasoning of autonomous robotic systems. AI/ML-based tech startups will introduce smart online education systems for future pandemics. More interestingly, people are also moving for online job opportunities and trying to work from home. Future innovation needs closer relations between academia and industry. Therefore, online platforms need to be introduced that will only focus on academia and industry linkage. Future AI tech-based startups will focus more on research and development to introduce novel products to the market. Accordingly, engineers and many other people should be trained on AI tools and techniques to introduce innovative solutions for the smart world. In addition, integration of many new technologies with AI will be made possible. AI with IoT, smart cities, unmanned aerial vehicles (UAVs), wireless sensor networks, software-defined networks, network management, vehicular ad hoc networks, flying ad hoc networks, wireless communication technologies, ML, reinforcement learning, federated learning and other mechanisms will introduce new technological products.",
    "doi": "10.1201/9781032715957",
    "author_keywords": null,
    "contribution": "",
    "introduction": "Our book, Future of Tech Startups and Innovations in the Age of AI, mainly focuses on artificial intelligence (AI) tools, AI-based startups, AI-enabled innovations, Autonomous AI Agents (Auto-GPT), AI-based marketing startups, machine learning for organizations, AI-internet of things (IoT) for new tech companies, AI-enabled drones for agriculture industry, machine learning (ML)/deep learning (DL)-based drip farming, AI-based driverless cars, AI-based weather prediction startups, AI tools for personal branding, AI-based teaching, AI-based doctor/hospital startups, AI for game companies, AI-based finance tools, AI for human resource management, AI-powered management tools, AI tools for future pandemics, AI/ML-based transportation companies, AI for media, AI for carrier counseling, AI for customer care, AI for next generation businesses, and many more applications. AI tools and techniques will revolutionize startups all over the world. Entrepreneurs, engineers, and practitioners have already moved toward AI-based solutions to reshape businesses. AI/ML will create possibilities and opportunities for improving human lifestyles. AI-enabled startups will work on cost-effective solutions to solve difficult problems. Recently, many research companies are interested in providing solutions and investing a lot in AI-based startups. AI-driven products will revolutionize the â€œsmart world.â€ AI computing tech companies will help to model human speech recognition systems. Also, AI-based startups will focus on perception and reasoning of autonomous robotic systems. AI/ML-based tech startups will introduce smart online education systems for future pandemics. More interestingly, people are also moving for online job opportunities and trying to work from home. Future innovation needs closer relations between academia and industry. Therefore, online platforms need to be introduced that will only focus on academia and industry linkage. Future AI tech-based startups will focus more on research and development to introduce novel products to the market. Accordingly, engineers and many other people should be trained on AI tools and techniques to introduce innovative solutions for the smart world. In addition, integration of many new technologies with AI will be made possible. AI with IoT, smart cities, unmanned aerial vehicles (UAVs), wireless sensor networks, software-defined networks, network management, vehicular ad hoc networks, flying ad hoc networks, wireless communication technologies, ML, reinforcement learning, federated learning and other mechanisms will introduce new technological products.",
    "macro_domains": []
  },
  {
    "abstract": "In rapidly urbanizing cities with increasing populations, the challenges of managing traffic are becoming more pressing, highlighting the need for advanced technologies. The Advanced Intelligent Traffic Management System (AITMS) is a comprehensive solution designed to address the persistent challenges of traffic congestion, poor traffic management, and air pollution in densely populated urban areas. Current traffic management systems often rely on static algorithms and predetermined signal timings, which are insufficient to handle dynamic and unpredictable traffic patterns. This results in prolonged travel times, increased fuel consumption, and elevated levels of air pollution, posing serious threats to public health and environmental sustainability. AITMS integrates physical and digital infrastructures, leveraging Generative AI for real-time data collection, analysis, and decision-making. By incorporating sensors, IoT devices, and advanced data analytics, the system can predict traffic flow, optimize signal timings, and recommend alternate routes. It also communicates with connected vehicles to provide real-time updates. The incorporation of Generative AI enables the AITMS to continually adapt and learn from new data inputs and trends, ensuring sustainability and scalability in urban transportation. AITMS is an innovative framework enhanced by Generative AI, aimed at revolutionizing urban traffic management in smart cities. Similar frameworks demonstrate promising outcomes, including improved traffic management, reduced congestion, and enhanced driver safety. AITMS aims to transform urban transportation, elevate residents' quality of life, and foster more sustainable and resilient cities amidst urbanization challenges.",
    "doi": "10.1109/PowerAfrica61624.2024.10759478",
    "author_keywords": [
      "AITMS",
      "GAN",
      "Generative AI",
      "LLM",
      "Scalability",
      "Smart Cities"
    ],
    "contribution": "",
    "introduction": "In rapidly urbanizing cities with increasing populations, the challenges of managing traffic are becoming more pressing, highlighting the need for advanced technologies. The Advanced Intelligent Traffic Management System (AITMS) is a comprehensive solution designed to address the persistent challenges of traffic congestion, poor traffic management, and air pollution in densely populated urban areas. Current traffic management systems often rely on static algorithms and predetermined signal timings, which are insufficient to handle dynamic and unpredictable traffic patterns. This results in prolonged travel times, increased fuel consumption, and elevated levels of air pollution, posing serious threats to public health and environmental sustainability. AITMS integrates physical and digital infrastructures, leveraging Generative AI for real-time data collection, analysis, and decision-making. By incorporating sensors, IoT devices, and advanced data analytics, the system can predict traffic flow, optimize signal timings, and recommend alternate routes. It also communicates with connected vehicles to provide real-time updates. The incorporation of Generative AI enables the AITMS to continually adapt and learn from new data inputs and trends, ensuring sustainability and scalability in urban transportation. AITMS is an innovative framework enhanced by Generative AI, aimed at revolutionizing urban traffic management in smart cities. Similar frameworks demonstrate promising outcomes, including improved traffic management, reduced congestion, and enhanced driver safety. AITMS aims to transform urban transportation, elevate residents' quality of life, and foster more sustainable and resilient cities amidst urbanization challenges.",
    "macro_domains": []
  },
  {
    "abstract": "With the rapid advancement of remote sensing technology, the resolution of remote sensing satellites is improving, the number of spectral bands is increasing, and revisit periods are contracting. This progression empowers researchers to access more valuable data and information from remote sensing images. Concepts, such as remote sensing big data, remote sensing foundation models, and smart cities, have successively emerged in recent years, imposing increased demands on the intelligent extraction technology of massive remote sensing data, particularly regarding remote sensing image information. As an indispensable element of intelligent information extraction technology applied in fields, such as land use and cover, national land resource surveys, natural disaster observation, agricultural yield estimation, and forestry protection, remote sensing image classification exhibits substantial practical importance. Remote sensing image scene classification has been introduced in this context. The objective of scene classification in remote sensing images is to comprehensively and semantically categorize each given remote sensing image. This task entails summarizing and analyzing the extracted feature information at a high level and assigning different labels to areas of interest based on their features. In contrast with natural images, although they contain features, such as color, texture, and shape, remote sensing images encounter more challenges in classification due to the intricate scene content resulting from the overhead perspective, weak texture, and color information caused by low resolution. Nevertheless, as one of the technical means in remote sensing applications, remote sensing image scene classification technology plays a pivotal role in the development of practical application technologies. After years of development, numerous comprehensive review studies on remote sensing image scene classification have been conducted locally and abroad. However, the recent surge in remote sensing big data has introduced new challenges into scene classification. The ongoing evolution of deep learning technology, particularly the widespread application of Convolutional Neural Networks (CNNs) and transformers, has resulted in significant advancements in remote sensing image scene classification. In this context, self-supervised learning, as a method that is independent of annotated data, has become indispensable in the field of remote sensing image scene classification. Foundation models based on self-supervised learning have been successfully implemented in scene classification, presenting innovative solutions to this field. As the volume of remote sensing data continues to increase, the dataset scale for remote sensing image scene classification is expanding rapidly, giving rise to increasingly intricate classification tasks. Remote sensing image scene classification datasets are swiftly progressing toward the integration of multiple sources, the incorporation of multiple labels, and the inclusion of large-scale samples. Drawing from the findings of the current literature survey, this study systematically compiles a summary of deep learning methods within the domain of remote sensing image scene classification. Encompassing CNNs, visual transformers, and generative adversarial networks, this overview also introduces representative datasets and foundation models since the inception of scene classification. Several classical scene classification methods have undergone evaluation across various benchmark datasets. In addition, this study delves into primary challenges and prospects, paving the way for further research in the classification of scenes in remote sensing images.",
    "doi": "10.11834/jrs.20243519",
    "author_keywords": [
      "deep learning",
      "high-resolution remote sensing image",
      "image classification",
      "scene classification"
    ],
    "contribution": "Drawing from the findings of the current literature survey, this study systematically compiles a summary of deep learning methods within the domain of remote sensing image scene classification. Encompassing CNNs, visual transformers, and generative adversarial networks, this overview also introduces representative datasets and foundation models since the inception of scene classification. Several classical scene classification methods have undergone evaluation across various benchmark datasets. In addition, this study delves into primary challenges and prospects, paving the way for further research in the classification of scenes in remote sensing images.",
    "introduction": "With the rapid advancement of remote sensing technology, the resolution of remote sensing satellites is improving, the number of spectral bands is increasing, and revisit periods are contracting. This progression empowers researchers to access more valuable data and information from remote sensing images. Concepts, such as remote sensing big data, remote sensing foundation models, and smart cities, have successively emerged in recent years, imposing increased demands on the intelligent extraction technology of massive remote sensing data, particularly regarding remote sensing image information. As an indispensable element of intelligent information extraction technology applied in fields, such as land use and cover, national land resource surveys, natural disaster observation, agricultural yield estimation, and forestry protection, remote sensing image classification exhibits substantial practical importance. Remote sensing image scene classification has been introduced in this context. The objective of scene classification in remote sensing images is to comprehensively and semantically categorize each given remote sensing image. This task entails summarizing and analyzing the extracted feature information at a high level and assigning different labels to areas of interest based on their features. In contrast with natural images, although they contain features, such as color, texture, and shape, remote sensing images encounter more challenges in classification due to the intricate scene content resulting from the overhead perspective, weak texture, and color information caused by low resolution. Nevertheless, as one of the technical means in remote sensing applications, remote sensing image scene classification technology plays a pivotal role in the development of practical application technologies. After years of development, numerous comprehensive review studies on remote sensing image scene classification have been conducted locally and abroad. However, the recent surge in remote sensing big data has introduced new challenges into scene classification. The ongoing evolution of deep learning technology, particularly the widespread application of Convolutional Neural Networks (CNNs) and transformers, has resulted in significant advancements in remote sensing image scene classification. In this context, self-supervised learning, as a method that is independent of annotated data, has become indispensable in the field of remote sensing image scene classification. Foundation models based on self-supervised learning have been successfully implemented in scene classification, presenting innovative solutions to this field. As the volume of remote sensing data continues to increase, the dataset scale for remote sensing image scene classification is expanding rapidly, giving rise to increasingly intricate classification tasks. Remote sensing image scene classification datasets are swiftly progressing toward the integration of multiple sources, the incorporation of multiple labels, and the inclusion of large-scale samples.",
    "macro_domains": []
  },
  {
    "abstract": "In the rapidly evolving landscape of digital twins (DT) and 6G networks, the integration of large language models (LLMs) presents a novel approach to network management. This paper explores the application of LLMs in managing 6G-empowered DT networks, with a focus on optimizing data retrieval and communication efficiency in smart city scenarios. The proposed framework leverages LLMs for intelligent DT problem analysis and radio resource management (RRM) in fully autonomous way without any manual intervention. Our proposed framework - LINKs, builds up a lazy loading strategy which can minimize transmission delay by selectively retrieving the relevant data. Based on the data retrieval plan, LLMs transform the retrieval task into an numerical optimization problem and utilizing solvers to build an optimal RRM, ensuring efficient communication across the network. Simulation results demonstrate the performance improvements in data planning and network management, highlighting the potential of LLMs to enhance the integration of DT and 6G technologies.",
    "doi": "10.1109/VTC2024-Fall63153.2024.10757470",
    "author_keywords": null,
    "contribution": "This paper explores the application of LLMs in managing 6G-empowered DT networks, with a focus on optimizing data retrieval and communication efficiency in smart city scenarios. The proposed framework leverages LLMs for intelligent DT problem analysis and radio resource management (RRM) in fully autonomous way without any manual intervention. Our proposed framework - LINKs, builds up a lazy loading strategy which can minimize transmission delay by selectively retrieving the relevant data. Based on the data retrieval plan, LLMs transform the retrieval task into an numerical optimization problem and utilizing solvers to build an optimal RRM, ensuring efficient communication across the network. Simulation results demonstrate the performance improvements in data planning and network management, highlighting the potential of LLMs to enhance the integration of DT and 6G technologies.",
    "introduction": "In the rapidly evolving landscape of digital twins (DT) and 6G networks, the integration of large language models (LLMs) presents a novel approach to network management.",
    "macro_domains": []
  },
  {
    "abstract": "Outdoor landmark identification is a critical aspect of applications like tourism and navigation. This paper presents a novel approach based on Vision Transformer (ViT) architecture, to tackle the problem of outdoor landmark detection. Accurately identifying landmarks from images is the research challenge; this is an essential function for tourism, navigation, and cultural preservation. This approach is implemented using a state-of-the-art neural network architecture to effectively capture long-range relationships in images. The results highlight that the ViT model outperforms conventional convolutional neural networks in challenging outdoor conditions by having a higher accuracy rate when identifying landmarks. The research strengthens the potential of ViT models for outdoor landmark detection. The effective application of ViT has applications in the fields of smart city technology, tourism, and cultural heritage protection in addition to advancing computer vision.",
    "doi": "10.1109/ICCCNT61001.2024.10725838",
    "author_keywords": [
      "Deep learning",
      "Landmark identification",
      "landmarks",
      "Monument",
      "Navigation",
      "Vision Transformer(ViT)"
    ],
    "contribution": "This paper presents a novel approach based on Vision Transformer (ViT) architecture, to tackle the problem of outdoor landmark detection. Accurately identifying landmarks from images is the research challenge; this is an essential function for tourism, navigation, and cultural preservation. This approach is implemented using a state-of-the-art neural network architecture to effectively capture long-range relationships in images. The results highlight that the ViT model outperforms conventional convolutional neural networks in challenging outdoor conditions by having a higher accuracy rate when identifying landmarks. The research strengthens the potential of ViT models for outdoor landmark detection. The effective application of ViT has applications in the fields of smart city technology, tourism, and cultural heritage protection in addition to advancing computer vision.",
    "introduction": "Outdoor landmark identification is a critical aspect of applications like tourism and navigation.",
    "macro_domains": []
  },
  {
    "abstract": "This novel research into practice project explores Kigali, Rwandaâ€™s transition towards carbon-neutral urban planning and its implications for sustainability and urban development in the Global South. Notably, African countries are leading in the shift towards renewable energy, inspiring smart city initiatives, particularly in Kigali. The study critically documents and reflects on real-world architectural and infrastructural transformations in Kigali, examining socio-technical elements facilitating these changes and the effectiveness of implemented strategies. Our methodology utilises cloud-based simulation analysis, generative design optimisation, and building physics tools, incorporating Kigaliâ€™s cultural, geographical and climatic specifics. These strategies have led to various initiatives, such as sustainable smart buildings, smart traffic management, and digitally enabled economic environments. A Kigali Innovation City (KIC) case study exemplifies Kigaliâ€™s sustainable vision but also reveals challenges like neglect of demographic and economic realities. Learning from these hurdles, the team, including the author, is working on the large 42-ha Vision City Phase 2, aiming for carbon neutrality and the International Well-Being Institute certification. This project illustrates the significance of embracing challenges to achieve urban sustainability targets, offering insights into other citiesâ€™ sustainability and carbon-neutral endeavours and required research benchmarking.",
    "doi": "10.1007/978-3-031-74723-6_35",
    "author_keywords": [
      "AI",
      "Carbon neutrality",
      "Generative AI",
      "Generative design optimization",
      "Renewable energy",
      "Smart city initiatives"
    ],
    "contribution": "The study critically documents and reflects on real-world architectural and infrastructural transformations in Kigali, examining socio-technical elements facilitating these changes and the effectiveness of implemented strategies. Our methodology utilises cloud-based simulation analysis, generative design optimisation, and building physics tools, incorporating Kigaliâ€™s cultural, geographical and climatic specifics. These strategies have led to various initiatives, such as sustainable smart buildings, smart traffic management, and digitally enabled economic environments. A Kigali Innovation City (KIC) case study exemplifies Kigaliâ€™s sustainable vision but also reveals challenges like neglect of demographic and economic realities. Learning from these hurdles, the team, including the author, is working on the large 42-ha Vision City Phase 2, aiming for carbon neutrality and the International Well-Being Institute certification. This project illustrates the significance of embracing challenges to achieve urban sustainability targets, offering insights into other citiesâ€™ sustainability and carbon-neutral endeavours and required research benchmarking.",
    "introduction": "This novel research into practice project explores Kigali, Rwandaâ€™s transition towards carbon-neutral urban planning and its implications for sustainability and urban development in the Global South. Notably, African countries are leading in the shift towards renewable energy, inspiring smart city initiatives, particularly in Kigali.",
    "macro_domains": []
  },
  {
    "abstract": "Image caption generation has become a prominent area of research due to its potential applications in multimedia understanding and accessibility. This paper presents a comprehensive study of three state-of-the-art approaches for image caption generation, employing convolutional neural networks (CNN) with long short-term memory (LSTM) networks, attention mechanisms, and transformers. The first approach utilises a CNN-LSTM architecture, where the CNN acts as an encoder to extract meaningful visual features from input images. These features are then fed into an LSTM-based decoder, enabling the generation of descriptive captions. The second approach introduces the use of attention mechanisms, allowing the model to focus on specific regions of the image while generating captions. This technique improves the caption quality and ensures that the generated text corresponds more accurately to the content in the image. Lastly, the third approach incorporates the powerful transformer architecture to capture long-range dependencies in the generated captions, enabling better contextual understanding and coherence.",
    "doi": "10.1504/IJAMECHS.2024.143152",
    "author_keywords": [
      "attention mechanism",
      "benchmark",
      "CNN",
      "image caption",
      "LTSM",
      "NLP",
      "transformer"
    ],
    "contribution": "This paper presents a comprehensive study of three state-of-the-art approaches for image caption generation, employing convolutional neural networks (CNN) with long short-term memory (LSTM) networks, attention mechanisms, and transformers. The first approach utilises a CNN-LSTM architecture, where the CNN acts as an encoder to extract meaningful visual features from input images. These features are then fed into an LSTM-based decoder, enabling the generation of descriptive captions. The second approach introduces the use of attention mechanisms, allowing the model to focus on specific regions of the image while generating captions. This technique improves the caption quality and ensures that the generated text corresponds more accurately to the content in the image. Lastly, the third approach incorporates the powerful transformer architecture to capture long-range dependencies in the generated captions, enabling better contextual understanding and coherence.",
    "introduction": "Image caption generation has become a prominent area of research due to its potential applications in multimedia understanding and accessibility.",
    "macro_domains": []
  },
  {
    "abstract": "The rapid development of intelligent industry and smart city increases the number of surveillance devices, greatly enhancing the need for unsupervised automatic anomaly detection in real-Time video surveillance, which uses raw data without laborious manual annotations. Existing video anomaly detection (VAD) methods encounter limitations when utilizing pretext tasks, such as reconstruction or prediction to identify abnormal events, as these tasks are not completely consistent and complementary with the essential objective of anomaly detection. Motivated by recent advances in diffusion models, we propose a multiscale recovery diffusion model, which relies on the proposed novel and effective pretext task named recovery to introduce the notion of generation speed. It utilizes critical step-by-step generation of diffusion probabilistic models in unsupervised anomaly detection scenarios. By incorporating a proposed multiscale spatial-Temporal subtraction module, our model captures more detailed appearance and motion information of foreground objects without relying on other high-level pretrained models. Furthermore, an innovative push-pull loss further extends the disparity between normal and abnormal events through pseudolabels. We validate our model on five established benchmarks: UCSD Ped1, UCSD Ped2, CUHK Avenue, ShanghaiTech, and UCF-Crime, achieving frame-level area under the curves of 86.01%, 99.23%, 92.35%, 82.49%, and 74.79%, respectively, surpassing other state-of-The-Art unsupervised VAD methods.",
    "doi": "10.1109/TII.2024.3493390",
    "author_keywords": [
      "Anomaly detection",
      "diffusion model (DM)",
      "intelligent industry",
      "pretext task",
      "real-Time video surveillance",
      "unsupervised learning"
    ],
    "contribution": "Motivated by recent advances in diffusion models, we propose a multiscale recovery diffusion model, which relies on the proposed novel and effective pretext task named recovery to introduce the notion of generation speed. It utilizes critical step-by-step generation of diffusion probabilistic models in unsupervised anomaly detection scenarios. By incorporating a proposed multiscale spatial-Temporal subtraction module, our model captures more detailed appearance and motion information of foreground objects without relying on other high-level pretrained models. Furthermore, an innovative push-pull loss further extends the disparity between normal and abnormal events through pseudolabels. We validate our model on five established benchmarks: UCSD Ped1, UCSD Ped2, CUHK Avenue, ShanghaiTech, and UCF-Crime, achieving frame-level area under the curves of 86.01%, 99.23%, 92.35%, 82.49%, and 74.79%, respectively, surpassing other state-of-The-Art unsupervised VAD methods.",
    "introduction": "The rapid development of intelligent industry and smart city increases the number of surveillance devices, greatly enhancing the need for unsupervised automatic anomaly detection in real-Time video surveillance, which uses raw data without laborious manual annotations. Existing video anomaly detection (VAD) methods encounter limitations when utilizing pretext tasks, such as reconstruction or prediction to identify abnormal events, as these tasks are not completely consistent and complementary with the essential objective of anomaly detection.",
    "macro_domains": []
  },
  {
    "abstract": "Urban areas face various challenges, including urban planning, waste management, pollution, public safety, and other issues. Information technologies and artificial intelligence have proven helpful in addressing these problems. This paper explores the potential of Generative Artificial Intelligence (GenAI) to address urban challenges through geospatial analysis. We cover various GenAI models used in urban contexts, such as Generative Adversarial Networks (GAN), Variational Autoencoders (VAEs), Transformer-based models (or General Pre-trained Transformer), Large Language Models (LLMs), and Generative Diffusion models. The paper explains how GenAI can be used for urban analysis applications from an information management perspective. It presents examples of the operations that can be achieved. Additionally, it describes studies related to energy and resource management, urban planning, natural disaster management, and traffic management, demonstrating the advantages of applying this type of technology. The use of GenAI, along with Geographic Information Science and Technology (GIS&T) and Smart Cities concepts and tools, is being discussed. It presents some points to consider when designing, developing, and implementing GenAI-based applications for urban space analysis.",
    "doi": "10.1007/978-3-031-77290-0_13",
    "author_keywords": [
      "Generative Artificial Intelligence",
      "GIS",
      "Smart Cities"
    ],
    "contribution": "This paper explores the potential of Generative Artificial Intelligence (GenAI) to address urban challenges through geospatial analysis. We cover various GenAI models used in urban contexts, such as Generative Adversarial Networks (GAN), Variational Autoencoders (VAEs), Transformer-based models (or General Pre-trained Transformer), Large Language Models (LLMs), and Generative Diffusion models. The paper explains how GenAI can be used for urban analysis applications from an information management perspective. It presents examples of the operations that can be achieved. Additionally, it describes studies related to energy and resource management, urban planning, natural disaster management, and traffic management, demonstrating the advantages of applying this type of technology. The use of GenAI, along with Geographic Information Science and Technology (GIS&T) and Smart Cities concepts and tools, is being discussed. It presents some points to consider when designing, developing, and implementing GenAI-based applications for urban space analysis.",
    "introduction": "Urban areas face various challenges, including urban planning, waste management, pollution, public safety, and other issues. Information technologies and artificial intelligence have proven helpful in addressing these problems.",
    "macro_domains": []
  },
  {
    "abstract": "One of the main risks to the security and stability of Internet of Things (IoT) networks in smart cities is botnet assaults. The identification of complex and emerging botnet attacks has not been entirely contained by traditional methods of botnet detection. In this study, we present a new hybrid approach, called GNN-WGAN, to efficiently detect bots in IoT-based smart city networks by integrating Graph Neural Network and Wasserstein Generative Adversarial Network. The suggested method, which ultimately aims to improve the precision and robustness against botnet detection in dynamic IoT networks, effectively uses WGANs to generate synthetic botnet traffic patterns to add more training data and GNNs to capture dependencies between and interactions across network topology. The experimental results demonstrate the effectiveness of the GNN-WGAN technique in accurately recognizing botnet activities, which enhances the security and resilience of IoT networks in smart cities.",
    "doi": "10.1109/ICCCNT61001.2024.10724763",
    "author_keywords": [
      "Cyber Attacks",
      "Graph Neural Networks",
      "Internet of Things",
      "Smart Cities",
      "Wasserstein Generative Adversarial Networks"
    ],
    "contribution": "In this study, we present a new hybrid approach, called GNN-WGAN, to efficiently detect bots in IoT-based smart city networks by integrating Graph Neural Network and Wasserstein Generative Adversarial Network. The suggested method, which ultimately aims to improve the precision and robustness against botnet detection in dynamic IoT networks, effectively uses WGANs to generate synthetic botnet traffic patterns to add more training data and GNNs to capture dependencies between and interactions across network topology. The experimental results demonstrate the effectiveness of the GNN-WGAN technique in accurately recognizing botnet activities, which enhances the security and resilience of IoT networks in smart cities.",
    "introduction": "One of the main risks to the security and stability of Internet of Things (IoT) networks in smart cities is botnet assaults. The identification of complex and emerging botnet attacks has not been entirely contained by traditional methods of botnet detection.",
    "macro_domains": []
  },
  {
    "abstract": "Technology enhances the economic growth and development of a nation, and the 21st century is festooned with advanced technologies that make transactions and communication between government and its citizens, and between countries, easy. The use of technology, therefore, is a defining attribute of smart cities (Cairo, Algiers, Nairobi, Lagos, and Tunis, amongst others) across Africa. The technological impact of these cities has permeated the other aspects of life in the areas of e-government, e-education, e-commerce, e-communication, and e-advertisement, amongst others. With this, citizens also openly access data records and actively participate in public affairs. Despite the ample benefits of the use of technology, some citizens see technology as an avenue to carry out heinous cybercrimes such as fake news, internet fraud, and cyberbullying, amongst others. As such, our lead questions are: What impact do smart cities have on African digital space and the global economy? How best can the challenges confronting smart cities in Africa be dealt with? Where is the place of Africa in the 21st-century technological world? In this chapter, we adopt a qualitative method to bolster our argument that smart cities in Africa have progressed over the years and positively influenced African digital space and beyond. We also argue for generative artificial intelligence as an empowering tool in boosting smart cities in Africa and as a problem-solving tool for the likely challenges of smart governance of which African Luddite attitude towards technology is included.",
    "doi": "10.1201/9781003497189-8",
    "author_keywords": null,
    "contribution": "In this chapter, we adopt a qualitative method to bolster our argument that smart cities in Africa have progressed over the years and positively influenced African digital space and beyond. We also argue for generative artificial intelligence as an empowering tool in boosting smart cities in Africa and as a problem-solving tool for the likely challenges of smart governance of which African Luddite attitude towards technology is included.",
    "introduction": "Technology enhances the economic growth and development of a nation, and the 21st century is festooned with advanced technologies that make transactions and communication between government and its citizens, and between countries, easy. The use of technology, therefore, is a defining attribute of smart cities (Cairo, Algiers, Nairobi, Lagos, and Tunis, amongst others) across Africa. The technological impact of these cities has permeated the other aspects of life in the areas of e-government, e-education, e-commerce, e-communication, and e-advertisement, amongst others. With this, citizens also openly access data records and actively participate in public affairs. Despite the ample benefits of the use of technology, some citizens see technology as an avenue to carry out heinous cybercrimes such as fake news, internet fraud, and cyberbullying, amongst others. As such, our lead questions are: What impact do smart cities have on African digital space and the global economy? How best can the challenges confronting smart cities in Africa be dealt with? Where is the place of Africa in the 21st-century technological world?",
    "macro_domains": []
  },
  {
    "abstract": "The emergence of intelligent networks has revolutionized the use of machine learning (ML), allowing it to be applied in various domains of human life. This literature review paper provides in-depth analysis of the existing research on data poisoning attacks and examines how intelligent networks can mitigate these threats. Specifically, the author explores how malicious users inject fake training data into adversarial networks, a technique known as a data poisoning attack, which can severely compromise the modelâ€™s integrity. Through a comparative evaluation of the attack strategies and defense mechanisms, such as robust optimization and model-based detection, the author assesses the strengths and limitations of current defenses. Real-world applications are discussed, including the use of these networks in cybersecurity, healthcare, and smart city systems. The author concludes by outlining the challenges and future directions in developing more effective defense strategies to detect and mitigate data poisoning attacks in real time, ensuring the security and privacy of intelligent networks.",
    "doi": "10.4018/IJDWM.358335",
    "author_keywords": [
      "Adversarial Machine Learning",
      "Data Poisoning Attack",
      "Defense Strategies",
      "Emerging Security Challenges",
      "Security Threats"
    ],
    "contribution": "",
    "introduction": "The emergence of intelligent networks has revolutionized the use of machine learning (ML), allowing it to be applied in various domains of human life. This literature review paper provides in-depth analysis of the existing research on data poisoning attacks and examines how intelligent networks can mitigate these threats. Specifically, the author explores how malicious users inject fake training data into adversarial networks, a technique known as a data poisoning attack, which can severely compromise the modelâ€™s integrity. Through a comparative evaluation of the attack strategies and defense mechanisms, such as robust optimization and model-based detection, the author assesses the strengths and limitations of current defenses. Real-world applications are discussed, including the use of these networks in cybersecurity, healthcare, and smart city systems. The author concludes by outlining the challenges and future directions in developing more effective defense strategies to detect and mitigate data poisoning attacks in real time, ensuring the security and privacy of intelligent networks.",
    "macro_domains": []
  },
  {
    "abstract": "Biometric authentication systems are increasingly needed across a broad range of applications including in smart city environments (e.g., entering hotels), and in smart home environments (e.g., controlling smart devices). Traditional methods, such as face-based and fingerprint-based authentication, usually incur high costs to be installed in all this kind of environments. In this paper, we develop a ubiquitous low-effort user authentication approach, mmPalm, based on palm recognition using millimeter wave (mmWave) signals. mmWave technology has been adopted by WiGig and 5G, making mmPalm a low-cost solution that can be widely adopted in public places. In addition, the high resolution of mmWave signals allows mmPalm to extract detailed palm characteristics (e.g., palm geometry, skin thickness, and texture) that can assemble distinctive palmprints for user authentication. Our innovative virtual antennas design further increases the spatial resolution of a commercial mmWave device, enabling it to fully capture the comprehensive palmprint features. Moreover, to address the challenge of small-scale environmental changes (e.g., variations in palm-device distances and palm orientations), we design a novel palm profile augmentation method, utilizing a Conditional Generative Adversarial Network (cGAN) to generate synthetic palm profiles for mitigating palm instability. Furthermore, we design a cross-environment adaptation framework based on transfer learning to address the challenge of large-scale environmental changes, including multipath variations introduced by human bodies and nearby furniture. Extensive experiments with 30 participants through 6 months demonstrate that mmPalm achieves 99% authentication accuracy with resilience against different types of attacks, including random, impersonation, and counterfeit.",
    "doi": "10.1109/CNS62487.2024.10735583",
    "author_keywords": null,
    "contribution": "In this paper, we develop a ubiquitous low-effort user authentication approach, mmPalm, based on palm recognition using millimeter wave (mmWave) signals. mmWave technology has been adopted by WiGig and 5G, making mmPalm a low-cost solution that can be widely adopted in public places. In addition, the high resolution of mmWave signals allows mmPalm to extract detailed palm characteristics (e.g., palm geometry, skin thickness, and texture) that can assemble distinctive palmprints for user authentication. Our innovative virtual antennas design further increases the spatial resolution of a commercial mmWave device, enabling it to fully capture the comprehensive palmprint features. Moreover, to address the challenge of small-scale environmental changes (e.g., variations in palm-device distances and palm orientations), we design a novel palm profile augmentation method, utilizing a Conditional Generative Adversarial Network (cGAN) to generate synthetic palm profiles for mitigating palm instability. Furthermore, we design a cross-environment adaptation framework based on transfer learning to address the challenge of large-scale environmental changes, including multipath variations introduced by human bodies and nearby furniture. Extensive experiments with 30 participants through 6 months demonstrate that mmPalm achieves 99% authentication accuracy with resilience against different types of attacks, including random, impersonation, and counterfeit.",
    "introduction": "Biometric authentication systems are increasingly needed across a broad range of applications including in smart city environments (e.g., entering hotels), and in smart home environments (e.g., controlling smart devices). Traditional methods, such as face-based and fingerprint-based authentication, usually incur high costs to be installed in all this kind of environments.",
    "macro_domains": []
  },
  {
    "abstract": "Ensuring effective object tracking within Intelligent Transportation Systems (ITS) in smart cities is pivotal for enhancing urban mobility and sustainability. However, challenges arise, particularly in scenarios with occlusions and adverse weather conditions, where traditional methods may fall short in ensuring safety. To address these challenges, a novel track-by-detection approach is introduced aimed at enhancing transportation systems. The approach integrates key components, including the Detection Transformer (DETR) for emphasizing global context, and the You Only Look Once version 7 (YOLOv7) renowned for capturing local context. Additionally, the deep sort tracking filter is incorporated to enhance object tracking accuracy. A pivotal aspect of the approach lies in the utilization of the deep sort of filter for object tracking, preceded by preprocessing with the Principal Component Analysis (PCA) method to refine tracking outcomes. This buffering approach significantly improves tracking quality by reducing noise and enhancing feature representation. Moreover, the approach leverages tracking from satellite videos, enabling comprehensive monitoring of transportation activities across vast regions. The refined tracking outputs, including those from satellite videos, are fused with direct outputs from the trackers obtained from both YOLOv7 and DETR. These integrated fused buffered tracked bounding boxes demonstrate superior performance compared to individual approaches. Validation using simulated imagery under cloudy conditions, incorporating the Motion Evaluation Metric (MOT), showcases enhanced accuracy across various transportation objects. Implementing this approach in ITS promise's benefits such as enhanced traffic management and increased efficiency in public transportation. This underscores the role of Artificial Intelligence (AI) in revolutionizing smart city mobility.",
    "doi": "10.1109/SM63044.2024.10733409",
    "author_keywords": [
      "Intelligent Transportation System",
      "Object tracking",
      "Satellite Videos",
      "Smart City"
    ],
    "contribution": "Implementing this approach in ITS promise's benefits such as enhanced traffic management and increased efficiency in public transportation. This underscores the role of Artificial Intelligence (AI) in revolutionizing smart city mobility.",
    "introduction": "Ensuring effective object tracking within Intelligent Transportation Systems (ITS) in smart cities is pivotal for enhancing urban mobility and sustainability. However, challenges arise, particularly in scenarios with occlusions and adverse weather conditions, where traditional methods may fall short in ensuring safety. To address these challenges, a novel track-by-detection approach is introduced aimed at enhancing transportation systems. The approach integrates key components, including the Detection Transformer (DETR) for emphasizing global context, and the You Only Look Once version 7 (YOLOv7) renowned for capturing local context. Additionally, the deep sort tracking filter is incorporated to enhance object tracking accuracy. A pivotal aspect of the approach lies in the utilization of the deep sort of filter for object tracking, preceded by preprocessing with the Principal Component Analysis (PCA) method to refine tracking outcomes. This buffering approach significantly improves tracking quality by reducing noise and enhancing feature representation. Moreover, the approach leverages tracking from satellite videos, enabling comprehensive monitoring of transportation activities across vast regions. The refined tracking outputs, including those from satellite videos, are fused with direct outputs from the trackers obtained from both YOLOv7 and DETR. These integrated fused buffered tracked bounding boxes demonstrate superior performance compared to individual approaches. Validation using simulated imagery under cloudy conditions, incorporating the Motion Evaluation Metric (MOT), showcases enhanced accuracy across various transportation objects.",
    "macro_domains": []
  },
  {
    "abstract": "Building type information indicates the functional properties of buildings and plays a crucial role in smart city development and urban socio-economic activities. Existing methods for classifying building types often face challenges in accurately distinguishing buildings between types while maintaining well-delineated boundaries, especially in complex urban environments. This study introduces a novel framework, i.e., CNN-Transformer cross-attention feature fusion network (CTCFNet), for building type classification from very-high-resolution remote sensing images. CTCFNet integrates CNNs and Transformers using an interactive cross-encoder fusion (ICEF) module that enhances semantic feature learning and improves classification accuracy in complex scenarios. We develop an adaptive collaboration optimization (ACO) module that applies human visual attention mechanisms to enhance the feature representation of building types and boundaries simultaneously. To address the scarcity of datasets in building type classification, we create two new datasets: the urban building type (UBT) dataset and the town building type (TBT) dataset, for model evaluation. Extensive experiments on these datasets demonstrate that CTCFNet outperforms popular CNNs, Transformers, and dual-encoder methods in identifying building types across various regions, achieving the highest MIoU of 78.20% and 77.11%, F1 scores of 86.83% and 88.22%, and OA of 95.07% and 95.73% on the UBT and TBT datasets, respectively. We conclude that CTCFNet effectively addresses the challenges of high interclass similarity and intraclass inconsistency in complex scenes, yielding results with well-delineated building boundaries and accurate building types. The codes and datasets in this article are accessible at https://github.com/zsfaff/CTCFNet.",
    "doi": "10.1109/JSTARS.2024.3501678",
    "author_keywords": [
      "Building type classification",
      "CNN- transformer networks",
      "cross-encoder",
      "feature interaction",
      "very-high-resolution remote sensing"
    ],
    "contribution": "This study introduces a novel framework, i.e., CNN-Transformer cross-attention feature fusion network (CTCFNet), for building type classification from very-high-resolution remote sensing images. CTCFNet integrates CNNs and Transformers using an interactive cross-encoder fusion (ICEF) module that enhances semantic feature learning and improves classification accuracy in complex scenarios. We develop an adaptive collaboration optimization (ACO) module that applies human visual attention mechanisms to enhance the feature representation of building types and boundaries simultaneously. To address the scarcity of datasets in building type classification, we create two new datasets: the urban building type (UBT) dataset and the town building type (TBT) dataset, for model evaluation. Extensive experiments on these datasets demonstrate that CTCFNet outperforms popular CNNs, Transformers, and dual-encoder methods in identifying building types across various regions, achieving the highest MIoU of 78.20% and 77.11%, F1 scores of 86.83% and 88.22%, and OA of 95.07% and 95.73% on the UBT and TBT datasets, respectively. We conclude that CTCFNet effectively addresses the challenges of high interclass similarity and intraclass inconsistency in complex scenes, yielding results with well-delineated building boundaries and accurate building types. The codes and datasets in this article are accessible at https://github.com/zsfaff/CTCFNet.",
    "introduction": "Building type information indicates the functional properties of buildings and plays a crucial role in smart city development and urban socio-economic activities. Existing methods for classifying building types often face challenges in accurately distinguishing buildings between types while maintaining well-delineated boundaries, especially in complex urban environments.",
    "macro_domains": []
  },
  {
    "abstract": "Preserving the value of buildings and ensuring performance levels within acceptable parameters throughout their lifespan necessitates constant monitoring. In recent years, artificial intelligence has provided a valuable supplement to conventional inspection practices, potentially offering a supporting tool for building maintenance in smart cities. Exploiting machine learning algorithms for detecting or classifying building facade defects from acquired images has emerged as a promising automatic building monitoring strategy. However, an effective approach should be capable of accurately classifying fine-grained defects, thus requiring ad-hoc solutions to maximize predictive accuracy. For this reason, in this work, we introduced a novel and effective classification protocol, based on different ensemble strategies of complex and recent deep neural networks, namely Vision Transformers and ConvNexts, for building facade defects automatic classification. First, we validated our method on a popular benchmark dataset with different damage classification tasks, outperforming the state-of-the-art available works. Then, we analyzed a custom dataset, named Facade Building Defects (FBD), containing building facade images labeled into four different defect classes, that we introduced in this work and released as open access. The proposed ensemble showed a test accuracy of 90.9%, achieving an improvement of 1.6% with respect to the best single model, thus empirically proving the benefit of model ensembling for the task of automatic building facade defects classification.",
    "doi": "10.1109/ACCESS.2024.3494550",
    "author_keywords": [
      "building facade defects classification",
      "Building monitoring",
      "deep learning",
      "ensemble of deep neural networks",
      "vision transformers"
    ],
    "contribution": "For this reason, in this work, we introduced a novel and effective classification protocol, based on different ensemble strategies of complex and recent deep neural networks, namely Vision Transformers and ConvNexts, for building facade defects automatic classification. First, we validated our method on a popular benchmark dataset with different damage classification tasks, outperforming the state-of-the-art available works. Then, we analyzed a custom dataset, named Facade Building Defects (FBD), containing building facade images labeled into four different defect classes, that we introduced in this work and released as open access. The proposed ensemble showed a test accuracy of 90.9%, achieving an improvement of 1.6% with respect to the best single model, thus empirically proving the benefit of model ensembling for the task of automatic building facade defects classification.",
    "introduction": "Preserving the value of buildings and ensuring performance levels within acceptable parameters throughout their lifespan necessitates constant monitoring. In recent years, artificial intelligence has provided a valuable supplement to conventional inspection practices, potentially offering a supporting tool for building maintenance in smart cities. Exploiting machine learning algorithms for detecting or classifying building facade defects from acquired images has emerged as a promising automatic building monitoring strategy. However, an effective approach should be capable of accurately classifying fine-grained defects, thus requiring ad-hoc solutions to maximize predictive accuracy.",
    "macro_domains": []
  },
  {
    "abstract": "When it comes to smart healthcare business systems, network-based intrusion detection systems are crucial for protecting the system and its networks from malicious network assaults. To protect IoMT devices and networks in healthcare and medical settings, our proposed model serves as a powerful tool for monitoring IoMT networks. This study presents a robust methodology for intrusion detection in Internet of Medical Things (IoMT) environments, integrating data augmentation, feature selection, and ensemble learning to effectively handle IoMT data complexity. Following rigorous preprocessing, including feature extraction, correlation removal, and Recursive Feature Elimination (RFE), selected features are standardized and reshaped for deep learning models. Augmentation using the BAT algorithm enhances dataset variability. Three deep learning models, Transformer-based neural networks, self-attention Deep Convolutional Neural Networks (DCNNs), and Long Short-Term Memory (LSTM) networks, are trained to capture diverse data aspects. Their predictions form a meta-feature set for a subsequent meta-learner, which combines model strengths. Conventional classifiers validate meta-learner features for broad algorithm suitability. This comprehensive method demonstrates high accuracy and robustness in IoMT intrusion detection. Evaluations were conducted using two datasets: the publicly available WUSTL-EHMS-2020 dataset, which contains two distinct categories, and the CICIoMT2024 dataset, encompassing sixteen categories. Experimental results showcase the methodâ€™s exceptional performance, achieving optimal scores of 100% on the WUSTL-EHMS-2020 dataset and 99% on the CICIoMT2024.",
    "doi": "10.32604/cmes.2024.056308",
    "author_keywords": [
      "BAT augmentation",
      "Cyberattack",
      "ensemble learning",
      "feature selection",
      "intrusion detection",
      "machine learning",
      "smart cities"
    ],
    "contribution": "This study presents a robust methodology for intrusion detection in Internet of Medical Things (IoMT) environments, integrating data augmentation, feature selection, and ensemble learning to effectively handle IoMT data complexity. Following rigorous preprocessing, including feature extraction, correlation removal, and Recursive Feature Elimination (RFE), selected features are standardized and reshaped for deep learning models. Augmentation using the BAT algorithm enhances dataset variability. Three deep learning models, Transformer-based neural networks, self-attention Deep Convolutional Neural Networks (DCNNs), and Long Short-Term Memory (LSTM) networks, are trained to capture diverse data aspects. Their predictions form a meta-feature set for a subsequent meta-learner, which combines model strengths. Conventional classifiers validate meta-learner features for broad algorithm suitability. This comprehensive method demonstrates high accuracy and robustness in IoMT intrusion detection. Evaluations were conducted using two datasets: the publicly available WUSTL-EHMS-2020 dataset, which contains two distinct categories, and the CICIoMT2024 dataset, encompassing sixteen categories. Experimental results showcase the methodâ€™s exceptional performance, achieving optimal scores of 100% on the WUSTL-EHMS-2020 dataset and 99% on the CICIoMT2024.",
    "introduction": "When it comes to smart healthcare business systems, network-based intrusion detection systems are crucial for protecting the system and its networks from malicious network assaults. To protect IoMT devices and networks in healthcare and medical settings, our proposed model serves as a powerful tool for monitoring IoMT networks.",
    "macro_domains": []
  },
  {
    "abstract": "Most people on our planet increasingly live in cities and towns. For those who plan, design, deliver, and manage the built environment, they have become prime sites of creativity and production, real and virtual. In practice, architects and designers working in urban environments do so in three core contexts. The continuing evolution of the cityâ€™s physical fabric, core supporting networks, and planning and zoning frameworks. Changing environmental policies and shifting public priorities. Revolution in technology, digital networks, devices, and data-driven enterprises and services. In identifying these three contexts, we do not suggest that the potential of all is being fully realized or that interactions and integrations between them are fully explored. Instead, this chapter contends that Architecture and design have not always fully exploited the possibilities of the digital toolkit. Smart City initiatives have not been systematically pursued by as many cities as first envisaged. Opportunities for integration of smart buildings, smart precincts, and smart green infrastructure with Smart City systems and data-driven city governance have been implemented patchily. The arrival of Artificial Intelligence (AI), particularly generative AI, into city design, infrastructure, and management systems has resulted in a new combination that is being termed â€˜Urban AIâ€™ (Luusua et al., 2023). We suggest progress toward realizing Smart City objectives has been uneven and modest, particularly in cities of â€˜the West.' This will have implications for tech adoption and future professional practice in built environments.",
    "doi": "10.4324/9781003384113-20",
    "author_keywords": null,
    "contribution": "Instead, this chapter contends that Architecture and design have not always fully exploited the possibilities of the digital toolkit. Smart City initiatives have not been systematically pursued by as many cities as first envisaged. Opportunities for integration of smart buildings, smart precincts, and smart green infrastructure with Smart City systems and data-driven city governance have been implemented patchily. The arrival of Artificial Intelligence (AI), particularly generative AI, into city design, infrastructure, and management systems has resulted in a new combination that is being termed â€˜Urban AIâ€™ (Luusua et al., 2023). We suggest progress toward realizing Smart City objectives has been uneven and modest, particularly in cities of â€˜the West.' This will have implications for tech adoption and future professional practice in built environments.",
    "introduction": "Most people on our planet increasingly live in cities and towns. For those who plan, design, deliver, and manage the built environment, they have become prime sites of creativity and production, real and virtual. In practice, architects and designers working in urban environments do so in three core contexts. The continuing evolution of the cityâ€™s physical fabric, core supporting networks, and planning and zoning frameworks. Changing environmental policies and shifting public priorities. Revolution in technology, digital networks, devices, and data-driven enterprises and services. In identifying these three contexts, we do not suggest that the potential of all is being fully realized or that interactions and integrations between them are fully explored.",
    "macro_domains": []
  },
  {
    "abstract": "Recent cybersecurity research is shifting to favor adversarial attacks, which are harder to detect and counteract, as they are not apparent, and they exploit the vulnerability of the deployed machine learning model. With machine learning seeing wider adoption to forecast the electricity load in smart cities to help maintain grid stability and better integrate with renewable energies, the energy sector is at risk. Although several methods exist to mitigate the problem, adversarial training fails against the attack that utilizes a surrogate model. In addition, it cannot differentiate between the original and adversarial data without relying on adversarial detection. Furthermore, existing detections do not correct the data to keep the forecast running. In this paper, the Multivariable Convolutional Encoder implementation in a Trusted Input Framework was proposed, which utilizes hidden input data with a high correlation to act as a trap when creating the surrogate model, measuring the attack intensity, and improve the accuracy to 'correct' and 'forecast' on the target data. In the experiment, the proposed method not only fooled the surrogate but also achieved a coefficient of determination score of 0.9183 on the most robust Projected Gradient Descent-based adversarial attack, which is 13.933% better than the adversarial training.",
    "doi": "10.1109/ICFTSS61109.2024.10690268",
    "author_keywords": [
      "Cyberattack",
      "Forecast",
      "Smart Grids"
    ],
    "contribution": "In this paper, the Multivariable Convolutional Encoder implementation in a Trusted Input Framework was proposed, which utilizes hidden input data with a high correlation to act as a trap when creating the surrogate model, measuring the attack intensity, and improve the accuracy to 'correct' and 'forecast' on the target data. In the experiment, the proposed method not only fooled the surrogate but also achieved a coefficient of determination score of 0.9183 on the most robust Projected Gradient Descent-based adversarial attack, which is 13.933% better than the adversarial training.",
    "introduction": "Recent cybersecurity research is shifting to favor adversarial attacks, which are harder to detect and counteract, as they are not apparent, and they exploit the vulnerability of the deployed machine learning model. With machine learning seeing wider adoption to forecast the electricity load in smart cities to help maintain grid stability and better integrate with renewable energies, the energy sector is at risk. Although several methods exist to mitigate the problem, adversarial training fails against the attack that utilizes a surrogate model. In addition, it cannot differentiate between the original and adversarial data without relying on adversarial detection. Furthermore, existing detections do not correct the data to keep the forecast running.",
    "macro_domains": []
  },
  {
    "abstract": "A city's economic growth is heavily influenced by its transport infrastructure, since the demand to move workers, customers, and goods is on the rise. Intelligent transport systems (ITS) are an integral part of the smart cities project. These systems use state-of-the-art technology to solve traffic problems. There are a lot of ITS solutions in use all over the world right now. The approach consists of three phases, which are feature selection, feature extraction, and model training. The goal of feature selection in smart cities is to identify relevant qualities and exclude those that aren't essential in order to collect data that correctly represents the problem at hand while reducing inefficiencies. A variant of principal component analysis (PCA) that has gained favor in feature extraction, kernel-PCA allows one to understand nonlinearities in data. A KNN-TACGAN was used for the model's training. Compared to KNN and TACGAN, the proposed technique has a better average accuracy of 92.47%.",
    "doi": "10.1109/ICDSNS62112.2024.10690988",
    "author_keywords": [
      "smart cities",
      "tabular auxiliary classifier generative adversarial networks model (TACGAN)",
      "traffic surveillance and management"
    ],
    "contribution": "",
    "introduction": "A city's economic growth is heavily influenced by its transport infrastructure, since the demand to move workers, customers, and goods is on the rise. Intelligent transport systems (ITS) are an integral part of the smart cities project. These systems use state-of-the-art technology to solve traffic problems. There are a lot of ITS solutions in use all over the world right now. The approach consists of three phases, which are feature selection, feature extraction, and model training. The goal of feature selection in smart cities is to identify relevant qualities and exclude those that aren't essential in order to collect data that correctly represents the problem at hand while reducing inefficiencies. A variant of principal component analysis (PCA) that has gained favor in feature extraction, kernel-PCA allows one to understand nonlinearities in data. A KNN-TACGAN was used for the model's training. Compared to KNN and TACGAN, the proposed technique has a better average accuracy of 92.47%.",
    "macro_domains": []
  },
  {
    "abstract": "With the development of large language models, these technologies show tremendous potential in various areas of smart cities, particularly in enhancing urban services and residents' quality of life. There is an increasing acceptance among the public for highly interactive virtual entities. Leveraging large language models and speech synthesis technology has not only garnered attention in the entertainment industry but also holds great promise across various facets of smart cities. This study aims to integrate advanced language understanding and speech synthesis technologies to provide residents and visitors in smart cities with a more natural and interactive experience, ultimately contributing to the thriving development of smart cities in the consumer market.",
    "doi": "10.1109/ICCE-Taiwan62264.2024.10674564",
    "author_keywords": null,
    "contribution": "This study aims to integrate advanced language understanding and speech synthesis technologies to provide residents and visitors in smart cities with a more natural and interactive experience, ultimately contributing to the thriving development of smart cities in the consumer market.",
    "introduction": "With the development of large language models, these technologies show tremendous potential in various areas of smart cities, particularly in enhancing urban services and residents' quality of life. There is an increasing acceptance among the public for highly interactive virtual entities. Leveraging large language models and speech synthesis technology has not only garnered attention in the entertainment industry but also holds great promise across various facets of smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Deep learning, a cornerstone of artificial intelligence (AI), has revolutionized a number of fields, including self-driving cars, image recognition, and intelligent medical applications. These developments have aided in the development of smart cities. That being said, new findings have shown that deep neural networks are susceptible to hostile attacks on security-critical tasks. This research paper investigates the related defensive strategies and explores the crucial problem of adversarial intrusions in deep learning. It draws attention to the adversarial attacks that deep neural networks are susceptible to, especially in high-security applications like network intrusion detection systems and radiofrequency identification. This paper presents the idea of adversarial intrusions, looks at their theoretical underpinnings, and evaluates how they affect different kinds of data, such as text, graphs, and images. The field of cybersecurity is given special attention, with attacks being categorized using adversarial examples and defensive measures being discussed. Additionally, the study introduces FIAT, a novel adversarial defense strategy based on feature-level interpretability. This paper intends to stimulate future research endeavors to guarantee the security and resilience of deep learning algorithms in real-world scenarios by offering a thorough overview of adversarial intrusions and defenses in the field of deep learning for Edge AI.",
    "doi": "10.1109/INNOCOMP63224.2024.00059",
    "author_keywords": [
      "Adversarial Attack",
      "Adversarial Defense",
      "Black-Box Attack",
      "Convolutional Neural Network",
      "Deep Learning",
      "Deep Neural Network (DNN)",
      "Feature-Level Interpretability",
      "Network Intrusion Detection",
      "Radiofrequency Fingerprinting Identification",
      "Robustness",
      "White-Box Attack"
    ],
    "contribution": "This research paper investigates the related defensive strategies and explores the crucial problem of adversarial intrusions in deep learning. It draws attention to the adversarial attacks that deep neural networks are susceptible to, especially in high-security applications like network intrusion detection systems and radiofrequency identification. This paper presents the idea of adversarial intrusions, looks at their theoretical underpinnings, and evaluates how they affect different kinds of data, such as text, graphs, and images. The field of cybersecurity is given special attention, with attacks being categorized using adversarial examples and defensive measures being discussed. Additionally, the study introduces FIAT, a novel adversarial defense strategy based on feature-level interpretability. This paper intends to stimulate future research endeavors to guarantee the security and resilience of deep learning algorithms in real-world scenarios by offering a thorough overview of adversarial intrusions and defenses in the field of deep learning for Edge AI.",
    "introduction": "Deep learning, a cornerstone of artificial intelligence (AI), has revolutionized a number of fields, including self-driving cars, image recognition, and intelligent medical applications. These developments have aided in the development of smart cities. That being said, new findings have shown that deep neural networks are susceptible to hostile attacks on security-critical tasks.",
    "macro_domains": []
  },
  {
    "abstract": "Urbanization presents formidable challenges to global urban transportation systems, accentuating safety concerns amidst burgeoning vehicular traffic. Commercial vehicles, owing to their prevalence and size, significantly contribute to congestion and accidents. Statistics from authoritative bodies such as Malaysia Highway Authority (LLM) underscore this severity, with large trucks notably implicated in a significant share of traffic fatalities. Asia, among rapid urbanization, grapples with heightened road safety issues, as emphasized by the World Health Organization (WHO). The alarming statistics reveal substantial involvement of commercial vehicles in traffic-related fatalities, necessitating urgent innovative interventions. In response, this research advocates for the Smart Urban Vehicular Traffic Management System, harnessing automatic control and intelligent systems integrated with Artificial Intelligence of Things (AIoT) in a cloud computing environment to boost safety and efficiency in commercial vehicle operations. Addressing challenges inherent in the traditional cloud computing paradigm, particularly with the increasing AIoT devices, we propose an edge-cloud architecture. Leveraging by the federated learning techniques, this architecture ensures privacy while optimizing service quality for AIoT devices essential to commercial vehicle management. Central to this proposal is the pursuit of scalability and adaptability, promising transformative impacts on urban traffic safety. Through meticulous analysis, this research underscores the imperative for innovative transportation management solutions, with proposed applications extending to the development of smart sensor devices for data-driven urban road traffic bans management, signalling a paradigm shift towards smarter cities.",
    "doi": "10.1109/ISCI62787.2024.10668243",
    "author_keywords": [
      "Cloud computing",
      "Commercial transportation road-banning",
      "Edge-cloud computing",
      "Smart Cities",
      "Vehicular management system"
    ],
    "contribution": "In response, this research advocates for the Smart Urban Vehicular Traffic Management System, harnessing automatic control and intelligent systems integrated with Artificial Intelligence of Things (AIoT) in a cloud computing environment to boost safety and efficiency in commercial vehicle operations. Addressing challenges inherent in the traditional cloud computing paradigm, particularly with the increasing AIoT devices, we propose an edge-cloud architecture. Leveraging by the federated learning techniques, this architecture ensures privacy while optimizing service quality for AIoT devices essential to commercial vehicle management. Central to this proposal is the pursuit of scalability and adaptability, promising transformative impacts on urban traffic safety. Through meticulous analysis, this research underscores the imperative for innovative transportation management solutions, with proposed applications extending to the development of smart sensor devices for data-driven urban road traffic bans management, signalling a paradigm shift towards smarter cities.",
    "introduction": "Urbanization presents formidable challenges to global urban transportation systems, accentuating safety concerns amidst burgeoning vehicular traffic. Commercial vehicles, owing to their prevalence and size, significantly contribute to congestion and accidents. Statistics from authoritative bodies such as Malaysia Highway Authority (LLM) underscore this severity, with large trucks notably implicated in a significant share of traffic fatalities. Asia, among rapid urbanization, grapples with heightened road safety issues, as emphasized by the World Health Organization (WHO). The alarming statistics reveal substantial involvement of commercial vehicles in traffic-related fatalities, necessitating urgent innovative interventions.",
    "macro_domains": []
  },
  {
    "abstract": "As wireless communication technology progresses towards the sixth generation (6G), high-frequency millimeter-wave (mmWave) communication has emerged as a promising candidate for enabling vehicular networks. It offers high data rates and low-latency communication. However, obstacles such as buildings, trees, and other vehicles can cause signal attenuation and blockage, leading to communication failures that can result in fatal accidents or traffic congestion. Predicting blockages is crucial for ensuring reliable and efficient communications. Furthermore, the advent of 6G technology is anticipated to integrate advanced sensing capabilities, utilizing a variety of sensor types. These sensors, ranging from traditional RF sensors to cameras and Lidar sensors, are expected to provide access to rich multimodal data, thereby enriching communication systems with a wealth of additional contextual information. Leveraging this multimodal data becomes essential for making precise network management decisions, including the crucial task of blockage detection. In this paper, we propose a Deep Learning (DL)-based approach that combines Convolutional Neural Networks (CNNs) and customized Vision Transformers (ViTs) to effectively extract essential information from multimodal data and predict blockages in vehicular networks. We train and evaluate our proposed method on the DL dataset framework for vision-aided wireless communications (ViWi) and demonstrate its potential for predicting blockages in vehicular networks through simulations. The results show that the proposed approach achieves over 95% accurate predictions, proving its potential for integration into 6G vehicular networks to enhance communication reliability and support advanced applications such as autonomous driving and smart city infrastructure. These findings underscore the practical significance and future impact of our work in advancing ultra-reliable and low-latency communication systems.",
    "doi": "10.1109/ACCESS.2024.3460480",
    "author_keywords": [
      "Computer vision",
      "deep learning",
      "sixth generation (6G)",
      "vehicle-to-everything (V2X) communication"
    ],
    "contribution": "In this paper, we propose a Deep Learning (DL)-based approach that combines Convolutional Neural Networks (CNNs) and customized Vision Transformers (ViTs) to effectively extract essential information from multimodal data and predict blockages in vehicular networks. We train and evaluate our proposed method on the DL dataset framework for vision-aided wireless communications (ViWi) and demonstrate its potential for predicting blockages in vehicular networks through simulations. The results show that the proposed approach achieves over 95% accurate predictions, proving its potential for integration into 6G vehicular networks to enhance communication reliability and support advanced applications such as autonomous driving and smart city infrastructure. These findings underscore the practical significance and future impact of our work in advancing ultra-reliable and low-latency communication systems.",
    "introduction": "As wireless communication technology progresses towards the sixth generation (6G), high-frequency millimeter-wave (mmWave) communication has emerged as a promising candidate for enabling vehicular networks. It offers high data rates and low-latency communication. However, obstacles such as buildings, trees, and other vehicles can cause signal attenuation and blockage, leading to communication failures that can result in fatal accidents or traffic congestion. Predicting blockages is crucial for ensuring reliable and efficient communications. Furthermore, the advent of 6G technology is anticipated to integrate advanced sensing capabilities, utilizing a variety of sensor types. These sensors, ranging from traditional RF sensors to cameras and Lidar sensors, are expected to provide access to rich multimodal data, thereby enriching communication systems with a wealth of additional contextual information. Leveraging this multimodal data becomes essential for making precise network management decisions, including the crucial task of blockage detection.",
    "macro_domains": []
  },
  {
    "abstract": "This book chapter seeks to present a concise introduction and contextualization affecting the topics correlated to the disruptive perspectives of vehicle electrification in modern power grids, welcoming innovative power electronics technologies, and control challenges in support of the power grid interface. As demonstrated in this book chapter, the main objective is to combine in a single book, power electronics technologies and control strategies for vehicle electrification in modern power grids in a future viewpoint, indicating that vehicle electrification is facing challenges, but it is also of added value for the power grid: in terms of power electronics technologies covered aspects such as power charging and traction systems; the interface of the vehicle electrification with renewables and energy storage systems; vehicle electrification operating as power quality conditioners for the power grid; vehicle electrification framed with solid-state transformers and within AC, DC, and hybrid power grids; vehicle electrification in smart homes, smart cities, and smart grids; and advanced topologies of power electronics converters. To deal with the increasing penetration of vehicle electrification, control strategies are also retained: for the power electronics converters; for interfacing renewable energy sources and energy storage systems as support of electric mobility; for operation modes, e.g., innovative modes in addition of vehicle-to-grid; for ensuring power quality and reliability in smart grids; for demand response strategies; and for forecasting strategies.",
    "doi": "10.1016/B978-0-443-13969-7.00001-1",
    "author_keywords": [
      "Control engineering",
      "control systems",
      "electrochemical energy engineering",
      "energy application",
      "energy engineering",
      "energy management",
      "energy resource",
      "energy storage",
      "energy sustainability",
      "energy systems",
      "engineering",
      "EV charging",
      "EV traction systems",
      "operation modes",
      "optimal control theory",
      "power electronics",
      "power engineering",
      "power quality",
      "sensor",
      "smart grids",
      "sustainability engineering",
      "sustainable development",
      "systems engineering",
      "vehicle",
      "vehicle electrification"
    ],
    "contribution": "",
    "introduction": "This book chapter seeks to present a concise introduction and contextualization affecting the topics correlated to the disruptive perspectives of vehicle electrification in modern power grids, welcoming innovative power electronics technologies, and control challenges in support of the power grid interface. As demonstrated in this book chapter, the main objective is to combine in a single book, power electronics technologies and control strategies for vehicle electrification in modern power grids in a future viewpoint, indicating that vehicle electrification is facing challenges, but it is also of added value for the power grid: in terms of power electronics technologies covered aspects such as power charging and traction systems; the interface of the vehicle electrification with renewables and energy storage systems; vehicle electrification operating as power quality conditioners for the power grid; vehicle electrification framed with solid-state transformers and within AC, DC, and hybrid power grids; vehicle electrification in smart homes, smart cities, and smart grids; and advanced topologies of power electronics converters. To deal with the increasing penetration of vehicle electrification, control strategies are also retained: for the power electronics converters; for interfacing renewable energy sources and energy storage systems as support of electric mobility; for operation modes, e.g., innovative modes in addition of vehicle-to-grid; for ensuring power quality and reliability in smart grids; for demand response strategies; and for forecasting strategies.",
    "macro_domains": []
  },
  {
    "abstract": "One of the leading issues in adopting electricity load prediction today is the lack of high-quality and high-resolution real-world datasets. This poses a major problem especially in the context of electricity load prediction where high quality data are essential. To address this issue, this paper presents a framework that transforms datasets with missing values into high quality and high-resolution datasets using Generative Adversarial Networks (GANs). The capability of this framework was exhibited through a case study, the CIC-IPN electricity consumption dataset. Results show that the framework was able to successfully impute the missing values in the dataset while capturing the general patterns in the data. This framework can then be used to upscale other electricity datasets that contain missing values which can then be further used for electricity load prediction for smart cities and smart buildings.",
    "doi": "10.1007/978-3-031-52517-9_13",
    "author_keywords": [
      "Electricity consumption dataset",
      "Generative Adversarial Networks",
      "Missing Data",
      "Upscaling"
    ],
    "contribution": "To address this issue, this paper presents a framework that transforms datasets with missing values into high quality and high-resolution datasets using Generative Adversarial Networks (GANs). The capability of this framework was exhibited through a case study, the CIC-IPN electricity consumption dataset. Results show that the framework was able to successfully impute the missing values in the dataset while capturing the general patterns in the data. This framework can then be used to upscale other electricity datasets that contain missing values which can then be further used for electricity load prediction for smart cities and smart buildings.",
    "introduction": "One of the leading issues in adopting electricity load prediction today is the lack of high-quality and high-resolution real-world datasets. This poses a major problem especially in the context of electricity load prediction where high quality data are essential.",
    "macro_domains": []
  },
  {
    "abstract": "In the context of smart cities, autonomous vehicles, such as unmanned delivery vehicles and taxis are gradually gaining acceptance. However, their application scenarios remain significantly fragmented. Typically, an Autonomous Multi-Functional Vehicle (AMFV) is not engaged in other scenarios when idle in a specific one. Currently, a unified system capable of coordinating and using these resources efficiently is lacking. Moreover, there is an absence of an advanced navigation algorithm for facilitating coordinated navigation among Heterogeneous Vehicles (HVs). To address these issues, we propose the LLM-driven Multi-vehicle Dispatching and navigation (LiMeda) framework. It comprises an LLM-driven scheduling module that facilitates efficient allocation considering task scenarios and vehicle information, which addresses the issue of incompatible vehicle resources across various smart city scenarios. And the other is a navigation module, founded on the Heterogeneous Agent Reinforcement Learning (HARL) framework we previously proposed, which can effectively perform cooperative navigation tasks among heterogeneous agents, assisting the cooperative task completion by HVs in a smart city. Experimental results show our method outperforms both traditional scheduling algorithms and Reinforcement Learning navigation algorithms in metric terms. Additionally, it shows remarkable scalability and generalization under varying city scales, vehicle numbers, and task numbers.",
    "doi": "10.1109/ICRA57147.2024.10610578",
    "author_keywords": null,
    "contribution": "To address these issues, we propose the LLM-driven Multi-vehicle Dispatching and navigation (LiMeda) framework. It comprises an LLM-driven scheduling module that facilitates efficient allocation considering task scenarios and vehicle information, which addresses the issue of incompatible vehicle resources across various smart city scenarios. And the other is a navigation module, founded on the Heterogeneous Agent Reinforcement Learning (HARL) framework we previously proposed, which can effectively perform cooperative navigation tasks among heterogeneous agents, assisting the cooperative task completion by HVs in a smart city. Experimental results show our method outperforms both traditional scheduling algorithms and Reinforcement Learning navigation algorithms in metric terms. Additionally, it shows remarkable scalability and generalization under varying city scales, vehicle numbers, and task numbers.",
    "introduction": "In the context of smart cities, autonomous vehicles, such as unmanned delivery vehicles and taxis are gradually gaining acceptance. However, their application scenarios remain significantly fragmented. Typically, an Autonomous Multi-Functional Vehicle (AMFV) is not engaged in other scenarios when idle in a specific one. Currently, a unified system capable of coordinating and using these resources efficiently is lacking. Moreover, there is an absence of an advanced navigation algorithm for facilitating coordinated navigation among Heterogeneous Vehicles (HVs).",
    "macro_domains": []
  },
  {
    "abstract": "Intelligent Transportation Systems (ITS) play a pivotal role in shaping the foundation of smart cities, providing data-driven solutions for traffic management, prediction, and safety. However, these applications often face a significant challenge - data scarcity. Insufficient data limits the effectiveness of machine learning models in the context of ITS. To address this issue, this paper presents a novel data augmentation solution using Generative Adversarial Networks (GANs). By collecting sensor-based traffic speed data with contextual labels and training a GAN-based model to generate realistic traffic data for specific days and times, this research successfully proposes a solution to the problem of data scarcity. The generated data undergoes comprehensive qualitative and quantitative evaluations, demonstrating its potential to enhance ITS applications. Furthermore, the generated data is utilized to augment the training data for multiple traffic prediction models, effectively enhancing their performance. This approach opens new avenues for the development of intelligent and sustainable transportation systems, ultimately contributing to the advancement of smarter and more resilient cities.",
    "doi": "10.1109/DCOSS-IoT61029.2024.00020",
    "author_keywords": [
      "GAN",
      "Intelligent Transportation Systems",
      "IoT",
      "Machine Learning",
      "Smart Cities",
      "Traffic Prediction",
      "Wasserstein GAN"
    ],
    "contribution": "To address this issue, this paper presents a novel data augmentation solution using Generative Adversarial Networks (GANs). By collecting sensor-based traffic speed data with contextual labels and training a GAN-based model to generate realistic traffic data for specific days and times, this research successfully proposes a solution to the problem of data scarcity. The generated data undergoes comprehensive qualitative and quantitative evaluations, demonstrating its potential to enhance ITS applications. Furthermore, the generated data is utilized to augment the training data for multiple traffic prediction models, effectively enhancing their performance. This approach opens new avenues for the development of intelligent and sustainable transportation systems, ultimately contributing to the advancement of smarter and more resilient cities.",
    "introduction": "Intelligent Transportation Systems (ITS) play a pivotal role in shaping the foundation of smart cities, providing data-driven solutions for traffic management, prediction, and safety. However, these applications often face a significant challenge - data scarcity. Insufficient data limits the effectiveness of machine learning models in the context of ITS.",
    "macro_domains": []
  },
  {
    "abstract": "Intelligent video surveillance systems, automatic entry and retail systems at theme parks, airport passenger flow control, and automated driving behavior analysis are a few applications where critical insights can be generated by detecting and identifying people through a camera network. In different public locations, such as train stations, airports, hospitals, shopping centers, etc., widespread camera networks are used daily, covering vast areas and having non-overlapping perspectives and providing a tremendous amount of relevant data. We cannot rely on manual monitoring to use this data efficiently for public safety applications and thus need reliable automated systems that can track the behavior of a person through several cameras. Person reidentification (PReID) is a simple task for this and plays a vital role in re-identifying persons from video surveillance cameras. In this paper, we leverage the attention-based mechanism to re-identify persons from video surveillance cameras by using the image modality translation and CycleGAN, which served as data augmentation in our proposed network. We outperformed against all measures compared to other state-of-the-art methods.",
    "doi": "10.1007/978-981-97-3682-9_72",
    "author_keywords": [
      "Generative Adversarial Network",
      "Person Reidentification",
      "Smart Cities",
      "Video Surveillance"
    ],
    "contribution": "In this paper, we leverage the attention-based mechanism to re-identify persons from video surveillance cameras by using the image modality translation and CycleGAN, which served as data augmentation in our proposed network. We outperformed against all measures compared to other state-of-the-art methods.",
    "introduction": "Intelligent video surveillance systems, automatic entry and retail systems at theme parks, airport passenger flow control, and automated driving behavior analysis are a few applications where critical insights can be generated by detecting and identifying people through a camera network. In different public locations, such as train stations, airports, hospitals, shopping centers, etc., widespread camera networks are used daily, covering vast areas and having non-overlapping perspectives and providing a tremendous amount of relevant data. We cannot rely on manual monitoring to use this data efficiently for public safety applications and thus need reliable automated systems that can track the behavior of a person through several cameras. Person reidentification (PReID) is a simple task for this and plays a vital role in re-identifying persons from video surveillance cameras.",
    "macro_domains": []
  },
  {
    "abstract": "In recent years, the Internet of Things (IoT) has penetrated all aspects of our lives through smart cities, health, industries and others that are related to people's livelihood. With the increasing number of IoT devices, more and more personal information is exposed in the network space, which inevitably brings some network security problems. Due to the diversity and heterogeneity of IoT devices, identification of such devices in the complex IoT environments remains a major challenge. Existing deep learning-based device identification methods achieve identification of IoT devices by automatically extracting device traffic features, but usually only single modal features of device traffic are considered, which cannot achieve all-around characterization features of communication traffic and affect the identification results. Therefore, we propose an identification method, termed DMRMTT, that employs a Deep convolutional maxout network and MTT model (Multiple Time-series Transformers) to automatically extract the spatial and temporal features of IoT communication session fingerprints and perform further fusion using the structure of the residual, which makes up for the limitations of the existing methods for studying device traffic. This method can improve the characterization of device traffic behaviour and achieve a more accurate identification of IoT devices. Its efficacy is experimentally validated by using two publicly availbale datasets and compared with existing methods. Results show that our method outperforms other methods in widely used performance metrics and achieves 99.82% identification accuracy, demonstrating its superiority and usefulness in IoT device identification.",
    "doi": "10.1109/TSC.2024.3440013",
    "author_keywords": [
      "deep learning",
      "IoT device classification",
      "Maxout network",
      "residual connections",
      "Transformer"
    ],
    "contribution": "Therefore, we propose an identification method, termed DMRMTT, that employs a Deep convolutional maxout network and MTT model (Multiple Time-series Transformers) to automatically extract the spatial and temporal features of IoT communication session fingerprints and perform further fusion using the structure of the residual, which makes up for the limitations of the existing methods for studying device traffic. This method can improve the characterization of device traffic behaviour and achieve a more accurate identification of IoT devices. Its efficacy is experimentally validated by using two publicly availbale datasets and compared with existing methods. Results show that our method outperforms other methods in widely used performance metrics and achieves 99.82% identification accuracy, demonstrating its superiority and usefulness in IoT device identification.",
    "introduction": "In recent years, the Internet of Things (IoT) has penetrated all aspects of our lives through smart cities, health, industries and others that are related to people's livelihood. With the increasing number of IoT devices, more and more personal information is exposed in the network space, which inevitably brings some network security problems. Due to the diversity and heterogeneity of IoT devices, identification of such devices in the complex IoT environments remains a major challenge. Existing deep learning-based device identification methods achieve identification of IoT devices by automatically extracting device traffic features, but usually only single modal features of device traffic are considered, which cannot achieve all-around characterization features of communication traffic and affect the identification results.",
    "macro_domains": []
  },
  {
    "abstract": "With the rapid development of smart cities, the collection of vehicle trajectory data through sensors has increased significantly. While many studies have utilized calibrated physical car-following models (CFM) and machine learning techniques for trajectory prediction, these approaches often falter in complex, dynamic traffic scenarios. Addressing this gap, this paper introduces PS-TrajGAIL, a generative adversarial imitation learning framework tailored for urban vehicle trajectory generation. Contrary to conventional discriminative models, PS-TrajGAIL employs a generative model to capture the inherent distribution of urban vehicle trajectories. This framework models the tasks of trajectory generation as a partially observable Markov decision process based on imitation learning. PS-TrajGAIL's architecture features a generator, which simulates vehicle behavior to produce synthetic trajectories, and a discriminator that distinguishes between authentic and generated trajectories. In addition, the driving policy within the generator is fine-tuned using the Trust Region Policy Optimization (TRPO) algorithm, ensuring safety in vehicle driving. Experimental evaluations on both synthetic and real-world datasets highlight that PS-TrajGAIL notably surpasses existing baselines and state-of-the-art approaches in trajectory generation.",
    "doi": "10.1109/TVT.2024.3437412",
    "author_keywords": [
      "Generative adversarial learning",
      "imitation learning",
      "traffic simulation",
      "trajectory data generation",
      "urban vehicle trajectories"
    ],
    "contribution": "Addressing this gap, this paper introduces PS-TrajGAIL, a generative adversarial imitation learning framework tailored for urban vehicle trajectory generation. Contrary to conventional discriminative models, PS-TrajGAIL employs a generative model to capture the inherent distribution of urban vehicle trajectories. This framework models the tasks of trajectory generation as a partially observable Markov decision process based on imitation learning. PS-TrajGAIL's architecture features a generator, which simulates vehicle behavior to produce synthetic trajectories, and a discriminator that distinguishes between authentic and generated trajectories. In addition, the driving policy within the generator is fine-tuned using the Trust Region Policy Optimization (TRPO) algorithm, ensuring safety in vehicle driving. Experimental evaluations on both synthetic and real-world datasets highlight that PS-TrajGAIL notably surpasses existing baselines and state-of-the-art approaches in trajectory generation.",
    "introduction": "With the rapid development of smart cities, the collection of vehicle trajectory data through sensors has increased significantly. While many studies have utilized calibrated physical car-following models (CFM) and machine learning techniques for trajectory prediction, these approaches often falter in complex, dynamic traffic scenarios.",
    "macro_domains": []
  },
  {
    "abstract": "Due to the growing level of transportation systems, numerous social troubles arise and create serious hazards like air pollution, the greenhouse effect, and traffic congestion. Hence, Traffic forecasting is essential for providing numerous applications in smart city management like congestion avoidance, navigation guidance, and urban traffic control. Still, the traffic prediction is difficult, since each road network is greatly dependent on other networks in a temporally and spatially manner. For capturing the temporal and spatial dependency, the Nonlinear autoregressive models with exogenous inputs (NARX) - Long Short Term Memory (LSTM) Forward Taylor Network (NxLFTN)based traffic forecasting is proposed in this paper. The traffic network is considered as a graph, which contains the spatio-temporal data. The spatio-temporal data is high-dimensional and complex. To embed the data into a low-dimensionality region, the spatio-temporal embedding (STE) generator is employed. Moreover, the STE generator is used for predicting the daily embedding and the weekly embedding of the time related to the present traffic signal. At last, the traffic forecasting is carried out using the NxLFTNet. In addition, the Mean absolute percentage error (MAPE), Root Mean square error (RMSE), and Mean Absolute Error (MAE) are used to validate the effectiveness of the NxLFTNet. It offered the finest MAPE, RMSE, and MAE of 0.003, 0.046, and 0.04 when considering the data from the Contra Costa country in Greater Bay Area (GBA) of LargeST dataset for delay is 50 minutes.",
    "doi": "10.22266/ijies2024.1031.14",
    "author_keywords": [
      "Long short term memory (LSTM)",
      "Nonlinear autoregressive models with exogenous inputs (NARX)",
      "Spatio-temporal embedding (STE) generator",
      "Traffic forecasting",
      "Traffic signal"
    ],
    "contribution": "For capturing the temporal and spatial dependency, the Nonlinear autoregressive models with exogenous inputs (NARX) - Long Short Term Memory (LSTM) Forward Taylor Network (NxLFTN)based traffic forecasting is proposed in this paper. The traffic network is considered as a graph, which contains the spatio-temporal data. The spatio-temporal data is high-dimensional and complex. To embed the data into a low-dimensionality region, the spatio-temporal embedding (STE) generator is employed. Moreover, the STE generator is used for predicting the daily embedding and the weekly embedding of the time related to the present traffic signal. At last, the traffic forecasting is carried out using the NxLFTNet. In addition, the Mean absolute percentage error (MAPE), Root Mean square error (RMSE), and Mean Absolute Error (MAE) are used to validate the effectiveness of the NxLFTNet. It offered the finest MAPE, RMSE, and MAE of 0.003, 0.046, and 0.04 when considering the data from the Contra Costa country in Greater Bay Area (GBA) of LargeST dataset for delay is 50 minutes.",
    "introduction": "Due to the growing level of transportation systems, numerous social troubles arise and create serious hazards like air pollution, the greenhouse effect, and traffic congestion. Hence, Traffic forecasting is essential for providing numerous applications in smart city management like congestion avoidance, navigation guidance, and urban traffic control. Still, the traffic prediction is difficult, since each road network is greatly dependent on other networks in a temporally and spatially manner.",
    "macro_domains": []
  },
  {
    "abstract": "Intelligent transportation systems are an important issue within the scope of smart cities. Vehicle routing problems, which are a combinatorial problem, need to be solved in the design of the relevant systems. In this regard, the use of artificial intelligence optimization algorithms such as meta-heuristics has increased significantly in recent years. To the best of our knowledge, there are no papers that address the Dial and Ride problem by using reinforcement learning, one of the learning-based models. In this study, the Dial and Ride problem is solved for a single service vehicle using the transformer-based deep reinforcement learning method. The proposed method is tested on a problem generated in an environment in EskiÅŸehir BÃ¼yÃ¼kdere Neighborhood. As a result of the test problem, it is shown that the proposed method produced a solution to the problem in a reasonable time. The study showed that the Dial and Ride Problems can be solved with reinforcement learning.",
    "doi": "10.1109/SIU61531.2024.10600947",
    "author_keywords": [
      "deep reinforcement learning",
      "dial-a-ride",
      "pickup end delivery tasks",
      "routing problem"
    ],
    "contribution": "In this study, the Dial and Ride problem is solved for a single service vehicle using the transformer-based deep reinforcement learning method. The proposed method is tested on a problem generated in an environment in EskiÅŸehir BÃ¼yÃ¼kdere Neighborhood. As a result of the test problem, it is shown that the proposed method produced a solution to the problem in a reasonable time. The study showed that the Dial and Ride Problems can be solved with reinforcement learning.",
    "introduction": "Intelligent transportation systems are an important issue within the scope of smart cities. Vehicle routing problems, which are a combinatorial problem, need to be solved in the design of the relevant systems. In this regard, the use of artificial intelligence optimization algorithms such as meta-heuristics has increased significantly in recent years. To the best of our knowledge, there are no papers that address the Dial and Ride problem by using reinforcement learning, one of the learning-based models.",
    "macro_domains": []
  },
  {
    "abstract": "With the proliferation of 4G and 5G mobile networks in smart cities, the adoption of Internet of Things (IoT) devices has surged, emphasizing the critical need for robust security measures. Existing firmware attestation techniques often require high computational budget or access to the device's authentic firmware, posing challenges due to resource and proprietary constraints. To counter these two fundamental challenges, this article introduces a novel software-based attestation framework utilizing RAM traces from IoT devices for remote verification. In the proposed framework, the need for an authentic firmware copy is eliminated, and the most computationally intensive task is assigned to the gateway node of the IoT ecosystem. This approach yields a robust and highly accurate device attestation strategy, while imposing minimal computational demands on the verification device itself. Employing deep learning models trained in a representation learning paradigm, our framework enables the remote verifier to authenticate the internal state of IoT devices. Leveraging data collected from real-world prototype devices, under eight different applications, our approach achieves a remarkable 100% accuracy in detecting critical attacks on IoT devices with a false positive rate of 10-3 Notably, our framework preserves device availability and maintains low authentication latency, underscoring its efficacy and practicality for securing IoT ecosystems.",
    "doi": "10.1109/JIOT.2024.3436057",
    "author_keywords": [
      "Device attestation",
      "firmware",
      "Internet of Things (IoT)",
      "RAM trace",
      "variational autoencoder (VAE)"
    ],
    "contribution": "To counter these two fundamental challenges, this article introduces a novel software-based attestation framework utilizing RAM traces from IoT devices for remote verification. In the proposed framework, the need for an authentic firmware copy is eliminated, and the most computationally intensive task is assigned to the gateway node of the IoT ecosystem. This approach yields a robust and highly accurate device attestation strategy, while imposing minimal computational demands on the verification device itself. Employing deep learning models trained in a representation learning paradigm, our framework enables the remote verifier to authenticate the internal state of IoT devices. Leveraging data collected from real-world prototype devices, under eight different applications, our approach achieves a remarkable 100% accuracy in detecting critical attacks on IoT devices with a false positive rate of 10-3 Notably, our framework preserves device availability and maintains low authentication latency, underscoring its efficacy and practicality for securing IoT ecosystems.",
    "introduction": "With the proliferation of 4G and 5G mobile networks in smart cities, the adoption of Internet of Things (IoT) devices has surged, emphasizing the critical need for robust security measures. Existing firmware attestation techniques often require high computational budget or access to the device's authentic firmware, posing challenges due to resource and proprietary constraints.",
    "macro_domains": []
  },
  {
    "abstract": "In the digital era, data has become a pivotal asset, advancing technologies such as autonomous driving. Despite this, data trading faces challenges like the absence of robust pricing methods and the lack of trustworthy trading mechanisms. To address these challenges, we introduce a traffic-oriented data trading platform named Data on The Move (DTM), integrating traffic simulation, data trading, and Artificial Intelligent (AI) agents. The DTM platform supports evident-based data value evaluation and AI-based trading mechanisms. Leveraging the common sense capabilities of Large Language Models (LLMs) to assess traffic state and data value, DTM can determine reasonable traffic data pricing through multi-round interaction and simulations. Moreover, DTM provides a pricing method validation by simulating traffic systems, multi-agent interactions, and the heterogeneity and irrational behaviors of individuals in the trading market. Within the DTM platform, entities such as connected vehicles and traffic light controllers could engage in information collecting, data pricing, trading, and decision-making. Simulation results demonstrate that our proposed AI agent-based pricing approach enhances data trading by offering rational prices, as evidenced by the observed improvement in traffic efficiency. This underscores the effectiveness and practical value of DTM, offering new perspectives for the evolution of data markets and smart cities. To the best of our knowledge, this is the first study employing LLMs in data pricing and a pioneering data trading practice in the field of intelligent vehicles and smart cities.",
    "doi": "10.1109/IV55156.2024.10588800",
    "author_keywords": null,
    "contribution": "To address these challenges, we introduce a traffic-oriented data trading platform named Data on The Move (DTM), integrating traffic simulation, data trading, and Artificial Intelligent (AI) agents. The DTM platform supports evident-based data value evaluation and AI-based trading mechanisms. Leveraging the common sense capabilities of Large Language Models (LLMs) to assess traffic state and data value, DTM can determine reasonable traffic data pricing through multi-round interaction and simulations. Moreover, DTM provides a pricing method validation by simulating traffic systems, multi-agent interactions, and the heterogeneity and irrational behaviors of individuals in the trading market. Within the DTM platform, entities such as connected vehicles and traffic light controllers could engage in information collecting, data pricing, trading, and decision-making. Simulation results demonstrate that our proposed AI agent-based pricing approach enhances data trading by offering rational prices, as evidenced by the observed improvement in traffic efficiency. This underscores the effectiveness and practical value of DTM, offering new perspectives for the evolution of data markets and smart cities. To the best of our knowledge, this is the first study employing LLMs in data pricing and a pioneering data trading practice in the field of intelligent vehicles and smart cities.",
    "introduction": "In the digital era, data has become a pivotal asset, advancing technologies such as autonomous driving. Despite this, data trading faces challenges like the absence of robust pricing methods and the lack of trustworthy trading mechanisms.",
    "macro_domains": []
  },
  {
    "abstract": "Street view images constitute an important part of urban computing, providing data support for tasks such as autonomous driving and landscape planning, and promoting the interaction and collaboration between machines and the urban environment. However, in current practice, the usability of street view images is hindered by low-light conditions, and existing low-light enhancement methods often overlook the high-frequency characteristics specific to street views. Therefore, this paper proposes a conditional diffusion model called SVBoost that incorporates high-frequency information and color balance to achieve targeted enhancement of street view images. The proposed model demonstrates favorable performance in terms of image quality, and the enhancement effect observed in semantic segmentation tasks suggests the potential of this method for downstream applications.",
    "doi": "10.1109/CSCWD61410.2024.10580863",
    "author_keywords": [
      "Diffusion Model",
      "Image Restoration",
      "Low Light Enhancement",
      "Urban Computing"
    ],
    "contribution": "Therefore, this paper proposes a conditional diffusion model called SVBoost that incorporates high-frequency information and color balance to achieve targeted enhancement of street view images. The proposed model demonstrates favorable performance in terms of image quality, and the enhancement effect observed in semantic segmentation tasks suggests the potential of this method for downstream applications.",
    "introduction": "Street view images constitute an important part of urban computing, providing data support for tasks such as autonomous driving and landscape planning, and promoting the interaction and collaboration between machines and the urban environment. However, in current practice, the usability of street view images is hindered by low-light conditions, and existing low-light enhancement methods often overlook the high-frequency characteristics specific to street views.",
    "macro_domains": []
  },
  {
    "abstract": "Since the invention of electrical energy, their consumption increased over time and nowadays, with electric cars and smart cities, the demand for electrical energy increased exponentially as the energy should be on 24/7, not only in the daylight as was in the past. Generally, electric cars transport people daily, and at night, connected to battery chargers fed by the AC mains. These revolutionary lifestyles are changing the electric demand. Nowadays we have found different ways to generate electrical energy (hydroelectric, thermoelectric, aeolian, solar); many of these central generations are far from consumer and use transmission lines to connect that, and transformers are used for almost all of that to increase or decrease voltage/current. Transformers are composed of three elements in their construction: copper winding, magnetic core, and oil. The oil used as insulation material for winding also cools down the device, transferring the heat from winding and magnetic core to the outside through the metal structure and circulating it by the convection process. In this work, we characterized the mineral oil voltage breakdown (BD) at room temperature as liquid insulators in transformers. On the pulsed condition, we reached a dielectric strength of order of 27.5 kV/mm, while under alternate current AC conditions, the dielectric strength was only around 5 kV/mm, testing with the same pair of electrodes. With the pulsed testing, the BD has a higher value due to less stress on the material than the AC 60 Hz continuous voltage application.",
    "doi": "10.1109/EIC58847.2024.10579398",
    "author_keywords": [
      "breakdown voltage",
      "Electrical characterization",
      "mineral oil",
      "transformer"
    ],
    "contribution": "In this work, we characterized the mineral oil voltage breakdown (BD) at room temperature as liquid insulators in transformers. On the pulsed condition, we reached a dielectric strength of order of 27.5 kV/mm, while under alternate current AC conditions, the dielectric strength was only around 5 kV/mm, testing with the same pair of electrodes. With the pulsed testing, the BD has a higher value due to less stress on the material than the AC 60 Hz continuous voltage application.",
    "introduction": "Since the invention of electrical energy, their consumption increased over time and nowadays, with electric cars and smart cities, the demand for electrical energy increased exponentially as the energy should be on 24/7, not only in the daylight as was in the past. Generally, electric cars transport people daily, and at night, connected to battery chargers fed by the AC mains. These revolutionary lifestyles are changing the electric demand. Nowadays we have found different ways to generate electrical energy (hydroelectric, thermoelectric, aeolian, solar); many of these central generations are far from consumer and use transmission lines to connect that, and transformers are used for almost all of that to increase or decrease voltage/current. Transformers are composed of three elements in their construction: copper winding, magnetic core, and oil. The oil used as insulation material for winding also cools down the device, transferring the heat from winding and magnetic core to the outside through the metal structure and circulating it by the convection process.",
    "macro_domains": []
  },
  {
    "abstract": "In the dynamic landscape of educational technology, the imperative to introduce young learners to Artificial Intelligence (AI) in a compelling and digestible manner has never been more critical. This paper delineates the novel Integrated Gamification-AI Learning Theory (IGALT), a pedagogical framework that synergizes gamification with AI education to foster engaging and effective learning experiences. At the heart of demonstrating IGALT's practical application is 'TransAI,' an inventive Lego-Transformer-like character that serves as an educational tool bridging sophisticated AI concepts with playful learning. Equipped with vision for environmental interaction, a brain for analytical processing, and additional modules like 'PetScada' for data gathering and 'Scooper' for action-based learning, TransAI exemplifies how gamification can make AI education accessible and captivating for children. Set within a smart city context, TransAI embarks on various missions that translate abstract AI concepts into concrete, hands-on experiences, thus enabling children to explore, understand, and apply AI in problem-solving. This educational approach not only ignites creativity and imagination but also instills a foundational understanding of AI, preparing young minds for future technological landscapes. By integrating IGALT with the TransAI platform, this paper proposes a groundbreaking method to acquaint the younger generation with AI, nurturing an early interest in STEM fields through an engaging, imaginative, and practical learning journey.",
    "doi": "10.1109/AIIoT61789.2024.10578991",
    "author_keywords": [
      "component",
      "formatting",
      "insert (key words)",
      "style",
      "styling"
    ],
    "contribution": "This paper delineates the novel Integrated Gamification-AI Learning Theory (IGALT), a pedagogical framework that synergizes gamification with AI education to foster engaging and effective learning experiences. At the heart of demonstrating IGALT's practical application is 'TransAI,' an inventive Lego-Transformer-like character that serves as an educational tool bridging sophisticated AI concepts with playful learning. Equipped with vision for environmental interaction, a brain for analytical processing, and additional modules like 'PetScada' for data gathering and 'Scooper' for action-based learning, TransAI exemplifies how gamification can make AI education accessible and captivating for children. Set within a smart city context, TransAI embarks on various missions that translate abstract AI concepts into concrete, hands-on experiences, thus enabling children to explore, understand, and apply AI in problem-solving. This educational approach not only ignites creativity and imagination but also instills a foundational understanding of AI, preparing young minds for future technological landscapes. By integrating IGALT with the TransAI platform, this paper proposes a groundbreaking method to acquaint the younger generation with AI, nurturing an early interest in STEM fields through an engaging, imaginative, and practical learning journey.",
    "introduction": "In the dynamic landscape of educational technology, the imperative to introduce young learners to Artificial Intelligence (AI) in a compelling and digestible manner has never been more critical.",
    "macro_domains": []
  },
  {
    "abstract": "As unmanned aerial vehicles (UAVs) become more prevalent in smart cities, their capacity for visual language navigation (VLN) is garnering increasing interest. VLN in cities has significant applications in delivery, rescue, and security patrol, among other fields. One of the most representative tasks is to navigate to specific locations following the language instructions. While some current methods have achieved notable results in indoor settings, challenges persist outdoors, including agents' inaccurate spatial understanding and ambiguous language instructions. In this work, we explore an embodied navigation agent design, in which a fine-grained spatial verbalizer and a history path memory are proposed to guarantee accurate VLN in open 3D urban environments.",
    "doi": "10.1109/IPSN61024.2024.00033",
    "author_keywords": [
      "embodied navigation agent",
      "urban",
      "Visual language navigation"
    ],
    "contribution": "In this work, we explore an embodied navigation agent design, in which a fine-grained spatial verbalizer and a history path memory are proposed to guarantee accurate VLN in open 3D urban environments.",
    "introduction": "As unmanned aerial vehicles (UAVs) become more prevalent in smart cities, their capacity for visual language navigation (VLN) is garnering increasing interest. VLN in cities has significant applications in delivery, rescue, and security patrol, among other fields. One of the most representative tasks is to navigate to specific locations following the language instructions. While some current methods have achieved notable results in indoor settings, challenges persist outdoors, including agents' inaccurate spatial understanding and ambiguous language instructions.",
    "macro_domains": []
  },
  {
    "abstract": "Systematic literature review (SLR) plays a crucial role in ensuring the originality, significance, and quality of research. However, conducting SLR can be a challenging task that is prone to errors and subjectivity. To mitigate these issues, text mining and machine learning (ML) techniques have been adopted. These techniques have been shown to improve the efficiency and quality of SLR. In this paper, we employ Latent Dirichlet Allocation (LDA) and Chat Generative Pre-Trained Transformer (ChatGPT) to conduct a comprehensive SLR on developments within smart cities, using a 7-step methodology. Our results demonstrate that LDA and ML (ChatGPT, in this case) can enhance SLR, resulting in over 80% improvement in both the efficiency and quality of the review. Specifically, the results highlight the importance of a comprehensive framework for planning and managing sustainable smart city projects, including stakeholder-driven design of common applications and deployment of technologies to implement these applications. The interrelationships between these themes are crucial for achieving the vision of a smart city. This paper contributes twofold: (1) a 7-step SLR methodology that incorporates LDA and ChatGPT and (2) a comprehensive SLR on the smart city concept.",
    "doi": "10.23919/IST-Africa63983.2024.10569979",
    "author_keywords": [
      "Chat Generative Pre-Trained Transformer (ChatGPT)",
      "governance",
      "inclusivity",
      "Latent Dirichlet Allocation (LDA)",
      "machine learning",
      "multi-disciplinary approach",
      "smart cities",
      "sustainability",
      "systematic literature review",
      "text mining"
    ],
    "contribution": "In this paper, we employ Latent Dirichlet Allocation (LDA) and Chat Generative Pre-Trained Transformer (ChatGPT) to conduct a comprehensive SLR on developments within smart cities, using a 7-step methodology. Our results demonstrate that LDA and ML (ChatGPT, in this case) can enhance SLR, resulting in over 80% improvement in both the efficiency and quality of the review. Specifically, the results highlight the importance of a comprehensive framework for planning and managing sustainable smart city projects, including stakeholder-driven design of common applications and deployment of technologies to implement these applications. The interrelationships between these themes are crucial for achieving the vision of a smart city. This paper contributes twofold: (1) a 7-step SLR methodology that incorporates LDA and ChatGPT and (2) a comprehensive SLR on the smart city concept.",
    "introduction": "Systematic literature review (SLR) plays a crucial role in ensuring the originality, significance, and quality of research. However, conducting SLR can be a challenging task that is prone to errors and subjectivity. To mitigate these issues, text mining and machine learning (ML) techniques have been adopted. These techniques have been shown to improve the efficiency and quality of SLR.",
    "macro_domains": []
  },
  {
    "abstract": "Spatio-temporal localization of the abnormal patterns in the video is known as video anomaly detection. Video anomaly detection is the most essential building block of any advanced video surveillance-based security application system. Annotation of the normal and anomalous videos at frame level is a tedious, time-consuming, and erroneous task. Hence, recently, weakly supervised video anomaly detection (WSVAD) methods, which use weakly labeled trained videos (or video-level annotations), have been proposed. This paper attempts to investigate and implement eight key state-of-the-art (SOTA) WSVAD methods on two publicly available benchmarked video anomaly datasets such as UCF crime and ShanghaiTech. The eight SOTA WSVAD implemented methods are Multiple Instance Learning (MIL), Robust Temporal Feature Magnitude (RTFM), Anomaly Regression Net (AR-Net), Bi-directional Encoder Representations from Transformers (BERT), Magnitude-Contrastive Glance-and-Focus Network (MGFN), Temporal Self-Attention (TSA), Weakly Supervised Anomaly Localization (WSAL), Prompt-Enhanced Learning (PEL) and Temporal Context Aggregation (TCA). Subsequently, a comparative analysis of these implemented WSVAD methods is carried out to draw some insightful conclusions.",
    "doi": "10.1109/AIIoT58432.2024.10574734",
    "author_keywords": [
      "Anomaly regression net",
      "deep learning",
      "multiple instant learning",
      "video anomaly detection",
      "weakly supervised video anomaly detection"
    ],
    "contribution": "This paper attempts to investigate and implement eight key state-of-the-art (SOTA) WSVAD methods on two publicly available benchmarked video anomaly datasets such as UCF crime and ShanghaiTech. The eight SOTA WSVAD implemented methods are Multiple Instance Learning (MIL), Robust Temporal Feature Magnitude (RTFM), Anomaly Regression Net (AR-Net), Bi-directional Encoder Representations from Transformers (BERT), Magnitude-Contrastive Glance-and-Focus Network (MGFN), Temporal Self-Attention (TSA), Weakly Supervised Anomaly Localization (WSAL), Prompt-Enhanced Learning (PEL) and Temporal Context Aggregation (TCA). Subsequently, a comparative analysis of these implemented WSVAD methods is carried out to draw some insightful conclusions.",
    "introduction": "Spatio-temporal localization of the abnormal patterns in the video is known as video anomaly detection. Video anomaly detection is the most essential building block of any advanced video surveillance-based security application system. Annotation of the normal and anomalous videos at frame level is a tedious, time-consuming, and erroneous task. Hence, recently, weakly supervised video anomaly detection (WSVAD) methods, which use weakly labeled trained videos (or video-level annotations), have been proposed.",
    "macro_domains": []
  },
  {
    "abstract": "Artificial Intelligence and Machine Learning (AI/ML) as analytical tools can be applied across multiple social domains. Thus, these tools are being deployed in several ways to address societal issues and concerns for 'social good'. For instance, AI/ML has applicable use cases for crisis response, economic empowerment, educational demands, environmental challenges, equality and inclusion, health and hunger, and security and justice. In this work, we seek to explore the power and capability of AI/ML in understanding citizens' engagement, which can improve governance and smart city deployment. Specifically, we studied the views expressed by online users about the city of Saskatoon in Canada. The analyzed views have become a value chain that community leaders can use to improve the governance structure of the city. In the study, we extracted 114,390 comments from Reddit (i.e., Saskatoon subreddit posts) between January 1, 2019, and September 20, 2023, to discover topics to highlight citizens' concerns. We compare the performance of three major topic models, namely, Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and BERTopic with a K-means clustering algorithm in the discovery of topics from the collected Reddit comments. The BERTopic with the K-means clustering algorithm achieved the highest coherence score of approximately 0.64 in the extraction of 25 topics from the dataset. Our findings showed that BERTopic can discover coherent and diverse topics compared to LDA and NMF. We found 12 underlying themes by merging related topics. Also, we leveraged SiEBERT (a pre-trained transformer model), 4 supervised ML models, and VADER (a lexical sentiment analysis classifier) to identify the sentiments expressed in each theme. The SiEBERT model outperformed the other sentiment classifiers with an accuracy of 89% in the prediction of sentiments. The research discovered factors for smart city engagement such as Housing and Facilities, Education, Downtown Development, Tourism and Entertainment, Policing, Healthcare, Online Community, and Cost.",
    "doi": "10.1109/ACCESS.2024.3426329",
    "author_keywords": [
      "citizens engagement",
      "Machine learning",
      "smart city",
      "social media",
      "textual mining"
    ],
    "contribution": "In this work, we seek to explore the power and capability of AI/ML in understanding citizens' engagement, which can improve governance and smart city deployment. Specifically, we studied the views expressed by online users about the city of Saskatoon in Canada. The analyzed views have become a value chain that community leaders can use to improve the governance structure of the city. In the study, we extracted 114,390 comments from Reddit (i.e., Saskatoon subreddit posts) between January 1, 2019, and September 20, 2023, to discover topics to highlight citizens' concerns. We compare the performance of three major topic models, namely, Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and BERTopic with a K-means clustering algorithm in the discovery of topics from the collected Reddit comments. The BERTopic with the K-means clustering algorithm achieved the highest coherence score of approximately 0.64 in the extraction of 25 topics from the dataset. Our findings showed that BERTopic can discover coherent and diverse topics compared to LDA and NMF. We found 12 underlying themes by merging related topics. Also, we leveraged SiEBERT (a pre-trained transformer model), 4 supervised ML models, and VADER (a lexical sentiment analysis classifier) to identify the sentiments expressed in each theme. The SiEBERT model outperformed the other sentiment classifiers with an accuracy of 89% in the prediction of sentiments. The research discovered factors for smart city engagement such as Housing and Facilities, Education, Downtown Development, Tourism and Entertainment, Policing, Healthcare, Online Community, and Cost.",
    "introduction": "Artificial Intelligence and Machine Learning (AI/ML) as analytical tools can be applied across multiple social domains. Thus, these tools are being deployed in several ways to address societal issues and concerns for 'social good'. For instance, AI/ML has applicable use cases for crisis response, economic empowerment, educational demands, environmental challenges, equality and inclusion, health and hunger, and security and justice.",
    "macro_domains": []
  },
  {
    "abstract": "The 3D virtual terrain generation is currently used in geography teaching and setting up relevant virtual scenes according to the teaching content, which can visually display the verification experimental conditions and results and enhance the universality of virtual geography experiments. In the field of digital twin smart city, traffic, and water simulation, constructing virtual terrain according to the real terrain can provide the basic environment for subsequent development and experiments. In military simulation, it can quickly build beyond the real scenes of extreme training environment, which has a key role in improving military training and enhancing combat capabilities. Hand-drawn feature sketches can express 3D virtual terrain under human subjective perception. Therefore, how to use hand-drawn feature sketches to build 3D terrain environment quickly and generate realistic virtual geographic environment is a hot spot and difficult point for the creation and development of geographic metaverse with virtual geographic environment as the core in the future. Although the traditional method of generating 3D virtual terrain provides an important reference for image cross-domain generation from hand-drawn feature sketch to virtual terrain, problems such as insufficient realism of the generated terrain remain. Especially when the terrain feature outline is too sparse, the generated terrain will have duplicate terrain blocks and grid artifacts. On this basis, a hand-drawn feature sketch virtual terrain generation method with improved generative adversarial network is proposed. The model is based on extracted data samples and hand-drawn sketch characteristics, and the input terrain feature information is involved in the sampling of each layer by improving the generator U-Net network, which enhances the control role of terrain features in the invisible space, reduces the possibility of model collapse, increases the random noise input, and improves the realism of the generated terrain, especially the detail when the terrain feature elements in the sketch are sparse. L1 loss (mean absolute value error function) and L2 loss (mean variance error function) are combined to form smooth L1 loss, and then optimized with CGAN loss function to form a new generator loss function to improve the stability and efficiency of model training. The Digital Elevation Model (DEM) data of some areas of the Loess Plateau with high accuracy is selected to produce data. The DEM data with high accuracy are selected and used for model training to compare and evaluate the terrain generation enhancement effect quantitatively before and after model improvement. Finally, the model inference process from hand-drawn feature sketch to virtual terrain is completely constructed. The experimental results show the improved virtual terrain generation model with the Loess Plateau terrain data can represent the hand-drawn feature sketch well, and the generated terrain conforms to the distribution and orientation of the terrain features described in the sketch, especially in the case of sparse sketch, and the generated terrain has high realistic surface details. This model is applied to the real natural landscape display and terrain evolution, and it can meet the userâ€™s needs to obtain the virtual terrain with high realistic feeling after inputting the hand-drawn terrain feature sketch. This improved model proposed in this paper has good prospects for 3D terrain modeling and editing.",
    "doi": "10.11834/jrs.20233090",
    "author_keywords": [
      "3D virtual terrain",
      "CGANs",
      "DEM",
      "hand-drawn feature sketch",
      "remote sensing"
    ],
    "contribution": "This improved model proposed in this paper has good prospects for 3D terrain modeling and editing.",
    "introduction": "The 3D virtual terrain generation is currently used in geography teaching and setting up relevant virtual scenes according to the teaching content, which can visually display the verification experimental conditions and results and enhance the universality of virtual geography experiments. In the field of digital twin smart city, traffic, and water simulation, constructing virtual terrain according to the real terrain can provide the basic environment for subsequent development and experiments. In military simulation, it can quickly build beyond the real scenes of extreme training environment, which has a key role in improving military training and enhancing combat capabilities. Hand-drawn feature sketches can express 3D virtual terrain under human subjective perception. Therefore, how to use hand-drawn feature sketches to build 3D terrain environment quickly and generate realistic virtual geographic environment is a hot spot and difficult point for the creation and development of geographic metaverse with virtual geographic environment as the core in the future. Although the traditional method of generating 3D virtual terrain provides an important reference for image cross-domain generation from hand-drawn feature sketch to virtual terrain, problems such as insufficient realism of the generated terrain remain. Especially when the terrain feature outline is too sparse, the generated terrain will have duplicate terrain blocks and grid artifacts. On this basis, a hand-drawn feature sketch virtual terrain generation method with improved generative adversarial network is proposed. The model is based on extracted data samples and hand-drawn sketch characteristics, and the input terrain feature information is involved in the sampling of each layer by improving the generator U-Net network, which enhances the control role of terrain features in the invisible space, reduces the possibility of model collapse, increases the random noise input, and improves the realism of the generated terrain, especially the detail when the terrain feature elements in the sketch are sparse. L1 loss (mean absolute value error function) and L2 loss (mean variance error function) are combined to form smooth L1 loss, and then optimized with CGAN loss function to form a new generator loss function to improve the stability and efficiency of model training. The Digital Elevation Model (DEM) data of some areas of the Loess Plateau with high accuracy is selected to produce data. The DEM data with high accuracy are selected and used for model training to compare and evaluate the terrain generation enhancement effect quantitatively before and after model improvement. Finally, the model inference process from hand-drawn feature sketch to virtual terrain is completely constructed. The experimental results show the improved virtual terrain generation model with the Loess Plateau terrain data can represent the hand-drawn feature sketch well, and the generated terrain conforms to the distribution and orientation of the terrain features described in the sketch, especially in the case of sparse sketch, and the generated terrain has high realistic surface details. This model is applied to the real natural landscape display and terrain evolution, and it can meet the userâ€™s needs to obtain the virtual terrain with high realistic feeling after inputting the hand-drawn terrain feature sketch.",
    "macro_domains": []
  },
  {
    "abstract": "Estimating Visual Quality of Street Space (VQoSS) is pivotal for urban design, environmental sustainability, civic engagement, etc. Recent advancements, notably in deep learning, have enabled large-scale analysis. However, traditional deep learning approaches are hampered by extensive data annotation requirements and limited adaptability across diverse VQoSS tasks. Multimodal Large Language Models (MLLMs) have recently demonstrated proficiency in various computer vision tasks, positioning them as promising tools for automated VQoSS assessment. In this paper, we pioneer the application of MLLMs to VQoSS change estimation, with our empirical findings affirming their effectiveness. In addition, we introduce Street Quality Generative Pre-trained Transformer (SQ-GPT), a model that distills knowledge from the current most powerful but inaccessible (not free) GPT-4V, requiring no human efforts. SQ-GPT approaches GPT-4V's performance and is viable for large-scale VQoSS change estimation. In a case study of Nanjing, we showcase the practicality of SQ-GPT and knowledge distillation pipeline. Our work promises to be a valuable asset for future urban studies research.",
    "doi": "10.1109/ACCESS.2024.3408843",
    "author_keywords": [
      "deep learning",
      "multimodal large language models",
      "Smart city",
      "visual quality"
    ],
    "contribution": "In this paper, we pioneer the application of MLLMs to VQoSS change estimation, with our empirical findings affirming their effectiveness. In addition, we introduce Street Quality Generative Pre-trained Transformer (SQ-GPT), a model that distills knowledge from the current most powerful but inaccessible (not free) GPT-4V, requiring no human efforts. SQ-GPT approaches GPT-4V's performance and is viable for large-scale VQoSS change estimation. In a case study of Nanjing, we showcase the practicality of SQ-GPT and knowledge distillation pipeline. Our work promises to be a valuable asset for future urban studies research.",
    "introduction": "Estimating Visual Quality of Street Space (VQoSS) is pivotal for urban design, environmental sustainability, civic engagement, etc. Recent advancements, notably in deep learning, have enabled large-scale analysis. However, traditional deep learning approaches are hampered by extensive data annotation requirements and limited adaptability across diverse VQoSS tasks. Multimodal Large Language Models (MLLMs) have recently demonstrated proficiency in various computer vision tasks, positioning them as promising tools for automated VQoSS assessment.",
    "macro_domains": []
  },
  {
    "abstract": "Dependable utilization of computer vision applications, such as smart surveillance, requires training deep learning networks on datasets that sufficiently represent the classes of interest. However, the bottleneck in many computer vision applications lies in the limited availability of adequate datasets. One particular application that is of great importance for the safety of cities and crowded areas is smart surveillance. Conventional surveillance methods are reactive and often ineffective in enable real-time action. However, smart surveillance is a key component of smart and proactive security in a smart city. Motivated by a smart city application which aims at the automatic identification of concerning events for alerting law-enforcement and governmental agencies, we craft a large video dataset that focuses on the distinction between small-scale violence, large-scale violence, peaceful gatherings, and natural events. This dataset classifies public events along two axes, the size of the crowd observed and the level of perceived violence in the crowd. We name this newly-built dataset the Multi-Scale Violence and Public Gathering (MSV-PG) dataset. The videos in the dataset go through several pre-processing steps to prepare them to be fed into a deep learning architecture. We conduct several experiments on the MSV-PG datasets using a ResNet3D, a Swin Transformer and an R(2 + 1)D architecture. The results achieved by these models when trained on the MSV-PG dataset, 88.37%, 89.76%, and 89.3%, respectively, indicate that the dataset is well-labeled and is rich enough to train deep learning models for automatic smart surveillance for diverse scenarios.",
    "doi": "10.3389/fcomp.2024.1242690",
    "author_keywords": [
      "computer vision",
      "crowd analysis",
      "human action recognition",
      "smart surveillance",
      "violence detection"
    ],
    "contribution": "",
    "introduction": "Dependable utilization of computer vision applications, such as smart surveillance, requires training deep learning networks on datasets that sufficiently represent the classes of interest. However, the bottleneck in many computer vision applications lies in the limited availability of adequate datasets. One particular application that is of great importance for the safety of cities and crowded areas is smart surveillance. Conventional surveillance methods are reactive and often ineffective in enable real-time action. However, smart surveillance is a key component of smart and proactive security in a smart city. Motivated by a smart city application which aims at the automatic identification of concerning events for alerting law-enforcement and governmental agencies, we craft a large video dataset that focuses on the distinction between small-scale violence, large-scale violence, peaceful gatherings, and natural events. This dataset classifies public events along two axes, the size of the crowd observed and the level of perceived violence in the crowd. We name this newly-built dataset the Multi-Scale Violence and Public Gathering (MSV-PG) dataset. The videos in the dataset go through several pre-processing steps to prepare them to be fed into a deep learning architecture. We conduct several experiments on the MSV-PG datasets using a ResNet3D, a Swin Transformer and an R(2 + 1)D architecture. The results achieved by these models when trained on the MSV-PG dataset, 88.37%, 89.76%, and 89.3%, respectively, indicate that the dataset is well-labeled and is rich enough to train deep learning models for automatic smart surveillance for diverse scenarios.",
    "macro_domains": []
  },
  {
    "abstract": "Urban planners and academics are influenced by the idea of smart cities to develop sustainable, modern, and reliable infrastructure that offers their citizens a respectable standard of living. To meet this demand, there have been video monitoring devices installed to improve public security and welfare. Despite scientific advancements, it is difficult and labor-intensive to identify odd events in surveillance video systems. In this research, we concentrate on the improvement of anomaly detection in intelligent video surveillance using regressive bidirectional Long Short-Term Memory (LSTM) (RBLSTM) with hyperparameter optimization (HO). The suggested framework is tested on a real-time dataset, the ShanghaiTech Campus dataset, and it outperforms state-of-the-art techniques in terms of performance. It is important to take advantage of higher-quality features from accessible videos. This work uses the Video Swin Transformer model to extract features. As a consequence, anomaly detection in video surveillance applications provides reliable outcomes for real-time situations. In this study, an abnormality was correctly identified in videos with a 98.5% accuracy rate. Future research might explore further experiments by investigating other methods to reduce the noise present in the positive bag.",
    "doi": "10.1002/9781394233953.ch5",
    "author_keywords": [
      "hyperparameter optimization (HO)",
      "Regressive bidirectional LSTM (RBLSTM)",
      "ShanghaiTech",
      "video anomaly detection",
      "Video Swin"
    ],
    "contribution": "In this research, we concentrate on the improvement of anomaly detection in intelligent video surveillance using regressive bidirectional Long Short-Term Memory (LSTM) (RBLSTM) with hyperparameter optimization (HO). The suggested framework is tested on a real-time dataset, the ShanghaiTech Campus dataset, and it outperforms state-of-the-art techniques in terms of performance. It is important to take advantage of higher-quality features from accessible videos. This work uses the Video Swin Transformer model to extract features. As a consequence, anomaly detection in video surveillance applications provides reliable outcomes for real-time situations. In this study, an abnormality was correctly identified in videos with a 98.5% accuracy rate. Future research might explore further experiments by investigating other methods to reduce the noise present in the positive bag.",
    "introduction": "Urban planners and academics are influenced by the idea of smart cities to develop sustainable, modern, and reliable infrastructure that offers their citizens a respectable standard of living. To meet this demand, there have been video monitoring devices installed to improve public security and welfare. Despite scientific advancements, it is difficult and labor-intensive to identify odd events in surveillance video systems.",
    "macro_domains": []
  },
  {
    "abstract": "The surge in the proliferation of private vehicles within urban centers has exacerbated challenges in parking management, primarily due to a scarcity of available spaces. To address this issue, the implementation of intelligent parking systems featuring autonomous monitoring and guidance has become imperative. This paper proposes a manual model of ResNet-50 and other classification networks using the Global Perceptual Feature Extractor (GPFE) module. Evaluated on established datasets, namely PKLot and CNREXT, the GPFE module significantly enhances accuracy and resilience when integrated with CNN classifiers like ResNet-50. Additionally, the methodology of the paper employs cost-effective cameras for binary classification across diverse lighting scenarios. This innovative decision eliminates the need for Internet of Things (IoT) sensors, leading to substantial reductions in maintenance expenses. The integration of this module not only enhances the precision of binary classification but also addresses cost-related challenges, establishing it as a sustainable solution for parking problems.",
    "doi": "10.1109/ICICACS60521.2024.10499086",
    "author_keywords": [
      "autonomous parking",
      "Parking space detection",
      "transformer"
    ],
    "contribution": "This paper proposes a manual model of ResNet-50 and other classification networks using the Global Perceptual Feature Extractor (GPFE) module. Evaluated on established datasets, namely PKLot and CNREXT, the GPFE module significantly enhances accuracy and resilience when integrated with CNN classifiers like ResNet-50. Additionally, the methodology of the paper employs cost-effective cameras for binary classification across diverse lighting scenarios. This innovative decision eliminates the need for Internet of Things (IoT) sensors, leading to substantial reductions in maintenance expenses. The integration of this module not only enhances the precision of binary classification but also addresses cost-related challenges, establishing it as a sustainable solution for parking problems.",
    "introduction": "The surge in the proliferation of private vehicles within urban centers has exacerbated challenges in parking management, primarily due to a scarcity of available spaces. To address this issue, the implementation of intelligent parking systems featuring autonomous monitoring and guidance has become imperative.",
    "macro_domains": []
  },
  {
    "abstract": "In computer vision, vehicle re-identification (Re-ID) addresses the challenge of recognizing and distinguishing vehicles as they move through different environments, under varying lighting conditions, and with changing poses and perspectives. This task is essential for applications such as video surveillance, and intelligent transportation systems. In this paper, we propose a Multi-details Vision Transformer (MD-ViT) approach for vehicle Re-ID. Our method leverages the power of transformers to handle multiple levels of detail in vehicle appearance, enabling more accurate and robust re-identification across diverse scenarios. We introduce a multiple details feature extraction process to capture fine-grained information, improving the model's ability to distinguish between vehicles with similar attributes. Furthermore, we incorporate attention mechanisms to focus on relevant vehicle details, enhancing the model's discriminative capabilities. Through comprehensive experiments on benchmark datasets, we demonstrate the effectiveness of our approach, achieving state-of-the-art results in vehicle Re-ID. Our transformer-based framework offers a promising direction for advancing vehicle re-identification with multiple details, with potential applications in smart cities, traffic monitoring, and security systems.",
    "doi": "10.1117/12.3024821",
    "author_keywords": [
      "computer vision",
      "Intelligent Transport Systems",
      "Transformers",
      "vehicle Re-ID"
    ],
    "contribution": "In this paper, we propose a Multi-details Vision Transformer (MD-ViT) approach for vehicle Re-ID. Our method leverages the power of transformers to handle multiple levels of detail in vehicle appearance, enabling more accurate and robust re-identification across diverse scenarios. We introduce a multiple details feature extraction process to capture fine-grained information, improving the model's ability to distinguish between vehicles with similar attributes. Furthermore, we incorporate attention mechanisms to focus on relevant vehicle details, enhancing the model's discriminative capabilities. Through comprehensive experiments on benchmark datasets, we demonstrate the effectiveness of our approach, achieving state-of-the-art results in vehicle Re-ID. Our transformer-based framework offers a promising direction for advancing vehicle re-identification with multiple details, with potential applications in smart cities, traffic monitoring, and security systems.",
    "introduction": "In computer vision, vehicle re-identification (Re-ID) addresses the challenge of recognizing and distinguishing vehicles as they move through different environments, under varying lighting conditions, and with changing poses and perspectives. This task is essential for applications such as video surveillance, and intelligent transportation systems.",
    "macro_domains": []
  },
  {
    "abstract": "Artificial Intelligence (AI) has impacted global economy, workforce productivity, smart health, smart cities, smart transport, and much more to come. Large Language Models (LLM) such as ChatGPT and Googleâ€™s Gemini, have been widely adopted in various applications. Blockchain Technology stands as a towering disruptor in today's tech landscape, offering assurances of enhanced security and scalability for various applications. Within the realm of healthcare, its adoption has surged, spanning from streamlined record-keeping to bolstered clinical trials, fortified medical supply chains, and vigilant patient monitoring. These applications harness the intrinsic attributes of blockchain to elevate standards of safety, privacy, and security within the healthcare sector. The combined power of AI and blockchain has the potential to revolutionize healthcare delivery, ensuring improved security, transparency, and efficiency. Nevertheless, Porru et al. [1] have highlighted deficiencies in the processes, tools, and techniques within this domain. Hence, this paper aims to furnish a structured framework that ensures both security and sustainability in the development of healthcare blockchain applications. This paper also provides an overview of societal impact on both technologies. This article has evolved best practice guidelines and a systematic development framework for AI-Blockchain integration, known as AI-BlockchainOps. This research has also developed a reference architecture, exemplifying the modeling of an Electronic Health Record (EHR) using BPMN and simulation. Within this Electronic Health Record (EHR) scenario encompassing 100 user requests, the simulation absorbed 97.09% of cloud resources, with 76.33% allocated to knowledge discovery, and a utilization rate of 93.20% for blockchain scientists, alongside various other contributing factors.",
    "doi": "10.2298/FUEE2401169R",
    "author_keywords": [
      "AI",
      "Blockchain",
      "Requirements Engineering for AI-Blockchain (RE-AIBC)",
      "Secure and Sustainable Software Engineering Framework for AI-Blockchain (AI-BlockchainOps)",
      "Smart Contract"
    ],
    "contribution": "Hence, this paper aims to furnish a structured framework that ensures both security and sustainability in the development of healthcare blockchain applications. This paper also provides an overview of societal impact on both technologies. This article has evolved best practice guidelines and a systematic development framework for AI-Blockchain integration, known as AI-BlockchainOps. This research has also developed a reference architecture, exemplifying the modeling of an Electronic Health Record (EHR) using BPMN and simulation. Within this Electronic Health Record (EHR) scenario encompassing 100 user requests, the simulation absorbed 97.09% of cloud resources, with 76.33% allocated to knowledge discovery, and a utilization rate of 93.20% for blockchain scientists, alongside various other contributing factors.",
    "introduction": "Artificial Intelligence (AI) has impacted global economy, workforce productivity, smart health, smart cities, smart transport, and much more to come. Large Language Models (LLM) such as ChatGPT and Googleâ€™s Gemini, have been widely adopted in various applications. Blockchain Technology stands as a towering disruptor in today's tech landscape, offering assurances of enhanced security and scalability for various applications. Within the realm of healthcare, its adoption has surged, spanning from streamlined record-keeping to bolstered clinical trials, fortified medical supply chains, and vigilant patient monitoring. These applications harness the intrinsic attributes of blockchain to elevate standards of safety, privacy, and security within the healthcare sector. The combined power of AI and blockchain has the potential to revolutionize healthcare delivery, ensuring improved security, transparency, and efficiency. Nevertheless, Porru et al. [1] have highlighted deficiencies in the processes, tools, and techniques within this domain.",
    "macro_domains": []
  },
  {
    "abstract": "Automatic building detection from remote sensing images holds significant applications in various domains, including cartography, land-use change detection, urban planning, and 3D intelligent city construction. Driven by the innovation of deep learning technology, convolutional neural networks (CNNs) have emerged as a powerful framework for automatic interpretation, exhibiting hierarchical feature generation and robust representation for building extraction. However, the inherent computational limitations of convolutional operators hinder the acquisition of an effective global receptive field. Recent advancements in deep learning have witnessed the adoption of the multi-head self-attention (MHSA) mechanism by Transformer, presenting the superiority of global context construction. Nonetheless, this network structure encounters difficulties in effectively modelling two-dimensional spatial structure features with scale variation in semantic segmentation and often has huge parameters with high algorithm complexity. To address the above problems, this paper proposed a hybrid deep neural network synergistically harnessing the superiority of CNN and Transformer to extract buildings from remote sensing images. Meanwhile, an improved MHSA mechanism is developed to facilitate the construction of multiscale global representations, concurrently reducing computational complexity. Furthermore, the cross-level MHSA modules the semantic correlation between the deep and shallow-level features to refine spatial fine-grained information. The proposed method was comprehensively evaluated on two building datasets via quantitative analysis and visualization. The experimental results confirmed that the developed network and modules outperform other state-of-the-art methods and can effectively improve the accuracy (93.4% F1-score on the WHU dataset, 89.38% F1-score on the CAMB dataset) with high efficiency for building extraction.",
    "doi": "10.1080/01431161.2024.2339199",
    "author_keywords": [
      "Building extraction",
      "CNN",
      "deep learning",
      "Transformer"
    ],
    "contribution": "To address the above problems, this paper proposed a hybrid deep neural network synergistically harnessing the superiority of CNN and Transformer to extract buildings from remote sensing images. Meanwhile, an improved MHSA mechanism is developed to facilitate the construction of multiscale global representations, concurrently reducing computational complexity. Furthermore, the cross-level MHSA modules the semantic correlation between the deep and shallow-level features to refine spatial fine-grained information. The proposed method was comprehensively evaluated on two building datasets via quantitative analysis and visualization. The experimental results confirmed that the developed network and modules outperform other state-of-the-art methods and can effectively improve the accuracy (93.4% F1-score on the WHU dataset, 89.38% F1-score on the CAMB dataset) with high efficiency for building extraction.",
    "introduction": "Automatic building detection from remote sensing images holds significant applications in various domains, including cartography, land-use change detection, urban planning, and 3D intelligent city construction. Driven by the innovation of deep learning technology, convolutional neural networks (CNNs) have emerged as a powerful framework for automatic interpretation, exhibiting hierarchical feature generation and robust representation for building extraction. However, the inherent computational limitations of convolutional operators hinder the acquisition of an effective global receptive field. Recent advancements in deep learning have witnessed the adoption of the multi-head self-attention (MHSA) mechanism by Transformer, presenting the superiority of global context construction. Nonetheless, this network structure encounters difficulties in effectively modelling two-dimensional spatial structure features with scale variation in semantic segmentation and often has huge parameters with high algorithm complexity.",
    "macro_domains": []
  },
  {
    "abstract": "Analogy allowing distinction, specificity and knowledge, in line with the articles in this thematic issue on the measurement of human intelligence, we question what artificial intelligence is as compared to human. What's about it? What are these human built technical systems, computers, robots, but also things where we live in, that are qualified as intelligent : smart clothes, smart cars, smart homes, smart cities? Are they intended to solve human problems? Can we measure their intelligence? In the era of generative AI and human digital twins, we recommend that artificial intelligence be measured by its adaptation to humans: knowing to what extent the machine is adapted to the smartness of its human user.",
    "doi": "10.3917/enf2.241.0051",
    "author_keywords": [
      "ARTIFICIAL INTELLIGENCE",
      "AUTONOMOUS SYSTEMS",
      "PROBLEM SOLVING"
    ],
    "contribution": "",
    "introduction": "Analogy allowing distinction, specificity and knowledge, in line with the articles in this thematic issue on the measurement of human intelligence, we question what artificial intelligence is as compared to human. What's about it? What are these human built technical systems, computers, robots, but also things where we live in, that are qualified as intelligent : smart clothes, smart cars, smart homes, smart cities? Are they intended to solve human problems? Can we measure their intelligence? In the era of generative AI and human digital twins, we recommend that artificial intelligence be measured by its adaptation to humans: knowing to what extent the machine is adapted to the smartness of its human user.",
    "macro_domains": []
  },
  {
    "abstract": "Sunlight and shadow play critical roles in how urban spaces are utilized, thrive, and grow. While access to sunlight is essential to the success of urban environments, shadows can provide shaded places to stay during the hot seasons, mitigate heat island effect, and increase pedestrian comfort levels. Properly quantifying sunlight access and shadows in large urban environments is key in tackling some of the important challenges facing cities today. In this paper, we propose Deep Umbra, a novel computational framework that enables the quantification of sunlight access and shadows at a global scale. Our framework is based on a conditional generative adversarial network that considers the physical form of cities to compute high-resolution spatial information of accumulated sunlight access for the different seasons of the year. We use data from seven different cities to train our model, and show, through an extensive set of experiments, its low overall RMSE (below 0.1) as well as its extensibility to cities that were not part of the training set. Additionally, we contribute a set of case studies and a comprehensive dataset with sunlight access information for more than 100 cities across six continents of the world. Deep Umbra is available at <uri>http://urbantk.org/shadows</uri>.",
    "doi": "10.1109/TBDATA.2024.3382964",
    "author_keywords": [
      "Big Data",
      "Buildings",
      "Generative adversarial networks",
      "Generative adversarial networks",
      "Shadow",
      "Sunlight access",
      "Task analysis",
      "Training",
      "Urban analytics",
      "Urban areas",
      "Urban computing",
      "Urban planning"
    ],
    "contribution": "In this paper, we propose Deep Umbra, a novel computational framework that enables the quantification of sunlight access and shadows at a global scale. Our framework is based on a conditional generative adversarial network that considers the physical form of cities to compute high-resolution spatial information of accumulated sunlight access for the different seasons of the year. We use data from seven different cities to train our model, and show, through an extensive set of experiments, its low overall RMSE (below 0.1) as well as its extensibility to cities that were not part of the training set. Additionally, we contribute a set of case studies and a comprehensive dataset with sunlight access information for more than 100 cities across six continents of the world. Deep Umbra is available at <uri>http://urbantk.org/shadows</uri>.",
    "introduction": "Sunlight and shadow play critical roles in how urban spaces are utilized, thrive, and grow. While access to sunlight is essential to the success of urban environments, shadows can provide shaded places to stay during the hot seasons, mitigate heat island effect, and increase pedestrian comfort levels. Properly quantifying sunlight access and shadows in large urban environments is key in tackling some of the important challenges facing cities today.",
    "macro_domains": []
  },
  {
    "abstract": "The automation of surveillance systems, driven by the rapid development of computer vision technology, has significantly enhanced the analysis of surveillance videos, particularly in recognition of human activity, including behavior analysis and violence detection, thereby bolstering public and industrial security. Despite these advancements, detecting and analyzing violent actions remains challenging, especially for real-time surveillance systems with limited computing power. We propose an artificial intelligence-based framework called VD-Net (Violence Detection Network), enabled by Intelligent Internet-of-Things (IIoT) to detect violent behavior in public and private spaces. The model utilizes lightweight special task temporal convolutional network (ST-TCN) blocks and several bottleneck layers to focus on salient features in the input sequence. The learned features passed from the classifier to discriminate between violent and nonviolent actions. Additionally, our system is supposed to trigger an alert if violence is detected, which is then communicated to relevant departments. We checked the robustness of our system by surveillance and non-surveillance datasets and ensured a 1-4 % improvement in State-of-The-Art (SoTA) accuracy.",
    "doi": "10.1109/ACCESS.2024.3380192",
    "author_keywords": [
      "Artificial intelligence",
      "cloud computing",
      "edge intelligence",
      "Internet of Things (IoT)",
      "security",
      "smart city",
      "violence detection"
    ],
    "contribution": "We propose an artificial intelligence-based framework called VD-Net (Violence Detection Network), enabled by Intelligent Internet-of-Things (IIoT) to detect violent behavior in public and private spaces. The model utilizes lightweight special task temporal convolutional network (ST-TCN) blocks and several bottleneck layers to focus on salient features in the input sequence. The learned features passed from the classifier to discriminate between violent and nonviolent actions. Additionally, our system is supposed to trigger an alert if violence is detected, which is then communicated to relevant departments. We checked the robustness of our system by surveillance and non-surveillance datasets and ensured a 1-4 % improvement in State-of-The-Art (SoTA) accuracy.",
    "introduction": "The automation of surveillance systems, driven by the rapid development of computer vision technology, has significantly enhanced the analysis of surveillance videos, particularly in recognition of human activity, including behavior analysis and violence detection, thereby bolstering public and industrial security. Despite these advancements, detecting and analyzing violent actions remains challenging, especially for real-time surveillance systems with limited computing power.",
    "macro_domains": []
  },
  {
    "abstract": "Internet-of-Things (IoT) has played a critical role in developing sustainable smart cities and emerging numerous latency-sensitive IoT applications. Mobile edge computing (MEC) federation has the capability to incorporate a transparent resource management approach, which enables the sharing and utilization of MEC services from edge infrastructure providers (EIPs) and provides agile access services to mobile devices (MDs). In this paper, we investigate the joint optimization problem of computation offloading, task migration, and resource allocation in the MEC federation. The objective is to minimize the weighted sum of latency and energy consumption while maintaining load balancing under the constraint of the long-term migration cost budget of EIPs. To address the problem, we decompose it into two sub-problems: 1) the MDs clustering sub-problem and 2) the sub-problem of joint computation offloading, task migration, and resource allocation. First, an MDs clustering matching (MDCM) algorithm is proposed to cluster the MDs in edge servers (ESs) according to the differences in channel gains. Afterward, the second sub-problem is simplified by the Lyapunov optimization technique, and then we propose a Transformer-based mobility prediction model and a decentralized deep deterministic policy gradient (DDPG)-based framework to solve it. Extensive simulation results demonstrate the cost-efficiency of the proposed algorithm.",
    "doi": "10.1109/TMC.2024.3376377",
    "author_keywords": [
      "Computation offloading",
      "deep reinforcement learning",
      "mobile edge computing",
      "resource allocation",
      "task migration"
    ],
    "contribution": "In this paper, we investigate the joint optimization problem of computation offloading, task migration, and resource allocation in the MEC federation. The objective is to minimize the weighted sum of latency and energy consumption while maintaining load balancing under the constraint of the long-term migration cost budget of EIPs. To address the problem, we decompose it into two sub-problems: 1) the MDs clustering sub-problem and 2) the sub-problem of joint computation offloading, task migration, and resource allocation. First, an MDs clustering matching (MDCM) algorithm is proposed to cluster the MDs in edge servers (ESs) according to the differences in channel gains. Afterward, the second sub-problem is simplified by the Lyapunov optimization technique, and then we propose a Transformer-based mobility prediction model and a decentralized deep deterministic policy gradient (DDPG)-based framework to solve it. Extensive simulation results demonstrate the cost-efficiency of the proposed algorithm.",
    "introduction": "Internet-of-Things (IoT) has played a critical role in developing sustainable smart cities and emerging numerous latency-sensitive IoT applications. Mobile edge computing (MEC) federation has the capability to incorporate a transparent resource management approach, which enables the sharing and utilization of MEC services from edge infrastructure providers (EIPs) and provides agile access services to mobile devices (MDs).",
    "macro_domains": []
  },
  {
    "abstract": "Traffic flow forecasting is essential and challenging to intelligent city management and public safety. In this paper, we attempt to use a pure self-attention method in traffic flow forecasting. However, when dealing with input sequences, including large-scale regions' historical records, it is difficult for the self-attention mechanism to focus on the most relevant ones for forecasting. To address this issue, we design a progressive space-time self-attention mechanism named ProSTformer, which can reduce self-attention computation times from thousands to tens. Our design is based on two pieces of prior knowledge in the traffic flow forecasting literature: (i) spatiotemporal dependencies can be factorized into spatial and temporal dependencies; (ii) adjacent regions have more influences than distant regions, and temporal characteristics of closeness, period and trend are more important than crossed relations between them. Our ProSTformer has two characteristics. First, each block in ProSTformer highlights the unique dependencies, ProSTformer progressively focuses on spatial dependencies from local to global regions, on temporal dependencies from closeness, period and trend to crossed relations between them, and on external dependencies such as weather conditions, temperature and day-of-week. Second, we use the Tensor Rearranging technique to force the model to compute self-attention only to adjacent regions and to the unique temporal characteristic. Then, we use the Patch Merging technique to greatly reduce self-attention computation times to distant regions and crossed temporal relations. We evaluate ProSTformer on two traffic datasets and find that it performs better than sixteen baseline models. The code is available at https://github.com/yanxiao1930/ProSTformer_code/tree/main.",
    "doi": "10.1109/TITS.2024.3367754",
    "author_keywords": [
      "deep learning",
      "self-attention mechanism",
      "spatial-temporal learning",
      "Traffic flow forecasting",
      "transformer"
    ],
    "contribution": "In this paper, we attempt to use a pure self-attention method in traffic flow forecasting. However, when dealing with input sequences, including large-scale regions' historical records, it is difficult for the self-attention mechanism to focus on the most relevant ones for forecasting. To address this issue, we design a progressive space-time self-attention mechanism named ProSTformer, which can reduce self-attention computation times from thousands to tens. Our design is based on two pieces of prior knowledge in the traffic flow forecasting literature: (i) spatiotemporal dependencies can be factorized into spatial and temporal dependencies; (ii) adjacent regions have more influences than distant regions, and temporal characteristics of closeness, period and trend are more important than crossed relations between them. Our ProSTformer has two characteristics. First, each block in ProSTformer highlights the unique dependencies, ProSTformer progressively focuses on spatial dependencies from local to global regions, on temporal dependencies from closeness, period and trend to crossed relations between them, and on external dependencies such as weather conditions, temperature and day-of-week. Second, we use the Tensor Rearranging technique to force the model to compute self-attention only to adjacent regions and to the unique temporal characteristic. Then, we use the Patch Merging technique to greatly reduce self-attention computation times to distant regions and crossed temporal relations. We evaluate ProSTformer on two traffic datasets and find that it performs better than sixteen baseline models. The code is available at https://github.com/yanxiao1930/ProSTformer_code/tree/main.",
    "introduction": "Traffic flow forecasting is essential and challenging to intelligent city management and public safety.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate traffic flow prediction plays an important role in intelligent transportation management and reducing traffic congestion for smart cities. Existing traffic flow prediction techniques using deep learning, mostly LSTMs, have achieved enormous success based on the large traffic flow datasets collected by governments and different organizations. Nevertheless, a lot of these datasets contain sensitive attributes that may relate to usersâ€™ private data. Hence, there is a need to develop an accurate traffic flow prediction mechanism that preserves usersâ€™ privacy. To address this challenge, we propose a federated learning-based temporal fusion transformer framework for traffic flow prediction which is a distributed machine learning approach where all the model updates are aggregated through an aggregation algorithm rather than sharing and storing the raw data in one centralized location. The proposed framework trains the data locally on client devices using temporal fusion transformers and differential privacy. Experiments show that the proposed framework can guarantee accuracy in predicting traffic flow for both the short and long term.",
    "doi": "10.1007/978-3-031-54204-6_15",
    "author_keywords": [
      "Differential Privacy",
      "Federated Learning",
      "Temporal Fusion Transformer",
      "Time Series Data",
      "Traffic Flow Prediction"
    ],
    "contribution": "To address this challenge, we propose a federated learning-based temporal fusion transformer framework for traffic flow prediction which is a distributed machine learning approach where all the model updates are aggregated through an aggregation algorithm rather than sharing and storing the raw data in one centralized location. The proposed framework trains the data locally on client devices using temporal fusion transformers and differential privacy. Experiments show that the proposed framework can guarantee accuracy in predicting traffic flow for both the short and long term.",
    "introduction": "Accurate traffic flow prediction plays an important role in intelligent transportation management and reducing traffic congestion for smart cities. Existing traffic flow prediction techniques using deep learning, mostly LSTMs, have achieved enormous success based on the large traffic flow datasets collected by governments and different organizations. Nevertheless, a lot of these datasets contain sensitive attributes that may relate to usersâ€™ private data. Hence, there is a need to develop an accurate traffic flow prediction mechanism that preserves usersâ€™ privacy.",
    "macro_domains": []
  },
  {
    "abstract": "In an era of 5G smart cities, precise traffic prediction remains elusive due to limited real-world data. Our paper introduces a novel approach using Generative Adversarial Networks (GANs) to create synthetic traffic data that closely mimics real-world statistics. This artificial dataset enhances our new 5GT-GAN-NET-based prediction model. The result is a significant boost in prediction accuracy, with Mean Square Error (MSE) reduced to 0.000346 and Mean Absolute Error (MAE) to 0.00685. Compared to benchmarks, our model improves MSE and MAE by up to 95.45% with respect to the ARIMA model and 87.31% with respect to the NARNN model respectively. User privacy remains a cornerstone of our approach, crucial for smart city applications. Our predictive capabilities enable more efficient resource allocation by service providers, increasing communication infrastructure reliability. Although tailored for smart cities, the approach is adaptable to other fields facing data scarcity and privacy concerns. Our research highlights the potential of GANs in generating large, accurate datasets for traffic prediction in 5G environments while prioritizing user privacy.",
    "doi": "10.1109/TMC.2024.3364655",
    "author_keywords": [
      "5G",
      "cellular traffic forecasting",
      "deep learning",
      "generative adversarial network (GAN)",
      "internet traffic",
      "mobile edge computing (MEC)",
      "synthetic data"
    ],
    "contribution": "Our paper introduces a novel approach using Generative Adversarial Networks (GANs) to create synthetic traffic data that closely mimics real-world statistics. This artificial dataset enhances our new 5GT-GAN-NET-based prediction model. The result is a significant boost in prediction accuracy, with Mean Square Error (MSE) reduced to 0.000346 and Mean Absolute Error (MAE) to 0.00685. Compared to benchmarks, our model improves MSE and MAE by up to 95.45% with respect to the ARIMA model and 87.31% with respect to the NARNN model respectively. User privacy remains a cornerstone of our approach, crucial for smart city applications. Our predictive capabilities enable more efficient resource allocation by service providers, increasing communication infrastructure reliability. Although tailored for smart cities, the approach is adaptable to other fields facing data scarcity and privacy concerns. Our research highlights the potential of GANs in generating large, accurate datasets for traffic prediction in 5G environments while prioritizing user privacy.",
    "introduction": "In an era of 5G smart cities, precise traffic prediction remains elusive due to limited real-world data.",
    "macro_domains": []
  },
  {
    "abstract": "Indoor Positioning Systems (IPS) have recently emerged as a crucial technology in the Internet of Things (IoT), with widespread applications in smart cities and homes. Radio frequency-based fingerprinting, enabling location estimation through signal observations, requires manual surveys for constructing location maps. This process involves annotating radio signatures with corresponding locations, rendering it time-consuming and labor-intensive. To address this challenge, our paper proposes a data augmentation method that leverages a conditional generative adversarial network with LSTM and CNN. This approach effectively captures patterns in the training data, generating synthetic data that aligns with the distribution. Experiments in a real scenario demonstrate an average localization error of 1.966 and 1.218 m for Wi-Fi and Bluetooth low energy (BLE), surpassing traditional fingerprinting and comparable to the baseline data augmentation methods.",
    "doi": "10.1109/ICCE59016.2024.10444463",
    "author_keywords": [
      "Bluetooth low energy (BLE)",
      "data augmentation",
      "fingerprinting localization",
      "Generative adversarial network (GAN)",
      "Internet of Things",
      "Wi-Fi"
    ],
    "contribution": "To address this challenge, our paper proposes a data augmentation method that leverages a conditional generative adversarial network with LSTM and CNN. This approach effectively captures patterns in the training data, generating synthetic data that aligns with the distribution. Experiments in a real scenario demonstrate an average localization error of 1.966 and 1.218 m for Wi-Fi and Bluetooth low energy (BLE), surpassing traditional fingerprinting and comparable to the baseline data augmentation methods.",
    "introduction": "Indoor Positioning Systems (IPS) have recently emerged as a crucial technology in the Internet of Things (IoT), with widespread applications in smart cities and homes. Radio frequency-based fingerprinting, enabling location estimation through signal observations, requires manual surveys for constructing location maps. This process involves annotating radio signatures with corresponding locations, rendering it time-consuming and labor-intensive.",
    "macro_domains": []
  },
  {
    "abstract": "Taxonomy mining plays an important role for organizing and structuring of data in Content Management Systems (CMS). In this paper, we propose a novel approach that leverages multidimensional knowledge representation (MKR) for taxonomy mining from text documents and enriching the extracted information via Large Language Model (LLM). The data originates from a Smart City project in Germany, which addresses housing, care and health for elderly people. The applied method involves the extraction of relevant keywords from text and the utilization of the MKR framework to analyze and represent the information. Results are provided for a context builder that utilizes GPT-4 to enrich the taxonomy. The enriched taxonomy is then used in a WordPress CMS for information search, structuring and tagging of the blog entries accordingly.",
    "doi": "10.1109/CCWC60891.2024.10427816",
    "author_keywords": [
      "CMS",
      "Content Management System",
      "Knowledge Representation",
      "Smart City",
      "Taxonomy Mining"
    ],
    "contribution": "In this paper, we propose a novel approach that leverages multidimensional knowledge representation (MKR) for taxonomy mining from text documents and enriching the extracted information via Large Language Model (LLM). The data originates from a Smart City project in Germany, which addresses housing, care and health for elderly people. The applied method involves the extraction of relevant keywords from text and the utilization of the MKR framework to analyze and represent the information. Results are provided for a context builder that utilizes GPT-4 to enrich the taxonomy. The enriched taxonomy is then used in a WordPress CMS for information search, structuring and tagging of the blog entries accordingly.",
    "introduction": "Taxonomy mining plays an important role for organizing and structuring of data in Content Management Systems (CMS).",
    "macro_domains": []
  },
  {
    "abstract": "Fast and high-precision urban scene 3D modeling is the foundational data infrastructure for the digital earth and smart cities. However, due to challenges such as water-area matching difficulties and issues like data redundancy and insufficient observations, existing full-automatic 3D modeling methods often result in water-area missing and many small holes in the models and insufficient local-model accuracy. To overcome these challenges, full-automatic high-precision scene 3D reconstruction method with water-area intelligent complementation on depth maps and mesh optimization is proposed. Firstly, SfM was used to calculated image poses and PatchMatch was used to generated initial depth maps. Secondly, a simplified GAN extracted water-area masks and ray tracing was used achieve high-precision auto-completed water-area depth values. Thirdly, fully connected CRF optimized water-areas and arounds in depth maps. Fourthly, high-precision 3D point clouds were obtained using depth map fusion based on clustering culling and depth least squares. Then, mesh was generated and optimized using similarity measurement and vertex gradients to obtain refined mesh. Finally, high-precision scene 3D models without water-area missing or holes were generated. The results showed that: to compare with the-state-of-art ContextCapture, the proposed method enhances model completeness by 14.3%, raises average accuracy by 14.5% and improves processing efficiency by 63.6%.",
    "doi": "10.1080/17538947.2024.2317441",
    "author_keywords": [
      "depth map optimization",
      "High-completeness scene 3D modeling",
      "mesh refinement",
      "UAV images",
      "water-area intelligent complementation"
    ],
    "contribution": "",
    "introduction": "Fast and high-precision urban scene 3D modeling is the foundational data infrastructure for the digital earth and smart cities. However, due to challenges such as water-area matching difficulties and issues like data redundancy and insufficient observations, existing full-automatic 3D modeling methods often result in water-area missing and many small holes in the models and insufficient local-model accuracy. To overcome these challenges, full-automatic high-precision scene 3D reconstruction method with water-area intelligent complementation on depth maps and mesh optimization is proposed. Firstly, SfM was used to calculated image poses and PatchMatch was used to generated initial depth maps. Secondly, a simplified GAN extracted water-area masks and ray tracing was used achieve high-precision auto-completed water-area depth values. Thirdly, fully connected CRF optimized water-areas and arounds in depth maps. Fourthly, high-precision 3D point clouds were obtained using depth map fusion based on clustering culling and depth least squares. Then, mesh was generated and optimized using similarity measurement and vertex gradients to obtain refined mesh. Finally, high-precision scene 3D models without water-area missing or holes were generated. The results showed that: to compare with the-state-of-art ContextCapture, the proposed method enhances model completeness by 14.3%, raises average accuracy by 14.5% and improves processing efficiency by 63.6%.",
    "macro_domains": []
  },
  {
    "abstract": "Fast and reliable identification of cyber attacks in network systems of smart cities is currently a critical and demanding task. Machine learning algorithms have been used for intrusion detection, but the existing data sets intended for their training are often imbalanced, which can reduce the effectiveness of the proposed model. Oversampling and undersampling techniques can solve the problem but have limitations, such as the risk of overfitting and information loss. Furthermore, network data logs are noisy and inconsistent, making it challenging to capture essential patterns in the data accurately. To address these issues, this study proposes using Generative Adversarial Networks to generate synthetic network traffic data. The results offer new insight into developing more effective intrusion detection systems, especially in the context of smart citiesâ€™ network infrastructure.",
    "doi": "10.1007/978-3-031-52426-4_3",
    "author_keywords": [
      "generative adversarial networks",
      "imbalanced datasets",
      "intrusion detection",
      "smart cities"
    ],
    "contribution": "To address these issues, this study proposes using Generative Adversarial Networks to generate synthetic network traffic data. The results offer new insight into developing more effective intrusion detection systems, especially in the context of smart citiesâ€™ network infrastructure.",
    "introduction": "Fast and reliable identification of cyber attacks in network systems of smart cities is currently a critical and demanding task. Machine learning algorithms have been used for intrusion detection, but the existing data sets intended for their training are often imbalanced, which can reduce the effectiveness of the proposed model. Oversampling and undersampling techniques can solve the problem but have limitations, such as the risk of overfitting and information loss. Furthermore, network data logs are noisy and inconsistent, making it challenging to capture essential patterns in the data accurately.",
    "macro_domains": []
  },
  {
    "abstract": "Significance Optical fiber sensors play an increasingly important role in safety monitoring areas in the smart Internet of Things (IoT). Particularly, a fiber-optic distributed acoustic sensor (fiber-optic DAS) based on the phase-sensitive optical time-domain reflectometry (Î¦â€‘OTDR) technology provides a highly dense, cost-effective, and continuous environment measurement way over a wide range. All kinds of vibration sources can be sensed and located with high sensitivity and precision utilizing the widely laid ordinary telecommunication cables, and thus fiber-optic DAS has been applied in various ground listening applications, such as natural disaster prediction of ocean-floor seismic activity, volcanic events, and earthquake, energy exploration in oil and gas industry, and civil infrastructure monitoring in the pipelines, railways, and perimeters. It leads to a new generation of large-scale fiber-optic IoT for ground and underwater listening technology. From the current research status in China and abroad, DAS is becoming mature in its hardware performance, such as the demodulation fidelity, sensing distance, detection bandwidth, and sensitivity, which are all approaching their perfection. However, with the rapid advance of DAS applications, the complicated and ever-changing environments for large-scale monitoring have brought about challenges of high false alarm rates due to its advantages of high sensitivity. It is difficult to achieve high-precision detection, recognition, and positioning of perceived vibration and acoustic targets, which has become the biggest technical bottleneck restricting the large-scale application of DAS technology. In recent years, driven by the development of advanced signal processing and artificial intelligence (AI) technology, the signal processing methods of fully intelligent DAS with high accuracy and real-time performance in practical complex environments have become a research hotspot and focus in the field of fiber-optic sensing. The signal processing method in DAS plays a crucial and decisive role in improving the intelligent perception ability of the entire system. Progress We review the current research status of signal processing methods in smart fiber-optic DAS entering the deep learning stage, from mainstream supervised learning to unsupervised, semi-supervised, and transfer learning, from single-source detection to multi-source aliasing detection, and from single-task recognition or localization to simultaneous implementation of recognition and localization tasks, and we predict possible research directions for further improving the intelligent processing performance and perception ability of DAS in the future. Firstly, the typical fiber-optic DAS system structure and its vibration/sound sensing mechanism (Fig. 2), and the smart DAS and its signal processing architecture in smart city monitoring applications (Fig. 3) are introduced. Then, the signal processing methods based on deep learning are explained in detail, which includes the main stream of supervised learning methods based on multi-dimensional information extraction, and semi-supervised, unsupervised learning, and cross-scene transfer learning methods in DAS. For the supervised learning method, it includes DAS signal recognition models based on temporal information extraction, such as one-dimensional convolutional neural networks (1D-CNNs) (Fig. 4), multi-scale convolutional neural networks (MS-CNNs) (Fig. 5), multi-scale and contextual temporal relationship mining methods (Figs. 6-7), and the two-dimensional recognition models based on time-frequency (Figs. 8-11), time-space (Figs. 12-14), and space-frequency (Fig. 15) information extraction technologies. Besides, some other supervised methods are also included, for example, recognition models based on attention-based long short-term memory (Fig. 16) and the fusion of manual features and deep features. It proves that the combination of traditional empirical rules and deep learning networks can further reduce the false alarm rate of the system. In response to the problem of insufficient labeled samples in new scenarios in practical applications, several semi-supervised recognition methods based on the 1D-SSGAN (one-dimensional semi-supervised generative adversarial network), SSAE (sparse stacked autoencoder), and FixMatch models have been involved to achieve accurate recognition of DAS signals with a small amount of labeled data and a large amount of unlabeled data. Furthermore, the SNN-based DAS unsupervised learning network (Fig. 17) and the cross-scene transfer learning network based on AlexNet+SVM (Fig. 18) also appear to improve the generalization ability of DAS signal recognition methods. In order to evaluate the performance of these recognition models, we introduce seven indicators for evaluating the recognition accuracy and four indicators for the processing time of the algorithms. The above key DAS recognition methods and their performance are statistically compared in Table 2. At last, the new challenges of smart DAS sensing, from single-source detection to multi-source aliasing detection, from target recognition to localization, and from a single task to multi-task processing, as well as other methods to enhance its intelligent perception capabilities, have also been introduced. Conclusions and Prospects Further improvement of signal processing and its sensing capabilities still faces new challenges and opportunities and will open a new chapter in fully intelligent DAS. Stable, accurate, real-time, and efficient signal recognition in DAS in new complicated application scenarios remains a research hotspot in the field of distributed fiber-optic sensing in the future, including: 1) improving the generalization ability of DAS recognition models in cross scenarios; 2) significant improvement in real-time processing capabilities in DAS; 3) improvement of multi-task processing ability in DAS; 4) implementation of high-performance on-chip DAS.",
    "doi": "10.3788/AOS231384",
    "author_keywords": [
      "fiber-optic distributed acoustic sensor",
      "fiber-optic Internet of Things",
      "phase-sensitive optical time domain reflectometry",
      "signal processing",
      "smart sensing"
    ],
    "contribution": "In order to evaluate the performance of these recognition models, we introduce seven indicators for evaluating the recognition accuracy and four indicators for the processing time of the algorithms. The above key DAS recognition methods and their performance are statistically compared in Table 2. At last, the new challenges of smart DAS sensing, from single-source detection to multi-source aliasing detection, from target recognition to localization, and from a single task to multi-task processing, as well as other methods to enhance its intelligent perception capabilities, have also been introduced. Conclusions and Prospects Further improvement of signal processing and its sensing capabilities still faces new challenges and opportunities and will open a new chapter in fully intelligent DAS. Stable, accurate, real-time, and efficient signal recognition in DAS in new complicated application scenarios remains a research hotspot in the field of distributed fiber-optic sensing in the future, including: 1) improving the generalization ability of DAS recognition models in cross scenarios; 2) significant improvement in real-time processing capabilities in DAS; 3) improvement of multi-task processing ability in DAS; 4) implementation of high-performance on-chip DAS.",
    "introduction": "Significance Optical fiber sensors play an increasingly important role in safety monitoring areas in the smart Internet of Things (IoT). Particularly, a fiber-optic distributed acoustic sensor (fiber-optic DAS) based on the phase-sensitive optical time-domain reflectometry (Î¦â€‘OTDR) technology provides a highly dense, cost-effective, and continuous environment measurement way over a wide range. All kinds of vibration sources can be sensed and located with high sensitivity and precision utilizing the widely laid ordinary telecommunication cables, and thus fiber-optic DAS has been applied in various ground listening applications, such as natural disaster prediction of ocean-floor seismic activity, volcanic events, and earthquake, energy exploration in oil and gas industry, and civil infrastructure monitoring in the pipelines, railways, and perimeters. It leads to a new generation of large-scale fiber-optic IoT for ground and underwater listening technology. From the current research status in China and abroad, DAS is becoming mature in its hardware performance, such as the demodulation fidelity, sensing distance, detection bandwidth, and sensitivity, which are all approaching their perfection. However, with the rapid advance of DAS applications, the complicated and ever-changing environments for large-scale monitoring have brought about challenges of high false alarm rates due to its advantages of high sensitivity. It is difficult to achieve high-precision detection, recognition, and positioning of perceived vibration and acoustic targets, which has become the biggest technical bottleneck restricting the large-scale application of DAS technology. In recent years, driven by the development of advanced signal processing and artificial intelligence (AI) technology, the signal processing methods of fully intelligent DAS with high accuracy and real-time performance in practical complex environments have become a research hotspot and focus in the field of fiber-optic sensing. The signal processing method in DAS plays a crucial and decisive role in improving the intelligent perception ability of the entire system. Progress We review the current research status of signal processing methods in smart fiber-optic DAS entering the deep learning stage, from mainstream supervised learning to unsupervised, semi-supervised, and transfer learning, from single-source detection to multi-source aliasing detection, and from single-task recognition or localization to simultaneous implementation of recognition and localization tasks, and we predict possible research directions for further improving the intelligent processing performance and perception ability of DAS in the future. Firstly, the typical fiber-optic DAS system structure and its vibration/sound sensing mechanism (Fig. 2), and the smart DAS and its signal processing architecture in smart city monitoring applications (Fig. 3) are introduced. Then, the signal processing methods based on deep learning are explained in detail, which includes the main stream of supervised learning methods based on multi-dimensional information extraction, and semi-supervised, unsupervised learning, and cross-scene transfer learning methods in DAS. For the supervised learning method, it includes DAS signal recognition models based on temporal information extraction, such as one-dimensional convolutional neural networks (1D-CNNs) (Fig. 4), multi-scale convolutional neural networks (MS-CNNs) (Fig. 5), multi-scale and contextual temporal relationship mining methods (Figs. 6-7), and the two-dimensional recognition models based on time-frequency (Figs. 8-11), time-space (Figs. 12-14), and space-frequency (Fig. 15) information extraction technologies. Besides, some other supervised methods are also included, for example, recognition models based on attention-based long short-term memory (Fig. 16) and the fusion of manual features and deep features. It proves that the combination of traditional empirical rules and deep learning networks can further reduce the false alarm rate of the system. In response to the problem of insufficient labeled samples in new scenarios in practical applications, several semi-supervised recognition methods based on the 1D-SSGAN (one-dimensional semi-supervised generative adversarial network), SSAE (sparse stacked autoencoder), and FixMatch models have been involved to achieve accurate recognition of DAS signals with a small amount of labeled data and a large amount of unlabeled data. Furthermore, the SNN-based DAS unsupervised learning network (Fig. 17) and the cross-scene transfer learning network based on AlexNet+SVM (Fig. 18) also appear to improve the generalization ability of DAS signal recognition methods.",
    "macro_domains": []
  },
  {
    "abstract": "Stable Diffusion is a captivating text-to-image model that generates images based on text input. However, a major challenge is that it is pretrained on a specific dataset, limiting its ability to generate images outside of the given data. In this paper, we propose to harness two models based on neural networks, Hypernetworks and DreamBooth, to allow the introduction of any image into Stable Diffusion, addressing versatility with minimal additional training data. This work targets AI applications such as augmenting next-generation multipurpose robots, enhancing human-robot collaboration, feeding intelligent tutoring systems, training autonomous cars, injecting subjects for photo personalization, producing high quality movie animations etc. It can contribute to AI in smart cities: facets such as smart living and smart mobility.",
    "doi": "10.1007/978-3-031-47721-8_44",
    "author_keywords": [
      "ANN",
      "Data mining",
      "Image processing",
      "Movie animations",
      "Photo personalization",
      "Stable diffusion",
      "Text-to-image creation"
    ],
    "contribution": "In this paper, we propose to harness two models based on neural networks, Hypernetworks and DreamBooth, to allow the introduction of any image into Stable Diffusion, addressing versatility with minimal additional training data. This work targets AI applications such as augmenting next-generation multipurpose robots, enhancing human-robot collaboration, feeding intelligent tutoring systems, training autonomous cars, injecting subjects for photo personalization, producing high quality movie animations etc. It can contribute to AI in smart cities: facets such as smart living and smart mobility.",
    "introduction": "Stable Diffusion is a captivating text-to-image model that generates images based on text input. However, a major challenge is that it is pretrained on a specific dataset, limiting its ability to generate images outside of the given data.",
    "macro_domains": []
  },
  {
    "abstract": "Smart cities are promising communities that leverage intelligent technologies to connect citizens through internet devices, thereby improving their quality of life. This is especially crucial for citizens with disabilities, who face significant challenges in urban living. This paper reviews, summarises, and synthesises the current literature on smart cities for people with disabilities. The analysis is grounded in a sociotechnical framework and the Quadruple Helix Model, with a focus on effective collaborations among various stakeholders to provide sustainable and inclusive smart cities. In examining 83 peer-reviewed articles, our literature analysis reveals that, despite the growing number of studies on smart cities, very few have explored the challenges and opportunities for people with disabilities from a socio-technical and collaborative perspective. Accordingly, we call for interdisciplinary research to understand how smart technologies should be developed, implemented, and used to address the special needs of people with disabilities and to build inclusive and technologically advanced smart cities. This study contributes to both research and practice by highlighting the underexamined area of inclusive smart cities. It provides a conceptual framework that can serve as a guideline to address and enhance the understanding of the critical role of smart cities in fostering social inclusion.",
    "doi": "10.1080/0960085X.2023.2297974",
    "author_keywords": [
      "generative AI",
      "internet of things",
      "people with disabilities",
      "quadruple helix model",
      "Smart cities",
      "social inclusion"
    ],
    "contribution": "This paper reviews, summarises, and synthesises the current literature on smart cities for people with disabilities. The analysis is grounded in a sociotechnical framework and the Quadruple Helix Model, with a focus on effective collaborations among various stakeholders to provide sustainable and inclusive smart cities. In examining 83 peer-reviewed articles, our literature analysis reveals that, despite the growing number of studies on smart cities, very few have explored the challenges and opportunities for people with disabilities from a socio-technical and collaborative perspective. Accordingly, we call for interdisciplinary research to understand how smart technologies should be developed, implemented, and used to address the special needs of people with disabilities and to build inclusive and technologically advanced smart cities. This study contributes to both research and practice by highlighting the underexamined area of inclusive smart cities. It provides a conceptual framework that can serve as a guideline to address and enhance the understanding of the critical role of smart cities in fostering social inclusion.",
    "introduction": "Smart cities are promising communities that leverage intelligent technologies to connect citizens through internet devices, thereby improving their quality of life. This is especially crucial for citizens with disabilities, who face significant challenges in urban living.",
    "macro_domains": []
  },
  {
    "abstract": "Semantic image synthesis, a pivotal task in image-to-image translation, has been widely addressed using generative adversarial network (GAN) models. However, existing GAN-based approaches often suffer from inadequate incorporation of structural and spatial information, resulting in unsatisfactory quality of the synthesized images and a pronounced disparity between photo-realistic and generated images. In this paper, we propose a novel GAN-based methodology to address these limitations, enabling the generation of high-resolution images from semantic label maps while bridging the quality gap and preserving detailed information in the generated outputs. The proposed approach leverages a two-step process, starting with a local binary pattern convolutional generator that produces a local binary pattern feature map. Subsequently, a global convolutional generator is fed with the segmentation map and the feature map through a learned modulation scheme facilitated by a multi-feature adaptive denormalization layer (MFADE) during the training process to generate photo-realistic images. Extensive experiments using Cityscapes, ADE20K, and COCO-stuff datasets validate the performance of our proposed method and showcase its accuracy and robustness in addressing semantic image synthesis tasks, thereby paving the way for its potential applications in enhancing urban sensing and data analytics in Smart Cities. The source code is available at https://github.com/karimmagdy/ULBPGAN.",
    "doi": "10.1007/978-3-031-49333-1_24",
    "author_keywords": [
      "Generative Adversarial Networks (GANs)",
      "Local Binary Pattern (LBP)",
      "Semantic Image Synthesis"
    ],
    "contribution": "In this paper, we propose a novel GAN-based methodology to address these limitations, enabling the generation of high-resolution images from semantic label maps while bridging the quality gap and preserving detailed information in the generated outputs. The proposed approach leverages a two-step process, starting with a local binary pattern convolutional generator that produces a local binary pattern feature map. Subsequently, a global convolutional generator is fed with the segmentation map and the feature map through a learned modulation scheme facilitated by a multi-feature adaptive denormalization layer (MFADE) during the training process to generate photo-realistic images. Extensive experiments using Cityscapes, ADE20K, and COCO-stuff datasets validate the performance of our proposed method and showcase its accuracy and robustness in addressing semantic image synthesis tasks, thereby paving the way for its potential applications in enhancing urban sensing and data analytics in Smart Cities. The source code is available at https://github.com/karimmagdy/ULBPGAN.",
    "introduction": "Semantic image synthesis, a pivotal task in image-to-image translation, has been widely addressed using generative adversarial network (GAN) models. However, existing GAN-based approaches often suffer from inadequate incorporation of structural and spatial information, resulting in unsatisfactory quality of the synthesized images and a pronounced disparity between photo-realistic and generated images.",
    "macro_domains": []
  },
  {
    "abstract": "Semantic segmentation of large-scale point clouds provides foundational knowledge for various geodetic and cartographic applications, including autonomous driving, smart cities, and indoor navigation. However, point cloud data's unstructured and inherently disordered characteristics pose challenges in extracting accurate 3-D semantic information. In this study, we introduce a novel semantic segmentation network for large-scale point cloud scenes, referred to as dense dual-branch cross attention network (D2CAN). We propose a local multidimensional feature aggregation (LMFA) module to increase multidimensional feature representation types and preserve rich local details. Based on the augmented local features, an expanded dual-branch cross attention (EDCA) module establishes internal deep connections between multidimensional attributes and semantic features. This assists the network in reducing boundary ambiguities and expanding the receptive field, enabling the parallel capture of long-range contexts specifically adapted for large-scale scene point cloud segmentation. These two modules work collaboratively to constitute a local context deep perception (LCDP) block. To reduce information loss during feature sampling and propagation, we propose a global feature pyramid dense fusion (GFDF) block. This block adaptively integrates features across different scales and effectively captures global context with long-range dependencies. In conclusion, D2CAN combines LCDP and GFDF to aggregate both local and global contexts, resulting in robust feature discrimination for semantic segmentation of large-scale scenes. Our method's effectiveness and superior generation ability have been validated across three challenging benchmarks and achieve state-of-the-art performance on Toronto-3D, SensatUrban, and Stanford large-scale 3-D indoor spaces (S3DIS) datasets, with mean intersection over union (IoU) values of 83.5%, 61.1%, and 72.3%, respectively.",
    "doi": "10.1109/TGRS.2023.3341894",
    "author_keywords": [
      "Attention mechanism",
      "deep learning",
      "large-scale point clouds",
      "multiscale fusion",
      "point cloud segmentation",
      "semantic segmentation"
    ],
    "contribution": "In this study, we introduce a novel semantic segmentation network for large-scale point cloud scenes, referred to as dense dual-branch cross attention network (D2CAN). We propose a local multidimensional feature aggregation (LMFA) module to increase multidimensional feature representation types and preserve rich local details. Based on the augmented local features, an expanded dual-branch cross attention (EDCA) module establishes internal deep connections between multidimensional attributes and semantic features. This assists the network in reducing boundary ambiguities and expanding the receptive field, enabling the parallel capture of long-range contexts specifically adapted for large-scale scene point cloud segmentation. These two modules work collaboratively to constitute a local context deep perception (LCDP) block. To reduce information loss during feature sampling and propagation, we propose a global feature pyramid dense fusion (GFDF) block. This block adaptively integrates features across different scales and effectively captures global context with long-range dependencies. In conclusion, D2CAN combines LCDP and GFDF to aggregate both local and global contexts, resulting in robust feature discrimination for semantic segmentation of large-scale scenes. Our method's effectiveness and superior generation ability have been validated across three challenging benchmarks and achieve state-of-the-art performance on Toronto-3D, SensatUrban, and Stanford large-scale 3-D indoor spaces (S3DIS) datasets, with mean intersection over union (IoU) values of 83.5%, 61.1%, and 72.3%, respectively.",
    "introduction": "Semantic segmentation of large-scale point clouds provides foundational knowledge for various geodetic and cartographic applications, including autonomous driving, smart cities, and indoor navigation. However, point cloud data's unstructured and inherently disordered characteristics pose challenges in extracting accurate 3-D semantic information.",
    "macro_domains": []
  },
  {
    "abstract": "With the development of the field of deep learning, image recognition, enhancement and other technologies have been widely used.However, dark lighting environments in reality, such as insufficient light at night, cause or block photographic images in low brightness, severe noise, and a large number of details are lost, resulting in a huge loss of image content and information, which hinders further analysis and use. Such problems not only exist in the traditional deep learning field, but also exist in criminal investigation, scientific photography and other fields, such as the accuracy of low-light image. However, in the current research results, there is no perfect means to deal with the above problems. Therefore, the study of low-light image enhancement has important theoretical significance and practical application value for the development of smart cities. In order to improve the quality of low-light enhanced images, this paper tries to introduce the luminance attention mechanism to improve the enhancement efficiency. The main contents of this paper are summarized as follows: using the attention mechanism, we proposed a method of low-light image enhancement based on the brightness attention mechanism and generative adversarial networks. This method uses brightness attention mechanism to predict the illumination distribution of low-light image and guides the enhancement network to enhance the image adaptiveness in different luminance regions. At the same time, u-NET network is designed and constructed to improve the modeling process of low-light image. We verified the performance of the algorithm on the synthetic data set and compared it with traditional image enhancement methods (HE, SRIE) and deep learning methods (DSLR). The experimental results show that our proposed network model has relatively good enhancement quality for low-light images, and improves the overall robustness, which has practical significance for solving the problem of low-light image enhancement.",
    "doi": "10.1007/s11042-023-15815-x",
    "author_keywords": [
      "Attention mechanism",
      "Generative adversarial networks",
      "Low-light image enhancement"
    ],
    "contribution": "Therefore, the study of low-light image enhancement has important theoretical significance and practical application value for the development of smart cities. In order to improve the quality of low-light enhanced images, this paper tries to introduce the luminance attention mechanism to improve the enhancement efficiency. The main contents of this paper are summarized as follows: using the attention mechanism, we proposed a method of low-light image enhancement based on the brightness attention mechanism and generative adversarial networks. This method uses brightness attention mechanism to predict the illumination distribution of low-light image and guides the enhancement network to enhance the image adaptiveness in different luminance regions. At the same time, u-NET network is designed and constructed to improve the modeling process of low-light image. We verified the performance of the algorithm on the synthetic data set and compared it with traditional image enhancement methods (HE, SRIE) and deep learning methods (DSLR). The experimental results show that our proposed network model has relatively good enhancement quality for low-light images, and improves the overall robustness, which has practical significance for solving the problem of low-light image enhancement.",
    "introduction": "With the development of the field of deep learning, image recognition, enhancement and other technologies have been widely used.However, dark lighting environments in reality, such as insufficient light at night, cause or block photographic images in low brightness, severe noise, and a large number of details are lost, resulting in a huge loss of image content and information, which hinders further analysis and use. Such problems not only exist in the traditional deep learning field, but also exist in criminal investigation, scientific photography and other fields, such as the accuracy of low-light image. However, in the current research results, there is no perfect means to deal with the above problems.",
    "macro_domains": []
  },
  {
    "abstract": "Crowdsourcing has gradually become an effective e-government process to gather citizen complaints over the implementation of various public services. In practice, the collected complaints form a massive dataset, making it difficult for government officers to analyze the big data effectively. It is consequently vital to use data mining algorithms to classify the citizen complaint data for efficient follow-up actions. However, different classification algorithms produce varied classification accuracies. Thus, this study aimed to compare the accuracy of several classification algorithms on crowdsourced citizen complaint data. Taking the case of the LAKSA app in Tangerang City, Indonesia, this study included k-Nearest Neighbors, Random Forest, Support Vector Machine, and AdaBoost for the accuracy assessment. The data were taken from crowdsourced citizen complaints submitted to the LAKSA app, including those aggregated from official social media channels, from May 2021 to April 2022. The results showed SVM with a linear kernel as the most accurate among the assessed algorithms (89.2%). In contrast, AdaBoost (base learner: Decision Trees) produced the lowest accuracy. Still, the accuracy levels of all algorithms varied in parallel to the amount of training data available for the actual classification categories. Overall, the assessments on all algorithms indicated that their accuracies were insignificantly different, with an overall variation of 4.3%. The AdaBoost-based classification, in particular, showed its large dependence on the choice of base learners. Looking at the method and results, this study contributes to e-government, data mining, and big data discourses. This research recommends that governments continuously conduct supervised training of classification algorithms over their crowdsourced citizen complaints to seek the highest accuracy possible, paving the way for smart and sustainable governance.",
    "doi": "10.3390/informatics10040084",
    "author_keywords": [
      "citizen science",
      "crowdsourcing",
      "generative AI",
      "knowledge extraction",
      "large language model",
      "machine learning",
      "public complaint",
      "smart city",
      "sustainable city",
      "text mining"
    ],
    "contribution": "Thus, this study aimed to compare the accuracy of several classification algorithms on crowdsourced citizen complaint data. Taking the case of the LAKSA app in Tangerang City, Indonesia, this study included k-Nearest Neighbors, Random Forest, Support Vector Machine, and AdaBoost for the accuracy assessment. The data were taken from crowdsourced citizen complaints submitted to the LAKSA app, including those aggregated from official social media channels, from May 2021 to April 2022. The results showed SVM with a linear kernel as the most accurate among the assessed algorithms (89.2%). In contrast, AdaBoost (base learner: Decision Trees) produced the lowest accuracy. Still, the accuracy levels of all algorithms varied in parallel to the amount of training data available for the actual classification categories. Overall, the assessments on all algorithms indicated that their accuracies were insignificantly different, with an overall variation of 4.3%. The AdaBoost-based classification, in particular, showed its large dependence on the choice of base learners. Looking at the method and results, this study contributes to e-government, data mining, and big data discourses. This research recommends that governments continuously conduct supervised training of classification algorithms over their crowdsourced citizen complaints to seek the highest accuracy possible, paving the way for smart and sustainable governance.",
    "introduction": "Crowdsourcing has gradually become an effective e-government process to gather citizen complaints over the implementation of various public services. In practice, the collected complaints form a massive dataset, making it difficult for government officers to analyze the big data effectively. It is consequently vital to use data mining algorithms to classify the citizen complaint data for efficient follow-up actions. However, different classification algorithms produce varied classification accuracies.",
    "macro_domains": []
  },
  {
    "abstract": "Birdâ€™s eye view (BEV) semantic maps have evolved into a crucial element of urban intelligent traffic management and monitoring, offering invaluable visual and significant data representations for informed intelligent city decision making. Nevertheless, current methodologies continue underutilizing the temporal information embedded within dynamic frames throughout the BEV feature transformation process. This limitation results in decreased accuracy when mapping high-speed moving objects, particularly in capturing their shape and dynamic trajectory. A framework is proposed for cross-view semantic segmentation to address this challenge, leveraging simulated environments as a starting point before applying it to real-life urban imaginative transportation scenarios. The view converter module is thoughtfully designed to collate information from multiple initial view observations captured from various angles and modes. This module outputs a top-down view semantic graph characterized by its object space layout to preserve beneficial temporal information in BEV transformation. The NuScenes dataset is used to evaluate model effectiveness. A novel application is also devised that harnesses transformer networks to map images and video sequences into top-down or comprehensive birdâ€™s-eye views. By combining physics-based and constraint-based formulations and conducting ablation studies, the approach has been substantiated, highlighting the significance of context above and below a given point in generating these maps. This innovative method has been thoroughly validated on the NuScenes dataset. Notably, it has yielded state-of-the-art instantaneous mapping results, with particular benefits observed for smaller dynamic category displays. The experimental findings include comparing axial attention with the state-of-the-art (SOTA) model, demonstrating the performance enhancement associated with temporal awareness.",
    "doi": "10.3390/electronics12245017",
    "author_keywords": [
      "BEV",
      "urban intelligent traffic management",
      "view semantic graph"
    ],
    "contribution": "",
    "introduction": "Birdâ€™s eye view (BEV) semantic maps have evolved into a crucial element of urban intelligent traffic management and monitoring, offering invaluable visual and significant data representations for informed intelligent city decision making. Nevertheless, current methodologies continue underutilizing the temporal information embedded within dynamic frames throughout the BEV feature transformation process. This limitation results in decreased accuracy when mapping high-speed moving objects, particularly in capturing their shape and dynamic trajectory. A framework is proposed for cross-view semantic segmentation to address this challenge, leveraging simulated environments as a starting point before applying it to real-life urban imaginative transportation scenarios. The view converter module is thoughtfully designed to collate information from multiple initial view observations captured from various angles and modes. This module outputs a top-down view semantic graph characterized by its object space layout to preserve beneficial temporal information in BEV transformation. The NuScenes dataset is used to evaluate model effectiveness. A novel application is also devised that harnesses transformer networks to map images and video sequences into top-down or comprehensive birdâ€™s-eye views. By combining physics-based and constraint-based formulations and conducting ablation studies, the approach has been substantiated, highlighting the significance of context above and below a given point in generating these maps. This innovative method has been thoroughly validated on the NuScenes dataset. Notably, it has yielded state-of-the-art instantaneous mapping results, with particular benefits observed for smaller dynamic category displays. The experimental findings include comparing axial attention with the state-of-the-art (SOTA) model, demonstrating the performance enhancement associated with temporal awareness.",
    "macro_domains": []
  },
  {
    "abstract": "Carbon Dioxide (CO 2) is a significant contributor to greenhouse gas emissions and one of the main drivers behind global warming and climate change. In spite of the global economic slowdown due to the COVID-19 pandemic, the global average atmospheric CO 2 concentration reached a new record high in 2020 with its year-on-year increase being the fifth highest annual increase in 63 years, according to the National Oceanic and Atmospheric Administration. Furthermore, the years 2020 and 2019 were respectively the second and third warmest, while the decade 2010â€“2019 was the warmest decade ever recorded. In an attempt to curb this climate emergency, many countries and organizations globally have adopted ambitious goals and announced plans to help dramatically reduce CO 2 emissions. As part of these plans, various innovative smart city projects are being developed, focusing on implementing Internet of Things (IoT) technologies. By collecting sensor-based data, such technologies aim towards automating data-driven decision-making around carbon emission management and reduction. In this work, a hybrid machine learning system, aimed at forecasting CO 2 concentration levels in a smart city environment was developed using a multivariate time series dataset containing IoT sensor measurements of CO 2 , as well as various environmental factors, taken at every second. The proposed system demonstrated superior performance to similar methods, while also maintaining a high degree of interpretability. More specifically, the approach was empirically compared against other similar approaches in several scenarios and use cases, thus also offering more insight into the predictive capabilities of such state-of-the-art systems. For this comparison, both traditional time series and deep learning approaches were employed, including the current state-of-the-art architectures, such as attention-based, transformer networks. Results demonstrated that, when measured across various settings and metrics, including three different forecasting horizons, the hybrid solution achieved the best overall results, and in some cases, the difference in performance was statistically significant. At the same time, insights from the systemâ€™s inner workings were extracted, shedding light on the reasoning behind the modelâ€™s predictions and the factors that contribute to them, thus showcasing its transparency. Lastly, throughout the experiments, deep learning approaches illustrated their ability to better handle the multivariate nature of the dataset and in general tended to outperform the traditional time series methods, especially for longer forecasting horizons.",
    "doi": "10.1038/s41598-023-42346-0",
    "author_keywords": null,
    "contribution": "In this work, a hybrid machine learning system, aimed at forecasting CO 2 concentration levels in a smart city environment was developed using a multivariate time series dataset containing IoT sensor measurements of CO 2 , as well as various environmental factors, taken at every second. The proposed system demonstrated superior performance to similar methods, while also maintaining a high degree of interpretability. More specifically, the approach was empirically compared against other similar approaches in several scenarios and use cases, thus also offering more insight into the predictive capabilities of such state-of-the-art systems. For this comparison, both traditional time series and deep learning approaches were employed, including the current state-of-the-art architectures, such as attention-based, transformer networks. Results demonstrated that, when measured across various settings and metrics, including three different forecasting horizons, the hybrid solution achieved the best overall results, and in some cases, the difference in performance was statistically significant. At the same time, insights from the systemâ€™s inner workings were extracted, shedding light on the reasoning behind the modelâ€™s predictions and the factors that contribute to them, thus showcasing its transparency. Lastly, throughout the experiments, deep learning approaches illustrated their ability to better handle the multivariate nature of the dataset and in general tended to outperform the traditional time series methods, especially for longer forecasting horizons.",
    "introduction": "Carbon Dioxide (CO 2) is a significant contributor to greenhouse gas emissions and one of the main drivers behind global warming and climate change. In spite of the global economic slowdown due to the COVID-19 pandemic, the global average atmospheric CO 2 concentration reached a new record high in 2020 with its year-on-year increase being the fifth highest annual increase in 63 years, according to the National Oceanic and Atmospheric Administration. Furthermore, the years 2020 and 2019 were respectively the second and third warmest, while the decade 2010â€“2019 was the warmest decade ever recorded. In an attempt to curb this climate emergency, many countries and organizations globally have adopted ambitious goals and announced plans to help dramatically reduce CO 2 emissions. As part of these plans, various innovative smart city projects are being developed, focusing on implementing Internet of Things (IoT) technologies. By collecting sensor-based data, such technologies aim towards automating data-driven decision-making around carbon emission management and reduction.",
    "macro_domains": []
  },
  {
    "abstract": "Activity pattern prediction is a critical part of urban computing, urban planning, intelligent transportation, and so on. Based on a dataset with more than 10 million GPS trajectory records collected by mobile sensors, this research proposed a CNN-BiLSTM-VAE-ATT-based encoder-decoder model for fine-grained individual activity sequence prediction. The model combines the long-term and short-term dependencies crosswise and also considers randomness, diversity, and uncertainty of individual activity patterns. The proposed results show higher accuracy compared to the ten baselines. The model can generate high diversity results while approximating the original activity patterns distribution. Moreover, the model also has interpretability in revealing the time dependency importance of the activity pattern prediction.",
    "doi": "10.1109/TBDATA.2023.3310241",
    "author_keywords": [
      "Activity pattern prediction",
      "Big GPS data",
      "Human mobility",
      "LSTM",
      "Variational autoencoder"
    ],
    "contribution": "Based on a dataset with more than 10 million GPS trajectory records collected by mobile sensors, this research proposed a CNN-BiLSTM-VAE-ATT-based encoder-decoder model for fine-grained individual activity sequence prediction. The model combines the long-term and short-term dependencies crosswise and also considers randomness, diversity, and uncertainty of individual activity patterns. The proposed results show higher accuracy compared to the ten baselines. The model can generate high diversity results while approximating the original activity patterns distribution. Moreover, the model also has interpretability in revealing the time dependency importance of the activity pattern prediction.",
    "introduction": "Activity pattern prediction is a critical part of urban computing, urban planning, intelligent transportation, and so on.",
    "macro_domains": []
  },
  {
    "abstract": "Climate change is one of the most trend topics of the decade in the world. The recent years were the warmest in 139 years, however identifying deniers and believers of this subject still a very big issue. The challenge is to have an efficient tool to detect deniers in order to deploy the appropriate strategy facing this phenomenon. Moreover, Bidirectional Encoder Representations from Transformers (BERT) pre-trained model has taken Natural Language Processing tasks results so far. In this paper we presented an efficient technological tool based on deep learning model and BERT model for detecting peopleâ€™s opinions on climate change on social media platforms. We used convolutional neural network targeting the public opinions on climate change on Twitter. The results showed that our model outperforms the machine learning approaches: Naive Bays, Support Vector Machine and Logistic Regression. This model is able to analyze peopleâ€™s behavior and detect believers and deniers of this disaster with high accuracy results (98% for believers and 90% for deniers). Our model could be a powerful citizen sensing tool that can be used by governments for monitoring and governance, especially for smart cities.",
    "doi": "10.1007/s13278-022-01014-3",
    "author_keywords": [
      "Climate change",
      "Convolutional neural network",
      "Sentiment analysis",
      "Twitter"
    ],
    "contribution": "In this paper we presented an efficient technological tool based on deep learning model and BERT model for detecting peopleâ€™s opinions on climate change on social media platforms. We used convolutional neural network targeting the public opinions on climate change on Twitter. The results showed that our model outperforms the machine learning approaches: Naive Bays, Support Vector Machine and Logistic Regression. This model is able to analyze peopleâ€™s behavior and detect believers and deniers of this disaster with high accuracy results (98% for believers and 90% for deniers). Our model could be a powerful citizen sensing tool that can be used by governments for monitoring and governance, especially for smart cities.",
    "introduction": "Climate change is one of the most trend topics of the decade in the world. The recent years were the warmest in 139 years, however identifying deniers and believers of this subject still a very big issue. The challenge is to have an efficient tool to detect deniers in order to deploy the appropriate strategy facing this phenomenon. Moreover, Bidirectional Encoder Representations from Transformers (BERT) pre-trained model has taken Natural Language Processing tasks results so far.",
    "macro_domains": []
  },
  {
    "abstract": "Accurately predicting base station traffic volumes and understanding mobile traffic patterns is essential for smart city development, enabling efficient resource allocation and ensuring high-quality communication services. However, existing works have limitations in capturing spatial information, though the surrounding environment plays a critical role in mobile traffic prediction. In this paper, we utilize a spatial knowledge graph to represent spatial information and add important urban components to augment it making it a more effective tool for capturing environmental information. we further propose a multi-relational knowledge graph convolutional network model for mobile traffic prediction, which consists of three parts. The environmental context modelling captures spatial information from the augmented spatial knowledge graph using tucker decomposition and relational graph convolutional network. The semantic relationship modelling extracts semantic relationships between base stations and employs transformer and causal convolution to capture temporal features. The inter-attentional fusion modelling utilizes the self-attention mechanism to further capture base station relationships and predict future traffic volumes. Extensive experiments demonstrate that our proposed model significantly outperforms the state-of-the-art models by over 10% in mobile traffic prediction. The code is available at https://github.com/tsinghua-fiblab/Mobile-Traffic-Prediction-sigspatial23",
    "doi": "10.1145/3589132.3625569",
    "author_keywords": [
      "graph neural networks",
      "knowledge graph",
      "mobile traffic prediction"
    ],
    "contribution": "In this paper, we utilize a spatial knowledge graph to represent spatial information and add important urban components to augment it making it a more effective tool for capturing environmental information. we further propose a multi-relational knowledge graph convolutional network model for mobile traffic prediction, which consists of three parts. The environmental context modelling captures spatial information from the augmented spatial knowledge graph using tucker decomposition and relational graph convolutional network. The semantic relationship modelling extracts semantic relationships between base stations and employs transformer and causal convolution to capture temporal features. The inter-attentional fusion modelling utilizes the self-attention mechanism to further capture base station relationships and predict future traffic volumes. Extensive experiments demonstrate that our proposed model significantly outperforms the state-of-the-art models by over 10% in mobile traffic prediction. The code is available at https://github.com/tsinghua-fiblab/Mobile-Traffic-Prediction-sigspatial23",
    "introduction": "Accurately predicting base station traffic volumes and understanding mobile traffic patterns is essential for smart city development, enabling efficient resource allocation and ensuring high-quality communication services. However, existing works have limitations in capturing spatial information, though the surrounding environment plays a critical role in mobile traffic prediction.",
    "macro_domains": []
  },
  {
    "abstract": "One of the major problems that cause continual trouble in deep learning networks is that training a large network requires massive labelled datasets. The preparation of a massive labelled dataset is a cumbersome task and requires lot of human interventions. This paper proposes a novel generator network â€˜Sim2Realâ€™ transfer is a recent and fast-developing field in machine learning used to bridge the gap between simulated and real data. Training with simulated datasets often converges due to its size but fails to generalize real-world applications. Simulated datasets can be used to train and test deep learning models, enables the development and evaluation of new algorithms and architectures. By simulating road dataset, researchers can generate large amounts of realistic road-traffic dataset that can be used to study and understand several problems such as vehicular object tracking and classification, traffic situation analysis etc. The main advantage of such a transfer algorithm is to use the abundance of a simulated dataset to generate huge realistic-looking datasets to solve data-intense tasks. This work presents a novel, robust sim2real algorithm that converts the labels of a semantic segmentation map to a realistic-looking street view using the Cityscapes dataset and aims to achieve robust urban mobility for smart cities. Further, the generalizability of the Cycle Generative Adversarial Network (CycleGAN) architecture was tested by using an origami robot dataset for sim2real transfer. We show that the results were found to be qualitatively satisfactory for different traffic analysis applications. In addition, road perception was done using a lightweight SVM pipeline and evaluated on the KITTI dataset. We have incorporated Cycle Consistency Loss and Identity Loss as the metrics to evaluate the performance of the proposed Cycle GAN model. We inferred that the proposed Cycle GAN model provides an Identity loss of less than 0.2 in both the Cityscapes dataset and KITTI datasets. Also, we understand that the super-pixel resolution has a good impact on the quantitative results of the proposed Cycle GAN models.",
    "doi": "10.1371/journal.pone.0293978",
    "author_keywords": null,
    "contribution": "This paper proposes a novel generator network â€˜Sim2Realâ€™ transfer is a recent and fast-developing field in machine learning used to bridge the gap between simulated and real data. Training with simulated datasets often converges due to its size but fails to generalize real-world applications. Simulated datasets can be used to train and test deep learning models, enables the development and evaluation of new algorithms and architectures. By simulating road dataset, researchers can generate large amounts of realistic road-traffic dataset that can be used to study and understand several problems such as vehicular object tracking and classification, traffic situation analysis etc. The main advantage of such a transfer algorithm is to use the abundance of a simulated dataset to generate huge realistic-looking datasets to solve data-intense tasks. This work presents a novel, robust sim2real algorithm that converts the labels of a semantic segmentation map to a realistic-looking street view using the Cityscapes dataset and aims to achieve robust urban mobility for smart cities. Further, the generalizability of the Cycle Generative Adversarial Network (CycleGAN) architecture was tested by using an origami robot dataset for sim2real transfer. We show that the results were found to be qualitatively satisfactory for different traffic analysis applications. In addition, road perception was done using a lightweight SVM pipeline and evaluated on the KITTI dataset. We have incorporated Cycle Consistency Loss and Identity Loss as the metrics to evaluate the performance of the proposed Cycle GAN model. We inferred that the proposed Cycle GAN model provides an Identity loss of less than 0.2 in both the Cityscapes dataset and KITTI datasets. Also, we understand that the super-pixel resolution has a good impact on the quantitative results of the proposed Cycle GAN models.",
    "introduction": "One of the major problems that cause continual trouble in deep learning networks is that training a large network requires massive labelled datasets. The preparation of a massive labelled dataset is a cumbersome task and requires lot of human interventions.",
    "macro_domains": []
  },
  {
    "abstract": "In the context of smart city development, video surveillance serves as a critical component for maintaining public safety and operational efficiency. However, traditional surveillance systems are often constrained by a limited dynamic range, leading to the loss of essential image details. To address this limitation, this paper introduces HDRFormer, an innovative framework designed to enhance high dynamic range (HDR) image quality in edgeâ€“cloud-based video surveillance systems. Leveraging advanced deep learning algorithms and Internet of Things (IoT) technology, HDRFormer employs a unique architecture comprising a feature extraction module (FEM) and a weighted attention module (WAM). The FEM leverages a transformer-based hierarchical structure to adeptly capture multi-scale image information. In addition, the guided filters are utilized to steer the network, thereby enhancing the structural integrity of the images. On the other hand, the WAM focuses on reconstructing saturated areas, improving the perceptual quality of the images, and rendering the reconstructed HDR images with naturalness and color saturation. Extensive experiments on multiple HDR image reconstruction datasets demonstrate HDRFormerâ€™s substantial improvements, achieving up to a 2.7 dB increase in the peak signal-to-noise ratio (PSNR) and an enhancement of 0.09 in the structural similarity (SSIM) compared to existing methods. In addition, the framework exhibits outstanding performance in multi-scale structural similarity (MS-SSIM) and HDR visual difference predictor (HDR-VDP2.2). The proposed method not only outperforms the existing HDR reconstruction techniques but also offers better generalization capabilities, laying a robust foundation for future applications in smart cities.",
    "doi": "10.3390/electronics12224625",
    "author_keywords": [
      "attention mechanism",
      "guided filter",
      "high dynamic range",
      "image reconstruction",
      "smart city",
      "surveillance system",
      "vision transformer"
    ],
    "contribution": "To address this limitation, this paper introduces HDRFormer, an innovative framework designed to enhance high dynamic range (HDR) image quality in edgeâ€“cloud-based video surveillance systems. Leveraging advanced deep learning algorithms and Internet of Things (IoT) technology, HDRFormer employs a unique architecture comprising a feature extraction module (FEM) and a weighted attention module (WAM). The FEM leverages a transformer-based hierarchical structure to adeptly capture multi-scale image information. In addition, the guided filters are utilized to steer the network, thereby enhancing the structural integrity of the images. On the other hand, the WAM focuses on reconstructing saturated areas, improving the perceptual quality of the images, and rendering the reconstructed HDR images with naturalness and color saturation. Extensive experiments on multiple HDR image reconstruction datasets demonstrate HDRFormerâ€™s substantial improvements, achieving up to a 2.7 dB increase in the peak signal-to-noise ratio (PSNR) and an enhancement of 0.09 in the structural similarity (SSIM) compared to existing methods. In addition, the framework exhibits outstanding performance in multi-scale structural similarity (MS-SSIM) and HDR visual difference predictor (HDR-VDP2.2). The proposed method not only outperforms the existing HDR reconstruction techniques but also offers better generalization capabilities, laying a robust foundation for future applications in smart cities.",
    "introduction": "In the context of smart city development, video surveillance serves as a critical component for maintaining public safety and operational efficiency. However, traditional surveillance systems are often constrained by a limited dynamic range, leading to the loss of essential image details.",
    "macro_domains": []
  },
  {
    "abstract": "Effective response strategies to earthquake disasters are crucial for disaster management in smart cities. However, in regions where earthquakes do not occur frequently, model construction may be difficult due to a lack of training data. To address this issue, there is a need for technology that can generate earthquake scenarios for response training at any location. We proposed a model for generating earthquake scenarios using an auxiliary classifier Generative Adversarial Network (AC-GAN)-based data synthesis. The proposed ACGAN model generates various earthquake scenarios by incorporating an auxiliary classifier learning process into the discriminator of GAN. Our results at borehole sensors showed that the seismic data generated by the proposed model had similar characteristics to actual data. To further validate our results, we compared the generated IM (such as PGA, PGV, and SA) with Ground Motion Prediction Equations (GMPE). Furthermore, we evaluated the potential of using the generated scenarios for earthquake early warning training. The proposed model and algorithm have significant potential in advancing seismic analysis and detection management systems, and also contribute to disaster management.",
    "doi": "10.3390/s23229209",
    "author_keywords": [
      "borehole-seismometer",
      "earthquake early warning",
      "Generative Adversarial Network",
      "seismic sensor",
      "virtual seismic scenarios"
    ],
    "contribution": "",
    "introduction": "Effective response strategies to earthquake disasters are crucial for disaster management in smart cities. However, in regions where earthquakes do not occur frequently, model construction may be difficult due to a lack of training data. To address this issue, there is a need for technology that can generate earthquake scenarios for response training at any location. We proposed a model for generating earthquake scenarios using an auxiliary classifier Generative Adversarial Network (AC-GAN)-based data synthesis. The proposed ACGAN model generates various earthquake scenarios by incorporating an auxiliary classifier learning process into the discriminator of GAN. Our results at borehole sensors showed that the seismic data generated by the proposed model had similar characteristics to actual data. To further validate our results, we compared the generated IM (such as PGA, PGV, and SA) with Ground Motion Prediction Equations (GMPE). Furthermore, we evaluated the potential of using the generated scenarios for earthquake early warning training. The proposed model and algorithm have significant potential in advancing seismic analysis and detection management systems, and also contribute to disaster management.",
    "macro_domains": []
  },
  {
    "abstract": "Pedestrian gender classification (PGC) is a key task in full-body-based pedestrian image analysis and has become an important area in applications like content-based image retrieval, visual surveillance, smart city, and demographic collection. In the last decade, convolutional neural networks (CNN) have appeared with great potential and with reliable choices for vision tasks, such as object classification, recognition, detection, etc. But CNN has a limited local receptive field that prevents them from learning information about the global context. In contrast, a vision transformer (ViT) is a better alternative to CNN because it utilizes a self-attention mechanism to attend to a different patch of an input image. In this work, generic and effective modules such as locality self-attention (LSA), and shifted patch tokenization (SPT)-based vision transformer model are explored for the PGC task. With the use of these modules in ViT, it is successfully able to learn from stretch even on small-size (SS) datasets and overcome the lack of locality inductive bias. Through extensive experimentation, we found that the proposed ViT model produced better results in terms of overall and mean accuracies. The better results confirm that ViT outperformed state-of-the-art (SOTA) PGC methods.",
    "doi": "10.1007/s10044-023-01196-2",
    "author_keywords": [
      "Deep CNN models",
      "LSA and SPT",
      "Pedestrian gender classification",
      "SS datasets",
      "Vision transformer"
    ],
    "contribution": "In this work, generic and effective modules such as locality self-attention (LSA), and shifted patch tokenization (SPT)-based vision transformer model are explored for the PGC task. With the use of these modules in ViT, it is successfully able to learn from stretch even on small-size (SS) datasets and overcome the lack of locality inductive bias. Through extensive experimentation, we found that the proposed ViT model produced better results in terms of overall and mean accuracies. The better results confirm that ViT outperformed state-of-the-art (SOTA) PGC methods.",
    "introduction": "Pedestrian gender classification (PGC) is a key task in full-body-based pedestrian image analysis and has become an important area in applications like content-based image retrieval, visual surveillance, smart city, and demographic collection. In the last decade, convolutional neural networks (CNN) have appeared with great potential and with reliable choices for vision tasks, such as object classification, recognition, detection, etc. But CNN has a limited local receptive field that prevents them from learning information about the global context. In contrast, a vision transformer (ViT) is a better alternative to CNN because it utilizes a self-attention mechanism to attend to a different patch of an input image.",
    "macro_domains": []
  },
  {
    "abstract": "The conventional approaches for traffic intensity (TI) detection in smart cities use specialized sensors, such as loop detectors, cameras, and radar. These sensors come with high costs, limited reuse, and specialized maintenance. Thus, we propose the utilization of general-purpose sensing, which involves the use of cost-effective and easily deployable sensors, such as microphones, and air quality sensors that are cheaper, reusable, and easily manageable sensors. A general-purpose sensing infrastructure can be used for several applications including measuring TI. The main objective of this letter is to demonstrate how noise signatures can be leveraged to measure TI. Traditionally, image classification techniques are used for audio data analysis and vision-transformers (ViT) have shown remarkable results in this area. However, there is limited research that explores ViT models for traffic intensity detection. For TI detection, two approaches: vehicle count prediction and vehicle type detection (VTD), which use ViT models, are proposed. VTD approach performed better and it achieved an F1-score of 0.95 and a mean vehicle counting error of 0.032. In addition, the computational complexity of the approach was evaluated by implementing an edge solution. The proposed approaches can be effectively used even on resource-limited edge devices, with a notable increase in detection time.",
    "doi": "10.1109/LSENS.2023.3315251",
    "author_keywords": [
      "acoustic",
      "audio",
      "general-purpose sensing",
      "Internet-of-Things (IoT)",
      "Sensor applications",
      "traffic detection (TI)",
      "vision-transformers (ViT)"
    ],
    "contribution": "Thus, we propose the utilization of general-purpose sensing, which involves the use of cost-effective and easily deployable sensors, such as microphones, and air quality sensors that are cheaper, reusable, and easily manageable sensors. A general-purpose sensing infrastructure can be used for several applications including measuring TI. The main objective of this letter is to demonstrate how noise signatures can be leveraged to measure TI. Traditionally, image classification techniques are used for audio data analysis and vision-transformers (ViT) have shown remarkable results in this area. However, there is limited research that explores ViT models for traffic intensity detection. For TI detection, two approaches: vehicle count prediction and vehicle type detection (VTD), which use ViT models, are proposed. VTD approach performed better and it achieved an F1-score of 0.95 and a mean vehicle counting error of 0.032. In addition, the computational complexity of the approach was evaluated by implementing an edge solution. The proposed approaches can be effectively used even on resource-limited edge devices, with a notable increase in detection time.",
    "introduction": "The conventional approaches for traffic intensity (TI) detection in smart cities use specialized sensors, such as loop detectors, cameras, and radar. These sensors come with high costs, limited reuse, and specialized maintenance.",
    "macro_domains": []
  },
  {
    "abstract": "Assigning detailed use categories to buildings is a challenging and relevant task in urban land use classification with applications in urban planning, digital city modelling and twinning. This study aims to provide the categorisation of buildings with detailed use information by considering the possibilities of mixed-use. Mixed-use combines different use forms, and serves as a new type of use category. We obtain attributive information by combining satellite imagery that reflects spatial information and textual information from publicly available point-of-interest data collected by citizens and available on online maps. We propose a multimodal transformer-based building-use classification method to capture and fuse these different data sources within an end-to-end learning workflow. We evaluate the effectiveness of our proposed method on four urban areas in China. Experiments show that the proposed method effectively maps building use according to eight types of fine-grain categories, with a Micro F1 score equal to 80.9%, and a Macro F1 score equal to 62% for Wuhan research area. The proposed method is able to harness the relationship between the features obtained from the different data sources and results in higher accuracy than the state-of-the-art fusion-based multimodal integration methods. The proposed method can effectively increase the attributive grain of building use resulting in high classification accuracy.",
    "doi": "10.1016/j.rse.2023.113767",
    "author_keywords": [
      "Building use classification",
      "Data fusion",
      "Mixed-use classification",
      "Multimodal deep learning",
      "Natural language processing",
      "Remote sensing",
      "Transformers"
    ],
    "contribution": "This study aims to provide the categorisation of buildings with detailed use information by considering the possibilities of mixed-use. Mixed-use combines different use forms, and serves as a new type of use category. We obtain attributive information by combining satellite imagery that reflects spatial information and textual information from publicly available point-of-interest data collected by citizens and available on online maps. We propose a multimodal transformer-based building-use classification method to capture and fuse these different data sources within an end-to-end learning workflow. We evaluate the effectiveness of our proposed method on four urban areas in China. Experiments show that the proposed method effectively maps building use according to eight types of fine-grain categories, with a Micro F1 score equal to 80.9%, and a Macro F1 score equal to 62% for Wuhan research area. The proposed method is able to harness the relationship between the features obtained from the different data sources and results in higher accuracy than the state-of-the-art fusion-based multimodal integration methods. The proposed method can effectively increase the attributive grain of building use resulting in high classification accuracy.",
    "introduction": "Assigning detailed use categories to buildings is a challenging and relevant task in urban land use classification with applications in urban planning, digital city modelling and twinning.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic prediction is an important part of smart city management. Accurate traffic prediction can be deployed in urban applications such as congestion alerting and route planning, thus providing sustainable services to the public or relevant departments. Although some improvements have been made in existing traffic prediction methods, there are challenges due to the following: (1) Time series has multi-scale nature, that is, from different scale time ranges, traffic flow changes show different trends; (2) Spatial heterogeneity, meaning that traffic conditions in similar functional areas are usually similar. This task remains difficult. To address the above challenges, we propose a new spatial-temporal prediction method, namely Multi-Scale Spatial-Temporal Aware Transformer (MSSTAT), which is a Transformer architecture with multi-scale characteristics. Specifically, compared to the input of encoder, the input of different decoder layers has different scale information, MSSTAT synchronizes model the connection between time steps and scale information by a kind of Parallel Cross Multi-Head Attention, which gives each time step several times the perceived field while also being able to weaken the impact brought by anomaly point. In addition, to add connections between regions with similar functions, we map the traffic data of each node as a probability distribution and then measure the similarity between the nodes by the Wasserstein Distance, which leads to our proposed spatial-temporal aware adjacency matrix. Experimental results on four traffic flow datasets show that MSSTAT outperforms the state-of-the-art baseline.",
    "doi": "10.1016/j.ins.2023.119557",
    "author_keywords": [
      "Multi-scale",
      "Spatial heterogeneity",
      "Traffic prediction",
      "Transformer"
    ],
    "contribution": "To address the above challenges, we propose a new spatial-temporal prediction method, namely Multi-Scale Spatial-Temporal Aware Transformer (MSSTAT), which is a Transformer architecture with multi-scale characteristics. Specifically, compared to the input of encoder, the input of different decoder layers has different scale information, MSSTAT synchronizes model the connection between time steps and scale information by a kind of Parallel Cross Multi-Head Attention, which gives each time step several times the perceived field while also being able to weaken the impact brought by anomaly point. In addition, to add connections between regions with similar functions, we map the traffic data of each node as a probability distribution and then measure the similarity between the nodes by the Wasserstein Distance, which leads to our proposed spatial-temporal aware adjacency matrix. Experimental results on four traffic flow datasets show that MSSTAT outperforms the state-of-the-art baseline.",
    "introduction": "Traffic prediction is an important part of smart city management. Accurate traffic prediction can be deployed in urban applications such as congestion alerting and route planning, thus providing sustainable services to the public or relevant departments. Although some improvements have been made in existing traffic prediction methods, there are challenges due to the following: (1) Time series has multi-scale nature, that is, from different scale time ranges, traffic flow changes show different trends; (2) Spatial heterogeneity, meaning that traffic conditions in similar functional areas are usually similar. This task remains difficult.",
    "macro_domains": []
  },
  {
    "abstract": "Smart cities are designed to satisfy the needs of residents and improve their quality of life by providing a wide range of smart city services. One of the keys to the efficient operation of smart city services is the accurate forecast of the missing Quality of Service (QoS). Presently, many approaches utilize the context information of users and services, such as geographic location and network location, to somewhat increase the prediction accuracy and forecast the missing QoS values. However, because the network conditions and server status are unpredictable, time is also considered as one of the important factors affecting QoS prediction, which brings more challenges as follows: higher data dimension, more complex data characteristics, and higher data sparsity. To overcome these challenges, we propose an approach for time-aware Web service QoS prediction based on contrastive learning (named CLpred). CLpred utilizes a sequential data input format for QoS data and models these QoS sequences through transformer encoder with CLpred framework. Therefore, it can downscale QoS data and extract a more efficient representation in complex QoS data. Furthermore, it makes it possible to apply data augmentation methods to address the problems of data sparsity. In order to prove the superiority of the proposed approach, particularly inside the presence of extremely high-data sparsity, extensive experiments are conducted on the well-known service QoS data set WSDREAM.",
    "doi": "10.1109/JIOT.2023.3281869",
    "author_keywords": [
      "Constrastive learning",
      "Quality-of-Service (QoS) prediction",
      "smart city",
      "smart city service",
      "time aware"
    ],
    "contribution": "To overcome these challenges, we propose an approach for time-aware Web service QoS prediction based on contrastive learning (named CLpred). CLpred utilizes a sequential data input format for QoS data and models these QoS sequences through transformer encoder with CLpred framework. Therefore, it can downscale QoS data and extract a more efficient representation in complex QoS data. Furthermore, it makes it possible to apply data augmentation methods to address the problems of data sparsity. In order to prove the superiority of the proposed approach, particularly inside the presence of extremely high-data sparsity, extensive experiments are conducted on the well-known service QoS data set WSDREAM.",
    "introduction": "Smart cities are designed to satisfy the needs of residents and improve their quality of life by providing a wide range of smart city services. One of the keys to the efficient operation of smart city services is the accurate forecast of the missing Quality of Service (QoS). Presently, many approaches utilize the context information of users and services, such as geographic location and network location, to somewhat increase the prediction accuracy and forecast the missing QoS values. However, because the network conditions and server status are unpredictable, time is also considered as one of the important factors affecting QoS prediction, which brings more challenges as follows: higher data dimension, more complex data characteristics, and higher data sparsity.",
    "macro_domains": []
  },
  {
    "abstract": "Layout planning is centrally important in the field of architecture and urban design. Among the various basic units carrying urban functions, residential community plays a vital part for supporting human life. Therefore, the layout planning of residential community has always been of concern, and has attracted particular attention since the advent of deep learning that facilitates the automated layout generation and spatial pattern recognition. However, the research circles generally suffer from the insufficiency of residential community layout benchmark or high-quality datasets, which hampers the future exploration of data-driven methods for residential community layout planning. The lack of datasets is largely due to the difficulties of large-scale real-world residential data acquisition and long-term expert screening. In order to address the issues and advance a benchmark dataset for various intelligent spatial design and analysis applications in the development of smart city, we introduce Residential Community Layout Planning (ReCo) Dataset, which is the first and largest open-source vector dataset related to real-world community to date. ReCo Dataset is presented in multiple data formats with 37,646 residential community layout plans, covering 598,728 residential buildings with height information. ReCo can be conveniently adapted for residential community layout related urban design tasks, e.g., generative layout design, morphological pattern recognition and spatial evaluation. To validate the utility of ReCo in automated residential community layout planning, two Generative Adversarial Network (GAN) based generative models are further applied to the dataset. We expect ReCo Dataset to inspire more creative and practical work in intelligent design and beyond. The ReCo Dataset is published at: https://www.kaggle.com/fdudsde/reco-dataset and related code can be found at: \\urlhttps://github.com/FDUDSDE/ReCo-Dataset.",
    "doi": "10.1145/3581783.3612465",
    "author_keywords": [
      "dataset",
      "layout generation",
      "layout planning and design",
      "residential community layout"
    ],
    "contribution": "However, the research circles generally suffer from the insufficiency of residential community layout benchmark or high-quality datasets, which hampers the future exploration of data-driven methods for residential community layout planning. The lack of datasets is largely due to the difficulties of large-scale real-world residential data acquisition and long-term expert screening. In order to address the issues and advance a benchmark dataset for various intelligent spatial design and analysis applications in the development of smart city, we introduce Residential Community Layout Planning (ReCo) Dataset, which is the first and largest open-source vector dataset related to real-world community to date. ReCo Dataset is presented in multiple data formats with 37,646 residential community layout plans, covering 598,728 residential buildings with height information. ReCo can be conveniently adapted for residential community layout related urban design tasks, e.g., generative layout design, morphological pattern recognition and spatial evaluation. To validate the utility of ReCo in automated residential community layout planning, two Generative Adversarial Network (GAN) based generative models are further applied to the dataset. We expect ReCo Dataset to inspire more creative and practical work in intelligent design and beyond. The ReCo Dataset is published at: https://www.kaggle.com/fdudsde/reco-dataset and related code can be found at: \\urlhttps://github.com/FDUDSDE/ReCo-Dataset.",
    "introduction": "Layout planning is centrally important in the field of architecture and urban design. Among the various basic units carrying urban functions, residential community plays a vital part for supporting human life. Therefore, the layout planning of residential community has always been of concern, and has attracted particular attention since the advent of deep learning that facilitates the automated layout generation and spatial pattern recognition.",
    "macro_domains": []
  },
  {
    "abstract": "Long term dependency capture is essentially important for time series prediction and spatialâ€“temporal forecasting. In recent years, many deep learning-based forecasting methods have been proposed, leading to rapid development in this area. We systematically reviewed long-term dependency capture methods, including temporal dependency in sequence (named intra-sequence temporal dependency), temporal dependency out of sequence (named inter-sequence temporal dependency, in this scenario the long-term dependencies are split by many subsequences). Because the batch technique is widely adopted in machine learning and deep learning, the range of temporal capturing ability for many proposed methods is intra-sequence temporal dependency, which limits the capacity of long-term dependency capture. Aiming at the above problems, we designed three type memory mechanisms (i.e., a temporal encoding memory mechanism, a cross-sequence memory mechanism and a query-key based memory mechanism) to solve those long term dependency problems. Moreover, based on the cross-sequence memory mechanism and query-key architecture, an Attention-based Long-Term Dependency Capture model (ALTDC) is proposed for long-term dependency modeling and further solves the temporal dependency coherence problem. ALTDC includes temporal Transformer and spatial Transformer. The temporal Transformer adopts multi-head attention mechanism in temporal dimension and takes into consideration the relative position encoding. The spatial Transformer leverages attention mechanism in spatial dimension, and utilizes learnable position encoding and graph convolution to capture spatial relationships. Experiments demonstrate that the proposed model outperforms the state-of-art baselines on real world time-series datasets and spatialâ€“temporal datasets.",
    "doi": "10.1016/j.knosys.2023.110818",
    "author_keywords": [
      "Long-term dependency",
      "Smart city",
      "Spatial temporal forecasting"
    ],
    "contribution": "",
    "introduction": "Long term dependency capture is essentially important for time series prediction and spatialâ€“temporal forecasting. In recent years, many deep learning-based forecasting methods have been proposed, leading to rapid development in this area. We systematically reviewed long-term dependency capture methods, including temporal dependency in sequence (named intra-sequence temporal dependency), temporal dependency out of sequence (named inter-sequence temporal dependency, in this scenario the long-term dependencies are split by many subsequences). Because the batch technique is widely adopted in machine learning and deep learning, the range of temporal capturing ability for many proposed methods is intra-sequence temporal dependency, which limits the capacity of long-term dependency capture. Aiming at the above problems, we designed three type memory mechanisms (i.e., a temporal encoding memory mechanism, a cross-sequence memory mechanism and a query-key based memory mechanism) to solve those long term dependency problems. Moreover, based on the cross-sequence memory mechanism and query-key architecture, an Attention-based Long-Term Dependency Capture model (ALTDC) is proposed for long-term dependency modeling and further solves the temporal dependency coherence problem. ALTDC includes temporal Transformer and spatial Transformer. The temporal Transformer adopts multi-head attention mechanism in temporal dimension and takes into consideration the relative position encoding. The spatial Transformer leverages attention mechanism in spatial dimension, and utilizes learnable position encoding and graph convolution to capture spatial relationships. Experiments demonstrate that the proposed model outperforms the state-of-art baselines on real world time-series datasets and spatialâ€“temporal datasets.",
    "macro_domains": []
  },
  {
    "abstract": "In the era of information explosion, spatio-temporal data mining serves as a critical part of urban management. Considering the various fields demanding attention, e.g., traffic state, human activity, and social event, predicting multiple spatio-temporal attributes simultaneously can alleviate regulatory pressure and foster smart city construction. However, current research can not handle the spatio-temporal multi-attribute prediction well due to the complex relationships between diverse attributes. The key challenge lies in how to address the common spatio-temporal patterns while tackling their distinctions. In this paper, we propose an effective solution for spatio-temporal multi-attribute prediction, PromptST. We devise a spatio-temporal transformer and a parameter-sharing training scheme to address the common knowledge among different spatiotemporal attributes. Then, we elaborate a spatio-temporal prompt tuning strategy to fit the specific attributes in a lightweight manner. Through the pretrain and prompt tuning phases, our PromptST is able to enhance the specific spatio-temoral characteristic capture by prompting the backbone model to fit the specific target attribute while maintaining the learned common knowledge. Extensive experiments on real-world datasets verify that our PromptST attains state-of-the-art performance. Furthermore, we also prove PromptST owns good transferability on unseen spatio-temporal attributes, which brings promising application potential in urban computing. The implementation code is available to ease reproducibility.",
    "doi": "10.1145/3583780.3615016",
    "author_keywords": [
      "multi-attribute prediction",
      "prompt learning",
      "smart city",
      "spatio-temporal prediction"
    ],
    "contribution": "In this paper, we propose an effective solution for spatio-temporal multi-attribute prediction, PromptST. We devise a spatio-temporal transformer and a parameter-sharing training scheme to address the common knowledge among different spatiotemporal attributes. Then, we elaborate a spatio-temporal prompt tuning strategy to fit the specific attributes in a lightweight manner. Through the pretrain and prompt tuning phases, our PromptST is able to enhance the specific spatio-temoral characteristic capture by prompting the backbone model to fit the specific target attribute while maintaining the learned common knowledge. Extensive experiments on real-world datasets verify that our PromptST attains state-of-the-art performance. Furthermore, we also prove PromptST owns good transferability on unseen spatio-temporal attributes, which brings promising application potential in urban computing. The implementation code is available to ease reproducibility.",
    "introduction": "In the era of information explosion, spatio-temporal data mining serves as a critical part of urban management. Considering the various fields demanding attention, e.g., traffic state, human activity, and social event, predicting multiple spatio-temporal attributes simultaneously can alleviate regulatory pressure and foster smart city construction. However, current research can not handle the spatio-temporal multi-attribute prediction well due to the complex relationships between diverse attributes. The key challenge lies in how to address the common spatio-temporal patterns while tackling their distinctions.",
    "macro_domains": []
  },
  {
    "abstract": "Inferring the fine-grained urban flows based on the coarse-grained flow observations is practically important to many smart city-related applications. However, the collected urban flows are usually rather unreliable, may contain noise and sometimes are incomplete, thus posing great challenges to existing approaches. In this paper, we present a pioneering study on robust fine-grained urban flow inference with noisy and incomplete urban flow observations, and propose a denoising diffusion model named DiffUFlow to effectively address it with an improved reverse diffusion strategy. Specifically, a spatial-temporal feature extraction network called STFormer and a semantic features extraction network called ELFetcher are proposed. Then, we overlay the extracted spatial-temporal feature map onto the coarse-grained flow map, serving as a conditional guidance for the reverse diffusion process. We further integrate the semantic features extracted by ELFetcher to cross-attention layers, enabling the comprehensive consideration of semantic information for fine-grained flow inference. Extensive experiments on two large real-world datasets validate the effectiveness of our method compared with the state-of-the-art baselines.",
    "doi": "10.1145/3583780.3614842",
    "author_keywords": [
      "Denoising diffusion model",
      "Spatial-temporal data mining",
      "Urban flow inference"
    ],
    "contribution": "In this paper, we present a pioneering study on robust fine-grained urban flow inference with noisy and incomplete urban flow observations, and propose a denoising diffusion model named DiffUFlow to effectively address it with an improved reverse diffusion strategy. Specifically, a spatial-temporal feature extraction network called STFormer and a semantic features extraction network called ELFetcher are proposed. Then, we overlay the extracted spatial-temporal feature map onto the coarse-grained flow map, serving as a conditional guidance for the reverse diffusion process. We further integrate the semantic features extracted by ELFetcher to cross-attention layers, enabling the comprehensive consideration of semantic information for fine-grained flow inference. Extensive experiments on two large real-world datasets validate the effectiveness of our method compared with the state-of-the-art baselines.",
    "introduction": "Inferring the fine-grained urban flows based on the coarse-grained flow observations is practically important to many smart city-related applications. However, the collected urban flows are usually rather unreliable, may contain noise and sometimes are incomplete, thus posing great challenges to existing approaches.",
    "macro_domains": []
  },
  {
    "abstract": "In Smart City and Vehicle-to-Everything (V2X) systems, acquiring pedestrians' accurate locations is crucial to traffic and pedestrian safety. Current systems adopt cameras and wireless sensors to estimate people's locations via sensor fusion. Standard fusion algorithms, however, become inapplicable when multi-modal data is not associated. For example, pedestrians are out of the camera field of view, or data from the camera modality is missing. To address this challenge and produce more accurate location estimations for pedestrians, we propose a localization solution based on a Generative Adversarial Network (GAN) architecture. During training, it learns the underlying linkage between pedestrians' camera-phone data correspondences. During inference, it generates refined position estimations based only on pedestrians' phone data that consists of GPS, IMU, and FTM. Results show that our GAN produces 3D coordinates at 1 to 2 meters localization error across 5 different outdoor scenes. We further show that the proposed model supports self-learning. The generated coordinates can be associated with pedestrians' bounding box coordinates to obtain additional camera-phone data correspondences. This allows automatic data collection during inference. Results show that after fine-tuning the GAN model on the expanded dataset, localization accuracy is further improved by up to 26%.",
    "doi": "10.1145/3577190.3614119",
    "author_keywords": [
      "Computer Vision",
      "GAN",
      "IMU",
      "Localization",
      "Multi-modal",
      "WiFi FTM"
    ],
    "contribution": "To address this challenge and produce more accurate location estimations for pedestrians, we propose a localization solution based on a Generative Adversarial Network (GAN) architecture. During training, it learns the underlying linkage between pedestrians' camera-phone data correspondences. During inference, it generates refined position estimations based only on pedestrians' phone data that consists of GPS, IMU, and FTM. Results show that our GAN produces 3D coordinates at 1 to 2 meters localization error across 5 different outdoor scenes. We further show that the proposed model supports self-learning. The generated coordinates can be associated with pedestrians' bounding box coordinates to obtain additional camera-phone data correspondences. This allows automatic data collection during inference. Results show that after fine-tuning the GAN model on the expanded dataset, localization accuracy is further improved by up to 26%.",
    "introduction": "In Smart City and Vehicle-to-Everything (V2X) systems, acquiring pedestrians' accurate locations is crucial to traffic and pedestrian safety. Current systems adopt cameras and wireless sensors to estimate people's locations via sensor fusion. Standard fusion algorithms, however, become inapplicable when multi-modal data is not associated. For example, pedestrians are out of the camera field of view, or data from the camera modality is missing.",
    "macro_domains": []
  },
  {
    "abstract": "Tracking subjects in videos is one of the most widely used functions in camera-based IoT applications such as security surveillance, smart city traffic safety enhancement, vehicle to pedestrian communication and so on. In computer vision domain, tracking is usually achieved by first detecting subjects, then associating detected bounding boxes across video frames. Typically, frames are transmitted to a remote site for processing, incurring high latency and network costs. To address this, we propose ViFiT, a transformer-based model that reconstructs vision bounding box trajectories from phone data (IMU and Fine Time Measurements). It leverages a transformer's ability of better modeling long-term time series data. ViFiT is evaluated on Vi-Fi Dataset, a large-scale multimodal dataset in 5 diverse real world scenes, including indoor and outdoor environments. Results demonstrate that ViFiT outperforms the state-of-the-art approach for cross-modal reconstruction in LSTM Encoder-Decoder architecture X-Translator and achieves a high frame reduction rate as 97.76% with IMU and Wi-Fi data.",
    "doi": "10.1145/3615984.3616503",
    "author_keywords": [
      "Efficient Video System",
      "IMU",
      "Multimodal Learning",
      "Multimodal Reconstruction",
      "Object Detection",
      "Tracking",
      "Transformer"
    ],
    "contribution": "To address this, we propose ViFiT, a transformer-based model that reconstructs vision bounding box trajectories from phone data (IMU and Fine Time Measurements). It leverages a transformer's ability of better modeling long-term time series data. ViFiT is evaluated on Vi-Fi Dataset, a large-scale multimodal dataset in 5 diverse real world scenes, including indoor and outdoor environments. Results demonstrate that ViFiT outperforms the state-of-the-art approach for cross-modal reconstruction in LSTM Encoder-Decoder architecture X-Translator and achieves a high frame reduction rate as 97.76% with IMU and Wi-Fi data.",
    "introduction": "Tracking subjects in videos is one of the most widely used functions in camera-based IoT applications such as security surveillance, smart city traffic safety enhancement, vehicle to pedestrian communication and so on. In computer vision domain, tracking is usually achieved by first detecting subjects, then associating detected bounding boxes across video frames. Typically, frames are transmitted to a remote site for processing, incurring high latency and network costs.",
    "macro_domains": []
  },
  {
    "abstract": "Networks within the Internet of Things (IoT) have some of the most targeted devices due to their lightweight design and the sensitive data exchanged through smart city networks. One way to protect a system from an attack is to use machine learning (ML)-based intrusion detection systems (IDSs), significantly improving classification tasks. Training ML algorithms require a large network traffic dataset; however, large storage and months of recording are required to capture the attacks, which is costly for IoT environments. This study proposes an ML pipeline using the conditional tabular generative adversarial network (CTGAN) model to generate a synthetic dataset. Then, the synthetic dataset was evaluated using several types of statistical and ML metrics. Using a decision tree, the accuracy of the generated dataset reached 0.99, and its lower complexity reached 0.05 s training and 0.004 s test times. The results show that synthetic data accurately reflect real data and are less complex, making them suitable for IoT environments and smart city applications. Thus, the generated synthetic dataset can further train models to secure IoT networks and applications.",
    "doi": "10.3390/app131910951",
    "author_keywords": [
      "advanced persistent threat",
      "CTGAN",
      "information security",
      "intrusion detection system",
      "IoT",
      "machine learning"
    ],
    "contribution": "This study proposes an ML pipeline using the conditional tabular generative adversarial network (CTGAN) model to generate a synthetic dataset. Then, the synthetic dataset was evaluated using several types of statistical and ML metrics. Using a decision tree, the accuracy of the generated dataset reached 0.99, and its lower complexity reached 0.05 s training and 0.004 s test times. The results show that synthetic data accurately reflect real data and are less complex, making them suitable for IoT environments and smart city applications. Thus, the generated synthetic dataset can further train models to secure IoT networks and applications.",
    "introduction": "Networks within the Internet of Things (IoT) have some of the most targeted devices due to their lightweight design and the sensitive data exchanged through smart city networks. One way to protect a system from an attack is to use machine learning (ML)-based intrusion detection systems (IDSs), significantly improving classification tasks. Training ML algorithms require a large network traffic dataset; however, large storage and months of recording are required to capture the attacks, which is costly for IoT environments.",
    "macro_domains": []
  },
  {
    "abstract": "In the context of promoting the integration of smart cities, the pace of construction of smart chemical parks is gradually accelerating. Since accidents in Chinaâ€™s chemical industry have occurred frequently in recent years, causing great damage and loss to public safety, improving the safety management and emergency response capability of chemical parks is an urgent need to be solved. For this kind of safety problems, this paper proposed a game patrol strategy for hazardous gas leakage in chemical parks. Firstly, the convective diffusion model was used to describe the process of hazardous gas leakage. Secondly, game theory was introduced to model the confrontation process between the attacking and defending parties in the patrol problem, and the response time of the defenders to a safety incident was correlated with its benefit. Then, a multilinear programming-based GGC algorithm was proposed to solve this game model. Finally, the gains of the game model in this paper were compared with the other two basic methods in the scenarios of three real chemical park case with different sizes. The results show that the model can effectively improve the gains of the defender and reduce the gains of the attacker.",
    "doi": "10.11959/j.issn.2096-6652.202338",
    "author_keywords": [
      "chemical park",
      "game patrol",
      "game theory",
      "gas leakage",
      "response time"
    ],
    "contribution": "For this kind of safety problems, this paper proposed a game patrol strategy for hazardous gas leakage in chemical parks. Firstly, the convective diffusion model was used to describe the process of hazardous gas leakage. Secondly, game theory was introduced to model the confrontation process between the attacking and defending parties in the patrol problem, and the response time of the defenders to a safety incident was correlated with its benefit. Then, a multilinear programming-based GGC algorithm was proposed to solve this game model. Finally, the gains of the game model in this paper were compared with the other two basic methods in the scenarios of three real chemical park case with different sizes. The results show that the model can effectively improve the gains of the defender and reduce the gains of the attacker.",
    "introduction": "In the context of promoting the integration of smart cities, the pace of construction of smart chemical parks is gradually accelerating. Since accidents in Chinaâ€™s chemical industry have occurred frequently in recent years, causing great damage and loss to public safety, improving the safety management and emergency response capability of chemical parks is an urgent need to be solved.",
    "macro_domains": []
  },
  {
    "abstract": "Tourism is vital for most historical and cultural cities. In the context of Smart Cities, there are numerous data sources in tourism domain that could be analyzed to monitor and forecast a range of different indicators related to touristic locations and attractions. In this paper, we propose a framework which exploits social media and big data to forecast both online reputation and touristic attraction presences. To this end, some techniques have been tested and proposed on the basis of machine learning, deep learning, causality assessment and explainable Artificial Intelligence, so as to provide evidence of the relevant variables for each prediction and estimation. An approach has been introduced to analyze the explainability of the proposed solutions, i.e., a multilingual sentiment analysis tool for social media data based on transformers to compare data sources as Trip Advisor and Twitter. Furthermore, causality analysis has been performed to evaluate the temporal impact of social media posts and other factors with respect to the number of presences. The work has been developed in the context of Herit-Data, a European Commission funded project on the exploitation of big data for tourism management and based on the Snap4City infrastructure and platform. Herit-Data has developed solutions for 6 major European touristic locations. In this paper, some of the solutions developed for Florence, Italy and Pont du Gard, France, are reported.",
    "doi": "10.1016/j.osnem.2023.100274",
    "author_keywords": [
      "Data driven tourism attraction management",
      "People count prediction",
      "Reputation computing and predictions"
    ],
    "contribution": "In this paper, we propose a framework which exploits social media and big data to forecast both online reputation and touristic attraction presences. To this end, some techniques have been tested and proposed on the basis of machine learning, deep learning, causality assessment and explainable Artificial Intelligence, so as to provide evidence of the relevant variables for each prediction and estimation. An approach has been introduced to analyze the explainability of the proposed solutions, i.e., a multilingual sentiment analysis tool for social media data based on transformers to compare data sources as Trip Advisor and Twitter. Furthermore, causality analysis has been performed to evaluate the temporal impact of social media posts and other factors with respect to the number of presences. The work has been developed in the context of Herit-Data, a European Commission funded project on the exploitation of big data for tourism management and based on the Snap4City infrastructure and platform. Herit-Data has developed solutions for 6 major European touristic locations. In this paper, some of the solutions developed for Florence, Italy and Pont du Gard, France, are reported.",
    "introduction": "Tourism is vital for most historical and cultural cities. In the context of Smart Cities, there are numerous data sources in tourism domain that could be analyzed to monitor and forecast a range of different indicators related to touristic locations and attractions.",
    "macro_domains": []
  },
  {
    "abstract": "Autonomous vehicles (AVs) play a crucial role in enhancing urban mobility within the context of a smarter and more connected urban environment. Three-dimensional object detection in AVs is an essential task for comprehending the driving environment to contribute to their safe use in urban environments. Existing 3D LiDAR object detection systems lose many critical point features during the down-sampling process and neglect the crucial interactions between local features, providing insufficient semantic information and leading to subpar detection performance. We propose a dynamic feature abstraction with self-attention (DFA-SAT), which utilizes self-attention to learn semantic features with contextual information by incorporating neighboring data and focusing on vital geometric details. DFA-SAT comprises four modules: object-based down-sampling (OBDS), semantic and contextual feature extraction (SCFE), multi-level feature re-weighting (MLFR), and local and global features aggregation (LGFA). The OBDS module preserves the maximum number of semantic foreground points along with their spatial information. SCFE learns rich semantic and contextual information with respect to spatial dependencies, refining the point features. MLFR decodes all the point features using a channel-wise multi-layered transformer approach. LGFA combines local features with decoding weights for global features using matrix product keys and query embeddings to learn spatial information across each channel. Extensive experiments using the KITTI dataset demonstrate significant improvements over the mainstream methods SECOND and PointPillars, improving the mean average precision (AP) by 6.86% and 6.43%, respectively, on the KITTI test dataset. DFA-SAT yields better and more stable performance for medium and long distances with a limited impact on real-time performance and model parameters, ensuring a transformative shift akin to when automobiles replaced conventional transportation in cities.",
    "doi": "10.3390/su151813667",
    "author_keywords": [
      "3D object dejection",
      "self-attention",
      "semantic features leaning",
      "smart cities"
    ],
    "contribution": "We propose a dynamic feature abstraction with self-attention (DFA-SAT), which utilizes self-attention to learn semantic features with contextual information by incorporating neighboring data and focusing on vital geometric details. DFA-SAT comprises four modules: object-based down-sampling (OBDS), semantic and contextual feature extraction (SCFE), multi-level feature re-weighting (MLFR), and local and global features aggregation (LGFA). The OBDS module preserves the maximum number of semantic foreground points along with their spatial information. SCFE learns rich semantic and contextual information with respect to spatial dependencies, refining the point features. MLFR decodes all the point features using a channel-wise multi-layered transformer approach. LGFA combines local features with decoding weights for global features using matrix product keys and query embeddings to learn spatial information across each channel. Extensive experiments using the KITTI dataset demonstrate significant improvements over the mainstream methods SECOND and PointPillars, improving the mean average precision (AP) by 6.86% and 6.43%, respectively, on the KITTI test dataset. DFA-SAT yields better and more stable performance for medium and long distances with a limited impact on real-time performance and model parameters, ensuring a transformative shift akin to when automobiles replaced conventional transportation in cities.",
    "introduction": "Autonomous vehicles (AVs) play a crucial role in enhancing urban mobility within the context of a smarter and more connected urban environment. Three-dimensional object detection in AVs is an essential task for comprehending the driving environment to contribute to their safe use in urban environments. Existing 3D LiDAR object detection systems lose many critical point features during the down-sampling process and neglect the crucial interactions between local features, providing insufficient semantic information and leading to subpar detection performance.",
    "macro_domains": []
  },
  {
    "abstract": "Fire-detection technology plays a critical role in ensuring public safety and facilitating the development of smart cities. Early fire detection is imperative to mitigate potential hazards and minimize associated losses. However, existing vision-based fire-detection methods exhibit limited generalizability and fail to adequately consider the effect of fire object size on detection accuracy. To address this issue, in this study a decoder-free fully transformer-based (DFFT) detector is used to achieve early smoke and flame detection, improving the detection performance for fires of different sizes. This method effectively captures multi-level and multi-scale fire features with rich semantic information while using two powerful encoders to maintain the accuracy of the single-feature map prediction. First, data augmentation is performed to enhance the generalizability of the model. Second, the detection-oriented transformer (DOT) backbone network is treated as a single-layer fire-feature extractor to obtain fire-related features on four scales, which are then fed into an encoder-only single-layer dense prediction module. Finally, the prediction module aggregates the multi-scale fire features into a single feature map using a scale-aggregated encoder (SAE). The prediction module then aligns the classification and regression features using a task-aligned encoder (TAE) to ensure the semantic interaction of the classification and regression predictions. Experimental results on one private dataset and one public dataset demonstrate that the adopted DFFT possesses high detection accuracy and a strong generalizability for fires of different sizes, particularly early small fires. The DFFT achieved mean average precision (mAP) values of 87.40% and 81.12% for the two datasets, outperforming other baseline models. It exhibits a better detection performance on flame objects than on smoke objects because of the prominence of flame features.",
    "doi": "10.1016/j.jnlssr.2023.06.002",
    "author_keywords": [
      "Early fire",
      "Fire detection",
      "Public safety",
      "Smoke and flame detection",
      "Vision transformer"
    ],
    "contribution": "To address this issue, in this study a decoder-free fully transformer-based (DFFT) detector is used to achieve early smoke and flame detection, improving the detection performance for fires of different sizes. This method effectively captures multi-level and multi-scale fire features with rich semantic information while using two powerful encoders to maintain the accuracy of the single-feature map prediction. First, data augmentation is performed to enhance the generalizability of the model. Second, the detection-oriented transformer (DOT) backbone network is treated as a single-layer fire-feature extractor to obtain fire-related features on four scales, which are then fed into an encoder-only single-layer dense prediction module. Finally, the prediction module aggregates the multi-scale fire features into a single feature map using a scale-aggregated encoder (SAE). The prediction module then aligns the classification and regression features using a task-aligned encoder (TAE) to ensure the semantic interaction of the classification and regression predictions. Experimental results on one private dataset and one public dataset demonstrate that the adopted DFFT possesses high detection accuracy and a strong generalizability for fires of different sizes, particularly early small fires. The DFFT achieved mean average precision (mAP) values of 87.40% and 81.12% for the two datasets, outperforming other baseline models. It exhibits a better detection performance on flame objects than on smoke objects because of the prominence of flame features.",
    "introduction": "Fire-detection technology plays a critical role in ensuring public safety and facilitating the development of smart cities. Early fire detection is imperative to mitigate potential hazards and minimize associated losses. However, existing vision-based fire-detection methods exhibit limited generalizability and fail to adequately consider the effect of fire object size on detection accuracy.",
    "macro_domains": []
  },
  {
    "abstract": "The ability of spatial-temporal traffic demand prediction is crucial for urban computing, traffic management and future autonomous driving. In this paper, a novel Spatial-Temporal Guided Multi-graph Sandwich-Transformer (STGMT) is suggested to address the ubiquitous spatial-temporal heterogeneity in traffic demand forecasting. Compared to the original Transformer, we employ Time to Vector (Time2Vec) and Node to Vector (Node2Vec) in the embedding layer to obtain universal representations for temporal nodes and spatial nodes, respectively, which are then combined to form Spatial-Temporal Embedding (STE) blocks. The STE guides the attention mechanism, maintaining a unique parameter space for spatial-temporal nodes and enabling the learning of node-specific patterns. In STGMT, we develop Multi-head Temporal Attention (MTA) and Multi-head Temporal Interactive Attention (MTIA) for extracting temporal features, while Multi-head Spatial Attention (MSA) is employed for extracting spatial features. Furthermore, MSA incorporates both the accessibility graph determined by road topology and the similarity graph determined by specific traffic events to characterize the pairwise relationships among spatial nodes. Various attentions and feed-forward layers are rearranged and combined to form the Sandwich-Transformer. Extensive experiments are conducted on public datasets of node-level tasks of two different types (highway and urban) and indicate that the STGMT outperforms state-of-the-art models. The proposed STGMT effectively addresses the ubiquitous spatial-temporal heterogeneity challenge in traffic demand forecasting, thereby enhancing the accuracy of traffic demand prediction and offering valuable guidance for traffic planning and operations. Our code and data are open source at https://github.com/YanJieWen/STGMT-Tensorflow-implementation.",
    "doi": "10.1016/j.ins.2023.119269",
    "author_keywords": [
      "Intelligent transportation system",
      "Meta learning",
      "Multi-head attention mechanism",
      "Sandwich-Transformer",
      "Spatial-temporal learning"
    ],
    "contribution": "In this paper, a novel Spatial-Temporal Guided Multi-graph Sandwich-Transformer (STGMT) is suggested to address the ubiquitous spatial-temporal heterogeneity in traffic demand forecasting. Compared to the original Transformer, we employ Time to Vector (Time2Vec) and Node to Vector (Node2Vec) in the embedding layer to obtain universal representations for temporal nodes and spatial nodes, respectively, which are then combined to form Spatial-Temporal Embedding (STE) blocks. The STE guides the attention mechanism, maintaining a unique parameter space for spatial-temporal nodes and enabling the learning of node-specific patterns. In STGMT, we develop Multi-head Temporal Attention (MTA) and Multi-head Temporal Interactive Attention (MTIA) for extracting temporal features, while Multi-head Spatial Attention (MSA) is employed for extracting spatial features. Furthermore, MSA incorporates both the accessibility graph determined by road topology and the similarity graph determined by specific traffic events to characterize the pairwise relationships among spatial nodes. Various attentions and feed-forward layers are rearranged and combined to form the Sandwich-Transformer. Extensive experiments are conducted on public datasets of node-level tasks of two different types (highway and urban) and indicate that the STGMT outperforms state-of-the-art models. The proposed STGMT effectively addresses the ubiquitous spatial-temporal heterogeneity challenge in traffic demand forecasting, thereby enhancing the accuracy of traffic demand prediction and offering valuable guidance for traffic planning and operations. Our code and data are open source at https://github.com/YanJieWen/STGMT-Tensorflow-implementation.",
    "introduction": "The ability of spatial-temporal traffic demand prediction is crucial for urban computing, traffic management and future autonomous driving.",
    "macro_domains": []
  },
  {
    "abstract": "In the Energy Conversion for Next-Generation Smart Cities, intelligent substation plays an important role in the power conversion. As an important guarantee for the stable operation of intelligent substation, the research on fault diagnosis technology is particularly important. In this paper, the acoustic characteristic diagnosis of substation equipment (take transformers for example) is researched and the application of \"Voice Recognition + artificial neural network (ANN)\"technology in substation fault diagnosis is analyzed. At the same time, the continuous online monitoring of the intelligent substation equipment will produce a large amount of monitoring data, which needs to be analyzed timely and effectively to understand the operating status of the equipment accurately. Because of this, this paper adopts distributed computing by establishing a real-time distributed computing platform, using open source technology to store the online monitoring of sound data into the computing platform for data processing to achieve the purpose of automatic fault detection and analysis. The results show that distributed computing can realize the intelligent analysis, storage, and visualization of equipment data in the substation, which provides data support for fault diagnosis. Besides, the fitting accuracy rates of ANN model are 95.123% for training process and the fitting accuracy rates of ANN model are 99.353% for training process and the overall fitting accuracy rates of ANN model are 95.478% and the error between the predicted value and the actual value of the 5 sound signals is within 5% in the fault diagnosis process. Consequently, the ANN model can accurately identify each fault sound of substation and achieve the purpose of fault diagnosis.",
    "doi": "10.1142/S0129626423400042",
    "author_keywords": [
      "artificial neural network",
      "distributed computing",
      "fault diagnosis",
      "Substation monitoring"
    ],
    "contribution": "As an important guarantee for the stable operation of intelligent substation, the research on fault diagnosis technology is particularly important. In this paper, the acoustic characteristic diagnosis of substation equipment (take transformers for example) is researched and the application of \"Voice Recognition + artificial neural network (ANN)\"technology in substation fault diagnosis is analyzed. At the same time, the continuous online monitoring of the intelligent substation equipment will produce a large amount of monitoring data, which needs to be analyzed timely and effectively to understand the operating status of the equipment accurately. Because of this, this paper adopts distributed computing by establishing a real-time distributed computing platform, using open source technology to store the online monitoring of sound data into the computing platform for data processing to achieve the purpose of automatic fault detection and analysis. The results show that distributed computing can realize the intelligent analysis, storage, and visualization of equipment data in the substation, which provides data support for fault diagnosis. Besides, the fitting accuracy rates of ANN model are 95.123% for training process and the fitting accuracy rates of ANN model are 99.353% for training process and the overall fitting accuracy rates of ANN model are 95.478% and the error between the predicted value and the actual value of the 5 sound signals is within 5% in the fault diagnosis process. Consequently, the ANN model can accurately identify each fault sound of substation and achieve the purpose of fault diagnosis.",
    "introduction": "In the Energy Conversion for Next-Generation Smart Cities, intelligent substation plays an important role in the power conversion.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic prediction plays a significant part in creating intelligent cities such as traffic management, urban computing, and public safety. Nevertheless, the complex spatio-temporal linkages and dynamically shifting patterns make it somewhat challenging. Existing mainstream traffic prediction approaches heavily rely on graph convolutional networks and sequence prediction methods to extract complicated spatio-temporal patterns statically. However, they neglect to account for dynamic underlying correlations and thus fail to produce satisfactory prediction results. Therefore, we propose a novel Self-Adaptive Spatio-Temporal Graph Convolutional Network (SASTGCN) for traffic prediction. A self-adaptive calibrator, a spatio-temporal feature extractor, and a predictor comprise the bulk of the framework. To extract the distribution bias of the input in the self-adaptive calibrator, we employ a self-supervisor made of an encoderâ€“decoder structure. The concatenation of the bias and the original characteristics are provided as input to the spatio-temporal feature extractor, which leverages a transformer and graph convolution structures to learn the spatio-temporal pattern, and then applies a predictor to produce the final prediction. Extensive trials on two public traffic prediction datasets (METR-LA and PEMS-BAY) demonstrate that SASTGCN surpasses the most recent techniques in several metrics.",
    "doi": "10.3390/ijgi12080346",
    "author_keywords": [
      "graph convolutional network",
      "self-adaptive",
      "spatio-temporal sequence",
      "traffic prediction"
    ],
    "contribution": "Therefore, we propose a novel Self-Adaptive Spatio-Temporal Graph Convolutional Network (SASTGCN) for traffic prediction. A self-adaptive calibrator, a spatio-temporal feature extractor, and a predictor comprise the bulk of the framework. To extract the distribution bias of the input in the self-adaptive calibrator, we employ a self-supervisor made of an encoderâ€“decoder structure. The concatenation of the bias and the original characteristics are provided as input to the spatio-temporal feature extractor, which leverages a transformer and graph convolution structures to learn the spatio-temporal pattern, and then applies a predictor to produce the final prediction. Extensive trials on two public traffic prediction datasets (METR-LA and PEMS-BAY) demonstrate that SASTGCN surpasses the most recent techniques in several metrics.",
    "introduction": "Traffic prediction plays a significant part in creating intelligent cities such as traffic management, urban computing, and public safety. Nevertheless, the complex spatio-temporal linkages and dynamically shifting patterns make it somewhat challenging. Existing mainstream traffic prediction approaches heavily rely on graph convolutional networks and sequence prediction methods to extract complicated spatio-temporal patterns statically. However, they neglect to account for dynamic underlying correlations and thus fail to produce satisfactory prediction results.",
    "macro_domains": []
  },
  {
    "abstract": "It is important to capture passengersâ€™ public transit behavior and their mobility to create profiles, which are critical for analyzing human activities, understanding the social and economic structure of cities, improving public transportation, assisting urban planning, and promoting smart cities. In this paper, we develop a generative adversarial machine learning network to characterize the temporal and spatial mobility behavior of public transit passengers, based on massive smart card data and road network data. The Apriori algorithm is extended with spatio-temporal constraints to extract frequent transit mobility patterns of individual passengers based on a reconstructed personal trip dataset. This individual-level pattern information is used to construct personalized feature vectors. For regular and frequent public transit passengers, we identify similar transit mobility groups using spatio-temporal constraints to construct a group feature vector. We develop a generative adversarial network to embed public transit mobility of passengers. The proposed modelâ€™s generator consists of an auto-encoder, which extracts a low-dimensional and compact representation of passenger behavior, and a pre-trained sub-generator containing generalization features of public transit passengers. Shenzhen City is taken as the study area in this paper, and experiments were carried out based on smart card data, road network data, and bus GPS data. Clustering analysis of embedding vector representation and estimation of the top K transit destinations were conducted, verifying that the proposed method can profile passenger transit mobility in a comprehensive and compact manner.",
    "doi": "10.3390/ijgi12080338",
    "author_keywords": [
      "generative adversarial network",
      "public transit",
      "smart card data",
      "transit mobility embedding"
    ],
    "contribution": "In this paper, we develop a generative adversarial machine learning network to characterize the temporal and spatial mobility behavior of public transit passengers, based on massive smart card data and road network data. The Apriori algorithm is extended with spatio-temporal constraints to extract frequent transit mobility patterns of individual passengers based on a reconstructed personal trip dataset. This individual-level pattern information is used to construct personalized feature vectors. For regular and frequent public transit passengers, we identify similar transit mobility groups using spatio-temporal constraints to construct a group feature vector. We develop a generative adversarial network to embed public transit mobility of passengers. The proposed modelâ€™s generator consists of an auto-encoder, which extracts a low-dimensional and compact representation of passenger behavior, and a pre-trained sub-generator containing generalization features of public transit passengers. Shenzhen City is taken as the study area in this paper, and experiments were carried out based on smart card data, road network data, and bus GPS data. Clustering analysis of embedding vector representation and estimation of the top K transit destinations were conducted, verifying that the proposed method can profile passenger transit mobility in a comprehensive and compact manner.",
    "introduction": "It is important to capture passengersâ€™ public transit behavior and their mobility to create profiles, which are critical for analyzing human activities, understanding the social and economic structure of cities, improving public transportation, assisting urban planning, and promoting smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Citizen complaint classification plays an important role in the construction of the smart city. For text data, the most expressive semantic information is reflected in the keyword of the text. With the proposed Transformer structure and further expansion of the model structure, natural language processing has embarked on a path of fine-tuning the pre-trained model based on the multi-headed attention mechanism. Although the above method works well, it further deepens the black box model of the network. To verify whether the multi-headed attention mechanism adds enough attention to the keyword information, this paper proposes a joint attention enhancement network that places the attention mechanism outside the main network model. This paper uses the idea of lexical frequency statistics to obtain keyword information through the macroscopic use of corpus contents and improves the attention through knowledge incorporation based on soft attention. In this paper, a comparison experiment is performed by the current hot open-source network models on Hugging Face. Experiments show that the proposed model improves about 10%-20% in accuracy compared with the different original models, while the network training time only increases about 5%. The joint enhancement network can identify the key region of input data more accurately and converge quickly.",
    "doi": "10.1007/s10489-023-04490-y",
    "author_keywords": [
      "Citizen complaint",
      "Knowledge incorporation",
      "Multi-headed attention mechanism",
      "Pre-trained model",
      "Soft attention"
    ],
    "contribution": "To verify whether the multi-headed attention mechanism adds enough attention to the keyword information, this paper proposes a joint attention enhancement network that places the attention mechanism outside the main network model. This paper uses the idea of lexical frequency statistics to obtain keyword information through the macroscopic use of corpus contents and improves the attention through knowledge incorporation based on soft attention. In this paper, a comparison experiment is performed by the current hot open-source network models on Hugging Face. Experiments show that the proposed model improves about 10%-20% in accuracy compared with the different original models, while the network training time only increases about 5%. The joint enhancement network can identify the key region of input data more accurately and converge quickly.",
    "introduction": "Citizen complaint classification plays an important role in the construction of the smart city. For text data, the most expressive semantic information is reflected in the keyword of the text. With the proposed Transformer structure and further expansion of the model structure, natural language processing has embarked on a path of fine-tuning the pre-trained model based on the multi-headed attention mechanism. Although the above method works well, it further deepens the black box model of the network.",
    "macro_domains": []
  },
  {
    "abstract": "Machine learning is considered advantageous smart cities through sentiment analysis using social media reviews. Social media reviews can be helpful inside smart cities for various purposes. Primary convolutional neural networks (CNNs) are hard to implement for parallelizing applications and inadequate to understand the contextual semantics in long-term sequences for emotion classification. In this context, this paper presents a Bidirectional Encoder Representations from Transformers (BERT) based Dilated Convolutional Neural Network (BERT-DCNN) model, which leverages BERT as a pre-trained language model to generate word embeddings. Additionally, three parallel layers of Dilated Convolutional Neural Network (DCNN) stacked with a global average pooling layer helps in fine-tuning the model. Our implemented BERT-DCNN model performs dimensionality reduction and assimilates an increase of related dimensions withstanding any information loss. Furthermore, the model can capture long-term dependencies by utilizing various dilation rates. Moreover, the sentic knowledge base is incorporated in our model, enabling it to achieve concept-level sentiment analysis. Our experimental study demonstrates the importance of the implemented model in terms of F-measure, recall, precision, and accuracy with different machine learning models.",
    "doi": "10.1007/s12652-022-03698-z",
    "author_keywords": [
      "BERT",
      "Dilated convolution neural network",
      "Machine learning",
      "Sentiment analysis",
      "Smart city",
      "Social media"
    ],
    "contribution": "In this context, this paper presents a Bidirectional Encoder Representations from Transformers (BERT) based Dilated Convolutional Neural Network (BERT-DCNN) model, which leverages BERT as a pre-trained language model to generate word embeddings. Additionally, three parallel layers of Dilated Convolutional Neural Network (DCNN) stacked with a global average pooling layer helps in fine-tuning the model. Our implemented BERT-DCNN model performs dimensionality reduction and assimilates an increase of related dimensions withstanding any information loss. Furthermore, the model can capture long-term dependencies by utilizing various dilation rates. Moreover, the sentic knowledge base is incorporated in our model, enabling it to achieve concept-level sentiment analysis. Our experimental study demonstrates the importance of the implemented model in terms of F-measure, recall, precision, and accuracy with different machine learning models.",
    "introduction": "Machine learning is considered advantageous smart cities through sentiment analysis using social media reviews. Social media reviews can be helpful inside smart cities for various purposes. Primary convolutional neural networks (CNNs) are hard to implement for parallelizing applications and inadequate to understand the contextual semantics in long-term sequences for emotion classification.",
    "macro_domains": []
  },
  {
    "abstract": "Remote sensing (RS) has developed significantly with the progress of the Internet of Things (IoT) which is allowed the cheap and fast acquisition of data in millions and billions of interrelated devices utilized throughout the whole world. RS scene classifier that purposes for classifying scene types for RS images has wide applications in several domains like urban planning, national defence security, environmental monitoring, and natural hazard detection. State-of-the-art deep learning (DL) successes are performed in a novel wave of RS scene classification applications, but it is the absence of explainability and trustworthiness. An intrusion detection system (IDS) plays a vital role to ensure security in the RS-based IoT environment. In this aspect, this study presents an ebola optimization algorithm with deep learning-based scene classification and intrusion detection (EOADL-SCID) technique on IoT-enabled remote sensing images. The aim of the EOADL-SCID system lies in the effectual scene classification of remote sensing images and intrusion detection. It involves a two-stage procedure. In the initial stage, the EOADL-SCID algorithm involves a modified DarkNet-53 feature extractor, EOA-based hyperparameter tuning, and graph convolution network (GCN) based classification. Next, in the second stage, the intrusion detection process takes place via two subprocesses namely variational autoencoder (VAE) based intrusion detection and skill optimization algorithm (SOA) based parameter tuning. The simulation outcomes of the EOADL-SCID approach are tested utilizing two benchmark databases and the experimental outcomes highlighted the improved performance of the EOADL-SCID algorithm on scene classification and intrusion classification processes.",
    "doi": "10.1016/j.aej.2023.05.049",
    "author_keywords": [
      "Ebola optimization algorithm",
      "Image classification",
      "Internet of Things",
      "Intrusion detection",
      "Remote sensing",
      "Scene classification",
      "Security"
    ],
    "contribution": "In this aspect, this study presents an ebola optimization algorithm with deep learning-based scene classification and intrusion detection (EOADL-SCID) technique on IoT-enabled remote sensing images. The aim of the EOADL-SCID system lies in the effectual scene classification of remote sensing images and intrusion detection. It involves a two-stage procedure. In the initial stage, the EOADL-SCID algorithm involves a modified DarkNet-53 feature extractor, EOA-based hyperparameter tuning, and graph convolution network (GCN) based classification. Next, in the second stage, the intrusion detection process takes place via two subprocesses namely variational autoencoder (VAE) based intrusion detection and skill optimization algorithm (SOA) based parameter tuning. The simulation outcomes of the EOADL-SCID approach are tested utilizing two benchmark databases and the experimental outcomes highlighted the improved performance of the EOADL-SCID algorithm on scene classification and intrusion classification processes.",
    "introduction": "Remote sensing (RS) has developed significantly with the progress of the Internet of Things (IoT) which is allowed the cheap and fast acquisition of data in millions and billions of interrelated devices utilized throughout the whole world. RS scene classifier that purposes for classifying scene types for RS images has wide applications in several domains like urban planning, national defence security, environmental monitoring, and natural hazard detection. State-of-the-art deep learning (DL) successes are performed in a novel wave of RS scene classification applications, but it is the absence of explainability and trustworthiness. An intrusion detection system (IDS) plays a vital role to ensure security in the RS-based IoT environment.",
    "macro_domains": []
  },
  {
    "abstract": "The increasing trend of autonomous driving vehicles in smart cities emphasizes the need for safe travel. However, the presence of obstacles, potholes, and complex road environments, such as poor illumination and occlusion, can cause blurred road images that may impact the accuracy of maneuver prediction in visual perception systems. To address these challenges, a novel ensemble model, named ABHO-based deep CNN-BiLSTM has been proposed for traffic sign detection. This model combines a hybrid convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM) with the alarming-based hunting optimization (ABHO) algorithm to improve maneuver prediction accuracy. Additionally, a modified hough-enabled lane generative adversarial network (ABHO based HoughGAN) has been proposed, which is designed to be robust to blurred images. The ABHO algorithm, inspired by the defending and social characteristics of starling birds and Canis latrans, allows the model to efficiently search for the optimal solution from the available solutions in the search space. The proposed ensemble model has shown significantly improved accuracy, sensitivity, and specificity in maneuver prediction compared to previously utilized methods, with minimal error during lane detection. Overall, the proposed ensemble model addresses the challenges faced by autonomous driving vehicles in complex and obstructed road environments, offering a promising solution for enhancing safety and reliability in smart cities.",
    "doi": "10.26555/ijain.v9i2.1048",
    "author_keywords": [
      "Autonomous vehicle driving",
      "Controller optimization",
      "Deep learning",
      "Lane prediction",
      "Traffic sign detection"
    ],
    "contribution": "",
    "introduction": "The increasing trend of autonomous driving vehicles in smart cities emphasizes the need for safe travel. However, the presence of obstacles, potholes, and complex road environments, such as poor illumination and occlusion, can cause blurred road images that may impact the accuracy of maneuver prediction in visual perception systems. To address these challenges, a novel ensemble model, named ABHO-based deep CNN-BiLSTM has been proposed for traffic sign detection. This model combines a hybrid convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM) with the alarming-based hunting optimization (ABHO) algorithm to improve maneuver prediction accuracy. Additionally, a modified hough-enabled lane generative adversarial network (ABHO based HoughGAN) has been proposed, which is designed to be robust to blurred images. The ABHO algorithm, inspired by the defending and social characteristics of starling birds and Canis latrans, allows the model to efficiently search for the optimal solution from the available solutions in the search space. The proposed ensemble model has shown significantly improved accuracy, sensitivity, and specificity in maneuver prediction compared to previously utilized methods, with minimal error during lane detection. Overall, the proposed ensemble model addresses the challenges faced by autonomous driving vehicles in complex and obstructed road environments, offering a promising solution for enhancing safety and reliability in smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Unmanned aerial vehicles (UAVs), known as drones, have played a significant role in recent years in creating resilient smart cities. UAVs can be used for a wide range of applications, including emergency response, civil protection, search and rescue, and surveillance, thanks to their high mobility and reasonable price. Automatic recognition of human activity in aerial videos captured by drones is critical for various tasks for these applications. However, this is difficult due to many factors specific to aerial views, including camera motion, vibration, low resolution, background clutter, lighting conditions, and variations in view. Although deep learning approaches have demonstrated their effectiveness in a variety of challenging vision tasks, they require either a large number of labelled aerial videos for training or a dataset with balanced classes, both of which can be difficult to obtain. To address these challenges, a hybrid data augmentation method is proposed which combines data transformation with the Wasserstein Generative Adversarial Network (GAN)-based feature augmentation method. In particular, we apply the basic transformation methods to increase the amount of video in the database. A Convolutional Neural Networkâ€“Long Short-Term Memory (CNN-LSTM) model is used to learn the spatio-temporal dynamics of actions, then a GAN-based technique is applied to generate synthetic CNN-LSTM features conditioned on action classes which provide a high discriminative spatio-temporal features. We tested our model on the YouTube aerial database, demonstrating encouraging results that surpass those of previous state-of-the-art works, including an accuracy rate of 97.83%.",
    "doi": "10.3390/rs15143626",
    "author_keywords": [
      "CNN-LSTM",
      "data augmentation",
      "deep learning",
      "human action recognition",
      "UAVs",
      "WGAN-GP"
    ],
    "contribution": "",
    "introduction": "Unmanned aerial vehicles (UAVs), known as drones, have played a significant role in recent years in creating resilient smart cities. UAVs can be used for a wide range of applications, including emergency response, civil protection, search and rescue, and surveillance, thanks to their high mobility and reasonable price. Automatic recognition of human activity in aerial videos captured by drones is critical for various tasks for these applications. However, this is difficult due to many factors specific to aerial views, including camera motion, vibration, low resolution, background clutter, lighting conditions, and variations in view. Although deep learning approaches have demonstrated their effectiveness in a variety of challenging vision tasks, they require either a large number of labelled aerial videos for training or a dataset with balanced classes, both of which can be difficult to obtain. To address these challenges, a hybrid data augmentation method is proposed which combines data transformation with the Wasserstein Generative Adversarial Network (GAN)-based feature augmentation method. In particular, we apply the basic transformation methods to increase the amount of video in the database. A Convolutional Neural Networkâ€“Long Short-Term Memory (CNN-LSTM) model is used to learn the spatio-temporal dynamics of actions, then a GAN-based technique is applied to generate synthetic CNN-LSTM features conditioned on action classes which provide a high discriminative spatio-temporal features. We tested our model on the YouTube aerial database, demonstrating encouraging results that surpass those of previous state-of-the-art works, including an accuracy rate of 97.83%.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate building detection is a critical task in urban development and digital city mapping. However, current building detection models for high-resolution remote sensing images are still facing challenges due to complex object characteristics and similarities in appearance. To address this issue, this paper proposes a novel algorithm for building detection based on in-depth feature extraction and classification of adaptive superpixel shredding. The proposed approach consists of four main steps: image segmentation into homogeneous superpixels using a modified Simple Linear Iterative Clustering (SLIC), in-depth feature extraction using an variational auto-encoder (VAE) scale on the superpixels for training and testing data collection, identification of four classes (buildings, roads, trees, and shadows) using extracted feature data as input to an Convolutional Neural Network (CNN), and extraction of building shapes through regional growth and morphological operations. The proposed approach offers more stability in identifying buildings with unclear boundaries, eliminating the requirement for extensive prior segmentation. It has been tested on two datasets of high-resolution aerial images from the New Zealand region, demonstrating superior accuracy compared to previous works with an average F1 score of 98.83%. The proposed approach shows potential for fast and accurate urban monitoring and city planning, particularly in urban areas.",
    "doi": "10.3390/buildings13071649",
    "author_keywords": [
      "arial imagery",
      "building detection",
      "CNN",
      "superpixels segmentation",
      "VAE"
    ],
    "contribution": "To address this issue, this paper proposes a novel algorithm for building detection based on in-depth feature extraction and classification of adaptive superpixel shredding. The proposed approach consists of four main steps: image segmentation into homogeneous superpixels using a modified Simple Linear Iterative Clustering (SLIC), in-depth feature extraction using an variational auto-encoder (VAE) scale on the superpixels for training and testing data collection, identification of four classes (buildings, roads, trees, and shadows) using extracted feature data as input to an Convolutional Neural Network (CNN), and extraction of building shapes through regional growth and morphological operations. The proposed approach offers more stability in identifying buildings with unclear boundaries, eliminating the requirement for extensive prior segmentation. It has been tested on two datasets of high-resolution aerial images from the New Zealand region, demonstrating superior accuracy compared to previous works with an average F1 score of 98.83%. The proposed approach shows potential for fast and accurate urban monitoring and city planning, particularly in urban areas.",
    "introduction": "Accurate building detection is a critical task in urban development and digital city mapping. However, current building detection models for high-resolution remote sensing images are still facing challenges due to complex object characteristics and similarities in appearance.",
    "macro_domains": []
  },
  {
    "abstract": "In recent years, traffic forecasting has gradually become a core component of smart cities. Due to the complex spatial-temporal correlation of traffic data, traffic flow prediction is highly challenging. Existing studies are mainly focused on graphical modeling of fixed road structures. However, this fixed graphical structure cannot accurately capture the relationship between different roads, affecting the accuracy of long-term traffic flow prediction. In order to address this problem, this paper proposes a modeling framework STN-GCN for spatial-temporal normalized graphical convolutional neural networks. In terms of temporal dependence, spatial-temporal normalization was used to divide the data into high-frequency and low-frequency parts, allowing the model to extract more distinct features. In addition, fine data input to the temporal convolutional network (TCN) was used in this module to conduct more detailed temporal feature extraction so as to ensure the accuracy of long-term sequence extraction. In addition, the transformer module was added to the model, which captured the real-time state of traffic flow by extracting spatial dependencies and dynamically establishing spatial correlations through a self-attention mechanism. During the training process, a curriculum learning (CL) method was adopted, which provided optimized target sequences. Learning from easier targets can help avoid getting trapped in local minima and yields better generalization performance to more accurately approximate global minima. As shown by experimental results the model performed well on two real-world public transportation datasets, METR-LA and PEMS-BAY.",
    "doi": "10.3390/electronics12143158",
    "author_keywords": [
      "graph neural network",
      "self-attention mechanism",
      "spatial-temporal correlation",
      "spatial-temporal normalization",
      "transformer"
    ],
    "contribution": "In order to address this problem, this paper proposes a modeling framework STN-GCN for spatial-temporal normalized graphical convolutional neural networks. In terms of temporal dependence, spatial-temporal normalization was used to divide the data into high-frequency and low-frequency parts, allowing the model to extract more distinct features. In addition, fine data input to the temporal convolutional network (TCN) was used in this module to conduct more detailed temporal feature extraction so as to ensure the accuracy of long-term sequence extraction. In addition, the transformer module was added to the model, which captured the real-time state of traffic flow by extracting spatial dependencies and dynamically establishing spatial correlations through a self-attention mechanism. During the training process, a curriculum learning (CL) method was adopted, which provided optimized target sequences. Learning from easier targets can help avoid getting trapped in local minima and yields better generalization performance to more accurately approximate global minima. As shown by experimental results the model performed well on two real-world public transportation datasets, METR-LA and PEMS-BAY.",
    "introduction": "In recent years, traffic forecasting has gradually become a core component of smart cities. Due to the complex spatial-temporal correlation of traffic data, traffic flow prediction is highly challenging. Existing studies are mainly focused on graphical modeling of fixed road structures. However, this fixed graphical structure cannot accurately capture the relationship between different roads, affecting the accuracy of long-term traffic flow prediction.",
    "macro_domains": []
  },
  {
    "abstract": "Trajectory prediction of vehicles is of great importance to various smart city applications ranging from transportation scheduling, vehicle navigation, to location-based advertisements. Existing methods all focus on modeling spatiotemporal relations with explicit contextual semantics from labeled trajectory data, and rarely consider the effective use of large amounts of available unlabeled trajectory data with the assistance of contrastive learning and pre-training techniques. To this end, we develop a novel Pretrained-based Contrastive Learning Network (PreCLN) for vehicle trajectory prediction. Specifically, we propose a dual-view trajectory contrastive learning framework to achieve self-supervised pre-training. A Transformer-based trajectory encoder is designed to effectively capture the long-term spatiotemporal dependencies in trajectories to embed input trajectories into fixed-length representation vectors. Moreover, three auxiliary pre-training tasks, i.e., trajectory imputation, trajectory destination prediction, and trajectory-user linking, are used to assist the training of PreCLN with the dual-view trajectory contrastive learning framework. After pre-training, the result trajectory encoder is used to generate trajectory representations for future trajectory prediction. Extensive experiments on two real-world large-scale trajectory datasets demonstrate the significant superiority of PreCLN against state-of-the-art trajectory prediction baselines in terms of all evaluation metrics.",
    "doi": "10.1007/s11280-022-01121-3",
    "author_keywords": [
      "Contrastive learning",
      "GPS trajectory",
      "Pre-training",
      "Trajectory Prediction",
      "Trajectory representation"
    ],
    "contribution": "To this end, we develop a novel Pretrained-based Contrastive Learning Network (PreCLN) for vehicle trajectory prediction. Specifically, we propose a dual-view trajectory contrastive learning framework to achieve self-supervised pre-training. A Transformer-based trajectory encoder is designed to effectively capture the long-term spatiotemporal dependencies in trajectories to embed input trajectories into fixed-length representation vectors. Moreover, three auxiliary pre-training tasks, i.e., trajectory imputation, trajectory destination prediction, and trajectory-user linking, are used to assist the training of PreCLN with the dual-view trajectory contrastive learning framework. After pre-training, the result trajectory encoder is used to generate trajectory representations for future trajectory prediction. Extensive experiments on two real-world large-scale trajectory datasets demonstrate the significant superiority of PreCLN against state-of-the-art trajectory prediction baselines in terms of all evaluation metrics.",
    "introduction": "Trajectory prediction of vehicles is of great importance to various smart city applications ranging from transportation scheduling, vehicle navigation, to location-based advertisements. Existing methods all focus on modeling spatiotemporal relations with explicit contextual semantics from labeled trajectory data, and rarely consider the effective use of large amounts of available unlabeled trajectory data with the assistance of contrastive learning and pre-training techniques.",
    "macro_domains": []
  },
  {
    "abstract": "Haze significantly impacts various fields, such as autonomous driving, smart cities, and security monitoring. Deep learning has been proven effective in removing haze from images. However, obtaining pixel-aligned hazy and clear paired images in the real world can be challenging. Therefore, synthesized hazed images are often used for training deep networks. These images are typically generated based on parameters such as depth information and atmospheric scattering coefficient. However, this approach may cause the loss of important haze details, leading to color distortion or incomplete dehazed images. To address this problem, this paper proposes a method for synthesizing hazed images using a cycle generative adversarial network (CycleGAN). The CycleGAN is trained with unpaired hazy and clear images to learn the features of the hazy images. Then, the real haze features are added to clear images using the trained CycleGAN, resulting in well-pixel-aligned synthesized hazy and clear paired images that can be used for dehaze training. The results demonstrate that the dataset synthesized using this method efficiently solves the problem associated with traditional synthesized datasets. Furthermore, the dehazed images are restored using a super-resolution algorithm, enabling the obtainment of high-resolution clear images. This method has broadened the applications of deep learning in haze removal, particularly highlighting its potential in the fields of autonomous driving and smart cities.",
    "doi": "10.1117/1.OE.62.6.063101",
    "author_keywords": [
      "cycle generative adversarial network",
      "image dehazing",
      "image sharpness enhancement"
    ],
    "contribution": "However, this approach may cause the loss of important haze details, leading to color distortion or incomplete dehazed images. To address this problem, this paper proposes a method for synthesizing hazed images using a cycle generative adversarial network (CycleGAN). The CycleGAN is trained with unpaired hazy and clear images to learn the features of the hazy images. Then, the real haze features are added to clear images using the trained CycleGAN, resulting in well-pixel-aligned synthesized hazy and clear paired images that can be used for dehaze training. The results demonstrate that the dataset synthesized using this method efficiently solves the problem associated with traditional synthesized datasets. Furthermore, the dehazed images are restored using a super-resolution algorithm, enabling the obtainment of high-resolution clear images. This method has broadened the applications of deep learning in haze removal, particularly highlighting its potential in the fields of autonomous driving and smart cities.",
    "introduction": "Haze significantly impacts various fields, such as autonomous driving, smart cities, and security monitoring. Deep learning has been proven effective in removing haze from images. However, obtaining pixel-aligned hazy and clear paired images in the real world can be challenging. Therefore, synthesized hazed images are often used for training deep networks. These images are typically generated based on parameters such as depth information and atmospheric scattering coefficient.",
    "macro_domains": []
  },
  {
    "abstract": "With the rapid development of computer vision, point clouds technique was widely used in practical applications, such as obstacle detection, roadside detection, smart city construction, etc. However, how to efficiently identify the large scale point clouds is still an open challenge. For relieving the large computation consumption and low accuracy problem in point cloud classification, a large scale point cloud classification framework based on light bottle transformer (light-BotNet) is proposed. Firstly, the two-dimensional (2D) and three-dimensional (3D) feature values of large scale point cloud were extracted for constructing point cloud feature images, which employed the prior knowledge to normalize the point cloud features. Then, the feature images are input to the classification network, and the light-BotNet network is applied for point cloud classification. It is an interesting attempt to combine the traditional image features with the transformer network. For proving the performance of the proposed method, the large scale point cloud benchmark Oakland 3D is utilized. In the experiments, the proposed method achieved 98.1% accuracy on the Oakland 3D dataset. Compared with the other methods, it can both reduce the memory consumption and improve the classification accuracy in large scale point cloud classification.",
    "doi": "10.1007/s11801-023-2190-2",
    "author_keywords": [
      "A"
    ],
    "contribution": "",
    "introduction": "With the rapid development of computer vision, point clouds technique was widely used in practical applications, such as obstacle detection, roadside detection, smart city construction, etc. However, how to efficiently identify the large scale point clouds is still an open challenge. For relieving the large computation consumption and low accuracy problem in point cloud classification, a large scale point cloud classification framework based on light bottle transformer (light-BotNet) is proposed. Firstly, the two-dimensional (2D) and three-dimensional (3D) feature values of large scale point cloud were extracted for constructing point cloud feature images, which employed the prior knowledge to normalize the point cloud features. Then, the feature images are input to the classification network, and the light-BotNet network is applied for point cloud classification. It is an interesting attempt to combine the traditional image features with the transformer network. For proving the performance of the proposed method, the large scale point cloud benchmark Oakland 3D is utilized. In the experiments, the proposed method achieved 98.1% accuracy on the Oakland 3D dataset. Compared with the other methods, it can both reduce the memory consumption and improve the classification accuracy in large scale point cloud classification.",
    "macro_domains": []
  },
  {
    "abstract": "The novel coronavirus that triggered the COVID-19 outburst is still active around the globe. By now, COVID-19 has affected practically every facet of progress, most importantly, it has shaken the healthcare system like never before. At its peak, it forced Governments throughout the world into lockdowns to limit the reach of the epidemic. Based on early advisories of the World Health Organization (WHO), the only method of safeguarding oneself from being infected was to wear a face mask. Even today, with fewer cases being reported, masking oneself remains the single most effective and cheap means of prevention. As urban areas continue to grow, effective city management is essential for mitigating the increase of the deadly COVID-19 disease. The success of smart cities depends on significant upgrades to public transportation, highways, companies, homes, and municipal streets. There is room for improvement in the public bus transportation system now in place, and one of those improvements would be to use artificial intelligence. To determine if the person is wearing a face mask, you need an autonomous mask detection and alert system. Therefore, this study introduced a deep learning-based design that combines the attention-based generative adversarial network (ABGAN) with the multi-objective interactive honeybee mating optimization (MOIHBMO) approach to create an automated face mask recognition system. A set of 1386 images has been used to create a real-time dataset. This database contains 690 pictures without face masks and 686 images with them. The suggested algorithm ABGAN-MOIHBMO is compared to other traditional methods for detection of face masks, such as DL, AI, and DNN. The performance indicators used are error rate, inference speed, precision, recall, accuracy, and over fitting assessments. The results demonstrate that the proposed ABGAN-MOIHBMO outperforms the existing methodologies. It provides 96% of precision, 86% of recall, 93% for the f1 score, which are higher/better than the other, traditional methods. The error rate in ABGAN-MOIHBMO is a low 1.1%, which is lower other approaches. To predict and underline the significance of face mask use, the face mask detection technique may be employed in the future at Saudi airports, shopping centers, and other congested locations. On a larger platform, our research will be an effective instrument in helping many nations throughout the globe combat the rapid spread of this contagious illness.",
    "doi": "10.18576/isl/120617",
    "author_keywords": [
      "ABGAN",
      "COVID-19",
      "MOIHBMO algorithm",
      "smart cities",
      "transportation system"
    ],
    "contribution": "Therefore, this study introduced a deep learning-based design that combines the attention-based generative adversarial network (ABGAN) with the multi-objective interactive honeybee mating optimization (MOIHBMO) approach to create an automated face mask recognition system. A set of 1386 images has been used to create a real-time dataset. This database contains 690 pictures without face masks and 686 images with them. The suggested algorithm ABGAN-MOIHBMO is compared to other traditional methods for detection of face masks, such as DL, AI, and DNN. The performance indicators used are error rate, inference speed, precision, recall, accuracy, and over fitting assessments. The results demonstrate that the proposed ABGAN-MOIHBMO outperforms the existing methodologies. It provides 96% of precision, 86% of recall, 93% for the f1 score, which are higher/better than the other, traditional methods. The error rate in ABGAN-MOIHBMO is a low 1.1%, which is lower other approaches. To predict and underline the significance of face mask use, the face mask detection technique may be employed in the future at Saudi airports, shopping centers, and other congested locations. On a larger platform, our research will be an effective instrument in helping many nations throughout the globe combat the rapid spread of this contagious illness.",
    "introduction": "The novel coronavirus that triggered the COVID-19 outburst is still active around the globe. By now, COVID-19 has affected practically every facet of progress, most importantly, it has shaken the healthcare system like never before. At its peak, it forced Governments throughout the world into lockdowns to limit the reach of the epidemic. Based on early advisories of the World Health Organization (WHO), the only method of safeguarding oneself from being infected was to wear a face mask. Even today, with fewer cases being reported, masking oneself remains the single most effective and cheap means of prevention. As urban areas continue to grow, effective city management is essential for mitigating the increase of the deadly COVID-19 disease. The success of smart cities depends on significant upgrades to public transportation, highways, companies, homes, and municipal streets. There is room for improvement in the public bus transportation system now in place, and one of those improvements would be to use artificial intelligence. To determine if the person is wearing a face mask, you need an autonomous mask detection and alert system.",
    "macro_domains": []
  },
  {
    "abstract": "Modeling time-evolving preferences of users with their sequential item interactions, has attracted increasing attention in many online applications. Hence, sequential recommender systems have been developed to learn the dynamic user interests from the historical interactions for suggesting items. However, the interaction pattern encoding functions in most existing sequential recommender systems have focused on single type of user-item interactions. In many real-life online platforms, user-item interactive behaviors are often multi-typed (e.g., click, add-to-favorite, purchase) with complex cross-type behavior inter-dependencies. Learning from informative representations of users and items based on their multi-typed interaction data, is of great importance to accurately characterize the time-evolving user preference. In this work, we tackle the dynamic user-item relation learning with the awareness of multi-behavior interactive patterns. Towards this end, we propose a new Temporal Graph Transformer (TGT) recommendation framework to jointly capture dynamic short-term and long-range user-item interactive patterns, by exploring the evolving correlations across different types of behaviors. The new TGT method endows the sequential recommendation architecture to distill dedicated knowledge for type-specific behavior relational context and the implicit behavior dependencies. Experiments on the real-world datasets indicate that our method TGT consistently outperforms various state-of-the-art recommendation methods. Our model implementation codes are available at https://github.com/akaxlh/TGT.",
    "doi": "10.1109/TKDE.2022.3175094",
    "author_keywords": [
      "Graph neural network",
      "multi-behavior recommendation",
      "sequential recommendation"
    ],
    "contribution": "In this work, we tackle the dynamic user-item relation learning with the awareness of multi-behavior interactive patterns. Towards this end, we propose a new Temporal Graph Transformer (TGT) recommendation framework to jointly capture dynamic short-term and long-range user-item interactive patterns, by exploring the evolving correlations across different types of behaviors. The new TGT method endows the sequential recommendation architecture to distill dedicated knowledge for type-specific behavior relational context and the implicit behavior dependencies. Experiments on the real-world datasets indicate that our method TGT consistently outperforms various state-of-the-art recommendation methods. Our model implementation codes are available at https://github.com/akaxlh/TGT.",
    "introduction": "Modeling time-evolving preferences of users with their sequential item interactions, has attracted increasing attention in many online applications. Hence, sequential recommender systems have been developed to learn the dynamic user interests from the historical interactions for suggesting items. However, the interaction pattern encoding functions in most existing sequential recommender systems have focused on single type of user-item interactions. In many real-life online platforms, user-item interactive behaviors are often multi-typed (e.g., click, add-to-favorite, purchase) with complex cross-type behavior inter-dependencies. Learning from informative representations of users and items based on their multi-typed interaction data, is of great importance to accurately characterize the time-evolving user preference.",
    "macro_domains": []
  },
  {
    "abstract": "Reconstruction-based and prediction-based approaches are widely used for video anomaly detection (VAD) in smart city surveillance applications. However, neither of these approaches can effectively utilize the rich contextual information that exists in videos, which makes it difficult to accurately perceive anomalous activities. In this paper, we exploit the idea of a training model based on the â€œCloze Testâ€ strategy in natural language processing (NLP) and introduce a novel unsupervised learning framework to encode both motion and appearance information at an object level. Specifically, to store the normal modes of video activity reconstructions, we first design an optical stream memory network with skip connections. Secondly, we build a spaceâ€“time cube (STC) for use as the basic processing unit of the model and erase a patch in the STC to form the frame to be reconstructed. This enables a so-called â€incomplete event (IE)â€ to be completed. On this basis, a conditional autoencoder is utilized to capture the high correspondence between optical flow and STC. The model predicts erased patches in IEs based on the context of the front and back frames. Finally, we employ a generating adversarial network (GAN)-based training method to improve the performance of VAD. By distinguishing the predicted erased optical flow and erased video frame, the anomaly detection results are shown to be more reliable with our proposed method which can help reconstruct the original video in IE. Comparative experiments conducted on the benchmark UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets demonstrate AUROC scores reaching 97.7%, 89.7%, and 75.8%, respectively.",
    "doi": "10.3390/s23104828",
    "author_keywords": [
      "incomplete event",
      "optical flow",
      "video anomaly detection"
    ],
    "contribution": "In this paper, we exploit the idea of a training model based on the â€œCloze Testâ€ strategy in natural language processing (NLP) and introduce a novel unsupervised learning framework to encode both motion and appearance information at an object level. Specifically, to store the normal modes of video activity reconstructions, we first design an optical stream memory network with skip connections. Secondly, we build a spaceâ€“time cube (STC) for use as the basic processing unit of the model and erase a patch in the STC to form the frame to be reconstructed. This enables a so-called â€incomplete event (IE)â€ to be completed. On this basis, a conditional autoencoder is utilized to capture the high correspondence between optical flow and STC. The model predicts erased patches in IEs based on the context of the front and back frames. Finally, we employ a generating adversarial network (GAN)-based training method to improve the performance of VAD. By distinguishing the predicted erased optical flow and erased video frame, the anomaly detection results are shown to be more reliable with our proposed method which can help reconstruct the original video in IE. Comparative experiments conducted on the benchmark UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets demonstrate AUROC scores reaching 97.7%, 89.7%, and 75.8%, respectively.",
    "introduction": "Reconstruction-based and prediction-based approaches are widely used for video anomaly detection (VAD) in smart city surveillance applications. However, neither of these approaches can effectively utilize the rich contextual information that exists in videos, which makes it difficult to accurately perceive anomalous activities.",
    "macro_domains": []
  },
  {
    "abstract": "As one of the key technologies of intelligent transportation systems, vehicle re-identification (Re-ID) aims to retrieve the same vehicle from different monitoring scenes and plays an important role in building a safe and smart city. With the continuous development of computer vision, the Re-ID method of using supervised learning suffers from the problems of strong reliance on manual annotation in the training process and weak scene generalization ability, so unsupervised learning of vehicle Re-ID gradually becomes the focus of research in recent years. Firstly, the present mainstream vehicle Re-ID datasets and the commonly used model evaluation metrics are introduced. Then, latest unsupervised learning-based vehicle Re-ID methods are grouped into two categories: generative adversarial networks and clustering algorithms according to the current research ideas. Starting from the problems of domain deviation, cross-view deviation and insufficient information of data samples, the former is further divided into three categories of style transfer, multi-view generation, and data augmentation. For the labeling pro-blem, the latter can be divided into two categories of pseudo-labeled unsupervised domain adaptation and no label information required. With problem solving as the starting point, the fundamentals, advantages and disadvantages, and performance results of each type of method on mainstream datasets are summarized. Finally, the challenges faced by the current unsupervised learning for vehicle Re-ID are analyzed, and the future work in this research direction is prospected.",
    "doi": "10.3778/j.issn.1673-9418.2209100",
    "author_keywords": [
      "clustering",
      "generative adversarial networks",
      "intelligent transportation",
      "unsupervised learning",
      "vehicle re-identification"
    ],
    "contribution": "Finally, the challenges faced by the current unsupervised learning for vehicle Re-ID are analyzed, and the future work in this research direction is prospected.",
    "introduction": "As one of the key technologies of intelligent transportation systems, vehicle re-identification (Re-ID) aims to retrieve the same vehicle from different monitoring scenes and plays an important role in building a safe and smart city. With the continuous development of computer vision, the Re-ID method of using supervised learning suffers from the problems of strong reliance on manual annotation in the training process and weak scene generalization ability, so unsupervised learning of vehicle Re-ID gradually becomes the focus of research in recent years. Firstly, the present mainstream vehicle Re-ID datasets and the commonly used model evaluation metrics are introduced. Then, latest unsupervised learning-based vehicle Re-ID methods are grouped into two categories: generative adversarial networks and clustering algorithms according to the current research ideas. Starting from the problems of domain deviation, cross-view deviation and insufficient information of data samples, the former is further divided into three categories of style transfer, multi-view generation, and data augmentation. For the labeling pro-blem, the latter can be divided into two categories of pseudo-labeled unsupervised domain adaptation and no label information required. With problem solving as the starting point, the fundamentals, advantages and disadvantages, and performance results of each type of method on mainstream datasets are summarized.",
    "macro_domains": []
  },
  {
    "abstract": "Machine learning (ML)-based Network Intrusion Detection Systems (NIDSs) can classify each networkâ€™s flow behavior as benign or malicious by detecting heterogeneous features, including both categorical and numerical features. However, the present ML-based NIDSs are deemed insufficient in terms of their ability to generalize, particularly in changing network environments such as the Internet of Things (IoT)-based smart home. Although IoT devices add so much to home comforts, they also introduce potential risks and vulnerabilities. Recently, many NIDS studies on other IoT scenarios, such as the Internet of Vehicles (IoV) and smart cities, focus on utilizing the telemetry data of IoT devices for IoT intrusion detection. Because when IoT devices are under attack, their abnormal telemetry data values can reflect the anomaly state of those devices. Those telemetry data-based IoT NIDS methods detect intrusion events from a different view, focusing on the attack impact, from the traditional network traffic-based NIDS, which focuses on analyzing attack behavior. The telemetry data-based NIDS is more suitable for IoT devices without built-in security mechanisms. Considering the smart home IoT scenario, which has a smaller scope and a limited number of IoT devices compared to other IoT scenarios, both NIDS views can work independently. This motivated us to propose a novel ML-based NIDS to combine the network traffic-based and telemetry data-based NIDS together. In this paper, we propose a Transformer-based IoT NIDS method to learn the behaviors and effects of attacks from different types of data that are generated in the heterogeneous IoT environment. The proposed method utilizes a self-attention mechanism to learn contextual embeddings for input network features. Based on the contextual embeddings, our method can solve the feature set challenge, including both continuous and categorical features. Our method is the first to utilize both network traffic data and IoT sensorsâ€™ telemetry data at the same time for intrusion detection. Experiments reveal the effectiveness of our method on a realistic network traffic intrusion detection dataset named ToN_IoT, with an accuracy of 97.95% for binary classification and 95.78% for multiple classifications on pure network data. With the extra IoT information, the performance of our method has been improved to 98.39% and 97.06%, respectively. A comparative study with existing works shows that our method can achieve state-of-the-art performance on the ToN_IoT dataset.",
    "doi": "10.3390/electronics12092100",
    "author_keywords": [
      "deep learning",
      "network intrusion detection systems",
      "network security"
    ],
    "contribution": "In this paper, we propose a Transformer-based IoT NIDS method to learn the behaviors and effects of attacks from different types of data that are generated in the heterogeneous IoT environment. The proposed method utilizes a self-attention mechanism to learn contextual embeddings for input network features. Based on the contextual embeddings, our method can solve the feature set challenge, including both continuous and categorical features. Our method is the first to utilize both network traffic data and IoT sensorsâ€™ telemetry data at the same time for intrusion detection. Experiments reveal the effectiveness of our method on a realistic network traffic intrusion detection dataset named ToN_IoT, with an accuracy of 97.95% for binary classification and 95.78% for multiple classifications on pure network data. With the extra IoT information, the performance of our method has been improved to 98.39% and 97.06%, respectively. A comparative study with existing works shows that our method can achieve state-of-the-art performance on the ToN_IoT dataset.",
    "introduction": "Machine learning (ML)-based Network Intrusion Detection Systems (NIDSs) can classify each networkâ€™s flow behavior as benign or malicious by detecting heterogeneous features, including both categorical and numerical features. However, the present ML-based NIDSs are deemed insufficient in terms of their ability to generalize, particularly in changing network environments such as the Internet of Things (IoT)-based smart home. Although IoT devices add so much to home comforts, they also introduce potential risks and vulnerabilities. Recently, many NIDS studies on other IoT scenarios, such as the Internet of Vehicles (IoV) and smart cities, focus on utilizing the telemetry data of IoT devices for IoT intrusion detection. Because when IoT devices are under attack, their abnormal telemetry data values can reflect the anomaly state of those devices. Those telemetry data-based IoT NIDS methods detect intrusion events from a different view, focusing on the attack impact, from the traditional network traffic-based NIDS, which focuses on analyzing attack behavior. The telemetry data-based NIDS is more suitable for IoT devices without built-in security mechanisms. Considering the smart home IoT scenario, which has a smaller scope and a limited number of IoT devices compared to other IoT scenarios, both NIDS views can work independently. This motivated us to propose a novel ML-based NIDS to combine the network traffic-based and telemetry data-based NIDS together.",
    "macro_domains": []
  },
  {
    "abstract": "The construction of Smart Cities is inseparable from the healthy operation of markets. Reasonable data analysis can provide a crucial foundation for the development of market behavior by considering the enormous amount of data generated by a market economy. To this end, we propose enhanced cluster generative adversarial networks (eClusterGAN) to achieve latent space clustering. However, data storage security is crucial. Moreover, we suggest a GAN-based network intrusion detection system (GANâ€“NIDS) that uses adversarial learning to assist the generator in learning the spatial distribution of normal network flows. The simulation results showed that the proposed eClusterGAN and GANâ€“NIDS outperformed the benchmarks in terms of clustering accuracy, running time, precision, recall, and F1, which can support researchers in studying economic data trends. The construction of Smart Cities can effectively ensure healthy market development by discovering and disseminating the potential value of market economic data.",
    "doi": "10.1016/j.compeleceng.2023.108722",
    "author_keywords": [
      "Clustering",
      "Deep learning",
      "Market economy",
      "Secure data analysis",
      "Smart cities"
    ],
    "contribution": "To this end, we propose enhanced cluster generative adversarial networks (eClusterGAN) to achieve latent space clustering. However, data storage security is crucial. Moreover, we suggest a GAN-based network intrusion detection system (GANâ€“NIDS) that uses adversarial learning to assist the generator in learning the spatial distribution of normal network flows. The simulation results showed that the proposed eClusterGAN and GANâ€“NIDS outperformed the benchmarks in terms of clustering accuracy, running time, precision, recall, and F1, which can support researchers in studying economic data trends. The construction of Smart Cities can effectively ensure healthy market development by discovering and disseminating the potential value of market economic data.",
    "introduction": "The construction of Smart Cities is inseparable from the healthy operation of markets. Reasonable data analysis can provide a crucial foundation for the development of market behavior by considering the enormous amount of data generated by a market economy.",
    "macro_domains": []
  },
  {
    "abstract": "Anomalous event recognition requires an instant response to reduce the loss of human life and property; however, existing automated systems show limited performance due to considerations related to the temporal domain of the videos and ignore the significant role of spatial information. Furthermore, although current surveillance systems can detect anomalous events, they require human intervention to recognise their nature and to select appropriate countermeasures, as there are no fully automatic surveillance techniques that can simultaneously detect and interpret anomalous events. Therefore, we present a framework called Vision Transformer Anomaly Recognition (ViT-ARN) that can detect and interpret anomalies in smart city surveillance videos. The framework consists of two stages: the first involves online anomaly detection, for which a customised, lightweight, one-class deep neural network is developed to detect anomalies in a surveillance environment, while in the second stage, the detected anomaly is further classified into the corresponding class. The size of our anomaly detection model is compressed using a filter pruning strategy based on a geometric median, with the aim of easy adaptability for resource-constrained devices. Anomaly classification is based on vision transformer features and is followed by a bottleneck attention mechanism to enhance the representation. The refined features are passed to a multi-reservoir echo state network for a detailed analysis of real-world anomalies such as vandalism and road accidents. A total of 858 and 1600 videos from two datasets are used to train the proposed model, and extensive experiments on the LAD-2000 and UCF-Crime datasets comprising 290 and 400 testing videos reveal that our framework can recognise anomalies more effectively, outperforming other state-of-the-art approaches with increases in accuracy of 10.14% and 3% on the LAD-2000 and UCF-Crime datasets, respectively.",
    "doi": "10.1016/j.ipm.2023.103289",
    "author_keywords": [
      "Anomaly detection and recognition",
      "Artificial intelligence",
      "Attention mechanism",
      "ESN",
      "Spatio-temporal",
      "Surveillance system",
      "Weakly supervised learning"
    ],
    "contribution": "Therefore, we present a framework called Vision Transformer Anomaly Recognition (ViT-ARN) that can detect and interpret anomalies in smart city surveillance videos. The framework consists of two stages: the first involves online anomaly detection, for which a customised, lightweight, one-class deep neural network is developed to detect anomalies in a surveillance environment, while in the second stage, the detected anomaly is further classified into the corresponding class. The size of our anomaly detection model is compressed using a filter pruning strategy based on a geometric median, with the aim of easy adaptability for resource-constrained devices. Anomaly classification is based on vision transformer features and is followed by a bottleneck attention mechanism to enhance the representation. The refined features are passed to a multi-reservoir echo state network for a detailed analysis of real-world anomalies such as vandalism and road accidents. A total of 858 and 1600 videos from two datasets are used to train the proposed model, and extensive experiments on the LAD-2000 and UCF-Crime datasets comprising 290 and 400 testing videos reveal that our framework can recognise anomalies more effectively, outperforming other state-of-the-art approaches with increases in accuracy of 10.14% and 3% on the LAD-2000 and UCF-Crime datasets, respectively.",
    "introduction": "Anomalous event recognition requires an instant response to reduce the loss of human life and property; however, existing automated systems show limited performance due to considerations related to the temporal domain of the videos and ignore the significant role of spatial information. Furthermore, although current surveillance systems can detect anomalous events, they require human intervention to recognise their nature and to select appropriate countermeasures, as there are no fully automatic surveillance techniques that can simultaneously detect and interpret anomalous events.",
    "macro_domains": []
  },
  {
    "abstract": "Detecting anomalies in large complex systems is a critical and challenging task. The difficulties arise from several aspects. First, collecting ground truth labels or prior knowledge for anomalies is hard in real-world systems, which often lead to limited or no anomaly labels in the dataset. Second, anomalies in large systems usually occur in a collective manner due to the underlying dependency structure among devices or sensors. Lastly, real-time anomaly detection for high-dimensional data requires efficient algorithms that are capable of handling different types of data (i.e. continuous and discrete). We propose a correlation structure-based collective anomaly detection (CSCAD) model for high-dimensional anomaly detection problem in large systems, which is also generalizable to semi-supervised or supervised settings. Our framework utilize graph convolutional network combining a variational autoencoder to jointly exploit the feature space correlation and reconstruction deficiency of samples to perform anomaly detection. We propose an extended mutual information (EMI) metric to mine the internal correlation structure among different data features, which enhances the data reconstruction capability of CSCAD. The reconstruction loss and latent standard deviation vector of a sample obtained from reconstruction network can be perceived as two natural anomalous degree measures. An anomaly discriminating network can then be trained using low anomalous degree samples as positive samples, and high anomalous degree samples as negative samples. Experimental results on five public datasets demonstrate that our approach consistently outperforms all the competing baselines.",
    "doi": "10.1109/TKDE.2022.3154166",
    "author_keywords": [
      "Anomaly detection",
      "complex system",
      "correlation mining",
      "unsupervised learning",
      "urban computing",
      "variational autoencoder"
    ],
    "contribution": "We propose a correlation structure-based collective anomaly detection (CSCAD) model for high-dimensional anomaly detection problem in large systems, which is also generalizable to semi-supervised or supervised settings. Our framework utilize graph convolutional network combining a variational autoencoder to jointly exploit the feature space correlation and reconstruction deficiency of samples to perform anomaly detection. We propose an extended mutual information (EMI) metric to mine the internal correlation structure among different data features, which enhances the data reconstruction capability of CSCAD. The reconstruction loss and latent standard deviation vector of a sample obtained from reconstruction network can be perceived as two natural anomalous degree measures. An anomaly discriminating network can then be trained using low anomalous degree samples as positive samples, and high anomalous degree samples as negative samples. Experimental results on five public datasets demonstrate that our approach consistently outperforms all the competing baselines.",
    "introduction": "Detecting anomalies in large complex systems is a critical and challenging task. The difficulties arise from several aspects. First, collecting ground truth labels or prior knowledge for anomalies is hard in real-world systems, which often lead to limited or no anomaly labels in the dataset. Second, anomalies in large systems usually occur in a collective manner due to the underlying dependency structure among devices or sensors. Lastly, real-time anomaly detection for high-dimensional data requires efficient algorithms that are capable of handling different types of data (i.e. continuous and discrete).",
    "macro_domains": []
  },
  {
    "abstract": "The most crucial component of any smart city traffic management system is traffic flow prediction. It can assist a driver in selecting the most efficient route to their destination. The digitalization of closed-circuit television (CCTV) systems has resulted in more effective and capable surveillance imaging systems for security applications. The number of automobiles on the worldâ€™s highways has steadily increased in recent decades. However, road capacity has not developed at the same rate, resulting in significantly increasing congestion. The model learning mechanism cannot be guided or improved by prior domain knowledge of real-world problems. In reality, symmetrical features are common in many real-world research objects. To mitigate this severe situation, the researchers chose adaptive traffic management to make intelligent and efficient use of the current infrastructure. Data grow exponentially and become a complex item that must be managed. Unstructured data are a subset of big data that are difficult to process and have volatile properties. CCTV cameras are used in traffic management to monitor a specific point on the roadway. CCTV generates unstructured data in the form of images and videos. Because of the dataâ€™s intricacy, these data are challenging to process. This study proposes using big data analytics to transform real-time unstructured data from CCTV into information that can be shown on a web dashboard. As a Hadoop-based architectural stack that can serve as the ICT backbone for managing unstructured data efficiently, the Hadoop Distributed File System (HDFS) stores several sorts of data using the Hadoop file storage system, a high-performance integrated virtual environment (HIVE) tables, and non-relational storage. Traditional computer vision algorithms are incapable of processing such massive amounts of visual data collected in real-time. However, the inferiority of traffic data and the quality of unit information are always symmetrical phenomena. As a result, there is a need for big data analytics with machine learning, which entails processing and analyzing vast amounts of visual data, such as photographs or videos, to uncover semantic patterns that may be interpreted. As a result, smart cities require a more accurate traffic flow prediction system. In comparison to other recent methods applied to the dataset, the proposed method achieved the highest accuracy of 98.21%. In this study, we look at the construction of a secure CCTV strategy that predicts traffic from CCTV surveillance using real-time traffic prediction analysis with generative adversarial networks (GAN) and HDFS.",
    "doi": "10.3390/sym15040779",
    "author_keywords": [
      "generative adversarial networks (GAN)",
      "Hadoop Distributed File System (HDFS)",
      "image synthesis",
      "Intelligent Transportation System (ITS)",
      "traffic management system"
    ],
    "contribution": "This study proposes using big data analytics to transform real-time unstructured data from CCTV into information that can be shown on a web dashboard. As a Hadoop-based architectural stack that can serve as the ICT backbone for managing unstructured data efficiently, the Hadoop Distributed File System (HDFS) stores several sorts of data using the Hadoop file storage system, a high-performance integrated virtual environment (HIVE) tables, and non-relational storage. Traditional computer vision algorithms are incapable of processing such massive amounts of visual data collected in real-time. However, the inferiority of traffic data and the quality of unit information are always symmetrical phenomena. As a result, there is a need for big data analytics with machine learning, which entails processing and analyzing vast amounts of visual data, such as photographs or videos, to uncover semantic patterns that may be interpreted. As a result, smart cities require a more accurate traffic flow prediction system. In comparison to other recent methods applied to the dataset, the proposed method achieved the highest accuracy of 98.21%. In this study, we look at the construction of a secure CCTV strategy that predicts traffic from CCTV surveillance using real-time traffic prediction analysis with generative adversarial networks (GAN) and HDFS.",
    "introduction": "The most crucial component of any smart city traffic management system is traffic flow prediction. It can assist a driver in selecting the most efficient route to their destination. The digitalization of closed-circuit television (CCTV) systems has resulted in more effective and capable surveillance imaging systems for security applications. The number of automobiles on the worldâ€™s highways has steadily increased in recent decades. However, road capacity has not developed at the same rate, resulting in significantly increasing congestion. The model learning mechanism cannot be guided or improved by prior domain knowledge of real-world problems. In reality, symmetrical features are common in many real-world research objects. To mitigate this severe situation, the researchers chose adaptive traffic management to make intelligent and efficient use of the current infrastructure. Data grow exponentially and become a complex item that must be managed. Unstructured data are a subset of big data that are difficult to process and have volatile properties. CCTV cameras are used in traffic management to monitor a specific point on the roadway. CCTV generates unstructured data in the form of images and videos. Because of the dataâ€™s intricacy, these data are challenging to process.",
    "macro_domains": []
  },
  {
    "abstract": "Urban flow monitoring and forecasting systems play important roles in smart city management. However, due to the long-lasting and enormous deployment cost of ubiquitous traffic monitoring devices (e.g., loop detectors, traffic video detection), it is very difficult to predict flow in high-resolution (HR) with limited monitoring devices. The existing spatiotemporal network based methods usually predict the urban flow in the same spatial scale without considering the spatial correlations between coarse-grained and fine-grained urban flows. To tackle these issues, we propose a HR spatiotemporal transformer network (HRSTT) to predict fine-grained urban flow. Specifically, residual convolution units are employed to constructs the high-level features of three-view temporal (e.g., closeness, period, and trend) flow data. Then, a transformer block is designed to jointly learn the spatiotemporal dynamic features of each temporal flow with self-attention mechanism. For the external factors (e.g., holidays, weather conditions) are extracted by embedding dense networks, which are fused with high level coarse-grained flow feature maps with gated-fusion scheme. Finally, the coarse-grained fusion feature maps are transferred to the distributional upsampling module, generating the fined-grained flow map of target predicted time. Furthermore, the proposed model is evaluated with several baselines on real-world TaxiBJ datasets, demonstrating the state-of-the-art performance of our approach on the fine-grained urban flow forecasting problem.",
    "doi": "10.1109/TAI.2022.3153750",
    "author_keywords": [
      "Deep neural network (DNN)",
      "high-resolution (HR)",
      "urban flow forecasting"
    ],
    "contribution": "To tackle these issues, we propose a HR spatiotemporal transformer network (HRSTT) to predict fine-grained urban flow. Specifically, residual convolution units are employed to constructs the high-level features of three-view temporal (e.g., closeness, period, and trend) flow data. Then, a transformer block is designed to jointly learn the spatiotemporal dynamic features of each temporal flow with self-attention mechanism. For the external factors (e.g., holidays, weather conditions) are extracted by embedding dense networks, which are fused with high level coarse-grained flow feature maps with gated-fusion scheme. Finally, the coarse-grained fusion feature maps are transferred to the distributional upsampling module, generating the fined-grained flow map of target predicted time. Furthermore, the proposed model is evaluated with several baselines on real-world TaxiBJ datasets, demonstrating the state-of-the-art performance of our approach on the fine-grained urban flow forecasting problem.",
    "introduction": "Urban flow monitoring and forecasting systems play important roles in smart city management. However, due to the long-lasting and enormous deployment cost of ubiquitous traffic monitoring devices (e.g., loop detectors, traffic video detection), it is very difficult to predict flow in high-resolution (HR) with limited monitoring devices. The existing spatiotemporal network based methods usually predict the urban flow in the same spatial scale without considering the spatial correlations between coarse-grained and fine-grained urban flows.",
    "macro_domains": []
  },
  {
    "abstract": "A community integrated energy system (CIES) is an important carrier of the energy internet and smart city in geographical and functional terms. Its emergence provides a new solution to the problems of energy utilization and environmental pollution. To coordinate the integrated demand response and uncertainty of renewable energy generation (RGs), a data-driven two-stage distributionally robust optimization (DRO) model is constructed. A comprehensive norm consisting of the 1-norm and âˆž-norm is used as the uncertainty probability distribution information set, thereby avoiding complex probability density information. To address multiple uncertainties of RGs, a generative adversarial network based on the Wasserstein distance with gradient penalty is proposed to generate RG scenarios, which has wide applicability. To further tap the potential of the demand response, we take into account the ambiguity of human thermal comfort and the thermal inertia of buildings. Thus, an integrated demand response mechanism is developed that effectively promotes the consumption of renewable energy. The proposed method is simulated in an actual CIES in North China. In comparison with traditional stochastic programming and robust optimization, it is verified that the proposed DRO model properly balances the relationship between economical operation and robustness while exhibiting stronger adaptability. Furthermore, our approach outperforms other commonly used DRO methods with better operational economy, lower renewable power curtailment rate, and higher computational efficiency.",
    "doi": "10.1016/j.apenergy.2023.120749",
    "author_keywords": [
      "Community integrated energy system",
      "Distributionally robust optimization",
      "Integrated demand response",
      "Renewable energy",
      "Scenario generation",
      "Uncertainty modeling"
    ],
    "contribution": "Furthermore, our approach outperforms other commonly used DRO methods with better operational economy, lower renewable power curtailment rate, and higher computational efficiency.",
    "introduction": "A community integrated energy system (CIES) is an important carrier of the energy internet and smart city in geographical and functional terms. Its emergence provides a new solution to the problems of energy utilization and environmental pollution. To coordinate the integrated demand response and uncertainty of renewable energy generation (RGs), a data-driven two-stage distributionally robust optimization (DRO) model is constructed. A comprehensive norm consisting of the 1-norm and âˆž-norm is used as the uncertainty probability distribution information set, thereby avoiding complex probability density information. To address multiple uncertainties of RGs, a generative adversarial network based on the Wasserstein distance with gradient penalty is proposed to generate RG scenarios, which has wide applicability. To further tap the potential of the demand response, we take into account the ambiguity of human thermal comfort and the thermal inertia of buildings. Thus, an integrated demand response mechanism is developed that effectively promotes the consumption of renewable energy. The proposed method is simulated in an actual CIES in North China. In comparison with traditional stochastic programming and robust optimization, it is verified that the proposed DRO model properly balances the relationship between economical operation and robustness while exhibiting stronger adaptability.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic problems continue to deteriorate because of increasing population in urban areas that rely on many modes of transportation, the transportation infrastructure has achieved considerable strides in the last several decades. This has led to an increase in congestion control difficulties, which directly affect citizens through air pollution, fuel consumption, traffic law breaches, noise pollution, accidents, and loss of time. Traffic prediction is an essential aspect of an intelligent transportation system in smart cities because it helps reduce overall traffic congestion. This article aims to design and enforce a traffic prediction scheme that is efficient and accurate in forecasting traffic flow. Available traffic flow prediction methods are still unsuitable for real-world applications. This fact motivated us to work on a traffic flow forecasting issue using Vision Transformers (VTs). In this work, VTs were used in conjunction with Convolutional neural networks (CNN) to predict traffic congestion in urban spaces on a city-wide scale. In our proposed architecture, a traffic image is fed to a CNN, which generates feature maps. These feature maps are then fed to the VT, which employs the dual techniques of tokenization and projection. Tokenization is used to convert features into tokens containing Vision information, which are then sent to projection, where they are transformed into feature maps and ultimately delivered to LSTM. The experimental results demonstrate that the vision transformer prediction method based on Spatio-temporal characteristics is an excellent way of predicting traffic flow, particularly during anomalous traffic situations. The proposed technology surpasses traditional methods in terms of precision, accuracy and recall and aids in energy conservation. Through rerouting, the proposed work will benefit travellers and reduce fuel use.",
    "doi": "10.1109/TITS.2022.3233801",
    "author_keywords": [
      "deep learning",
      "intelligent transportation system",
      "long-short-term-memory (LSTM)",
      "traffic congestion prediction",
      "Vision transformers"
    ],
    "contribution": "This article aims to design and enforce a traffic prediction scheme that is efficient and accurate in forecasting traffic flow. Available traffic flow prediction methods are still unsuitable for real-world applications. This fact motivated us to work on a traffic flow forecasting issue using Vision Transformers (VTs). In this work, VTs were used in conjunction with Convolutional neural networks (CNN) to predict traffic congestion in urban spaces on a city-wide scale. In our proposed architecture, a traffic image is fed to a CNN, which generates feature maps. These feature maps are then fed to the VT, which employs the dual techniques of tokenization and projection. Tokenization is used to convert features into tokens containing Vision information, which are then sent to projection, where they are transformed into feature maps and ultimately delivered to LSTM. The experimental results demonstrate that the vision transformer prediction method based on Spatio-temporal characteristics is an excellent way of predicting traffic flow, particularly during anomalous traffic situations. The proposed technology surpasses traditional methods in terms of precision, accuracy and recall and aids in energy conservation. Through rerouting, the proposed work will benefit travellers and reduce fuel use.",
    "introduction": "Traffic problems continue to deteriorate because of increasing population in urban areas that rely on many modes of transportation, the transportation infrastructure has achieved considerable strides in the last several decades. This has led to an increase in congestion control difficulties, which directly affect citizens through air pollution, fuel consumption, traffic law breaches, noise pollution, accidents, and loss of time. Traffic prediction is an essential aspect of an intelligent transportation system in smart cities because it helps reduce overall traffic congestion.",
    "macro_domains": []
  },
  {
    "abstract": "Acquiring road information is important for smart cities and sustainable urban development. In recent years, significant progress has been made in the extraction of urban road information from remote sensing images using deep learning (DL) algorithms. However, due to the complex shape, narrowness, and high span of roads in the images, the results are often unsatisfactory. This article proposes a Seg-Road model to improve road connectivity. The Seg-Road uses a transformer structure to extract the long-range dependency and global contextual information to improve the fragmentation of road segmentation and uses a convolutional neural network (CNN) structure to extract local contextual information to improve the segmentation of road details. Furthermore, a novel pixel connectivity structure (PCS) is proposed to improve the connectivity of road segmentation and the robustness of prediction results. To verify the effectiveness of Seg-Road for road segmentation, the DeepGlobe and Massachusetts datasets were used for training and testing. The experimental results show that Seg-Road achieves state-of-the-art (SOTA) performance, with an intersection over union (IoU) of 67.20%, mean intersection over union (MIoU) of 82.06%, F1 of 91.43%, precision of 90.05%, and recall of 92.85% in the DeepGlobe dataset, and achieves an IoU of 68.38%, MIoU of 83.89%, F1 of 90.01%, precision of 87.34%, and recall of 92.86% in the Massachusetts dataset, which is better than the values for CoANet. Further, it has higher application value for achieving sustainable urban development.",
    "doi": "10.3390/rs15061602",
    "author_keywords": [
      "pixel connectivity structure",
      "remote sensing imagery",
      "road extraction",
      "Seg-Road"
    ],
    "contribution": "This article proposes a Seg-Road model to improve road connectivity. The Seg-Road uses a transformer structure to extract the long-range dependency and global contextual information to improve the fragmentation of road segmentation and uses a convolutional neural network (CNN) structure to extract local contextual information to improve the segmentation of road details. Furthermore, a novel pixel connectivity structure (PCS) is proposed to improve the connectivity of road segmentation and the robustness of prediction results. To verify the effectiveness of Seg-Road for road segmentation, the DeepGlobe and Massachusetts datasets were used for training and testing. The experimental results show that Seg-Road achieves state-of-the-art (SOTA) performance, with an intersection over union (IoU) of 67.20%, mean intersection over union (MIoU) of 82.06%, F1 of 91.43%, precision of 90.05%, and recall of 92.85% in the DeepGlobe dataset, and achieves an IoU of 68.38%, MIoU of 83.89%, F1 of 90.01%, precision of 87.34%, and recall of 92.86% in the Massachusetts dataset, which is better than the values for CoANet. Further, it has higher application value for achieving sustainable urban development.",
    "introduction": "Acquiring road information is important for smart cities and sustainable urban development. In recent years, significant progress has been made in the extraction of urban road information from remote sensing images using deep learning (DL) algorithms. However, due to the complex shape, narrowness, and high span of roads in the images, the results are often unsatisfactory.",
    "macro_domains": []
  },
  {
    "abstract": "Smart cities require the development of information and communication technology to become a reality (ICT). A â€œsmart cityâ€ is built on top of a â€œsmart gridâ€. The implementation of numerous smart systems that are advantageous to the environment and improve the quality of life for the residents is one of the main goals of the new smart cities. In order to improve the reliability and sustainability of the transportation system, changes are being made to the way electric vehicles (EVs) are used. As EV use has increased, several problems have arisen, including the requirement to build a charging infrastructure, and forecast peak loads. Management must consider how challenging the situation is. There have been many original solutions to these problems. These heavily rely on automata models, machine learning, and the Internet of Things. Over time, there have been more EV drivers. Electric vehicle charging at a large scale negatively impacts the power grid. Transformers may face additional voltage fluctuations, power loss, and heat if already operating at full capacity. Without EV management, these challenges cannot be solved. A machine-learning (ML)-based charge management system considers conventional charging, rapid charging, and vehicle-to-grid (V2G) technologies while guiding electric cars (EVs) to charging stations. This operation reduces the expenses associated with charging, high voltages, load fluctuation, and power loss. The effectiveness of various machine learning (ML) approaches is evaluated and compared. These techniques include Deep Neural Networks (DNN), K-Nearest Neighbors (KNN), Long Short-Term Memory (LSTM), Random Forest (RF), Support Vector Machine (SVM), and Decision Tree (DT) (DNN). According to the results, LSTM might be used to give EV control in certain circumstances. The LSTM modelâ€™s peak voltage, power losses, and voltage stability may all be improved by compressing the load curve. In addition, we keep our billing costs to a minimum, as well.",
    "doi": "10.3390/su15032603",
    "author_keywords": [
      "electric vehicles",
      "load forecasting",
      "machine learning",
      "signal processing",
      "smart grid"
    ],
    "contribution": "",
    "introduction": "Smart cities require the development of information and communication technology to become a reality (ICT). A â€œsmart cityâ€ is built on top of a â€œsmart gridâ€. The implementation of numerous smart systems that are advantageous to the environment and improve the quality of life for the residents is one of the main goals of the new smart cities. In order to improve the reliability and sustainability of the transportation system, changes are being made to the way electric vehicles (EVs) are used. As EV use has increased, several problems have arisen, including the requirement to build a charging infrastructure, and forecast peak loads. Management must consider how challenging the situation is. There have been many original solutions to these problems. These heavily rely on automata models, machine learning, and the Internet of Things. Over time, there have been more EV drivers. Electric vehicle charging at a large scale negatively impacts the power grid. Transformers may face additional voltage fluctuations, power loss, and heat if already operating at full capacity. Without EV management, these challenges cannot be solved. A machine-learning (ML)-based charge management system considers conventional charging, rapid charging, and vehicle-to-grid (V2G) technologies while guiding electric cars (EVs) to charging stations. This operation reduces the expenses associated with charging, high voltages, load fluctuation, and power loss. The effectiveness of various machine learning (ML) approaches is evaluated and compared. These techniques include Deep Neural Networks (DNN), K-Nearest Neighbors (KNN), Long Short-Term Memory (LSTM), Random Forest (RF), Support Vector Machine (SVM), and Decision Tree (DT) (DNN). According to the results, LSTM might be used to give EV control in certain circumstances. The LSTM modelâ€™s peak voltage, power losses, and voltage stability may all be improved by compressing the load curve. In addition, we keep our billing costs to a minimum, as well.",
    "macro_domains": []
  },
  {
    "abstract": "As the basic element and module unit in the construction architecture of smart city, the Internet of things (IoT) is also the key foundation and important support for realizing \"automatic perception, rapid response, and scientific decision-making\" of smart city. The study aims to improve the efficiency of power inspection in power enterprises and provide intelligent technology for power inspection. After the theoretical analysis of IoT and RFID technology under the background of smart city, the study discusses the information acquisition principle of RFID technology. Second, based on IoT and smart grid, the study takes the power equipment of power company A as an example, and puts forward the power inspection scheme, including the information required for inspection and the inspection of primary and secondary equipment. The specific contents are as follows: health assessment is carried out according to the real-time alarm of power equipment, and the control command is sent to the downstream control equipment to confirm the alarm information. Meantime, based on the alarm information of power equipment and related equipment, the expert analysis system is used for reasoning and analysis, and the RFID tag is used to supervise the inspectors to arrive at the site and inspect the situation according to the predetermined route. The temperature of the cable of power company A is measured under normal and hidden dangers, and the body insulation test is conducted on No. 1 main transformer. The results show that under normal operation, the cable temperature at each point is slightly different, which is basically about 40 Â°C. The temperature before the fourth point of the cable rises obviously, indicating that the fourth point has faulty. Over time, the more chemical molecules are detected in phase A. When phase B and phase C are tested on the same day, the difference of chemical molecular content is relatively small. It indicates that the chemical molecular content detected by chromatographic test of bulk insulating oil is normal. To sum up, smart power, as the objective need of urban intelligent development, is an important foundation of smart city. The power inspection scheme based on IoT and RFID technology proposed has high detection efficiency.",
    "doi": "10.1016/j.micpro.2022.104510",
    "author_keywords": [
      "Expert analysis system",
      "Internet of things",
      "Power inspection",
      "Radio frequency identification technology",
      "Smart city"
    ],
    "contribution": "The study aims to improve the efficiency of power inspection in power enterprises and provide intelligent technology for power inspection. After the theoretical analysis of IoT and RFID technology under the background of smart city, the study discusses the information acquisition principle of RFID technology. Second, based on IoT and smart grid, the study takes the power equipment of power company A as an example, and puts forward the power inspection scheme, including the information required for inspection and the inspection of primary and secondary equipment. The specific contents are as follows: health assessment is carried out according to the real-time alarm of power equipment, and the control command is sent to the downstream control equipment to confirm the alarm information. Meantime, based on the alarm information of power equipment and related equipment, the expert analysis system is used for reasoning and analysis, and the RFID tag is used to supervise the inspectors to arrive at the site and inspect the situation according to the predetermined route. The temperature of the cable of power company A is measured under normal and hidden dangers, and the body insulation test is conducted on No. 1 main transformer. The results show that under normal operation, the cable temperature at each point is slightly different, which is basically about 40 Â°C. The temperature before the fourth point of the cable rises obviously, indicating that the fourth point has faulty. Over time, the more chemical molecules are detected in phase A. When phase B and phase C are tested on the same day, the difference of chemical molecular content is relatively small. It indicates that the chemical molecular content detected by chromatographic test of bulk insulating oil is normal. To sum up, smart power, as the objective need of urban intelligent development, is an important foundation of smart city. The power inspection scheme based on IoT and RFID technology proposed has high detection efficiency.",
    "introduction": "As the basic element and module unit in the construction architecture of smart city, the Internet of things (IoT) is also the key foundation and important support for realizing \"automatic perception, rapid response, and scientific decision-making\" of smart city.",
    "macro_domains": []
  },
  {
    "abstract": "Self-supervised depth estimation has drawn much attention in recent years as it does not require labeled data but image sequences. Moreover, it can be conveniently used in various applications, such as autonomous driving, robotics, realistic navigation, and smart cities. However, extracting global contextual information from images and predicting a geometrically natural depth map remain challenging. In this paper, we present DLNet for pixel-wise depth estimation, which simultaneously extracts global and local features with the aid of our depth Linformer block. This block consists of the Linformer and innovative soft split multi-layer perceptron blocks. Moreover, a three-dimensional geometry smoothness loss is proposed to predict a geometrically natural depth map by imposing the second-order smoothness constraint on the predicted three-dimensional point clouds, thereby realizing improved performance as a byproduct. Finally, we explore the multi-scale prediction strategy and propose the maximum margin dual-scale prediction strategy for further performance improvement. In experiments on the KITTI and Make3D benchmarks, the proposed DLNet achieves performance competitive to those of the state-of-the-art methods, reducing time and space complexities by more than 62% and 56% at a resolution of 416 Ã— 128 , respectively. Extensive testing on various real-world situations further demonstrates the strong practicality and generalization capability of the proposed model.",
    "doi": "10.1109/TITS.2022.3219604",
    "author_keywords": [
      "3D reconstruction",
      "Depth estimation",
      "linformer",
      "self-supervised learning",
      "visual odometry"
    ],
    "contribution": "In this paper, we present DLNet for pixel-wise depth estimation, which simultaneously extracts global and local features with the aid of our depth Linformer block. This block consists of the Linformer and innovative soft split multi-layer perceptron blocks. Moreover, a three-dimensional geometry smoothness loss is proposed to predict a geometrically natural depth map by imposing the second-order smoothness constraint on the predicted three-dimensional point clouds, thereby realizing improved performance as a byproduct. Finally, we explore the multi-scale prediction strategy and propose the maximum margin dual-scale prediction strategy for further performance improvement. In experiments on the KITTI and Make3D benchmarks, the proposed DLNet achieves performance competitive to those of the state-of-the-art methods, reducing time and space complexities by more than 62% and 56% at a resolution of 416 Ã— 128 , respectively. Extensive testing on various real-world situations further demonstrates the strong practicality and generalization capability of the proposed model.",
    "introduction": "Self-supervised depth estimation has drawn much attention in recent years as it does not require labeled data but image sequences. Moreover, it can be conveniently used in various applications, such as autonomous driving, robotics, realistic navigation, and smart cities. However, extracting global contextual information from images and predicting a geometrically natural depth map remain challenging.",
    "macro_domains": []
  },
  {
    "abstract": "Next location prediction is helpful for service recommendation, public safety, intelligent transportation, and other location-based applications. Existing location prediction methods usually use sparse check-in trajectories and require massive historical data to capture complex spatial-temporal correlations. High spatial-temporal resolution trajectories have rich information. However, obtaining personal trajectories with long time series and high spatiotemporal resolution usually proves challenging. Herein, this paper proposes a two-stage Context-Aware Spatial-Temporal Location Embedding (CASTLE) model, a multi-modal pre-training model for sequence-to-sequence prediction tasks. The method is built in two steps. First, large-scale location datasets, which are sparse but easier to be acquired (i.e., check-in and anomalous navigation data), are used for pre-training location embedding to capture the multi-functional properties under different contexts. After that, the learned contextual embedding is used for downstream location prediction in small-scale but higher spatiotemporal resolution trajectory datasets. Specifically, the CASTLE model combines Bidirectional and Auto-Regressive Transformers to generate contextual embedding vectors rather than a fixed vector for each location. Furthermore, we introduce a location and time-aware encoder to reflect the spatial distances between locations and visit times. Experiments are conducted on two real trajectory datasets. The results show that the CASTLE model can pre-train beneficial location embedding and outperforms the model without pre-training by 4.6-7.1%. The proposed method is expected to improve the next location prediction accuracy without massive historical data, which will greatly drive the use of trajectory data.",
    "doi": "10.5194/isprs-archives-XLVIII-4-W2-2022-15-2023",
    "author_keywords": [
      "Geospatial Data",
      "Location Embedding",
      "Location Prediction",
      "Smart City",
      "Trajectory Mining",
      "Ubiquitous Computing"
    ],
    "contribution": "Herein, this paper proposes a two-stage Context-Aware Spatial-Temporal Location Embedding (CASTLE) model, a multi-modal pre-training model for sequence-to-sequence prediction tasks. The method is built in two steps. First, large-scale location datasets, which are sparse but easier to be acquired (i.e., check-in and anomalous navigation data), are used for pre-training location embedding to capture the multi-functional properties under different contexts. After that, the learned contextual embedding is used for downstream location prediction in small-scale but higher spatiotemporal resolution trajectory datasets. Specifically, the CASTLE model combines Bidirectional and Auto-Regressive Transformers to generate contextual embedding vectors rather than a fixed vector for each location. Furthermore, we introduce a location and time-aware encoder to reflect the spatial distances between locations and visit times. Experiments are conducted on two real trajectory datasets. The results show that the CASTLE model can pre-train beneficial location embedding and outperforms the model without pre-training by 4.6-7.1%. The proposed method is expected to improve the next location prediction accuracy without massive historical data, which will greatly drive the use of trajectory data.",
    "introduction": "Next location prediction is helpful for service recommendation, public safety, intelligent transportation, and other location-based applications. Existing location prediction methods usually use sparse check-in trajectories and require massive historical data to capture complex spatial-temporal correlations. High spatial-temporal resolution trajectories have rich information. However, obtaining personal trajectories with long time series and high spatiotemporal resolution usually proves challenging.",
    "macro_domains": []
  },
  {
    "abstract": "Tunnel fire safety is currently a hot topic in fire research. Using deep learning methods to predict the location of tunnel fires can not only improve the accuracy and efficiency of tunnel fire prediction, but also provide important scientific guidance and technical support, paving the way for smart fire technology and future smart city emergency response strategies. In this study, a Transformer-based neural network is proposed, with revisions to the original Transformer model for the application of the tunnel fire location dataset. The original transformer model is also compared to our proposed one. It is shown that the loss of our proposed model is smaller, indicating better prediction performances. This indicates that the prediction effect based on the improved Transformer model proposed in this paper is relatively better. The research on tunnel fire source detection will provide a theoretical basis for the design of tunnel fire prevention and control systems.",
    "doi": "10.1109/ICMEE59781.2023.10525532",
    "author_keywords": [
      "fire location",
      "neural network",
      "Transformer",
      "Tunnel fire"
    ],
    "contribution": "In this study, a Transformer-based neural network is proposed, with revisions to the original Transformer model for the application of the tunnel fire location dataset. The original transformer model is also compared to our proposed one. It is shown that the loss of our proposed model is smaller, indicating better prediction performances. This indicates that the prediction effect based on the improved Transformer model proposed in this paper is relatively better. The research on tunnel fire source detection will provide a theoretical basis for the design of tunnel fire prevention and control systems.",
    "introduction": "Tunnel fire safety is currently a hot topic in fire research. Using deep learning methods to predict the location of tunnel fires can not only improve the accuracy and efficiency of tunnel fire prediction, but also provide important scientific guidance and technical support, paving the way for smart fire technology and future smart city emergency response strategies.",
    "macro_domains": []
  },
  {
    "abstract": "Smart cities represent the zenith of technological integration, aiming to uplift living experiences and operational efficiency within urban regions. With music being intrinsically intertwined with societal living, embedding it seamlessly into digitized cities remains a challenge. The rapid evolution of music generation algorithms based on Transformer models has opened a promising avenue in this context. However, applying music generation to smart cities presents two problems: 1) Previous work only considers forward information by adopting an upper-triangular mask. Although this can avoid information leakage, global information of music pieces may not be well captured, harming the overall structure and quality of generated samples and making it challenging to generate complete melodies in longer segments. 2) Due to the randomness of sampling, the generated music sometimes has discordant notes, affecting the practical usage experience. To alleviate these problems, we introduce the masked global information network on the transformer language model to incorporate global information constraints in a joint training manner. With this succinct approach, complete melodies with reasonable repetition and musical structure can be generated. Furthermore, we demonstrate that the global information network can be extended as a post-processing module by reusing the hidden layer states from prior networks to further improve the quality of samples in a non-autoregressive way. Both objective and subjective studies demonstrate the effectiveness of our method. Moreover, by integrating this pluggable global information network, an enhancement in generative outcomes is achieved without incurring additional computational complexity or energy expenditure during inference, presenting a green optimization strategy.",
    "doi": "10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics60724.2023.00138",
    "author_keywords": [
      "full-song level music",
      "global information",
      "joint training",
      "masked model",
      "symbolic music generation"
    ],
    "contribution": "To alleviate these problems, we introduce the masked global information network on the transformer language model to incorporate global information constraints in a joint training manner. With this succinct approach, complete melodies with reasonable repetition and musical structure can be generated. Furthermore, we demonstrate that the global information network can be extended as a post-processing module by reusing the hidden layer states from prior networks to further improve the quality of samples in a non-autoregressive way. Both objective and subjective studies demonstrate the effectiveness of our method. Moreover, by integrating this pluggable global information network, an enhancement in generative outcomes is achieved without incurring additional computational complexity or energy expenditure during inference, presenting a green optimization strategy.",
    "introduction": "Smart cities represent the zenith of technological integration, aiming to uplift living experiences and operational efficiency within urban regions. With music being intrinsically intertwined with societal living, embedding it seamlessly into digitized cities remains a challenge. The rapid evolution of music generation algorithms based on Transformer models has opened a promising avenue in this context. However, applying music generation to smart cities presents two problems: 1) Previous work only considers forward information by adopting an upper-triangular mask. Although this can avoid information leakage, global information of music pieces may not be well captured, harming the overall structure and quality of generated samples and making it challenging to generate complete melodies in longer segments. 2) Due to the randomness of sampling, the generated music sometimes has discordant notes, affecting the practical usage experience.",
    "macro_domains": []
  },
  {
    "abstract": "Smart City Digital Twin (SCDT), a virtual representation of a physical city, is an emerging technology for optimizing urban services and enhancing urban planning and decision-making. The integration of Machine Learning (ML) and social sensing provides valuable insights into public feedback to policymakers and for informed decision-making and responsive urban governance. This study aims to explore the use of social media data and topic modeling algorithms in the context of SCDT to highlight the concerns of citizens in Saskatoon, Canada. In this work, we use the Uniform Manifold Approximation and Projection (UMAP) and K-means clustering algorithm in the BERTopic architecture to extract 30 topics from comments collected through the Saskatoon subreddit posts. The topics were then merged into 15 themes to discover the concerns. A pretrained transformer model, SiEBERT was used to determine the sentiments of the Reddit comments. The research findings highlighted concerns such as - unreliable public transit, high cost of living, long wait times in emergency rooms, shortage of family doctors, drug addiction, and lack of mental awareness.",
    "doi": "10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00141",
    "author_keywords": [
      "BERTopic",
      "Machine Learning",
      "Reddit",
      "Sentiment Analysis",
      "Smart City Digital Twin",
      "Smart Governance",
      "Social Media Sensing"
    ],
    "contribution": "This study aims to explore the use of social media data and topic modeling algorithms in the context of SCDT to highlight the concerns of citizens in Saskatoon, Canada. In this work, we use the Uniform Manifold Approximation and Projection (UMAP) and K-means clustering algorithm in the BERTopic architecture to extract 30 topics from comments collected through the Saskatoon subreddit posts. The topics were then merged into 15 themes to discover the concerns. A pretrained transformer model, SiEBERT was used to determine the sentiments of the Reddit comments. The research findings highlighted concerns such as - unreliable public transit, high cost of living, long wait times in emergency rooms, shortage of family doctors, drug addiction, and lack of mental awareness.",
    "introduction": "Smart City Digital Twin (SCDT), a virtual representation of a physical city, is an emerging technology for optimizing urban services and enhancing urban planning and decision-making. The integration of Machine Learning (ML) and social sensing provides valuable insights into public feedback to policymakers and for informed decision-making and responsive urban governance.",
    "macro_domains": []
  },
  {
    "abstract": "Indoor location-based services (LBS) hold significant potential for social and commercial value in smart city development. However, fingerprint-based indoor localization technologies face challenges due to the dynamic indoor environment. Updating the fingerprint database through dense site surveys is costly. Therefore, a method utilizing sparse samples (10%) is attractive. This work proposes the fingerprint database adaptation paradigm (FDAP), an adaptive update framework designed for sparse samples. The FDAP creates a swin transformer-based reconstruction model (STRM), effectively addressing the issue of inaccurate map reconstruction from sparse samples. Using the STRM significantly reduces the expenses associated with updating the fingerprint database. Additionally, FDAP evaluates the quality of the samples with a signal quality evaluation algorithm (SQEA), assessing the features of dispersion degree, signal strength, and fingerprint correlation from sparse samples. Lastly, FDAP provides a signal correction algorithm (SCA) based on partial least squares regression, which minimizes potential errors for unreliable reconstruction signals. Experiments conducted on a public dataset demonstrate that FDAP effectively accommodates radio map variations over time. It reduces the reconstruction error by 22.2 % compared to the current state-of-the-art method. The code is publicly available at https://github.com/Cen-Shaoqi/FDAP.",
    "doi": "10.1109/GLOBECOM54140.2023.10436813",
    "author_keywords": [
      "Indoor localization",
      "Radio map reconstruction",
      "Swin transformer"
    ],
    "contribution": "This work proposes the fingerprint database adaptation paradigm (FDAP), an adaptive update framework designed for sparse samples. The FDAP creates a swin transformer-based reconstruction model (STRM), effectively addressing the issue of inaccurate map reconstruction from sparse samples. Using the STRM significantly reduces the expenses associated with updating the fingerprint database. Additionally, FDAP evaluates the quality of the samples with a signal quality evaluation algorithm (SQEA), assessing the features of dispersion degree, signal strength, and fingerprint correlation from sparse samples. Lastly, FDAP provides a signal correction algorithm (SCA) based on partial least squares regression, which minimizes potential errors for unreliable reconstruction signals. Experiments conducted on a public dataset demonstrate that FDAP effectively accommodates radio map variations over time. It reduces the reconstruction error by 22.2 % compared to the current state-of-the-art method. The code is publicly available at https://github.com/Cen-Shaoqi/FDAP.",
    "introduction": "Indoor location-based services (LBS) hold significant potential for social and commercial value in smart city development. However, fingerprint-based indoor localization technologies face challenges due to the dynamic indoor environment. Updating the fingerprint database through dense site surveys is costly. Therefore, a method utilizing sparse samples (10%) is attractive.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic flow prediction, which plays an important role in intelligent traffic systems, has become a pressing problem to be addressed with the continuous development of smart cities. Currently, the fundamental obstacle lies in effectively modelling the complex spatial-temporal dependencies present in traffic flow data. Deep learning models such as Graph Neural Network based models and Transformer based models have shown promising results in this field. However, methods founded on a single model or framework have one significant limitation: Such methods cannot adequately represent the spatial and temporal features of traffic flow data, restricting the model's ability to learn the dynamics of urban transportation. In this paper, we propose a transformer-based spatial-temporal graph attention network model called TSTGAT for traffic flow prediction, which integrates Transformer and Graph Attention Network. Experiments on two real-world traffic datasets from the Caltrans Performance Measurement System (PeMS) demonstrate that the proposed TSTGAT model outperforms well-known baselines.",
    "doi": "10.1109/CyberC58899.2023.00031",
    "author_keywords": [
      "deep learning",
      "graph neural network",
      "Traffic flow prediction",
      "transformer"
    ],
    "contribution": "In this paper, we propose a transformer-based spatial-temporal graph attention network model called TSTGAT for traffic flow prediction, which integrates Transformer and Graph Attention Network. Experiments on two real-world traffic datasets from the Caltrans Performance Measurement System (PeMS) demonstrate that the proposed TSTGAT model outperforms well-known baselines.",
    "introduction": "Traffic flow prediction, which plays an important role in intelligent traffic systems, has become a pressing problem to be addressed with the continuous development of smart cities. Currently, the fundamental obstacle lies in effectively modelling the complex spatial-temporal dependencies present in traffic flow data. Deep learning models such as Graph Neural Network based models and Transformer based models have shown promising results in this field. However, methods founded on a single model or framework have one significant limitation: Such methods cannot adequately represent the spatial and temporal features of traffic flow data, restricting the model's ability to learn the dynamics of urban transportation.",
    "macro_domains": []
  },
  {
    "abstract": "Automated and Autonomous vehicle has attracted considered interest in recent decade by leveraging the current telecommunication networks in order to reduce the traffic in both air and road network and to reduce the cost of fuel cost communication and reduce emissions and finally mitigates the parking related issues in the smart cities. However current telecommunication networks suffer from simultaneously handling the heterogeneous vehicle data traffic and network component failure due to natural disaster. In order to manage those challenges, a new distributed failure tolerant path planning framework has been modelled to generate the virtual path for automated vehicles like drone and grounded vehicles. Due to advent of artificial intelligence and deep learning technologies in the software defined networks, efficient management of the automated vehicle is feasible using existing telecommunication network like 3G/4G and LTE networks. Proposed model integrates architecture with the Amazon or IBM webserver to gather and manage the network data and its communications. Web Server has been deployed with developed virtual path planning algorithm to control the autonomous vehicles on extracting the various information from the sensor component in the ecosystem using telecommunication network. Base station also categories and schedules the data efficiently to reduce the computation time and cost. Especially each node which considered as sensor or transceiver is capable of the operating in fixed speed for specific data size and it is configured in transformers in electric grids, street lights, and overhead electric lines in railways and medians in the road. In order to increase the limit, data compression and signal amplification is enabled through amplifier connected with sensor or transceiver component. Further optical fibre channel is employed for data communication between transceiver and base station in the web server whereas two transceivers can be connected in wireless manner to reduce the dependence of the optical fibre. Controlled signal is transferred to transceiver built-in in the autonomous devices through trajectory of the intermediate transceivers. Control signal carries the information of the virtual path plan as route map containing the route number of the optical fiber channel and specific identification number of transceiver representing start and end point destinations for movement. Finally, transceiver communicates the information like speed limit, signal indication like one ways and closed roads etc. Experimental analysis of the proposed model is evaluated on various aspects. In that proposed architecture capable of controlling various devices in high heterogeneous traffics without loss of control signal. Proposed framework can be transformed to concept of intelligent transportation system for eco-friendly smart cities.",
    "doi": "10.1109/ICERCS57948.2023.10434207",
    "author_keywords": [
      "Autonomous Vehicles",
      "Data Communication",
      "Intelligent Transportation system",
      "Path Planning Approach",
      "Signal Controlling",
      "Signal transmission",
      "Smart Cities",
      "Virtual Path"
    ],
    "contribution": "",
    "introduction": "Automated and Autonomous vehicle has attracted considered interest in recent decade by leveraging the current telecommunication networks in order to reduce the traffic in both air and road network and to reduce the cost of fuel cost communication and reduce emissions and finally mitigates the parking related issues in the smart cities. However current telecommunication networks suffer from simultaneously handling the heterogeneous vehicle data traffic and network component failure due to natural disaster. In order to manage those challenges, a new distributed failure tolerant path planning framework has been modelled to generate the virtual path for automated vehicles like drone and grounded vehicles. Due to advent of artificial intelligence and deep learning technologies in the software defined networks, efficient management of the automated vehicle is feasible using existing telecommunication network like 3G/4G and LTE networks. Proposed model integrates architecture with the Amazon or IBM webserver to gather and manage the network data and its communications. Web Server has been deployed with developed virtual path planning algorithm to control the autonomous vehicles on extracting the various information from the sensor component in the ecosystem using telecommunication network. Base station also categories and schedules the data efficiently to reduce the computation time and cost. Especially each node which considered as sensor or transceiver is capable of the operating in fixed speed for specific data size and it is configured in transformers in electric grids, street lights, and overhead electric lines in railways and medians in the road. In order to increase the limit, data compression and signal amplification is enabled through amplifier connected with sensor or transceiver component. Further optical fibre channel is employed for data communication between transceiver and base station in the web server whereas two transceivers can be connected in wireless manner to reduce the dependence of the optical fibre. Controlled signal is transferred to transceiver built-in in the autonomous devices through trajectory of the intermediate transceivers. Control signal carries the information of the virtual path plan as route map containing the route number of the optical fiber channel and specific identification number of transceiver representing start and end point destinations for movement. Finally, transceiver communicates the information like speed limit, signal indication like one ways and closed roads etc. Experimental analysis of the proposed model is evaluated on various aspects. In that proposed architecture capable of controlling various devices in high heterogeneous traffics without loss of control signal. Proposed framework can be transformed to concept of intelligent transportation system for eco-friendly smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Networked Traffic Signal Control (NTSC) is a fundamental component of Intelligent Transportation Systems (ITS) and the broader vision of smart city development. While a plethora of intelligent strategies have been developed, the Sim2Real challenge often impedes their full realization. In response, this paper introduces the Parallel Learning-based Adaptive Network for Traffic Signal Control (PLANT) as a foundation model for NTSC. We employ the Wasserstein GAN with Gradient Penalty (WGAN-GP) to generate a wide range of artificial scenarios for robust PLANT training. Further, the Transformer-based Cooperation Mechanism (TCM) is integrated as the primary learner within PLANT, facilitating effective capture of traffic dynamics and knowledge accumulation. This knowledge is readily transferable to real-world applications through meticulous fine-tuning, equipping PLANT to adapt and evolve in alignment with shifting transportation paradigms. Our empirical study on the Hangzhou road network demonstrates PLANT's superiority over both traditional and emerging DRL-based approaches, emphasizing its viability as a potential foundation model for NTSC.",
    "doi": "10.1109/ITSC57777.2023.10422161",
    "author_keywords": null,
    "contribution": "In response, this paper introduces the Parallel Learning-based Adaptive Network for Traffic Signal Control (PLANT) as a foundation model for NTSC. We employ the Wasserstein GAN with Gradient Penalty (WGAN-GP) to generate a wide range of artificial scenarios for robust PLANT training. Further, the Transformer-based Cooperation Mechanism (TCM) is integrated as the primary learner within PLANT, facilitating effective capture of traffic dynamics and knowledge accumulation. This knowledge is readily transferable to real-world applications through meticulous fine-tuning, equipping PLANT to adapt and evolve in alignment with shifting transportation paradigms. Our empirical study on the Hangzhou road network demonstrates PLANT's superiority over both traditional and emerging DRL-based approaches, emphasizing its viability as a potential foundation model for NTSC.",
    "introduction": "Networked Traffic Signal Control (NTSC) is a fundamental component of Intelligent Transportation Systems (ITS) and the broader vision of smart city development. While a plethora of intelligent strategies have been developed, the Sim2Real challenge often impedes their full realization.",
    "macro_domains": []
  },
  {
    "abstract": "In the era of smart cities, the role of surveillance systems in ensuring community safety and environmental sustainability has become increasingly significant. Traditional surveillance methods, reliant on human monitoring, often exhibit deficiencies in terms of speed, accuracy, and scalability. However, to the best of our knowledge, there is no related dataset on this research field. This paper introduces a novel approach to address these challenges, leveraging the power of computer vision technology to enhance surveillance capabilities. To bridge the gap between algorithms research and application, in this paper, we propose the task and dataset, and highlight the necessity of camera grading. ONEWO comprises 18,307 images from 2,863 cameras, which covers 20 main objects of interest for city management, providing annotation of bounding boxes and segmentation masks of 121,342 instances. Experiments demonstrate that our best baseline model achieves mAP50 of 77.5 for the entire test set. This work aims at contributing to the development of more efficient, accurate, and scalable surveillance systems, thereby promoting community safety and environmental sustainability in smart cities.",
    "doi": "10.1109/ICNGN59831.2023.10396791",
    "author_keywords": [
      "Camera Grading",
      "Instance Segmentation",
      "Object Detection",
      "Surveillance Camera",
      "Transformer",
      "YOLO Series"
    ],
    "contribution": "However, to the best of our knowledge, there is no related dataset on this research field. This paper introduces a novel approach to address these challenges, leveraging the power of computer vision technology to enhance surveillance capabilities. To bridge the gap between algorithms research and application, in this paper, we propose the task and dataset, and highlight the necessity of camera grading. ONEWO comprises 18,307 images from 2,863 cameras, which covers 20 main objects of interest for city management, providing annotation of bounding boxes and segmentation masks of 121,342 instances. Experiments demonstrate that our best baseline model achieves mAP50 of 77.5 for the entire test set. This work aims at contributing to the development of more efficient, accurate, and scalable surveillance systems, thereby promoting community safety and environmental sustainability in smart cities.",
    "introduction": "In the era of smart cities, the role of surveillance systems in ensuring community safety and environmental sustainability has become increasingly significant. Traditional surveillance methods, reliant on human monitoring, often exhibit deficiencies in terms of speed, accuracy, and scalability.",
    "macro_domains": []
  },
  {
    "abstract": "Infrastructure for managing and distributing water in the traditional manner is somewhat outdated. As a result of incorporating information and communication technologies into the current system, a smart water management system has been developed. The smart water management system uses a number of different technologies to monitor and sense water leaks, theft, and delivery. The supervisory control and data acquisition system SCADA, which shows that the distribution side is being monitored less, has very little impact at the pump house level. The development of the Internet of Things (IoT) has made it possible to connect a large number of monitoring devices to the Internet, which will be more beneficial for automating water delivery and leak detection. As a result, a fog-integrated IoT-based smart water distribution and monitoring system for a smart city is proposed. This system will handle customer utilization, water theft detection, water quality control, fault prediction, fault localization, and rainfall prediction. Fog and cloud computing enable these system processes in order to achieve effective control action. In this work first, we apply the transformer for the rainfall prediction and then use ant colony optimization for optimization of the water distribution process.",
    "doi": "10.1109/BigData59044.2023.10386081",
    "author_keywords": [
      "Ant Colony Optimization",
      "informer transformer",
      "Rainfall prediction",
      "water distribution"
    ],
    "contribution": "This system will handle customer utilization, water theft detection, water quality control, fault prediction, fault localization, and rainfall prediction. Fog and cloud computing enable these system processes in order to achieve effective control action. In this work first, we apply the transformer for the rainfall prediction and then use ant colony optimization for optimization of the water distribution process.",
    "introduction": "Infrastructure for managing and distributing water in the traditional manner is somewhat outdated. As a result of incorporating information and communication technologies into the current system, a smart water management system has been developed. The smart water management system uses a number of different technologies to monitor and sense water leaks, theft, and delivery. The supervisory control and data acquisition system SCADA, which shows that the distribution side is being monitored less, has very little impact at the pump house level. The development of the Internet of Things (IoT) has made it possible to connect a large number of monitoring devices to the Internet, which will be more beneficial for automating water delivery and leak detection. As a result, a fog-integrated IoT-based smart water distribution and monitoring system for a smart city is proposed.",
    "macro_domains": []
  },
  {
    "abstract": "Retrieval of scenes from traffic videos is an important task in intelligent transportation systems (ITS) for efficient traffic management in AI smart cities. This work proposes natural language-based vehicle retrieval from traffic monitoring videos, emphasizing the significance of temporal information and context. We present contrastive learning as a technique to optimize joint representations of vision and language modalities within a shared latent representation space. The approach involves training contrastive losses to keep similar encodings closer in joint feature representation space by minimizing the distance between positive visual-text pairs and maximizing the distance between negative visual-text pairs. Our study employs state-of-the-art vision models for visual encoding and transformer-based language models for text encoding. We analyze the impact of feature selection from visuals and text on retrieval performance. We evaluate the efficacy of our proposed method on the AI City Challenge 2022 dataset for natural language-based vehicle retrieval, achieving performance accuracy of 49.84% Mean Reciprocal Rank (MRR) on the test dataset, securing second position on the leader board. Our approach highlights the effectiveness of feature selection and contrastive learning for enhancing multimodal retrieval tasks.",
    "doi": "10.1109/ICTAI59109.2023.00153",
    "author_keywords": [
      "Computer vision",
      "contrastive multimodal learning",
      "intelligent transportation systems",
      "neural networks"
    ],
    "contribution": "This work proposes natural language-based vehicle retrieval from traffic monitoring videos, emphasizing the significance of temporal information and context. We present contrastive learning as a technique to optimize joint representations of vision and language modalities within a shared latent representation space. The approach involves training contrastive losses to keep similar encodings closer in joint feature representation space by minimizing the distance between positive visual-text pairs and maximizing the distance between negative visual-text pairs. Our study employs state-of-the-art vision models for visual encoding and transformer-based language models for text encoding. We analyze the impact of feature selection from visuals and text on retrieval performance. We evaluate the efficacy of our proposed method on the AI City Challenge 2022 dataset for natural language-based vehicle retrieval, achieving performance accuracy of 49.84% Mean Reciprocal Rank (MRR) on the test dataset, securing second position on the leader board. Our approach highlights the effectiveness of feature selection and contrastive learning for enhancing multimodal retrieval tasks.",
    "introduction": "Retrieval of scenes from traffic videos is an important task in intelligent transportation systems (ITS) for efficient traffic management in AI smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "The metaverse is a virtual space that blends elements of augmented reality, virtual reality, and many other technologies, offering a tailored and immersive experience where individuals can communicate with each other and digital objects. Though the metaverse incorporates various advanced technologies, there is still room for enhancement in terms of interactivity and in achieving realism of virtual environments. Generative Pre-trained Transformers can help address these issues. GPTs advanced NLP algorithms that generate dynamic and realistic content in real-time, allowing the creation of interactive non-playable characters, improving NLP for chatbots and voice assistants, and generating realistic virtual environments in the metaverse. The integration of GPT and metaverse is essential to make it a more dynamic, realistic, and engaging workspace. This review paper explores the opportunity of integrating GPTs with the metaverse applications and highlights prospective challenges associated with this integration.",
    "doi": "10.1109/WPMC59531.2023.10338966",
    "author_keywords": [
      "Generative Pre-Trained Transformers",
      "GPT Models",
      "Language Models",
      "Metaverse",
      "Smart Cities"
    ],
    "contribution": "This review paper explores the opportunity of integrating GPTs with the metaverse applications and highlights prospective challenges associated with this integration.",
    "introduction": "The metaverse is a virtual space that blends elements of augmented reality, virtual reality, and many other technologies, offering a tailored and immersive experience where individuals can communicate with each other and digital objects. Though the metaverse incorporates various advanced technologies, there is still room for enhancement in terms of interactivity and in achieving realism of virtual environments. Generative Pre-trained Transformers can help address these issues. GPTs advanced NLP algorithms that generate dynamic and realistic content in real-time, allowing the creation of interactive non-playable characters, improving NLP for chatbots and voice assistants, and generating realistic virtual environments in the metaverse. The integration of GPT and metaverse is essential to make it a more dynamic, realistic, and engaging workspace.",
    "macro_domains": []
  },
  {
    "abstract": "In order to address the issues brought about by urbanization, population growth, and the demands of sustainable cultural development, the idea of \"smart cities\"was developed. One crucial element of smart cities that helps manage and lessen traffic is smart parking systems. Parking spots are a limited resource, and in crowded areas, finding free spots can be difficult. We provide a real-time free parking slot detection system that uses computer vision and machine learning techniques to locate and identify free parking spaces in real-time, thereby resolving the current issue. Our system uses a camera network deployed in the parking area to capture images of the parking slots. These images are processed using deep learning combined with vision transformer and transfer learning algorithms to detect the presence of vehicles in the slots. By analyzing the occupancy status of each slot, our system can identify and locate free parking slots. We evaluate the accomplishment of the model we have offered on a real-world dataset collected from a busy parking area. The findings demonstrate that the offered model outperformed the CNN model with a test accuracy of 95%, while CNN achieved an accuracy of 90%.",
    "doi": "10.1109/AICCSA59173.2023.10479293",
    "author_keywords": [
      "Convolutional neural networks",
      "deep learning",
      "parking slots",
      "smart cities",
      "smart parking",
      "Vision transformer"
    ],
    "contribution": "Our system uses a camera network deployed in the parking area to capture images of the parking slots. These images are processed using deep learning combined with vision transformer and transfer learning algorithms to detect the presence of vehicles in the slots. By analyzing the occupancy status of each slot, our system can identify and locate free parking slots. We evaluate the accomplishment of the model we have offered on a real-world dataset collected from a busy parking area. The findings demonstrate that the offered model outperformed the CNN model with a test accuracy of 95%, while CNN achieved an accuracy of 90%.",
    "introduction": "In order to address the issues brought about by urbanization, population growth, and the demands of sustainable cultural development, the idea of \"smart cities\"was developed. One crucial element of smart cities that helps manage and lessen traffic is smart parking systems. Parking spots are a limited resource, and in crowded areas, finding free spots can be difficult. We provide a real-time free parking slot detection system that uses computer vision and machine learning techniques to locate and identify free parking spaces in real-time, thereby resolving the current issue.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate prediction of the Air Quality Index (AQI) is of paramount importance as the negative health impact of poor air quality on humans has been widely established. The paper proposes an efficient model for AQI prediction based on the transformer algorithm. This model is compared with the widely used RNN-LSTM and regression model and outperforms both. Real-time data on pollutant concentration and meteorological data for the Anand Vihar, Delhi, India monitoring station from November 1, 2017, till August 6, 2022, has been used for analysis. From the data available for 11 pollutants, the AQI is determined as per the Central Pollution Control Boardâ€™s (CPCBâ€™s) formula. The paper aims to predict the AQI along with the levels of PM2.5, CO, and PM10 pollutants. RMSE and MAE for PM2.5 evaluated using transformer are 17.74 and 11.15, respectively, best amongst all the models. Prior and accurate knowledge about Air Quality Index levels is directly relevant for policy-makers and the population at large so that the administrators may implement corrective measures. As the concept of smart cities is rapidly taking shape, the residents of such cities have the right to know about the air quality they are likely to breathe in the near future so that smart responses may be planned well in advance.",
    "doi": "10.1007/978-981-99-5994-5_7",
    "author_keywords": [
      "AQI",
      "Deep learning",
      "LSTM",
      "Time series analysis",
      "Transformer"
    ],
    "contribution": "The paper proposes an efficient model for AQI prediction based on the transformer algorithm. This model is compared with the widely used RNN-LSTM and regression model and outperforms both. Real-time data on pollutant concentration and meteorological data for the Anand Vihar, Delhi, India monitoring station from November 1, 2017, till August 6, 2022, has been used for analysis. From the data available for 11 pollutants, the AQI is determined as per the Central Pollution Control Boardâ€™s (CPCBâ€™s) formula. The paper aims to predict the AQI along with the levels of PM2.5, CO, and PM10 pollutants. RMSE and MAE for PM2.5 evaluated using transformer are 17.74 and 11.15, respectively, best amongst all the models. Prior and accurate knowledge about Air Quality Index levels is directly relevant for policy-makers and the population at large so that the administrators may implement corrective measures. As the concept of smart cities is rapidly taking shape, the residents of such cities have the right to know about the air quality they are likely to breathe in the near future so that smart responses may be planned well in advance.",
    "introduction": "Accurate prediction of the Air Quality Index (AQI) is of paramount importance as the negative health impact of poor air quality on humans has been widely established.",
    "macro_domains": []
  },
  {
    "abstract": "Digital transformation is necessary to bring an inclusive opportunity for technology and society to meet the needs brought by both environment, circumstances, and events. In this work, we explore the capability of Generative AI in the societal context of smart city resource management with a particular focus on tourist service management. This work attempts to collaborate many services and resources as an information service to cater to the needs of smart city tourism. We demonstrated the potential of AI in achieving this collaborative information service dissemination with the help of an AI-enabled chatbot Web-application. We also discuss the technical elements required for the real-time information management that we envision for future smart city tourism initiatives. Our experimentation shows that LSTM outperforms CNN and ANN in performance.",
    "doi": "10.1109/ICCCNT56998.2023.10307912",
    "author_keywords": [
      "Chatbots",
      "LSTM",
      "Neural Network",
      "Smart City",
      "Tourism"
    ],
    "contribution": "In this work, we explore the capability of Generative AI in the societal context of smart city resource management with a particular focus on tourist service management. This work attempts to collaborate many services and resources as an information service to cater to the needs of smart city tourism. We demonstrated the potential of AI in achieving this collaborative information service dissemination with the help of an AI-enabled chatbot Web-application. We also discuss the technical elements required for the real-time information management that we envision for future smart city tourism initiatives. Our experimentation shows that LSTM outperforms CNN and ANN in performance.",
    "introduction": "Digital transformation is necessary to bring an inclusive opportunity for technology and society to meet the needs brought by both environment, circumstances, and events.",
    "macro_domains": []
  },
  {
    "abstract": "Sewer pipes are an fundamental infrastructure of modern cities, and their automatic maintenance is an important requirement for the operation of smart cities. The key issue for sewer pipe maintenance is the detection of their defects, which can lead to various levels of maintenance requirements. In this work, we present an optimized deep learning model for defect detection of sewer pipes. The model is optimized in three aspects: the backbone, the neck, and the detection head. The backbone is replaced with Swin Transformer, the neck is enhanced with Feature Pyramid Network (FPN) and RoI align, and the detection head is optimized by modifying the loss function with GIoU and introducing a new hyperparameter on classification loss. With these optimizations, the model has better feature extraction capability, better small defect detection, and better loss function for model training. Combined with data augmentation techniques, the optimized model achieves significant improvements over the baseline Faster R-CNN model, with mAP increased from 0.606 to 0.743. In addition to mAP improvements, our optimized model is especially effective on finding some sewer defects that are difficult to recognize.",
    "doi": "10.1109/SmartIoT58732.2023.00020",
    "author_keywords": [
      "data augmentation",
      "deep learning",
      "defect detection",
      "model optimization",
      "sewer pipes"
    ],
    "contribution": "In this work, we present an optimized deep learning model for defect detection of sewer pipes. The model is optimized in three aspects: the backbone, the neck, and the detection head. The backbone is replaced with Swin Transformer, the neck is enhanced with Feature Pyramid Network (FPN) and RoI align, and the detection head is optimized by modifying the loss function with GIoU and introducing a new hyperparameter on classification loss. With these optimizations, the model has better feature extraction capability, better small defect detection, and better loss function for model training. Combined with data augmentation techniques, the optimized model achieves significant improvements over the baseline Faster R-CNN model, with mAP increased from 0.606 to 0.743. In addition to mAP improvements, our optimized model is especially effective on finding some sewer defects that are difficult to recognize.",
    "introduction": "Sewer pipes are an fundamental infrastructure of modern cities, and their automatic maintenance is an important requirement for the operation of smart cities. The key issue for sewer pipe maintenance is the detection of their defects, which can lead to various levels of maintenance requirements.",
    "macro_domains": []
  },
  {
    "abstract": "In recent decades, mobile applications (apps) have gained enormous popularity. Smart services for smart cities increasingly gain attention. The main goal of this proposed research was to present a new artificial intelligence (AI)powered mobile app on Istanbul's traffic congestion forecast using traffic density data. It addresses the research question using time series approaches (long short-term memory (LSTM), Transformer, and eXtreme Gradient Boosting (XGBoost)) based on past data over the traffic load dataset combined with meteorological conditions. While previous studies were limited to direct Istanbul traffic forecasting, in this study, we focused on district-based traffic forecasting that can be queried with a mobile app. The proposed pipeline was tested on the summarized Istanbul traffic dataset for 6 main distinct districts (Fatih, Buyukcekmece, Atasehir, Kagithane, Tuzla, and Bagcilar). Analysis of the simulation results on predicted models will be discussed according to performance indicators such as mean absolute percentage error (MAPE), mean average error (MAE), and root mean squared error (RMSE). And then, it was observed that the Transformer model made the most accurate traffic prediction with a minimum MAE score for each district. The developed traffic forecasting prototype is expected to be a starting point for future products for a mobile app suitable for citizens' daily use.",
    "doi": "10.1109/ASYU58738.2023.10296669",
    "author_keywords": [
      "Deep Learning",
      "Mobile Applications",
      "Smart Cities",
      "Time Series",
      "Traffic Density",
      "Traffic Prediction"
    ],
    "contribution": "It addresses the research question using time series approaches (long short-term memory (LSTM), Transformer, and eXtreme Gradient Boosting (XGBoost)) based on past data over the traffic load dataset combined with meteorological conditions. While previous studies were limited to direct Istanbul traffic forecasting, in this study, we focused on district-based traffic forecasting that can be queried with a mobile app. The proposed pipeline was tested on the summarized Istanbul traffic dataset for 6 main distinct districts (Fatih, Buyukcekmece, Atasehir, Kagithane, Tuzla, and Bagcilar). Analysis of the simulation results on predicted models will be discussed according to performance indicators such as mean absolute percentage error (MAPE), mean average error (MAE), and root mean squared error (RMSE). And then, it was observed that the Transformer model made the most accurate traffic prediction with a minimum MAE score for each district. The developed traffic forecasting prototype is expected to be a starting point for future products for a mobile app suitable for citizens' daily use.",
    "introduction": "In recent decades, mobile applications (apps) have gained enormous popularity. Smart services for smart cities increasingly gain attention. The main goal of this proposed research was to present a new artificial intelligence (AI)powered mobile app on Istanbul's traffic congestion forecast using traffic density data.",
    "macro_domains": []
  },
  {
    "abstract": "Generating synthetic electricity consumption data is crucial for developing efficient energy systems in smart cities. In this paper, we propose the use of Tabular Generative Adversarial Networks (Tabular GAN) for generating synthetic data for residential electricity consumption. Tabular GANs have been used in various domains and have shown promising results in generating high-quality synthetic data. The performance of our proposed method was evaluated by comparing the probability density, mean, standard deviation, and variances of the synthetic data with the original data. The results showed that the Tabular GAN method generated synthetic data that closely match the statistical characteristics of the original data and the simulation outcome indicated that the synthetic data generated by Tabular GAN could effectively simulate the patterns and behaviors observed in the original data. Overall, the proposed method demonstrates the effectiveness of using Tabular GANs for generating synthetic electricity consumption data.",
    "doi": "10.1109/UPEC57427.2023.10294666",
    "author_keywords": [
      "CTGAN",
      "electricity consumption",
      "GAN",
      "synthetic data",
      "Tabular GAN"
    ],
    "contribution": "In this paper, we propose the use of Tabular Generative Adversarial Networks (Tabular GAN) for generating synthetic data for residential electricity consumption. Tabular GANs have been used in various domains and have shown promising results in generating high-quality synthetic data. The performance of our proposed method was evaluated by comparing the probability density, mean, standard deviation, and variances of the synthetic data with the original data. The results showed that the Tabular GAN method generated synthetic data that closely match the statistical characteristics of the original data and the simulation outcome indicated that the synthetic data generated by Tabular GAN could effectively simulate the patterns and behaviors observed in the original data. Overall, the proposed method demonstrates the effectiveness of using Tabular GANs for generating synthetic electricity consumption data.",
    "introduction": "Generating synthetic electricity consumption data is crucial for developing efficient energy systems in smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Video Surveillance Systems (VSSs) are used in a wide range of applications including public safety and perimeter security. They are deployed in places such as markets, hospitals, schools, banks, shopping malls, offices, and smart cities. VSSs generate a massive amount of surveillance data, and significant research has been published on the use of machine learning algorithms to handle surveillance data. In this paper, we present an extensive overview and a thorough analysis of cutting-edge learning methods used in VSSs. Existing surveys on learning approaches in video surveillance have some drawbacks, such as a lack of in-depth analysis of the learning algorithms, omission of certain methodologies, insufficient critical evaluation, and absence of recent learning algorithms. To fill these gaps, this survey provides a thorough examination of the most recent learning algorithms for anomaly detection. A critical assessment of the algorithms including their strengths, weaknesses, and applicability as well as tailored classifications of anomaly types for different domains are provided. Our study also offers insights into the future development of learning techniques in VSS, positioning itself as a valuable resource for both researchers and practitioners in the field. Finally, we share our thoughts on what we learned and how it can help with new developments in the future.",
    "doi": "10.1109/ACCESS.2023.3321800",
    "author_keywords": [
      "anomaly detection",
      "Machine learning",
      "semi-supervised learning methods",
      "supervised learning methods",
      "unsupervised learning methods",
      "video surveillance systems"
    ],
    "contribution": "In this paper, we present an extensive overview and a thorough analysis of cutting-edge learning methods used in VSSs. Existing surveys on learning approaches in video surveillance have some drawbacks, such as a lack of in-depth analysis of the learning algorithms, omission of certain methodologies, insufficient critical evaluation, and absence of recent learning algorithms. To fill these gaps, this survey provides a thorough examination of the most recent learning algorithms for anomaly detection. A critical assessment of the algorithms including their strengths, weaknesses, and applicability as well as tailored classifications of anomaly types for different domains are provided. Our study also offers insights into the future development of learning techniques in VSS, positioning itself as a valuable resource for both researchers and practitioners in the field. Finally, we share our thoughts on what we learned and how it can help with new developments in the future.",
    "introduction": "Video Surveillance Systems (VSSs) are used in a wide range of applications including public safety and perimeter security. They are deployed in places such as markets, hospitals, schools, banks, shopping malls, offices, and smart cities. VSSs generate a massive amount of surveillance data, and significant research has been published on the use of machine learning algorithms to handle surveillance data.",
    "macro_domains": []
  },
  {
    "abstract": "Photovoltaic systems are being used in almost every field such as smart cities, Internet of Things paradigms or remote Wireless Sensor Networks. In Internet of things paradigms deployed in natural environments, energy harvesting technology is crucial to power the devices. For the energy management system, it is important to predict how much energy can be harvested from the environment. In this work we focus on creating a model for forecasting the total energy produced by a photovoltaic installation one day in advance. The model is based on the original Transformer architecture. This structure has minor modifications for time series applications. The dataset was created with weather forecasts and the energy and power production of a real photovoltaic installation. The model was trained and compared with state-of-art approaches. The results show that our approach could predict the total energy generated by the photovoltaic installation one day-ahead.",
    "doi": "10.1109/ICECCME57830.2023.10253223",
    "author_keywords": [
      "Energy harvesting",
      "IoT",
      "PV",
      "Transformer"
    ],
    "contribution": "In this work we focus on creating a model for forecasting the total energy produced by a photovoltaic installation one day in advance. The model is based on the original Transformer architecture. This structure has minor modifications for time series applications. The dataset was created with weather forecasts and the energy and power production of a real photovoltaic installation. The model was trained and compared with state-of-art approaches. The results show that our approach could predict the total energy generated by the photovoltaic installation one day-ahead.",
    "introduction": "Photovoltaic systems are being used in almost every field such as smart cities, Internet of Things paradigms or remote Wireless Sensor Networks. In Internet of things paradigms deployed in natural environments, energy harvesting technology is crucial to power the devices. For the energy management system, it is important to predict how much energy can be harvested from the environment.",
    "macro_domains": []
  },
  {
    "abstract": "Structural defects in civil infrastructure, such as highways, roads, bridges, and dams, can severely impact their reliability and safety. Manual inspection of such infrastructure is labor-intensive and costly, creating the demand for automated damage-tracking systems. Data-driven techniques, such as machine learning, and statistical methods have been utilized in a remarkable number of Structural Health Monitoring (SHM) applications. However, real-time and high-accuracy concrete crack detection poses severe challenges for deployment on embedded systems and mobile robotic platforms, due to their computational constraints, low-latency requirements, and the robustness of model predictions in field deployments. This work proposes a robust and low-latency transformer-based deep-crack segmentation model that leverages both Red Green Blue (RGB) and Hyper Spectral (HYP) data for crack detection. The model is optimized for deployment on resource-constrained embedded systems, enabling structural health monitoring on robotic platforms, and studies the aleatoric and epistemic uncertainties of the estimated crack maps. The final model is deployed on one of the most popular robotic embedded computation platforms such as the NVIDIA Jetson Xavier NX, achieving state-of-the-art performance with an accuracy of 99.54% at an inference time of only 7.41ms using the RGB camera only. The proposed approach provides a promising solution for automating laborious SHM applications such as inspecting critical infrastructure.",
    "doi": "10.1109/SAS58821.2023.10254080",
    "author_keywords": [
      "Machine Learning",
      "Smart-Cities",
      "Structural Health Monitoring"
    ],
    "contribution": "This work proposes a robust and low-latency transformer-based deep-crack segmentation model that leverages both Red Green Blue (RGB) and Hyper Spectral (HYP) data for crack detection. The model is optimized for deployment on resource-constrained embedded systems, enabling structural health monitoring on robotic platforms, and studies the aleatoric and epistemic uncertainties of the estimated crack maps. The final model is deployed on one of the most popular robotic embedded computation platforms such as the NVIDIA Jetson Xavier NX, achieving state-of-the-art performance with an accuracy of 99.54% at an inference time of only 7.41ms using the RGB camera only. The proposed approach provides a promising solution for automating laborious SHM applications such as inspecting critical infrastructure.",
    "introduction": "Structural defects in civil infrastructure, such as highways, roads, bridges, and dams, can severely impact their reliability and safety. Manual inspection of such infrastructure is labor-intensive and costly, creating the demand for automated damage-tracking systems. Data-driven techniques, such as machine learning, and statistical methods have been utilized in a remarkable number of Structural Health Monitoring (SHM) applications. However, real-time and high-accuracy concrete crack detection poses severe challenges for deployment on embedded systems and mobile robotic platforms, due to their computational constraints, low-latency requirements, and the robustness of model predictions in field deployments.",
    "macro_domains": []
  },
  {
    "abstract": "Federated learning is a new distributed privacy-preserving learning paradigm which perfectly meets the requirements of many large service systems such as banking, healthcare, and smart city. Meanwhile, person re-identification, as a technology to associate the images of the same person from different data sources, has been widely used in many smart services such as smart logistics, smart surveillance, and many public searching and rescue missions. Therefore, it is a promising solution to use federated learning for person re-identification to improve the model accuracy while protecting the data privacy. However, the common problem of non-independent and identically distributed (Non-IID) data with heterogeneous clients in federated learning often causes undesirable model accuracy. To address such a problem, in this paper, we propose a novel strategy named federated learning with data augmentation for person re-identification (Fed4ReID). Specifically, to alleviate the impact of Non-IID data, we utilise a pre-trained DCGAN (Deep Convolutional Generative Adversarial Network) model for data augmentation at each edge servers. Experiments on public datasets show that our proposed strategy can outperform baseline method in general accuracy.",
    "doi": "10.1109/ICWS60048.2023.00021",
    "author_keywords": [
      "DCGAN",
      "Edge computing",
      "Federated learning",
      "Non-IID",
      "Person re-identification"
    ],
    "contribution": "To address such a problem, in this paper, we propose a novel strategy named federated learning with data augmentation for person re-identification (Fed4ReID). Specifically, to alleviate the impact of Non-IID data, we utilise a pre-trained DCGAN (Deep Convolutional Generative Adversarial Network) model for data augmentation at each edge servers. Experiments on public datasets show that our proposed strategy can outperform baseline method in general accuracy.",
    "introduction": "Federated learning is a new distributed privacy-preserving learning paradigm which perfectly meets the requirements of many large service systems such as banking, healthcare, and smart city. Meanwhile, person re-identification, as a technology to associate the images of the same person from different data sources, has been widely used in many smart services such as smart logistics, smart surveillance, and many public searching and rescue missions. Therefore, it is a promising solution to use federated learning for person re-identification to improve the model accuracy while protecting the data privacy. However, the common problem of non-independent and identically distributed (Non-IID) data with heterogeneous clients in federated learning often causes undesirable model accuracy.",
    "macro_domains": []
  },
  {
    "abstract": "The growing population in the metropolises is influencing the need to plan cities to be safer for people. Several Smart Cities initiatives are being implemented in the cities to achieve this goal. A network of acoustic sensors has been deployed in New York City thanks to the SONYC project. Sounds of the city are being collected and analyzed. In this research work, acoustic signal data are represented with Mel-spectrogram images with mel-scale frequency versus time on a decibel scale. Traditional autoencoders and variational autoencoder models are deployed to detect anomalies in the mel-spectrogram images. The obtained results demonstrate that the variational autoencoder model finds anomalies accurately in the acoustic records.",
    "doi": "10.1007/978-3-031-40725-3_3",
    "author_keywords": [
      "Acoustic sensor network",
      "Anomaly detection",
      "Autoencoders",
      "Urban sound data"
    ],
    "contribution": "In this research work, acoustic signal data are represented with Mel-spectrogram images with mel-scale frequency versus time on a decibel scale. Traditional autoencoders and variational autoencoder models are deployed to detect anomalies in the mel-spectrogram images. The obtained results demonstrate that the variational autoencoder model finds anomalies accurately in the acoustic records.",
    "introduction": "The growing population in the metropolises is influencing the need to plan cities to be safer for people. Several Smart Cities initiatives are being implemented in the cities to achieve this goal. A network of acoustic sensors has been deployed in New York City thanks to the SONYC project. Sounds of the city are being collected and analyzed.",
    "macro_domains": []
  },
  {
    "abstract": "Image Restoration under severe weather circumstances has drawn a lot of interest for many computer vision applications. In order to deliver accurate and high quality surveillance in the context of smart cities, image de-raining is a crucial subject that has been explored extensively in recent years. In order to handle the challenge of removing raindrops, two different strategies are adopted in this research study: The Diffusion model and the Generative adversarial network model. By considering the recent improvements in image deraining methods, this research study proposes a novel technique that makes use of conditional generative adversarial network with adversarial loss, which provides a factor to loss functions and regulates the output for achieving the improved results. In addition, diffusion modelling, a novel patch-based method is used to perform image restoration. Diffusion probabilistic frameworks are used for normalising noise over affected regions. This research study compares and evaluates how well these two techniques perform in eliminating the raindrops from images. This study demonstrates that the diffusion model outperforms the GAN technique in terms of qualitative assessments and visual appearance by conducting a comparative analysis on actual and synthetic data.",
    "doi": "10.1109/ICIRCA57980.2023.10220866",
    "author_keywords": [
      "Denoising diffusion model",
      "Generative adversarial networks",
      "Raindrop"
    ],
    "contribution": "In order to handle the challenge of removing raindrops, two different strategies are adopted in this research study: The Diffusion model and the Generative adversarial network model. By considering the recent improvements in image deraining methods, this research study proposes a novel technique that makes use of conditional generative adversarial network with adversarial loss, which provides a factor to loss functions and regulates the output for achieving the improved results. In addition, diffusion modelling, a novel patch-based method is used to perform image restoration. Diffusion probabilistic frameworks are used for normalising noise over affected regions. This research study compares and evaluates how well these two techniques perform in eliminating the raindrops from images. This study demonstrates that the diffusion model outperforms the GAN technique in terms of qualitative assessments and visual appearance by conducting a comparative analysis on actual and synthetic data.",
    "introduction": "Image Restoration under severe weather circumstances has drawn a lot of interest for many computer vision applications. In order to deliver accurate and high quality surveillance in the context of smart cities, image de-raining is a crucial subject that has been explored extensively in recent years.",
    "macro_domains": []
  },
  {
    "abstract": "Existing violent behavior datasets are not perfect in quantity and quality due to the difficulty of collecting. Although the state-of-the-art Transformer models had shown their capability in behavior recognition, it is unsuitable for the task of short-term behavior understanding (e.g., violent behavior recognition) due to the need for a large amount of data to achieve their best performance. Recently, a simple deep learning architecture, an all multilayer perceptron (MLP) architecture called MLP-Mixer, was proposed against Transformer in the task of a few-sample dataset to obtain competitive results. Motivated by spatio-temporal features on neurons, we invent a dual-form dataset for MLP-Mixer-based model training called aggregated spatio-temporal MLP-Mixer (ASM) to handle video understanding tasks. We show that ASM outperforms the state-of-the-art Transformer models as well as some of the best-performed convolutional neural network (CNN) approaches on three public datasets, smart-city CCTV violence detection dataset (SCVD), real-life violence situations (RLVS) dataset, and Hockey fight. Experimental results further validate our idea on short-term behavior scene understanding improvement.",
    "doi": "10.1109/IS3C57901.2023.00020",
    "author_keywords": null,
    "contribution": "",
    "introduction": "Existing violent behavior datasets are not perfect in quantity and quality due to the difficulty of collecting. Although the state-of-the-art Transformer models had shown their capability in behavior recognition, it is unsuitable for the task of short-term behavior understanding (e.g., violent behavior recognition) due to the need for a large amount of data to achieve their best performance. Recently, a simple deep learning architecture, an all multilayer perceptron (MLP) architecture called MLP-Mixer, was proposed against Transformer in the task of a few-sample dataset to obtain competitive results. Motivated by spatio-temporal features on neurons, we invent a dual-form dataset for MLP-Mixer-based model training called aggregated spatio-temporal MLP-Mixer (ASM) to handle video understanding tasks. We show that ASM outperforms the state-of-the-art Transformer models as well as some of the best-performed convolutional neural network (CNN) approaches on three public datasets, smart-city CCTV violence detection dataset (SCVD), real-life violence situations (RLVS) dataset, and Hockey fight. Experimental results further validate our idea on short-term behavior scene understanding improvement.",
    "macro_domains": []
  },
  {
    "abstract": "Camera surveillance plays an important role in maintaining the stability and safety of the social and public environment, and there are further requirements for the role of camera surveillance in building a smart city. This paper proposes a convolutional neural network based on the combination of the convolution module and the Transformer module. The network is applied to the tracking of pedestrian targets in infrared surveillance cameras to fill the shortcomings of surveillance cameras in the night environment. In this paper, the local features of the convolution module and the global features of the Transformer are combined into a comprehensive feature map. The feature information is used to solve the problem of less target feature information in infrared images, and the advantages of codec network structure design are used to ensure effective target features. At the same time, considering the embedding and portability of the network model, this paper adopts the method of grouping shared convolution kernels and Transformer nested segmentation in the design of the convolution module and the Transformer module, so as to achieve the purpose of lightweight. After several sets of control experiments, the network designed in this paper has a certain improvement in tracking speed and tracking performance, and effectively solves the problem that infrared weak and small targets are not easy to track.",
    "doi": "10.1117/12.2686716",
    "author_keywords": [
      "theoretical model",
      "Transformer",
      "Trendline"
    ],
    "contribution": "This paper proposes a convolutional neural network based on the combination of the convolution module and the Transformer module. The network is applied to the tracking of pedestrian targets in infrared surveillance cameras to fill the shortcomings of surveillance cameras in the night environment. In this paper, the local features of the convolution module and the global features of the Transformer are combined into a comprehensive feature map. The feature information is used to solve the problem of less target feature information in infrared images, and the advantages of codec network structure design are used to ensure effective target features. At the same time, considering the embedding and portability of the network model, this paper adopts the method of grouping shared convolution kernels and Transformer nested segmentation in the design of the convolution module and the Transformer module, so as to achieve the purpose of lightweight. After several sets of control experiments, the network designed in this paper has a certain improvement in tracking speed and tracking performance, and effectively solves the problem that infrared weak and small targets are not easy to track.",
    "introduction": "Camera surveillance plays an important role in maintaining the stability and safety of the social and public environment, and there are further requirements for the role of camera surveillance in building a smart city.",
    "macro_domains": []
  },
  {
    "abstract": "One of the most critical traffic management issues is congestion in modern and big smart cities. The first task is to accurately forecast traffic patterns to reduce congestion and accidents due to rapid economic development and rising number of vehicles. It is essential for Intelligent Transportation Systems to accurately anticipate future traffic circumstances (such as traffic flow, speed, and traffic time) so that administrators may take proper preventative actions against congestion and travelers can make better-informed judgments. Better trip planning, more efficient traffic operations, lower carbon emissions, and less congestion are all possible outcomes of this forecast. This paper explores different deep-learning time-series forecasting methods such as LSTM, BiLSTM, Prophet, and Transformer models for making short-term predictions regarding traffic flows to ensure smart mobility. The next step is to analyze traffic patterns to provide convenient transportation mobility. Then, we evaluated several performance matrices and computational loads of the proposed methods in this paper,",
    "doi": "10.1109/ITEC55900.2023.10186901",
    "author_keywords": [
      "Deep learning",
      "LSTM",
      "Prophet",
      "Smart mobility",
      "Traffic congestion",
      "Traffic flow prediction",
      "Transformer"
    ],
    "contribution": "This paper explores different deep-learning time-series forecasting methods such as LSTM, BiLSTM, Prophet, and Transformer models for making short-term predictions regarding traffic flows to ensure smart mobility. The next step is to analyze traffic patterns to provide convenient transportation mobility. Then, we evaluated several performance matrices and computational loads of the proposed methods in this paper,",
    "introduction": "One of the most critical traffic management issues is congestion in modern and big smart cities. The first task is to accurately forecast traffic patterns to reduce congestion and accidents due to rapid economic development and rising number of vehicles. It is essential for Intelligent Transportation Systems to accurately anticipate future traffic circumstances (such as traffic flow, speed, and traffic time) so that administrators may take proper preventative actions against congestion and travelers can make better-informed judgments. Better trip planning, more efficient traffic operations, lower carbon emissions, and less congestion are all possible outcomes of this forecast.",
    "macro_domains": []
  },
  {
    "abstract": "Internet of Things, low energy consumption, and intelligent and functionally integrated urban infrastructure construction are crucial elements in the development of smart cities. Distributed generation (DG) and electric vehicle charging infrastructure play a vital role in the planning and construction of smart cities. However, the uncertainty associated with the power output of distributed generation significantly impacts the planning of distribution networks. To address this issue, this paper proposes a site-selection recommendation algorithm that leverages urban multimedia data and improved generative adversarial networks. The proposed algorithm begins by modeling the uncertainty of wind power and photovoltaic (PV) generation using an enhanced conditional generative adversarial network model. To generate multimedia datasets with time-series characteristics for wind power and PV generation scenarios, monthly multimedia data labels are incorporated into the model. These multimedia datasets, representing a wide range of scenarios, are then clustered using the K-means clustering method. Furthermore, a distributed generation planning model is established, aiming to minimize the annual integrated cost. The planning problem is efficiently solved using CPLEX, a mathematical programming solver. In the simulation experiments, the proposed scheme is compared with alternative schemes. The results demonstrate that the proposed scheme achieves a significant total cost saving of 21.95% compared to the comparison scheme. Moreover, the experimental comparison reveals that the proposed scheme exhibits higher stability. Additionally, in terms of algorithm efficiency, the proposed algorithm outperforms the other three algorithms tested in terms of the number of iterations and speed. The experimental results highlight the effectiveness of the proposed planning model in improving the economy and stability of the distribution network. Furthermore, it enhances the computational efficiency of the planning problem associated with distributed power supply and electric vehicle charging stations. The findings of this research hold substantial research significance for the site selection planning of distributed power supply.",
    "doi": "10.1155/2023/6664219",
    "author_keywords": null,
    "contribution": "To address this issue, this paper proposes a site-selection recommendation algorithm that leverages urban multimedia data and improved generative adversarial networks. The proposed algorithm begins by modeling the uncertainty of wind power and photovoltaic (PV) generation using an enhanced conditional generative adversarial network model. To generate multimedia datasets with time-series characteristics for wind power and PV generation scenarios, monthly multimedia data labels are incorporated into the model. These multimedia datasets, representing a wide range of scenarios, are then clustered using the K-means clustering method. Furthermore, a distributed generation planning model is established, aiming to minimize the annual integrated cost. The planning problem is efficiently solved using CPLEX, a mathematical programming solver. In the simulation experiments, the proposed scheme is compared with alternative schemes. The results demonstrate that the proposed scheme achieves a significant total cost saving of 21.95% compared to the comparison scheme. Moreover, the experimental comparison reveals that the proposed scheme exhibits higher stability. Additionally, in terms of algorithm efficiency, the proposed algorithm outperforms the other three algorithms tested in terms of the number of iterations and speed. The experimental results highlight the effectiveness of the proposed planning model in improving the economy and stability of the distribution network. Furthermore, it enhances the computational efficiency of the planning problem associated with distributed power supply and electric vehicle charging stations. The findings of this research hold substantial research significance for the site selection planning of distributed power supply.",
    "introduction": "Internet of Things, low energy consumption, and intelligent and functionally integrated urban infrastructure construction are crucial elements in the development of smart cities. Distributed generation (DG) and electric vehicle charging infrastructure play a vital role in the planning and construction of smart cities. However, the uncertainty associated with the power output of distributed generation significantly impacts the planning of distribution networks.",
    "macro_domains": []
  },
  {
    "abstract": "With the rise of smart city construction, the importance of vehicle re-identification based on video surveillance has become increasingly prominent. The task of vehicle re-identification mainly focuses on recognizing the same vehicle image under different cameras. In this paper, we propose a multi-label fusion framework for vehicle re-identification based on VIT network. We design a method of anti-angle distortion data augmentation to solve the problem that the performance of VIT is limited by the relative position relationship inside the vehicle structure and the angle deviation caused by the different relative positions of camera and vehicle. At the same time, the key position weight information module is inserted into the coding layer to improve the network's attention to key information. Finally, in view of the insufficient use of the location information between patches in the VIT network, we design a location code based on the Minkowski distance metric to add the relative location relationships within the vehicle individuals to the network. The experiment shows that under the same conditions, our vehicle weight recognition system is superior to most of the more advanced work in vehicle-ID and VERI776 datasets compared with the most advanced supervised vehicle weight recognition work.",
    "doi": "10.1117/12.2675214",
    "author_keywords": [
      "Deep Learning",
      "Multi Labels",
      "Self-Attention Mechanism",
      "Vehicle Re-identification",
      "Visual Transformer"
    ],
    "contribution": "In this paper, we propose a multi-label fusion framework for vehicle re-identification based on VIT network. We design a method of anti-angle distortion data augmentation to solve the problem that the performance of VIT is limited by the relative position relationship inside the vehicle structure and the angle deviation caused by the different relative positions of camera and vehicle. At the same time, the key position weight information module is inserted into the coding layer to improve the network's attention to key information. Finally, in view of the insufficient use of the location information between patches in the VIT network, we design a location code based on the Minkowski distance metric to add the relative location relationships within the vehicle individuals to the network. The experiment shows that under the same conditions, our vehicle weight recognition system is superior to most of the more advanced work in vehicle-ID and VERI776 datasets compared with the most advanced supervised vehicle weight recognition work.",
    "introduction": "With the rise of smart city construction, the importance of vehicle re-identification based on video surveillance has become increasingly prominent. The task of vehicle re-identification mainly focuses on recognizing the same vehicle image under different cameras.",
    "macro_domains": []
  },
  {
    "abstract": "Background. As an important part of smart cities, smart water environmental protection has become an important way to solve water environmental pollution problems. It is proposed in this article to develop a water quality remote sensing image analysis and prediction method based on the improved Pix2Pix (3D-GAN) model to overcome the problems associated with water environment prediction of smart cities based on remote sensing image data having low accuracy in predicting image information, as well as being difficult to train. Methods. Firstly, due to inversion differences and weather conditions, water quality remote sensing images are not perfect, which leads to the creation of time series data that cannot be used directly in prediction modeling. Therefore, a method for preprocessing time series of remote sensing images has been proposed in this article. The original remote sensing image was unified by pixel substitution, the image was repaired by spatial weight matrix, and the time series data was supplemented by linear interpolation. Secondly, in order to enhance the ability of the prediction model to process spatial-temporal data and improve the prediction accuracy of remote sensing images, the convolutional gated recurrent unit network is concatenated with the Unet network as the generator of the improved Pix2Pix model. At the same time, the channel attention mechanism is introduced into the convolutional gated recurrent unit network to enhance the ability of extracting image time series information, and the residual structure is introduced into the downsampling of the U-net network to avoid gradient explosion or disappearance. After that, the remote sensing images of historical moments are superimposed on the channels as labels and sent to the discriminator for adversarial training. The improved Pix2Pix model no longer translates images, but can predict two dimensions of space and one dimension of time, so it is actually a 3D-GAN model. Third, remote sensing image inversion data of chlorophyll-a concentrations in the Taihu Lake basin are used to verify and predict the water environment at future moments. Results. The results show that the mean value of structural similarity, peak signal-tonoise ratio, cosine similarity, and mutual information between the predicted value of the proposed method and the real remote sensing image is higher than that of existing methods, which indicates that the proposed method is effective in predicting water environment of smart cities",
    "doi": "10.7717/PEERJ-CS.1292",
    "author_keywords": [
      "Artificial intelligence",
      "Deep learning",
      "Image analysis",
      "Neural network",
      "Pix2Pix model",
      "Prediction",
      "Remote sensing",
      "Smart cities",
      "Spatial-temporal data",
      "Water environment"
    ],
    "contribution": "It is proposed in this article to develop a water quality remote sensing image analysis and prediction method based on the improved Pix2Pix (3D-GAN) model to overcome the problems associated with water environment prediction of smart cities based on remote sensing image data having low accuracy in predicting image information, as well as being difficult to train. Methods. Firstly, due to inversion differences and weather conditions, water quality remote sensing images are not perfect, which leads to the creation of time series data that cannot be used directly in prediction modeling. Therefore, a method for preprocessing time series of remote sensing images has been proposed in this article. The original remote sensing image was unified by pixel substitution, the image was repaired by spatial weight matrix, and the time series data was supplemented by linear interpolation. Secondly, in order to enhance the ability of the prediction model to process spatial-temporal data and improve the prediction accuracy of remote sensing images, the convolutional gated recurrent unit network is concatenated with the Unet network as the generator of the improved Pix2Pix model. At the same time, the channel attention mechanism is introduced into the convolutional gated recurrent unit network to enhance the ability of extracting image time series information, and the residual structure is introduced into the downsampling of the U-net network to avoid gradient explosion or disappearance. After that, the remote sensing images of historical moments are superimposed on the channels as labels and sent to the discriminator for adversarial training. The improved Pix2Pix model no longer translates images, but can predict two dimensions of space and one dimension of time, so it is actually a 3D-GAN model. Third, remote sensing image inversion data of chlorophyll-a concentrations in the Taihu Lake basin are used to verify and predict the water environment at future moments. Results. The results show that the mean value of structural similarity, peak signal-tonoise ratio, cosine similarity, and mutual information between the predicted value of the proposed method and the real remote sensing image is higher than that of existing methods, which indicates that the proposed method is effective in predicting water environment of smart cities",
    "introduction": "Background. As an important part of smart cities, smart water environmental protection has become an important way to solve water environmental pollution problems.",
    "macro_domains": []
  },
  {
    "abstract": "Due to the high inherent uncertainty of renewable energy, probabilistic day-ahead wind power forecasting is crucial for modeling and controlling the uncertainty of renewable energy smart grids in smart cities. However, the accuracy and reliability of high-resolution day-ahead wind power forecasting are constrained by unreliable local weather prediction and incomplete power generation data. This article proposes a physics-informed artificial intelligence (AI) surrogates method to augment the incomplete dataset and quantify its uncertainty to improve wind power forecasting performance. The incomplete dataset, built with numerical weather prediction data, historical wind power generation, and weather factors data, is augmented based on generative adversarial networks. After augmentation, the enriched data is then fed into a multiple AI surrogates model constructed by two extreme learning machine networks to train the forecasting model for wind power. Therefore, the forecasting modelsâ€™ accuracy and generalization ability are improved by mining the implicit physics information from the incomplete dataset. An incomplete dataset gathered from a wind farm in North China, containing only 15 days of weather and wind power generation data with missing points caused by occasional shutdowns, is utilized to verify the proposed methodâ€™s performance. Compared with other probabilistic forecasting methods, the proposed method shows better accuracy and probabilistic performance on the same incomplete dataset, which highlights its potential for more flexible and sensitive maintenance of smart grids in smart cities.",
    "doi": "10.32604/cmes.2023.027124",
    "author_keywords": [
      "day-ahead forecasting",
      "extreme learning machine",
      "generative adversarial network",
      "incomplete data",
      "Physics-informed method",
      "probabilistic forecasting",
      "smart grids",
      "wind power"
    ],
    "contribution": "This article proposes a physics-informed artificial intelligence (AI) surrogates method to augment the incomplete dataset and quantify its uncertainty to improve wind power forecasting performance. The incomplete dataset, built with numerical weather prediction data, historical wind power generation, and weather factors data, is augmented based on generative adversarial networks. After augmentation, the enriched data is then fed into a multiple AI surrogates model constructed by two extreme learning machine networks to train the forecasting model for wind power. Therefore, the forecasting modelsâ€™ accuracy and generalization ability are improved by mining the implicit physics information from the incomplete dataset. An incomplete dataset gathered from a wind farm in North China, containing only 15 days of weather and wind power generation data with missing points caused by occasional shutdowns, is utilized to verify the proposed methodâ€™s performance. Compared with other probabilistic forecasting methods, the proposed method shows better accuracy and probabilistic performance on the same incomplete dataset, which highlights its potential for more flexible and sensitive maintenance of smart grids in smart cities.",
    "introduction": "Due to the high inherent uncertainty of renewable energy, probabilistic day-ahead wind power forecasting is crucial for modeling and controlling the uncertainty of renewable energy smart grids in smart cities. However, the accuracy and reliability of high-resolution day-ahead wind power forecasting are constrained by unreliable local weather prediction and incomplete power generation data.",
    "macro_domains": []
  },
  {
    "abstract": "Contemporary attackers, mainly motivated by financial gain, consistently devise sophisticated penetration techniques to access important information or data. The growing use of Internet of Things (IoT) technology in the contemporary convergence environment to connect to corporate networks and cloud-based applications only worsens this situation, as it facilitates multiple new attack vectors to emerge effortlessly. As such, existing intrusion detection systems suffer from performance degradation mainly because of insufficient considerations and poorly modeled detection systems. To address this problem, we designed a blended threat detection approach, considering the possible impact and dimensionality of new attack surfaces due to the aforementioned convergence.We collectively refer to the convergence of different technology sectors as the internet of blended environment. The proposed approach encompasses an ensemble of heterogeneous probabilistic autoencoders that leverage the corresponding advantages of a convolutional variational autoencoder and long short-term memory variational autoencoder. An extensive experimental analysis conducted on the TON_IoT dataset demonstrated 96.02% detection accuracy.Furthermore, performance of the proposed approach was compared with various single model (autoencoder)-based network intrusion detection approaches: autoencoder, variational autoencoder, convolutional variational autoencoder, and long short-term memory variational autoencoder. The proposed model outperformed all compared models, demonstrating F1-score improvements of 4.99%, 2.25%, 1.92%, and 3.69%, respectively.",
    "doi": "10.32604/csse.2023.037615",
    "author_keywords": [
      "anomaly detection",
      "autoencoder",
      "convolutional variational autoencoder",
      "digital healthcare",
      "ensemble learning",
      "LSTM",
      "Network intrusion detection",
      "smart city",
      "smart factory",
      "smart grid",
      "TON_IoT dataset",
      "variational autoencoder"
    ],
    "contribution": "",
    "introduction": "Contemporary attackers, mainly motivated by financial gain, consistently devise sophisticated penetration techniques to access important information or data. The growing use of Internet of Things (IoT) technology in the contemporary convergence environment to connect to corporate networks and cloud-based applications only worsens this situation, as it facilitates multiple new attack vectors to emerge effortlessly. As such, existing intrusion detection systems suffer from performance degradation mainly because of insufficient considerations and poorly modeled detection systems. To address this problem, we designed a blended threat detection approach, considering the possible impact and dimensionality of new attack surfaces due to the aforementioned convergence.We collectively refer to the convergence of different technology sectors as the internet of blended environment. The proposed approach encompasses an ensemble of heterogeneous probabilistic autoencoders that leverage the corresponding advantages of a convolutional variational autoencoder and long short-term memory variational autoencoder. An extensive experimental analysis conducted on the TON_IoT dataset demonstrated 96.02% detection accuracy.Furthermore, performance of the proposed approach was compared with various single model (autoencoder)-based network intrusion detection approaches: autoencoder, variational autoencoder, convolutional variational autoencoder, and long short-term memory variational autoencoder. The proposed model outperformed all compared models, demonstrating F1-score improvements of 4.99%, 2.25%, 1.92%, and 3.69%, respectively.",
    "macro_domains": []
  },
  {
    "abstract": "Smart grid is a key technology in realization of the vision of smart city. It is an electricity network which can intelligently combine actions of all the users connected to it, in order to efficiently deliver sustainable, economic, and secured electricity supplies. It consists of various smart devices through which energy demand and supply can be managed efficiently. It enables integration of various renewable energy sources (RES), distributed generation, and energy storage devices feasible which will reduce the environmental impact due to reducing dependency on conventional power plant (thermal power plant). With intelligent operation of various assets in the smart grid, their performance can be optimized for better delivery system depending on consumer needs. It will also improve reliability and resiliency of the system along with improved power quality of the electricity network.",
    "doi": "10.1016/B978-0-323-99503-0.00006-5",
    "author_keywords": [
      "Artificial intelligence",
      "Density",
      "Load demand",
      "Power plant",
      "Renewable energy sources (RES)",
      "Smart grid"
    ],
    "contribution": "",
    "introduction": "Smart grid is a key technology in realization of the vision of smart city. It is an electricity network which can intelligently combine actions of all the users connected to it, in order to efficiently deliver sustainable, economic, and secured electricity supplies. It consists of various smart devices through which energy demand and supply can be managed efficiently. It enables integration of various renewable energy sources (RES), distributed generation, and energy storage devices feasible which will reduce the environmental impact due to reducing dependency on conventional power plant (thermal power plant). With intelligent operation of various assets in the smart grid, their performance can be optimized for better delivery system depending on consumer needs. It will also improve reliability and resiliency of the system along with improved power quality of the electricity network.",
    "macro_domains": []
  },
  {
    "abstract": "Urban flow super-resolution (UFSR) can deduce fine-grained urban flow heatmap (UFH) based on coarse-grained observations and plays an essential role in urban planning (traffic prediction, public facility deployment, for instance). However, existing methods fail to capture the internal structural features of sparse UFHs and the external factors that lead to a significant waste of urban resources. To this end, we propose an enhanced super-resolution framework (Urban Flow-aware Super Resolution - Generative Adversarial Network, UrbanSG) to deduce fine-grained UFH for urban resource allocation. Specifically, we employ a conditional-GAN as the backbone, considering external factors as the specified condition. To capture the implicit urban structural correlation, we integrate the flow self-attention mechanism into our model, which focuses on urban grids with active traffic volumes. The evaluations of extensive experiments on two real-world datasets demonstrate the superiority of our framework. Especially when dealing with a sparse dataset, our method reduces error by 15.02% to the state-of-the-art baselines.",
    "doi": "10.1007/978-3-031-25201-3_32",
    "author_keywords": [
      "Attention mechanism",
      "Deep learning",
      "Super resolution",
      "Urban computing"
    ],
    "contribution": "To this end, we propose an enhanced super-resolution framework (Urban Flow-aware Super Resolution - Generative Adversarial Network, UrbanSG) to deduce fine-grained UFH for urban resource allocation. Specifically, we employ a conditional-GAN as the backbone, considering external factors as the specified condition. To capture the implicit urban structural correlation, we integrate the flow self-attention mechanism into our model, which focuses on urban grids with active traffic volumes. The evaluations of extensive experiments on two real-world datasets demonstrate the superiority of our framework. Especially when dealing with a sparse dataset, our method reduces error by 15.02% to the state-of-the-art baselines.",
    "introduction": "Urban flow super-resolution (UFSR) can deduce fine-grained urban flow heatmap (UFH) based on coarse-grained observations and plays an essential role in urban planning (traffic prediction, public facility deployment, for instance). However, existing methods fail to capture the internal structural features of sparse UFHs and the external factors that lead to a significant waste of urban resources.",
    "macro_domains": []
  },
  {
    "abstract": "Recently, It is easy to find network access points(APs), which can be used for more than simply connecting devices to the Internet. For example, the waveform of a WiFi signal changes when a human action is performed between the two APs. In previous research, we demonstrated how changes in an electric wave affect the channel state information of a signal and how deep learning can utilize this information to detect and predict human behavior. In this paper, we proposed a method to detect human behavior. The proposed method improves the performance of detection of human behavior and effective in a changing environment. We found that using a VAE-LSTM hybrid model with PCA is useful in terms of detecting abnormal human behavior Experimental results demonstrate that the proposed method can detect general abnormal behavior with >-79% overall precision in a changing environment.",
    "doi": "10.1109/ICOIN56518.2023.10048984",
    "author_keywords": [
      "autoencoder",
      "CNN",
      "CSI",
      "IOT",
      "LSTM",
      "PCA",
      "RNN",
      "Smart City",
      "VAE"
    ],
    "contribution": "In this paper, we proposed a method to detect human behavior. The proposed method improves the performance of detection of human behavior and effective in a changing environment. We found that using a VAE-LSTM hybrid model with PCA is useful in terms of detecting abnormal human behavior Experimental results demonstrate that the proposed method can detect general abnormal behavior with >-79% overall precision in a changing environment.",
    "introduction": "Recently, It is easy to find network access points(APs), which can be used for more than simply connecting devices to the Internet. For example, the waveform of a WiFi signal changes when a human action is performed between the two APs. In previous research, we demonstrated how changes in an electric wave affect the channel state information of a signal and how deep learning can utilize this information to detect and predict human behavior.",
    "macro_domains": []
  },
  {
    "abstract": "Street tree extraction based on the 3-D mobile mapping point cloud plays an important role in building smart cities and creating highly accurate urban street maps. Existing methods are often over- or under-segmented when segmenting overlapping street tree canopies and extracting geometrically complex trees. To address this problem, we propose a method based on improved 3-D morphological analysis for extracting street trees from mobile laser scanner (MLS) point clouds. First, the 3-D semantic point cloud segmentation framework based on deep learning is used for preclassification of the original point cloud to obtain the vegetation point cloud in the scene. Considering the influence of terrain unevenness, the vegetation point cloud is deterraformed and slice point cloud containing tree trunks is obtained through spatial filtering on height. On this basis, a voxel-based region growing method constrained with the changing rate of convex area is used to locate the stree trees. Then we propose a progressive tree crown segmentation method, which first completed the preliminary individual segmentation of the tree crown point cloud based on the voxel-based region growth constrained by the minimum increment rule, and then optimizes the crown edges by 'valley' structure-based clustering. In this article, the proposed method is validated and the accuracy is evaluated using three sets of MLS datasets collected from different scenarios. The experimental results show that the method can effectively identify and localize street trees with different geometries and has a good segmentation effect for street trees with large adhesion between canopies. The accuracy and recall of tree localization are higher than 96.08% and 95.83%, respectively, and the average precision and recall of instance segmentation in three datasets are higher than 93.23% and 95.41%, respectively.",
    "doi": "10.1109/JSTARS.2023.3243283",
    "author_keywords": [
      "Aquaculture ponds extraction",
      "diffusion model",
      "hyperspectral image",
      "image superresolution",
      "remote sensing",
      "unsupervised classification"
    ],
    "contribution": "To address this problem, we propose a method based on improved 3-D morphological analysis for extracting street trees from mobile laser scanner (MLS) point clouds. First, the 3-D semantic point cloud segmentation framework based on deep learning is used for preclassification of the original point cloud to obtain the vegetation point cloud in the scene. Considering the influence of terrain unevenness, the vegetation point cloud is deterraformed and slice point cloud containing tree trunks is obtained through spatial filtering on height. On this basis, a voxel-based region growing method constrained with the changing rate of convex area is used to locate the stree trees. Then we propose a progressive tree crown segmentation method, which first completed the preliminary individual segmentation of the tree crown point cloud based on the voxel-based region growth constrained by the minimum increment rule, and then optimizes the crown edges by 'valley' structure-based clustering. In this article, the proposed method is validated and the accuracy is evaluated using three sets of MLS datasets collected from different scenarios. The experimental results show that the method can effectively identify and localize street trees with different geometries and has a good segmentation effect for street trees with large adhesion between canopies. The accuracy and recall of tree localization are higher than 96.08% and 95.83%, respectively, and the average precision and recall of instance segmentation in three datasets are higher than 93.23% and 95.41%, respectively.",
    "introduction": "Street tree extraction based on the 3-D mobile mapping point cloud plays an important role in building smart cities and creating highly accurate urban street maps. Existing methods are often over- or under-segmented when segmenting overlapping street tree canopies and extracting geometrically complex trees.",
    "macro_domains": []
  },
  {
    "abstract": "Smart city power distributions have become promising technologies to meet the demand for energy in developed countries. However, increase in smart grids causes several power quality problems on the smart grid, in particular, current and voltage harmonic distortions, sudden voltage sag and swells, fault current, and isolation deterioration. Smart transformers are potential solutions to improve the power quality on the electric grid. They present energy efficiency, ensure grid reliability and power flow control, voltage regulation, bidirectional power flow, fault current limiting, harmonic blocking, and galvanic isolation. Therefore, this paper offers an optimal selection of a three-stage (AC-DC-DC-AC) smart transformer model and power control strategy for solar PV power plant integrated smart grids. The topology of the rectifier, isolated bidirectional converter, and inverter has soft-switching features. This enables low conduction loss, low electromagnetic interference (EMI), high efficiency, achievable zero-voltage switching for converters, and zero-current switching for electrical auxiliary systems. Operation strategies of the proposed ST, PWM control, voltage, and current control between converters, including a medium-voltage (MV) high-frequency transformer to realize a 10 kVA, 450 Vdc to 220 Vdc, or 220 Vac ST, are presented. Significantly, the ST prototype achieves 96.7% conversion efficiency thanks to its control strategy, even under unstable power generation conditions from the solar PV plant. Experimental results obtained on the 344 Vac 10.4 A load current validates the dv/dt rate 6.8 kV/us. The dynamic and experimental results of the proposed bidirectional smart transformer demonstrate the success in preventing power quality problems for photovoltaic integrated smart city power distribution.",
    "doi": "10.3390/su15010032",
    "author_keywords": [
      "power distribution",
      "power quality",
      "smart city",
      "smart transformer",
      "solar PV"
    ],
    "contribution": "Therefore, this paper offers an optimal selection of a three-stage (AC-DC-DC-AC) smart transformer model and power control strategy for solar PV power plant integrated smart grids. The topology of the rectifier, isolated bidirectional converter, and inverter has soft-switching features. This enables low conduction loss, low electromagnetic interference (EMI), high efficiency, achievable zero-voltage switching for converters, and zero-current switching for electrical auxiliary systems. Operation strategies of the proposed ST, PWM control, voltage, and current control between converters, including a medium-voltage (MV) high-frequency transformer to realize a 10 kVA, 450 Vdc to 220 Vdc, or 220 Vac ST, are presented. Significantly, the ST prototype achieves 96.7% conversion efficiency thanks to its control strategy, even under unstable power generation conditions from the solar PV plant. Experimental results obtained on the 344 Vac 10.4 A load current validates the dv/dt rate 6.8 kV/us. The dynamic and experimental results of the proposed bidirectional smart transformer demonstrate the success in preventing power quality problems for photovoltaic integrated smart city power distribution.",
    "introduction": "Smart city power distributions have become promising technologies to meet the demand for energy in developed countries. However, increase in smart grids causes several power quality problems on the smart grid, in particular, current and voltage harmonic distortions, sudden voltage sag and swells, fault current, and isolation deterioration. Smart transformers are potential solutions to improve the power quality on the electric grid. They present energy efficiency, ensure grid reliability and power flow control, voltage regulation, bidirectional power flow, fault current limiting, harmonic blocking, and galvanic isolation.",
    "macro_domains": []
  },
  {
    "abstract": "Urban scenes segmentation based on UAV (Unmanned aerial vehicle) view is a fundamental task for the applications of smart city such as city planning, land use monitoring, traffic monitoring, and crowd estimation. While urban scenes in UAV image characteristic by large scale variation of objects size and complexity background, which posed challenges to urban scenes segmentation of UAV image. The feature extracting backbone of existing networks cannot extract complex features of UAV image effectively, which limits the performance of urban scenes segmentation. To design segmentation network capable of extracting features of large scale variation urban ground scenes, this study proposed a novel composite transformer network for urban scenes segmentation of UAV image. A composite backbone with aggregation windows multi-head self-attention transformer blocks is proposed to make the extracted features more representatives by adaptive multi-level features fusion, and the full utilisation of contextual information and local information. Position attention modules are inserted in each stage between encoder and decoder to further enhance the spatial attention of extracted feature maps. Finally, a V-shaped decoder which is capable of utilising multi-level features is designed to get accurately dense prediction. The accuracy of urban scenes segmentation could significantly be enhanced in this way and successfully segmented the large scale variation objects from UAV views. Extensive ablation experiments and comparative experiments for the proposed network have been conducted on the public available urban scenes segmentation datasets for UAV imagery. Experimental results have demonstrated the effectiveness of designed network structure and the superiority of proposed network over state-of-the-art methods. Specifically, reached 53.2% mIoU on the UAVid dataset and 77.6% mIoU on the UDD6 dataset, respectively.",
    "doi": "10.1016/j.patcog.2022.109019",
    "author_keywords": [
      "Aggregation windows multi-head self-attention transformer block",
      "Composite backbone",
      "UAV image",
      "Urban scenes segmentation",
      "V-shaped decoder"
    ],
    "contribution": "To design segmentation network capable of extracting features of large scale variation urban ground scenes, this study proposed a novel composite transformer network for urban scenes segmentation of UAV image. A composite backbone with aggregation windows multi-head self-attention transformer blocks is proposed to make the extracted features more representatives by adaptive multi-level features fusion, and the full utilisation of contextual information and local information. Position attention modules are inserted in each stage between encoder and decoder to further enhance the spatial attention of extracted feature maps. Finally, a V-shaped decoder which is capable of utilising multi-level features is designed to get accurately dense prediction. The accuracy of urban scenes segmentation could significantly be enhanced in this way and successfully segmented the large scale variation objects from UAV views. Extensive ablation experiments and comparative experiments for the proposed network have been conducted on the public available urban scenes segmentation datasets for UAV imagery. Experimental results have demonstrated the effectiveness of designed network structure and the superiority of proposed network over state-of-the-art methods. Specifically, reached 53.2% mIoU on the UAVid dataset and 77.6% mIoU on the UDD6 dataset, respectively.",
    "introduction": "Urban scenes segmentation based on UAV (Unmanned aerial vehicle) view is a fundamental task for the applications of smart city such as city planning, land use monitoring, traffic monitoring, and crowd estimation. While urban scenes in UAV image characteristic by large scale variation of objects size and complexity background, which posed challenges to urban scenes segmentation of UAV image. The feature extracting backbone of existing networks cannot extract complex features of UAV image effectively, which limits the performance of urban scenes segmentation.",
    "macro_domains": []
  },
  {
    "abstract": "One of the most important factors in modern information systems of the Indian administrative agencies is the lack of easy access to information through organizations outside of the organization, with the name of the machine-guns in the app. In spite of the abundance of data, and they are locked into proprietary formats, or may not be available due to the lack of an API. In this report, we will focus on the architectural designs that make it easy to share data. Therefore, we focus on a data-based information, see the reference architecture, rather than focusing on the application and communication. Internet of Things (IoT) is a new technology that has emerged in the last couple of years, and it promises to be a continued explosion of data sources. With this technology, it will, in essence, a single â€œthingâ€ to begin with, the production and transmission of data. For example, each and every lamp post, street lamp, trash bin, power transformer, etc., almost anything that a person can to be created in order to be constantly informed about their disease, their perceptions, and their patterns of use, etc. These data, which, in turn, can be used to lower the level of the business processes of the administration, in order to ensure fast and efficient value-added services. In this report, we will limit ourselves to the architectural design for the integration of new IoT-based systems in a Smart City infrastructure.",
    "doi": "10.1007/978-981-16-9967-2_62",
    "author_keywords": [
      "APIs",
      "Application",
      "Internet of Things",
      "Smart City"
    ],
    "contribution": "",
    "introduction": "One of the most important factors in modern information systems of the Indian administrative agencies is the lack of easy access to information through organizations outside of the organization, with the name of the machine-guns in the app. In spite of the abundance of data, and they are locked into proprietary formats, or may not be available due to the lack of an API. In this report, we will focus on the architectural designs that make it easy to share data. Therefore, we focus on a data-based information, see the reference architecture, rather than focusing on the application and communication. Internet of Things (IoT) is a new technology that has emerged in the last couple of years, and it promises to be a continued explosion of data sources. With this technology, it will, in essence, a single â€œthingâ€ to begin with, the production and transmission of data. For example, each and every lamp post, street lamp, trash bin, power transformer, etc., almost anything that a person can to be created in order to be constantly informed about their disease, their perceptions, and their patterns of use, etc. These data, which, in turn, can be used to lower the level of the business processes of the administration, in order to ensure fast and efficient value-added services. In this report, we will limit ourselves to the architectural design for the integration of new IoT-based systems in a Smart City infrastructure.",
    "macro_domains": []
  },
  {
    "abstract": "Advances in Artificial intelligence (AI) and embedded systems have resulted on a recent increase in use of image processing applications for smart citiesâ€™ safety. This enables a cost-adequate scale of automated video surveillance, increasing the data available and releasing human intervention. At the same time, although deep learning is a very intensive task in terms of computing resources, hardware and software improvements have emerged, allowing embedded systems to implement sophisticated machine learning algorithms at the edge. Additionally, new lightweight open-source middleware for constrained resource devices, such as EdgeX Foundry, have appeared to facilitate the collection and processing of data at sensor level, with communication capabilities to exchange data with a cloud enterprise application. The objective of this work is to show and describe the development of two Edge Smart Camera Systems for safety of Smart cities within S4AllCities H2020 project. Hence, the work presents hardware and software modules developed within the project, including a custom hardware platform specifically developed for the deployment of deep learning models based on the I.MX8 Plus from NXP, which considerably reduces processing and inference times; a custom Video Analytics Edge Computing (VAEC) system deployed on a commercial NVIDIA Jetson TX2 platform, which provides high level results on person detection processes; and an edge computing framework for the management of those two edge devices, namely Distributed Edge Computing framework, DECIoT. To verify the utility and functionality of the systems, extended experiments were performed. The results highlight their potential to provide enhanced situational awareness and demonstrate the suitability for edge machine vision applications for safety in smart cities.",
    "doi": "10.3390/jimaging8120326",
    "author_keywords": [
      "artificial intelligence",
      "deep learning",
      "edge",
      "EdgeX Foundry",
      "embedded machine vision",
      "smart cities"
    ],
    "contribution": "The objective of this work is to show and describe the development of two Edge Smart Camera Systems for safety of Smart cities within S4AllCities H2020 project. Hence, the work presents hardware and software modules developed within the project, including a custom hardware platform specifically developed for the deployment of deep learning models based on the I.MX8 Plus from NXP, which considerably reduces processing and inference times; a custom Video Analytics Edge Computing (VAEC) system deployed on a commercial NVIDIA Jetson TX2 platform, which provides high level results on person detection processes; and an edge computing framework for the management of those two edge devices, namely Distributed Edge Computing framework, DECIoT. To verify the utility and functionality of the systems, extended experiments were performed. The results highlight their potential to provide enhanced situational awareness and demonstrate the suitability for edge machine vision applications for safety in smart cities.",
    "introduction": "Advances in Artificial intelligence (AI) and embedded systems have resulted on a recent increase in use of image processing applications for smart citiesâ€™ safety. This enables a cost-adequate scale of automated video surveillance, increasing the data available and releasing human intervention. At the same time, although deep learning is a very intensive task in terms of computing resources, hardware and software improvements have emerged, allowing embedded systems to implement sophisticated machine learning algorithms at the edge. Additionally, new lightweight open-source middleware for constrained resource devices, such as EdgeX Foundry, have appeared to facilitate the collection and processing of data at sensor level, with communication capabilities to exchange data with a cloud enterprise application.",
    "macro_domains": []
  },
  {
    "abstract": "Object detection technology for images generated by optical sensors is of great significance in areas such as national defense security, disaster prediction, and smart city construction. Aiming at the problems of small target size, arbitrary target direction, and complex background in aerial image object detection using optical sensors. By using the images captured by a wild range of optical sensors such as CCDï¼ˆCharge Coupled Deviceï¼‰ and SAR(Synthetic Aperture Radar), we propose a more efficient rotating frame object detection algorithm that introduces the MCAB (Multi-branch Convolutional Attention Block) that can process these same types of images taken by the aerial platform using light sensors. First, we construct the module by adding identity, residual branch, and CBAM (Convolutional Block Attention Module) structure to the traditional convolution layer and the activation function to substitute the simple conv module in the network. Secondly, we introduce the Transformer layer at the end of the backbone network to enhance the global perception of the model with low overhead, realize the relationship is modeling between the target and the scene content, and reduce the amount of calculation. We improve the structure of the neck layer by BiFPN (Bidirectional Feature Pyramid Network) to speed up network operation, and CBAM is added after C3 to highlight important characteristic information. Our improved YOLOv5 algorithm is tested on the self-made rotating small target aerial data set. Compared with the original algorithm, our model's mean Average Precision (mAP) is improved by 1.8 percentage points, and the accuracy and recall are also enhanced by 0.46 and 0.34 percentage points.",
    "doi": "10.1016/j.displa.2022.102328",
    "author_keywords": [
      "Convolutional Block Attention Module",
      "Multi-branch Convolutional Attention Block",
      "Optical Sensors",
      "Rotated boxes detection",
      "Transformer",
      "YOLOv5"
    ],
    "contribution": "By using the images captured by a wild range of optical sensors such as CCDï¼ˆCharge Coupled Deviceï¼‰ and SAR(Synthetic Aperture Radar), we propose a more efficient rotating frame object detection algorithm that introduces the MCAB (Multi-branch Convolutional Attention Block) that can process these same types of images taken by the aerial platform using light sensors. First, we construct the module by adding identity, residual branch, and CBAM (Convolutional Block Attention Module) structure to the traditional convolution layer and the activation function to substitute the simple conv module in the network. Secondly, we introduce the Transformer layer at the end of the backbone network to enhance the global perception of the model with low overhead, realize the relationship is modeling between the target and the scene content, and reduce the amount of calculation. We improve the structure of the neck layer by BiFPN (Bidirectional Feature Pyramid Network) to speed up network operation, and CBAM is added after C3 to highlight important characteristic information. Our improved YOLOv5 algorithm is tested on the self-made rotating small target aerial data set. Compared with the original algorithm, our model's mean Average Precision (mAP) is improved by 1.8 percentage points, and the accuracy and recall are also enhanced by 0.46 and 0.34 percentage points.",
    "introduction": "Object detection technology for images generated by optical sensors is of great significance in areas such as national defense security, disaster prediction, and smart city construction. Aiming at the problems of small target size, arbitrary target direction, and complex background in aerial image object detection using optical sensors.",
    "macro_domains": []
  },
  {
    "abstract": "Smart cities are our aspiration for a better life where transportation intelligence is indispensable. Recent technological advances in intelligent transportation systems have opened up new possibilities for smart mobility in smart cities. Here we present TengYun, a transportation foundation model designed and developed with parallel learning and federated intelligence for our transportation metaverse called TransVerse. TengYun enables decentralized/distributed autonomous organizations with decentralized/distributed operations, as well as various federated technologies, from federated security, federated control, federated management, federated services, to federated ecology for transportation intelligence in smart cities. An example for a federation of transportation transformers is discussed for illustrating the operating procedure of TengYun.",
    "doi": "10.1109/MIS.2022.3221342",
    "author_keywords": null,
    "contribution": "Here we present TengYun, a transportation foundation model designed and developed with parallel learning and federated intelligence for our transportation metaverse called TransVerse. TengYun enables decentralized/distributed autonomous organizations with decentralized/distributed operations, as well as various federated technologies, from federated security, federated control, federated management, federated services, to federated ecology for transportation intelligence in smart cities. An example for a federation of transportation transformers is discussed for illustrating the operating procedure of TengYun.",
    "introduction": "Smart cities are our aspiration for a better life where transportation intelligence is indispensable. Recent technological advances in intelligent transportation systems have opened up new possibilities for smart mobility in smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "A growing number of research areas such as location-based social networks, intelligent transportation systems, and urban computing utilize large amounts of trajectory data for benchmarking data management approaches and analysis methods. Given the general lackness of available large datasets, realistic synthetic trajectory datasets become important. This work proposes deep generative models for trajectory data that can learn disentangled models for sophisticated latent patterns. Existing methods rely on predefined heuristics and cannot learn the unknown underlying generative mechanisms. The proposed novel deep generative VAE-like models factorize global and local semantics (habits vs. random routing change). We further develop new inference strategies based on variational inference and constrained optimization to encapsulate spatiotemporal validity. New deep neural network architectures are developed to implement generative and inference models with dynamic latent priors. The proposed methods represent significant quantitative and qualitative improvements over existing approaches as demonstrated by extensive experiments. The software is made publicly available 1.",
    "doi": "10.1145/3557915.3560994",
    "author_keywords": [
      "deep generative models",
      "end-to-end trajectory generation",
      "spatiotemporal-validity constraint",
      "variational autoencoders"
    ],
    "contribution": "This work proposes deep generative models for trajectory data that can learn disentangled models for sophisticated latent patterns. Existing methods rely on predefined heuristics and cannot learn the unknown underlying generative mechanisms. The proposed novel deep generative VAE-like models factorize global and local semantics (habits vs. random routing change). We further develop new inference strategies based on variational inference and constrained optimization to encapsulate spatiotemporal validity. New deep neural network architectures are developed to implement generative and inference models with dynamic latent priors. The proposed methods represent significant quantitative and qualitative improvements over existing approaches as demonstrated by extensive experiments. The software is made publicly available 1.",
    "introduction": "A growing number of research areas such as location-based social networks, intelligent transportation systems, and urban computing utilize large amounts of trajectory data for benchmarking data management approaches and analysis methods. Given the general lackness of available large datasets, realistic synthetic trajectory datasets become important.",
    "macro_domains": []
  },
  {
    "abstract": "Audio recognition can be used in smart cities for security, surveillance, manufacturing, autonomous vehicles, and noise mitigation, just to name a few. However, urban sounds are everyday audio events that occur daily, presenting unstructured characteristics containing different genres of noise and sounds unrelated to the sound event under study, making it a challenging problem. Therefore, the main objective of this literature review is to summarize the most recent works on this subject to understand the current approaches and identify their limitations. Based on the reviewed articles, it can be realized that Deep Learning (DL) architectures, attention mechanisms, data augmentation techniques, and pretraining are the most crucial factors to consider while creating an efficient sound classification model. The best-found results were obtained by Mushtaq and Su, in 2020, using a DenseNet-161 with pretrained weights from ImageNet, and NA-1 and NA-2 as augmentation techniques, which were of 97.98%, 98.52%, and 99.22% for UrbanSound8K, ESC-50, and ESC-10 datasets, respectively. Nonetheless, the use of these models in real-world scenarios has not been properly addressed, so their effectiveness is still questionable in such situations.",
    "doi": "10.3390/s22228608",
    "author_keywords": [
      "attention mechanisms",
      "audio classification",
      "audio processing",
      "Convolutional Neural Networks",
      "deep learning",
      "transformers"
    ],
    "contribution": "",
    "introduction": "Audio recognition can be used in smart cities for security, surveillance, manufacturing, autonomous vehicles, and noise mitigation, just to name a few. However, urban sounds are everyday audio events that occur daily, presenting unstructured characteristics containing different genres of noise and sounds unrelated to the sound event under study, making it a challenging problem. Therefore, the main objective of this literature review is to summarize the most recent works on this subject to understand the current approaches and identify their limitations. Based on the reviewed articles, it can be realized that Deep Learning (DL) architectures, attention mechanisms, data augmentation techniques, and pretraining are the most crucial factors to consider while creating an efficient sound classification model. The best-found results were obtained by Mushtaq and Su, in 2020, using a DenseNet-161 with pretrained weights from ImageNet, and NA-1 and NA-2 as augmentation techniques, which were of 97.98%, 98.52%, and 99.22% for UrbanSound8K, ESC-50, and ESC-10 datasets, respectively. Nonetheless, the use of these models in real-world scenarios has not been properly addressed, so their effectiveness is still questionable in such situations.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate traffic prediction is significant in intelligent citiesâ€™ safe and stable development. However, due to the complex spatiotemporal correlation of traffic flow data, establishing an accurate traffic prediction model is still challenging. Aiming to meet the challenge, this paper proposes SGGformer, an advanced traffic grade prediction model which combines a shifted window operation, a multi-channel graph convolution network, and a graph Transformer network. Firstly, the shifted window operation is used for coarsening the time series data, thus, the computational complexity can be reduced. Then, a multi-channel graph convolutional network is adopted to capture and aggregate the spatial correlations of the roads in multiple dimensions. Finally, the improved graph Transformer based on the advanced Transformer model is proposed to extract the long-term temporal correlation of traffic data effectively. The prediction performance is evaluated by using actual traffic datasets, and the test results show that the SGGformer proposed exceeds the state-of-the-art baseline.",
    "doi": "10.3390/s22229024",
    "author_keywords": [
      "deep learning",
      "Graph Transformer",
      "multi-channel GCN",
      "shifted window operation",
      "traffic prediction"
    ],
    "contribution": "Aiming to meet the challenge, this paper proposes SGGformer, an advanced traffic grade prediction model which combines a shifted window operation, a multi-channel graph convolution network, and a graph Transformer network. Firstly, the shifted window operation is used for coarsening the time series data, thus, the computational complexity can be reduced. Then, a multi-channel graph convolutional network is adopted to capture and aggregate the spatial correlations of the roads in multiple dimensions. Finally, the improved graph Transformer based on the advanced Transformer model is proposed to extract the long-term temporal correlation of traffic data effectively. The prediction performance is evaluated by using actual traffic datasets, and the test results show that the SGGformer proposed exceeds the state-of-the-art baseline.",
    "introduction": "Accurate traffic prediction is significant in intelligent citiesâ€™ safe and stable development. However, due to the complex spatiotemporal correlation of traffic flow data, establishing an accurate traffic prediction model is still challenging.",
    "macro_domains": []
  },
  {
    "abstract": "With the increase of large camera networks around us, it is becoming more difficult to manually identify vehicles. Computer vision enables us to automate this task. More specifically, vehicle re-identification (ReID) aims to identify cars in a camera network with non-overlapping views. Images captured of vehicles can undergo intense variations of appearance due to illumination, pose, or viewpoint. Furthermore, due to small inter-class similarities and large intra-class differences, feature learning is often enhanced with non-visual cues, such as the topology of camera networks and temporal information. These are, however, not always available or can be resource intensive for the model. Following the success of Transformer baselines in ReID, we propose for the first time an outlook-attention-based vehicle ReID framework using the Vision Outlooker as its backbone, which is able to encode finer-level features. We show that, without embedding any additional side information and using only the visual cues, we can achieve an 80.31% mAP and 97.13% R-1 on the VeRi-776 dataset. Besides documenting our research, this paper also aims to provide a comprehensive walkthrough of vehicle ReID. We aim to provide a starting point for individuals and organisations, as it is difficult to navigate through the myriad of complex research in this field.",
    "doi": "10.3390/s22228651",
    "author_keywords": [
      "explainable AI",
      "secure AI",
      "smart cities",
      "vehicle re-identification",
      "Vision Outlooker"
    ],
    "contribution": "Following the success of Transformer baselines in ReID, we propose for the first time an outlook-attention-based vehicle ReID framework using the Vision Outlooker as its backbone, which is able to encode finer-level features. We show that, without embedding any additional side information and using only the visual cues, we can achieve an 80.31% mAP and 97.13% R-1 on the VeRi-776 dataset. Besides documenting our research, this paper also aims to provide a comprehensive walkthrough of vehicle ReID. We aim to provide a starting point for individuals and organisations, as it is difficult to navigate through the myriad of complex research in this field.",
    "introduction": "With the increase of large camera networks around us, it is becoming more difficult to manually identify vehicles. Computer vision enables us to automate this task. More specifically, vehicle re-identification (ReID) aims to identify cars in a camera network with non-overlapping views. Images captured of vehicles can undergo intense variations of appearance due to illumination, pose, or viewpoint. Furthermore, due to small inter-class similarities and large intra-class differences, feature learning is often enhanced with non-visual cues, such as the topology of camera networks and temporal information. These are, however, not always available or can be resource intensive for the model.",
    "macro_domains": []
  },
  {
    "abstract": "In smart city infrastructure, IoT networks contain intelligent devices for collecting and processing data using open channel internet. Some challenges have occurred in the existing methods while transferring the data, like centralism, safety, secrecy (data destroying, inference attacks), transparency, scalability, verification, and controlling the rapid adaptation of smart cities. To overcome these challenges, a machine learning based block chain method is proposed in this manuscript. The machine learning strategies can process massive datasets. Furthermore, they contain adequate generalization to identify various attack vectors. Here, the block chain fostered cycle-consistent generative adversarial network (CCGAN) framework espoused intrusion detection is proposed for protecting the IoT network. Also, a 3 level privacy model is introduced for protecting the IoT devices. The first level is block chain based privacy detection and the second level is CCGAN and the third level is classification. In first level, ToN-IoT, BoT-IoT datasets are taken to detect the IoT intrusion, these data's are given to the block chain to authenticate and to collect the data in the IoT devices in the smart cities and stored in the blocks present in the block chain. In second level, the feature mapping and feature selection are done. The normal and attacked instances are classified in level 3. The performance of the proposed method shows higher accuracy 25.37%, 29.57%, and 18.67%, higher recall 23.75%, 17.58%, and 14.68% better than the existing methods, like block chain and machine learning method based privacy protection in IoT using optimized gradient tree boosting system (IOT-BC-XGBoost), and block chain and machine learning method based privacy protection in IoT using deep gated recurrent neural network (IOT-BC-DGRNN), respectively.",
    "doi": "10.1002/ett.4578",
    "author_keywords": null,
    "contribution": "To overcome these challenges, a machine learning based block chain method is proposed in this manuscript. The machine learning strategies can process massive datasets. Furthermore, they contain adequate generalization to identify various attack vectors. Here, the block chain fostered cycle-consistent generative adversarial network (CCGAN) framework espoused intrusion detection is proposed for protecting the IoT network. Also, a 3 level privacy model is introduced for protecting the IoT devices. The first level is block chain based privacy detection and the second level is CCGAN and the third level is classification. In first level, ToN-IoT, BoT-IoT datasets are taken to detect the IoT intrusion, these data's are given to the block chain to authenticate and to collect the data in the IoT devices in the smart cities and stored in the blocks present in the block chain. In second level, the feature mapping and feature selection are done. The normal and attacked instances are classified in level 3. The performance of the proposed method shows higher accuracy 25.37%, 29.57%, and 18.67%, higher recall 23.75%, 17.58%, and 14.68% better than the existing methods, like block chain and machine learning method based privacy protection in IoT using optimized gradient tree boosting system (IOT-BC-XGBoost), and block chain and machine learning method based privacy protection in IoT using deep gated recurrent neural network (IOT-BC-DGRNN), respectively.",
    "introduction": "In smart city infrastructure, IoT networks contain intelligent devices for collecting and processing data using open channel internet. Some challenges have occurred in the existing methods while transferring the data, like centralism, safety, secrecy (data destroying, inference attacks), transparency, scalability, verification, and controlling the rapid adaptation of smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Private car transfer indicates that people drive private cars and travel between urban regions to perform daily activities. Foreseeing private car transfer between urban regions can facilitate a broad scope of applications ranging from route planning, hot region discovery to urban computing. However, three challenges remain. i) Private car transfer between regions is affected by multiple spatio-temporal correlations. ii) Transfer records are highly sparse and imbalanced. iii) Modeling the stay duration of private cars. In this paper, we model private carsâ€™ travel in urban regions as the spatio-temporal graph and formulate private car transfer foreseeing as the time-evolving adjacency matrix prediction of the graph. To specify, we propose MG-GAN (Multiple Graph-based Generative Adversarial Network) to predict private car transfer. For one thing, we design multi-graph dense convolutions with gated recurrent networks as the generative network to capture multiple spatio-temporal correlations. For another, the attentive multi-graph convolutional network is designed as the discriminative network to learn the stay duration correlations of private cars in each region. The iterative adversarial processes between generating and discriminating networks enhance the MG-GANâ€™s ability to tackle the sparse data problem. Besides, a topic clustering algorithm based on multi-source data fusion is proposed to balance the fused data. Extensive experiments on the real-world private car and taxi trip datasets demonstrate that MG-GAN performs better than the state-of-the-art baselines.",
    "doi": "10.1007/s11280-021-00995-z",
    "author_keywords": [
      "Generative adversarial networks",
      "Mulitple graph",
      "Private car",
      "Spatio-temporal prediction",
      "Transfer flow"
    ],
    "contribution": "In this paper, we model private carsâ€™ travel in urban regions as the spatio-temporal graph and formulate private car transfer foreseeing as the time-evolving adjacency matrix prediction of the graph. To specify, we propose MG-GAN (Multiple Graph-based Generative Adversarial Network) to predict private car transfer. For one thing, we design multi-graph dense convolutions with gated recurrent networks as the generative network to capture multiple spatio-temporal correlations. For another, the attentive multi-graph convolutional network is designed as the discriminative network to learn the stay duration correlations of private cars in each region. The iterative adversarial processes between generating and discriminating networks enhance the MG-GANâ€™s ability to tackle the sparse data problem. Besides, a topic clustering algorithm based on multi-source data fusion is proposed to balance the fused data. Extensive experiments on the real-world private car and taxi trip datasets demonstrate that MG-GAN performs better than the state-of-the-art baselines.",
    "introduction": "Private car transfer indicates that people drive private cars and travel between urban regions to perform daily activities. Foreseeing private car transfer between urban regions can facilitate a broad scope of applications ranging from route planning, hot region discovery to urban computing. However, three challenges remain. i) Private car transfer between regions is affected by multiple spatio-temporal correlations. ii) Transfer records are highly sparse and imbalanced. iii) Modeling the stay duration of private cars.",
    "macro_domains": []
  },
  {
    "abstract": "3D building plays the essential role in digital city construction, city augmented reality and smart urban planning & design. Conventional building construction is accomplished by modeling software which requires significant human intervention. In this paper, a method of 3D building fabrication via Hybrid generative adversarial network (GAN) is proposed, in which a loss function with the introduction of cycle consistency loss and perceptual loss is given, a multi-properties GAN chain is built to create the building with complex architectures. Additionally, a mixed GAN network to generate the geometry and texture coordination is put forward. The discussed method can refine rough architectural models for outputting realistic buildings. Experiments show that generated 3D buildings utilizing the presented method are realistic, with geometry and textural consistency, which improves performance by 20% over traditional methods.",
    "doi": "10.1007/s12652-020-02488-9",
    "author_keywords": [
      "3D building generation",
      "GAN chain",
      "Hybrid GAN",
      "multi-properties generation"
    ],
    "contribution": "In this paper, a method of 3D building fabrication via Hybrid generative adversarial network (GAN) is proposed, in which a loss function with the introduction of cycle consistency loss and perceptual loss is given, a multi-properties GAN chain is built to create the building with complex architectures. Additionally, a mixed GAN network to generate the geometry and texture coordination is put forward. The discussed method can refine rough architectural models for outputting realistic buildings. Experiments show that generated 3D buildings utilizing the presented method are realistic, with geometry and textural consistency, which improves performance by 20% over traditional methods.",
    "introduction": "3D building plays the essential role in digital city construction, city augmented reality and smart urban planning & design. Conventional building construction is accomplished by modeling software which requires significant human intervention.",
    "macro_domains": []
  },
  {
    "abstract": "Transformers have been an efficient alternative to recurrent neural networks in many sequential learning tasks. When adapting transformers to modeling trajectories, we encounter two major issues. First, being originally designed for language modeling, transformers assume regular intervals between input tokens, which contradicts the irregularity of trajectories. Second, transformers often suffer high computational costs, especially for long trajectories. In this paper, we address these challenges by presenting a novel transformer architecture entitled TrajFormer. Our model first generates continuous point embeddings by jointly considering the input features and the information of spatio-temporal intervals, and then adopts a squeeze function to speed up the representation learning. Moreover, we introduce an auxiliary loss to ease the training of transformers using the supervision signals provided by all output tokens. Extensive experiments verify that our TrajFormer achieves a preferable speed-accuracy balance compared to existing approaches.",
    "doi": "10.1145/3511808.3557481",
    "author_keywords": [
      "trajectory classification",
      "transformer",
      "urban computing"
    ],
    "contribution": "In this paper, we address these challenges by presenting a novel transformer architecture entitled TrajFormer. Our model first generates continuous point embeddings by jointly considering the input features and the information of spatio-temporal intervals, and then adopts a squeeze function to speed up the representation learning. Moreover, we introduce an auxiliary loss to ease the training of transformers using the supervision signals provided by all output tokens. Extensive experiments verify that our TrajFormer achieves a preferable speed-accuracy balance compared to existing approaches.",
    "introduction": "Transformers have been an efficient alternative to recurrent neural networks in many sequential learning tasks. When adapting transformers to modeling trajectories, we encounter two major issues. First, being originally designed for language modeling, transformers assume regular intervals between input tokens, which contradicts the irregularity of trajectories. Second, transformers often suffer high computational costs, especially for long trajectories.",
    "macro_domains": []
  },
  {
    "abstract": "Homes are the building block of cities and societies and therefore smart homes are critical to establishing smart living and are expected to play a key role in enabling smart, sustainable cities and societies. The current literature on smart homes has mainly focused on developing smart functions for homes such as security and ambiance management. Homes are composed of families and are inherently complex phenomena underlined by humans and their relationships with each other, subject to individual, intragroup, intergroup, and intercommunity goals. There is a clear need to understand, define, consolidate existing research, and actualize the overarching roles of smart homes, and the roles of smart homes that will serve the needs of future smart cities and societies. This paper introduces our data-driven parameter discovery methodology and uses it to provide, for the first time, an extensive, fairly comprehensive, analysis of the families and homes landscape seen through the eyes of academics and the public, using over a hundred thousand research papers and nearly a million tweets. We developed a methodology using deep learning, natural language processing (NLP), and big data analytics methods (BERT and other machine learning methods) and applied it to automatically discover parameters that capture a comprehensive knowledge and design space of smart families and homes comprising social, political, economic, environmental, and other dimensions. The 66 discovered parameters and the knowledge space comprising 100 s of dimensions are explained by reviewing and referencing over 300 articles from the academic literature and tweets. The knowledge and parameters discovered in this paper can be used to develop a holistic understanding of matters related to families and homes facilitating the development of better, community-specific policies, technologies, solutions, and industries for families and homes, leading to strengthening families and homes, and in turn, empowering sustainable societies across the globe.",
    "doi": "10.3390/su142013534",
    "author_keywords": [
      "Bidirectional Encoder Representations from Transformers (BERT)",
      "natural language processing (NLP)",
      "smart cities",
      "smart families",
      "smart homes",
      "sustainable societies"
    ],
    "contribution": "This paper introduces our data-driven parameter discovery methodology and uses it to provide, for the first time, an extensive, fairly comprehensive, analysis of the families and homes landscape seen through the eyes of academics and the public, using over a hundred thousand research papers and nearly a million tweets. We developed a methodology using deep learning, natural language processing (NLP), and big data analytics methods (BERT and other machine learning methods) and applied it to automatically discover parameters that capture a comprehensive knowledge and design space of smart families and homes comprising social, political, economic, environmental, and other dimensions. The 66 discovered parameters and the knowledge space comprising 100 s of dimensions are explained by reviewing and referencing over 300 articles from the academic literature and tweets. The knowledge and parameters discovered in this paper can be used to develop a holistic understanding of matters related to families and homes facilitating the development of better, community-specific policies, technologies, solutions, and industries for families and homes, leading to strengthening families and homes, and in turn, empowering sustainable societies across the globe.",
    "introduction": "Homes are the building block of cities and societies and therefore smart homes are critical to establishing smart living and are expected to play a key role in enabling smart, sustainable cities and societies. The current literature on smart homes has mainly focused on developing smart functions for homes such as security and ambiance management. Homes are composed of families and are inherently complex phenomena underlined by humans and their relationships with each other, subject to individual, intragroup, intergroup, and intercommunity goals. There is a clear need to understand, define, consolidate existing research, and actualize the overarching roles of smart homes, and the roles of smart homes that will serve the needs of future smart cities and societies.",
    "macro_domains": []
  },
  {
    "abstract": "In generative adversarial networks (GANs), a generator network and discriminator network compete in deep learning tasks to generate real images. To reduce the difference between the generated image and actual image, an edge GAN (eGAN) model using edge detection was proposed. This eGAN model can utilize ambient intelligence, a human-centered technology that includes IoT, smart cities, and autonomous driving. Ambient intelligence is essential for the interconnection between humans and objects. The eGAN model was used to make this connectivity more accurate and reliable. Edge detection is an edge feature that extracts the boundaries of an image and generate images in a fast manner; however, because its threshold is arbitrarily set, the connectivity may be unstable. To solve this problem and improve the performance of the eGAN model, we analyzed various GAN models and edge detection methods and proposed a new edge detection technology using threshold settings. This edge detection method sets the threshold value for images, thereby increasing the accuracy of edge connection and reducing the loss error between the image generated by the eGAN model and actual image. To evaluate the performance of the eGAN model, the error between the generated image and actual image was compared by applying the GAN and eGAN models to the same image dataset. Consequently, it was found that the performance of the eGAN model improved by 21% in comparison to the existing GAN model.",
    "doi": "10.1007/s12652-021-03261-2",
    "author_keywords": [
      "Ambient intelligence",
      "Edge detection",
      "EGAN",
      "Generative adversarial networks",
      "Smart cities",
      "Threshold"
    ],
    "contribution": "",
    "introduction": "In generative adversarial networks (GANs), a generator network and discriminator network compete in deep learning tasks to generate real images. To reduce the difference between the generated image and actual image, an edge GAN (eGAN) model using edge detection was proposed. This eGAN model can utilize ambient intelligence, a human-centered technology that includes IoT, smart cities, and autonomous driving. Ambient intelligence is essential for the interconnection between humans and objects. The eGAN model was used to make this connectivity more accurate and reliable. Edge detection is an edge feature that extracts the boundaries of an image and generate images in a fast manner; however, because its threshold is arbitrarily set, the connectivity may be unstable. To solve this problem and improve the performance of the eGAN model, we analyzed various GAN models and edge detection methods and proposed a new edge detection technology using threshold settings. This edge detection method sets the threshold value for images, thereby increasing the accuracy of edge connection and reducing the loss error between the image generated by the eGAN model and actual image. To evaluate the performance of the eGAN model, the error between the generated image and actual image was compared by applying the GAN and eGAN models to the same image dataset. Consequently, it was found that the performance of the eGAN model improved by 21% in comparison to the existing GAN model.",
    "macro_domains": []
  },
  {
    "abstract": "Service time is a part of time cost in the last-mile delivery, which is the time spent on delivering parcels at a certain location. Predicting the service time is fundamental for many downstream logistics applications, e.g., route planning with time windows, courier workload balancing and delivery time prediction. Nevertheless, it is non-trivial given the complex delivery circumstances, location heterogeneity, and skewed observations in space. The existing solution trains a supervised model based on aggregated features extracted from parcels to deliver, which cannot handle above challenges well. In this paper, we propose MetaSTP, a meta-learning based neural network model to predict the service time. MetaSTP treats the service time prediction at each location as a learning task, leverages a Transformer-based representation layer to encode the complex delivery circumstances, and devises a model-based meta-learning method enhanced by location prior knowledge to reserve the uniqueness of each location and handle the imbalanced distribution issue. Experiments show MetaSTP outperforms baselines by at least 9.5% and 7.6% on two real-world datasets. Finally, an intelligent waybill assignment system based on MetaSTP is deployed and used internally in JD Logistics.",
    "doi": "10.1145/3534678.3539027",
    "author_keywords": [
      "delivery data mining",
      "meta-learning",
      "urban computing"
    ],
    "contribution": "In this paper, we propose MetaSTP, a meta-learning based neural network model to predict the service time. MetaSTP treats the service time prediction at each location as a learning task, leverages a Transformer-based representation layer to encode the complex delivery circumstances, and devises a model-based meta-learning method enhanced by location prior knowledge to reserve the uniqueness of each location and handle the imbalanced distribution issue. Experiments show MetaSTP outperforms baselines by at least 9.5% and 7.6% on two real-world datasets. Finally, an intelligent waybill assignment system based on MetaSTP is deployed and used internally in JD Logistics.",
    "introduction": "Service time is a part of time cost in the last-mile delivery, which is the time spent on delivering parcels at a certain location. Predicting the service time is fundamental for many downstream logistics applications, e.g., route planning with time windows, courier workload balancing and delivery time prediction. Nevertheless, it is non-trivial given the complex delivery circumstances, location heterogeneity, and skewed observations in space. The existing solution trains a supervised model based on aggregated features extracted from parcels to deliver, which cannot handle above challenges well.",
    "macro_domains": []
  },
  {
    "abstract": "Federated Learning (FL) is a promising distributed training model that aims to minimize the data sharing to enhance privacy and performance. FL requires sufficient and diverse training data to build efficient models. Lack of data balance as seen in rare classes affects the model accuracy. Generative Adversarial Networks (GAN) are remarkable in data augmentation to balance the available training data. In this article, we propose a novel Federated Deep Learning (DL) Intrusion Detection System (IDS) using GAN, named FEDGAN-IDS, to detect cyber threats in smart Internet of Things (IoT) systems; smarthomes, smart e-healthcare systems and smart cities. We distribute the GAN network over IoT devices to act as a classifier and train using augmented local data. We compare the convergence and accuracy of our model with other federated intrusion detection models. Extensive experiments with multiple datasets demonstrates the effectiveness of the proposed FEDGAN-IDS. The model performs better and converges earlier than the state-of-the-art standalone IDS.",
    "doi": "10.1016/j.comcom.2022.06.015",
    "author_keywords": [
      "Deep Learning (DL)",
      "Federated Learning (FL)",
      "Generative Adversarial Network (GAN)",
      "Internet of Things (IoT)",
      "Intrusion Detection System (IDS)"
    ],
    "contribution": "In this article, we propose a novel Federated Deep Learning (DL) Intrusion Detection System (IDS) using GAN, named FEDGAN-IDS, to detect cyber threats in smart Internet of Things (IoT) systems; smarthomes, smart e-healthcare systems and smart cities. We distribute the GAN network over IoT devices to act as a classifier and train using augmented local data. We compare the convergence and accuracy of our model with other federated intrusion detection models. Extensive experiments with multiple datasets demonstrates the effectiveness of the proposed FEDGAN-IDS. The model performs better and converges earlier than the state-of-the-art standalone IDS.",
    "introduction": "Federated Learning (FL) is a promising distributed training model that aims to minimize the data sharing to enhance privacy and performance. FL requires sufficient and diverse training data to build efficient models. Lack of data balance as seen in rare classes affects the model accuracy. Generative Adversarial Networks (GAN) are remarkable in data augmentation to balance the available training data.",
    "macro_domains": []
  },
  {
    "abstract": "Urban informal settlements (UIS) are high-density population areas with low urban infrastructure standards. UIS classification, which automates identifying UIS, is of great significance for various urban computing tasks. Fast and accurate extraction of UIS has the following difficulties. First, from a high-resolution perspective, the buildings in informal settlement areas are low-floor and dense, with complex spatial relationships. Second, informal settlementsâ€™ remote sensing observation characteristics are highly inconspicuous, caused by the shooting angle and imaging environment. Therefore, it is inadequate to classify UIS using only a single remote sensing image modality. Multimodality data with multiple temporal and spatial characteristics provide a prospective opportunity for the more accurate mapping of UIS. Still, there is a lack of relevant works on UIS classification at present. In this paper, we proposed a hybrid Transformer-based spatio-temporal fusion network, namely, STNet, which integrates a proposed PDNet, ResMixer, and Transformer-based spatio-temporal fusing layer to classify UIS using very-high-resolution (VHR) remote sensing images and time-series Tencent population density (TPD) data. Experiments were conducted in Shenzhen City, confirming the superior performance of the proposed STNet and the fusing of spatio-temporal multimodal remote sensing and time-series TPD data. The proposed STNet reached an overall accuracy (OA) of 88.58% and Kappa of 0.7716, with increases of around 1% to 12% and around 0.03 to 0.25 in OA and Kappa, respectively, compared to other models.",
    "doi": "10.1016/j.jag.2022.102831",
    "author_keywords": [
      "Deep learning",
      "Multimodality data",
      "Remote sensing",
      "Urban informal settlements"
    ],
    "contribution": "In this paper, we proposed a hybrid Transformer-based spatio-temporal fusion network, namely, STNet, which integrates a proposed PDNet, ResMixer, and Transformer-based spatio-temporal fusing layer to classify UIS using very-high-resolution (VHR) remote sensing images and time-series Tencent population density (TPD) data. Experiments were conducted in Shenzhen City, confirming the superior performance of the proposed STNet and the fusing of spatio-temporal multimodal remote sensing and time-series TPD data. The proposed STNet reached an overall accuracy (OA) of 88.58% and Kappa of 0.7716, with increases of around 1% to 12% and around 0.03 to 0.25 in OA and Kappa, respectively, compared to other models.",
    "introduction": "Urban informal settlements (UIS) are high-density population areas with low urban infrastructure standards. UIS classification, which automates identifying UIS, is of great significance for various urban computing tasks. Fast and accurate extraction of UIS has the following difficulties. First, from a high-resolution perspective, the buildings in informal settlement areas are low-floor and dense, with complex spatial relationships. Second, informal settlementsâ€™ remote sensing observation characteristics are highly inconspicuous, caused by the shooting angle and imaging environment. Therefore, it is inadequate to classify UIS using only a single remote sensing image modality. Multimodality data with multiple temporal and spatial characteristics provide a prospective opportunity for the more accurate mapping of UIS. Still, there is a lack of relevant works on UIS classification at present.",
    "macro_domains": []
  },
  {
    "abstract": "The generation of topographic classification maps or relative heights from aerial or remote sensing images represents a crucial research tool in remote sensing. On the one hand, from auto-driving, three-dimensional city modeling, road design, and resource statistics to smart cities, each task requires relative height data and classification data of objects. On the other hand, most relative height data acquisition methods currently use multiple images. We find that relative height and geographic classification data can be mutually assisted through data distribution. In recent years, with the rapid development of artificial intelligence technology, it has become possible to estimate the relative height from a single image. It learns implicit mapping relationships in a data-driven manner that may not be explicitly available through mathematical modeling. On this basis, we propose a unified, in-depth learning structure that can generate both estimated relative height maps and semantically segmented maps and perform end-to-end training. Compared with the existing methods, our task is to perform both relative height estimation and semantic segmentation tasks simultaneously. We only need one picture to obtain the corresponding semantically segmented images and relative heights simultaneously. The modelâ€™s performance is much better than that of equivalent computational models. We also designed dynamic weights to enable the model to learn relative height estimation and semantic segmentation simultaneously. At the same time, we have conducted good experiments on existing datasets. The experimental results show that the proposed Transformer-based network architecture is suitable for relative height estimation tasks and vastly outperforms other state-of-the-art DL (Deep Learning) methods.",
    "doi": "10.3390/rs14143450",
    "author_keywords": [
      "artificial intelligence",
      "deep learning",
      "end-to-end",
      "multi-task",
      "relative height estimation",
      "remote sensing",
      "semantic segmentation"
    ],
    "contribution": "On this basis, we propose a unified, in-depth learning structure that can generate both estimated relative height maps and semantically segmented maps and perform end-to-end training. Compared with the existing methods, our task is to perform both relative height estimation and semantic segmentation tasks simultaneously. We only need one picture to obtain the corresponding semantically segmented images and relative heights simultaneously. The modelâ€™s performance is much better than that of equivalent computational models. We also designed dynamic weights to enable the model to learn relative height estimation and semantic segmentation simultaneously. At the same time, we have conducted good experiments on existing datasets. The experimental results show that the proposed Transformer-based network architecture is suitable for relative height estimation tasks and vastly outperforms other state-of-the-art DL (Deep Learning) methods.",
    "introduction": "The generation of topographic classification maps or relative heights from aerial or remote sensing images represents a crucial research tool in remote sensing. On the one hand, from auto-driving, three-dimensional city modeling, road design, and resource statistics to smart cities, each task requires relative height data and classification data of objects. On the other hand, most relative height data acquisition methods currently use multiple images. We find that relative height and geographic classification data can be mutually assisted through data distribution. In recent years, with the rapid development of artificial intelligence technology, it has become possible to estimate the relative height from a single image. It learns implicit mapping relationships in a data-driven manner that may not be explicitly available through mathematical modeling.",
    "macro_domains": []
  },
  {
    "abstract": "Under bad weather, the ability of intelligent vehicles to perceive the environment accurately is an important research content in many practical applications such as smart cities and unmanned driving. In order to improve vehicle environment perception technology in real hazy scenes, we propose an effective detection algorithm based on Swin Transformer for hazy vehicle detection. This algorithm includes two aspects. First of all, for the aspect of the difficulty in extracting haze features with poor visibility, a dehazing network is designed to obtain high-quality haze-free output through encoding and decoding methods using Swin Transformer blocks. In addition, for the aspect of the difficulty of vehicle detection in hazy images, a new end-to-end vehicle detection model in hazy days is constructed by fusing the dehazing module and the Swin Transformer detection module. In the training stage, the self-made dataset Haze-Car is used, and the haze detection model parameters are initialized by using the dehazing model and Swin-T through transfer learning. Finally, the final haze detection model is obtained by fine tuning. Through the joint learning of dehazing and object detection and comparative experiments on the self-made real hazy image dataset, it can be seen that the detection performance of the model in real-world scenes is improved by 12.5%.",
    "doi": "10.3390/math10132199",
    "author_keywords": [
      "image dehazing",
      "multi-scale feature",
      "Swin Transformer",
      "vehicle detection"
    ],
    "contribution": "In order to improve vehicle environment perception technology in real hazy scenes, we propose an effective detection algorithm based on Swin Transformer for hazy vehicle detection. This algorithm includes two aspects. First of all, for the aspect of the difficulty in extracting haze features with poor visibility, a dehazing network is designed to obtain high-quality haze-free output through encoding and decoding methods using Swin Transformer blocks. In addition, for the aspect of the difficulty of vehicle detection in hazy images, a new end-to-end vehicle detection model in hazy days is constructed by fusing the dehazing module and the Swin Transformer detection module. In the training stage, the self-made dataset Haze-Car is used, and the haze detection model parameters are initialized by using the dehazing model and Swin-T through transfer learning. Finally, the final haze detection model is obtained by fine tuning. Through the joint learning of dehazing and object detection and comparative experiments on the self-made real hazy image dataset, it can be seen that the detection performance of the model in real-world scenes is improved by 12.5%.",
    "introduction": "Under bad weather, the ability of intelligent vehicles to perceive the environment accurately is an important research content in many practical applications such as smart cities and unmanned driving.",
    "macro_domains": []
  },
  {
    "abstract": "Sustainable monitoring of traffic using clean energy supply has always been a significant problem for engineers. In this study, we proposed a self-powered smart transportation infrastructure skin (SSTIS) as an innovative and bionic system for the traffic classification of a smart city. This system incorporated the self-powered flexible sensors with net-zero power consumption based on the Triboelectric Nanogenerator (TENG) and an intelligent analysis system based on artificial intelligence (AI). The feasibility of the SSTIS was tested using the full-scale accelerated pavement tests (APT) and the long-short term memory (LSTM) deep learning model with a vehicle axle load classification accuracy up to 89.06%. This robust SSTIS was later tested on highway and collected around 869,600 pieces of signals data. The generative adversarial networks (GAN) WGAN-GP (Wasserstein GAN - Gradient Penalty) was used for data augmentation, due to the imbalanced data of different vehicle types in actual traffic. The overall accuracy for on-road vehicle type classification improved to 81.06% using the convolutional neural network ResNet. Finally, we developed a mobile traffic signal information monitoring system based on cloud platform and Android framework, which enabled engineers to obtain the vehicle axle-load information mobilely. This study is the emerging design and engineering application of the self-powered flexible sensors for smart traffic monitoring, which provides a significant advance for intelligent transportation and smart cities in future.",
    "doi": "10.1016/j.nanoen.2022.107245",
    "author_keywords": [
      "Bionic",
      "Flexible sensor",
      "Smart cities",
      "Smart transportation infrastructure skin",
      "TENG"
    ],
    "contribution": "In this study, we proposed a self-powered smart transportation infrastructure skin (SSTIS) as an innovative and bionic system for the traffic classification of a smart city. This system incorporated the self-powered flexible sensors with net-zero power consumption based on the Triboelectric Nanogenerator (TENG) and an intelligent analysis system based on artificial intelligence (AI). The feasibility of the SSTIS was tested using the full-scale accelerated pavement tests (APT) and the long-short term memory (LSTM) deep learning model with a vehicle axle load classification accuracy up to 89.06%. This robust SSTIS was later tested on highway and collected around 869,600 pieces of signals data. The generative adversarial networks (GAN) WGAN-GP (Wasserstein GAN - Gradient Penalty) was used for data augmentation, due to the imbalanced data of different vehicle types in actual traffic. The overall accuracy for on-road vehicle type classification improved to 81.06% using the convolutional neural network ResNet. Finally, we developed a mobile traffic signal information monitoring system based on cloud platform and Android framework, which enabled engineers to obtain the vehicle axle-load information mobilely. This study is the emerging design and engineering application of the self-powered flexible sensors for smart traffic monitoring, which provides a significant advance for intelligent transportation and smart cities in future.",
    "introduction": "Sustainable monitoring of traffic using clean energy supply has always been a significant problem for engineers.",
    "macro_domains": []
  },
  {
    "abstract": "Pedestrian trajectory prediction plays a vital role in intelligent city construction and public crisis management. Distinct from the single trajectory prediction which rely on strong temporal correlation, in the complex scenes, the trajectory reflects not only the temporal characteristics of a single person, but the interactive features between human and other moving objects nearby. Therefore, how to deeply describe such temporality and interactivity, and then to generate accurate trajectory prediction results according to the change of the scene has become a major problem in the field of trajectory prediction today. In recent years, deep learning has attracted great attention and achieved success in the trajectory prediction tasks. However, most of these methods capture the influence between pedestrians from a single view, and they fail to consider the multiple factors which have an effect on the decision of pedestrians, such as going straight or turning. To this end, in this paper, we propose a multi-head attention generative adversarial model (MAGAM) which combines the multi-head attention mechanism and the generative adversarial network to model the pedestrian trajectory in the complex scenes. Specifically, the MAGAM model employs multi-head attention mechanism with relative displacement information to learn the attentive weight of subspace features in the whole trajectory feature space on different aspects, to realize the characterization of the interactive trajectory features that resulting from mutual influence between pedestrians. Moreover, the adversarial generation strategy and multi-trajectory generation strategy are used to achieve the reasonable generation of individual moving trajectory in the complex scenes. During the training process, the generator firstly extracts the personalized temporal features of pedestrians from historical observation sequences with long short-term memory (LSTM) based encoders. Secondly, the locations of pedestrians and temporal features are integrated into the multi-head attention model to learn the different weights and output the interactive state of the pedestrians. Thirdly, the interactive states and the Gaussian noise are fed into the LSTM-based decoders to generate multiple prediction trajectories. Then the discriminators are employed to judge whether the input trajectory belongs to the truth trajectory or generated trajectory as much as possible. By training with the adversarial mechanism, we could obtain the approximate truth results when modeling convergences. Finally, in order to estimate the performance of the proposed model, we conduct the experiments on two public datasets (ETH and UCY) which are widely used in the trajectory prediction tasks. We evaluate the prediction results based on three evaluation indicators: the average displacement error, the final displacement error, and the average no-linear displacement error. Compared with the existing trajectory prediction methods, the three metrics of the MAGAM model on all the datasets reduced by 26.90%, 21.02% and 24.06% on average. And the prediction results and the interactive scenes among pedestrians are visualized and analyzed which demonstrates the rationality of the results. Additionally, the performance of the MAGAM model including the average convergence accuracy, the average convergence time and the average prediction time is verified through related experiments, compared with the baselines, the MAGAM model gets the longest convergence time and prediction time.",
    "doi": "10.11897/SP.J.1016.2022.01133",
    "author_keywords": [
      "Adversarial generation",
      "Complex scenes",
      "Multi-head attention",
      "Positional encoding",
      "Trajectory prediction"
    ],
    "contribution": "To this end, in this paper, we propose a multi-head attention generative adversarial model (MAGAM) which combines the multi-head attention mechanism and the generative adversarial network to model the pedestrian trajectory in the complex scenes. Specifically, the MAGAM model employs multi-head attention mechanism with relative displacement information to learn the attentive weight of subspace features in the whole trajectory feature space on different aspects, to realize the characterization of the interactive trajectory features that resulting from mutual influence between pedestrians. Moreover, the adversarial generation strategy and multi-trajectory generation strategy are used to achieve the reasonable generation of individual moving trajectory in the complex scenes. During the training process, the generator firstly extracts the personalized temporal features of pedestrians from historical observation sequences with long short-term memory (LSTM) based encoders. Secondly, the locations of pedestrians and temporal features are integrated into the multi-head attention model to learn the different weights and output the interactive state of the pedestrians. Thirdly, the interactive states and the Gaussian noise are fed into the LSTM-based decoders to generate multiple prediction trajectories. Then the discriminators are employed to judge whether the input trajectory belongs to the truth trajectory or generated trajectory as much as possible. By training with the adversarial mechanism, we could obtain the approximate truth results when modeling convergences. Finally, in order to estimate the performance of the proposed model, we conduct the experiments on two public datasets (ETH and UCY) which are widely used in the trajectory prediction tasks. We evaluate the prediction results based on three evaluation indicators: the average displacement error, the final displacement error, and the average no-linear displacement error. Compared with the existing trajectory prediction methods, the three metrics of the MAGAM model on all the datasets reduced by 26.90%, 21.02% and 24.06% on average. And the prediction results and the interactive scenes among pedestrians are visualized and analyzed which demonstrates the rationality of the results. Additionally, the performance of the MAGAM model including the average convergence accuracy, the average convergence time and the average prediction time is verified through related experiments, compared with the baselines, the MAGAM model gets the longest convergence time and prediction time.",
    "introduction": "Pedestrian trajectory prediction plays a vital role in intelligent city construction and public crisis management. Distinct from the single trajectory prediction which rely on strong temporal correlation, in the complex scenes, the trajectory reflects not only the temporal characteristics of a single person, but the interactive features between human and other moving objects nearby. Therefore, how to deeply describe such temporality and interactivity, and then to generate accurate trajectory prediction results according to the change of the scene has become a major problem in the field of trajectory prediction today. In recent years, deep learning has attracted great attention and achieved success in the trajectory prediction tasks. However, most of these methods capture the influence between pedestrians from a single view, and they fail to consider the multiple factors which have an effect on the decision of pedestrians, such as going straight or turning.",
    "macro_domains": []
  },
  {
    "abstract": "The production rate of crops is significantly declining due to natural disasters, animal interventions and plant diseases. Internet of things (IoT) and wireless sensor networks are widely applied in crop field monitoring systems to observe the quality of each plant and the field. This work proposes IoT based crop field protection system (ICFPS) that monitors and protects the crop fields from animal intrusions. This proposed system uses ultrasonic sensors, hyperspectral cameras, voice recorded buzzers and other agriculture sensors to protect the entire crop field. This system uses numerous sensor nodes and cameras for gathering field objects (images and environmental objects). The proposed ICFPS creates deep learning techniques such as recurrent convolutional neural networks (RCNN) and recurrent generative adversarial neural networks (RGAN) for feature extraction, disease detection and field data monitoring practices. This proposed work develops a smart city-based agriculture system using cognitive learning approaches. This proposed system analyses crop field data and provide automatic alerts regarding animal interferences and crop diseases. Moreover, the cognitive smart crop field system observes various field conditions which support for good production rate. In this system, sensors and camera-enabled agriculture drones are coordinated with each other to collect the field data regularly. At the same time, the proposed work trains the RCNN and RGAN units using effective crop field datasets to attain realistic decisions within minimal time intervals. The experiment details and results show the proposed ICFPS works with 8%â€“10% of more classification accuracy than existing systems.",
    "doi": "10.1111/exsy.12876",
    "author_keywords": [
      "cognitive smart systems",
      "crop field",
      "deep learning and data analysis",
      "internet of things",
      "smart cities",
      "wireless sensor networks"
    ],
    "contribution": "This work proposes IoT based crop field protection system (ICFPS) that monitors and protects the crop fields from animal intrusions. This proposed system uses ultrasonic sensors, hyperspectral cameras, voice recorded buzzers and other agriculture sensors to protect the entire crop field. This system uses numerous sensor nodes and cameras for gathering field objects (images and environmental objects). The proposed ICFPS creates deep learning techniques such as recurrent convolutional neural networks (RCNN) and recurrent generative adversarial neural networks (RGAN) for feature extraction, disease detection and field data monitoring practices. This proposed work develops a smart city-based agriculture system using cognitive learning approaches. This proposed system analyses crop field data and provide automatic alerts regarding animal interferences and crop diseases. Moreover, the cognitive smart crop field system observes various field conditions which support for good production rate. In this system, sensors and camera-enabled agriculture drones are coordinated with each other to collect the field data regularly. At the same time, the proposed work trains the RCNN and RGAN units using effective crop field datasets to attain realistic decisions within minimal time intervals. The experiment details and results show the proposed ICFPS works with 8%â€“10% of more classification accuracy than existing systems.",
    "introduction": "The production rate of crops is significantly declining due to natural disasters, animal interventions and plant diseases. Internet of things (IoT) and wireless sensor networks are widely applied in crop field monitoring systems to observe the quality of each plant and the field.",
    "macro_domains": []
  },
  {
    "abstract": "A smart city is an idea that is realized by the computing of a large amount of data collected through sensors, cameras, and other electronic methods to provide services, manage resources and solve daily life problems. The transformation of the conventional grid to a smart grid is one step in the direction towards smart city realization. An electric grid is composed of control stations, generation centres, transformers, communication lines, and distributors, which helps in transferring power from the power station to domestic and commercial consumers. Present electric grids are not smart enough that they can estimate the varying power requirement of the consumer. Also, these conventional grids are not enough robust and scalable. This has become the motivation for shifting from a conventional grid to a smart grid. The smart grid is a kind of power grid, which is robust and adapts itself to the varying needs of the consumer and self-healing in nature. In this way, the transformation from a conventional grid to a smart grid will help the government to make a smart city. The emergence of machine learning has helped in the prediction of the stability of the grid under the dynamically changing requirement of the consumer. Also, the usage of a variety of sensors will help in the collection of real-time consumption data. Through machine learning algorithms, we can gain an insight view of the collected data. This has helped the smart grid to convert into a robust smart grid, as this will help in avoiding the situation of failure. In this work, the authors have applied logistic regression, decision tree, support vector machine, linear discriminant analysis, quadratic discriminant analysis, naÃ¯ve Bayes, random forest, and k-nearest neighbour algorithms to predict the stability of the grid. The authors have used the smart grid stability dataset freely available on Kaggle to train and test the models. It has been found that a model designed using the support vector machine algorithm has given the most accurate result.",
    "doi": "10.1111/exsy.12832",
    "author_keywords": [
      "classifier algorithm",
      "machine learning",
      "prediction model",
      "smart city",
      "smart grid"
    ],
    "contribution": "In this work, the authors have applied logistic regression, decision tree, support vector machine, linear discriminant analysis, quadratic discriminant analysis, naÃ¯ve Bayes, random forest, and k-nearest neighbour algorithms to predict the stability of the grid. The authors have used the smart grid stability dataset freely available on Kaggle to train and test the models. It has been found that a model designed using the support vector machine algorithm has given the most accurate result.",
    "introduction": "A smart city is an idea that is realized by the computing of a large amount of data collected through sensors, cameras, and other electronic methods to provide services, manage resources and solve daily life problems. The transformation of the conventional grid to a smart grid is one step in the direction towards smart city realization. An electric grid is composed of control stations, generation centres, transformers, communication lines, and distributors, which helps in transferring power from the power station to domestic and commercial consumers. Present electric grids are not smart enough that they can estimate the varying power requirement of the consumer. Also, these conventional grids are not enough robust and scalable. This has become the motivation for shifting from a conventional grid to a smart grid. The smart grid is a kind of power grid, which is robust and adapts itself to the varying needs of the consumer and self-healing in nature. In this way, the transformation from a conventional grid to a smart grid will help the government to make a smart city. The emergence of machine learning has helped in the prediction of the stability of the grid under the dynamically changing requirement of the consumer. Also, the usage of a variety of sensors will help in the collection of real-time consumption data. Through machine learning algorithms, we can gain an insight view of the collected data. This has helped the smart grid to convert into a robust smart grid, as this will help in avoiding the situation of failure.",
    "macro_domains": []
  },
  {
    "abstract": "Person re-identification is an important part of multi-target tracking across cameras; its aim is to identify the same person across different cameras. Given a query image, the purpose of person re-identification is to find the best match for the query image in an image set. Person re-identification is a key component in an intelligent security system; it is beneficial for building a smart bank or smart factory and plays a crucial role in the construction of a smart city. Nowadays, with the development of artificial intelligence and increasing demand for precise identification in practical scenarios, deep learning-based person re-identification technology has become a popular research topic; this technology has achieved state-of-the-art results in comparison with conventional approaches. Although there are many recently proposed networks with stronger representation ability and a high level of accuracy for person re-identification, there also exist some problems that should be considered and solved. These include the insufficient generalization ability of various poses, the inability to fully utilize the temporal information, and the ineffective identification of occluded objects. As a result, many scholars have researched this field and have pointed out some promising solutions to cope with the aforementioned problems. This paper aims to summarize the application of deep learning in the field of person re-identification along with its advantages and shortcomings. First, the background of person re-identification is introduced, including the application scenarios, datasets, and evaluation indicators. Additionally, some basic methods of person re-identification based on deep learning are summarized. According to the existing research on person re-identification, the main approaches proposed by scholars worldwide can be summarized into four aspects, which are based on local features, generative adversarial networks, video data, and re-ranking. A detailed comparative study of these four methods is then conducted. Finally, the existing problems and future studies that can be done in the field of person re-identification are analyzed and discussed.",
    "doi": "10.13374/j.issn2095-9389.2020.12.22.004",
    "author_keywords": [
      "Deep learning",
      "Generating adversarial networks",
      "Local feature",
      "Person re-identification",
      "Reranking",
      "Video data"
    ],
    "contribution": "This paper aims to summarize the application of deep learning in the field of person re-identification along with its advantages and shortcomings. First, the background of person re-identification is introduced, including the application scenarios, datasets, and evaluation indicators. Additionally, some basic methods of person re-identification based on deep learning are summarized. According to the existing research on person re-identification, the main approaches proposed by scholars worldwide can be summarized into four aspects, which are based on local features, generative adversarial networks, video data, and re-ranking. A detailed comparative study of these four methods is then conducted. Finally, the existing problems and future studies that can be done in the field of person re-identification are analyzed and discussed.",
    "introduction": "Person re-identification is an important part of multi-target tracking across cameras; its aim is to identify the same person across different cameras. Given a query image, the purpose of person re-identification is to find the best match for the query image in an image set. Person re-identification is a key component in an intelligent security system; it is beneficial for building a smart bank or smart factory and plays a crucial role in the construction of a smart city. Nowadays, with the development of artificial intelligence and increasing demand for precise identification in practical scenarios, deep learning-based person re-identification technology has become a popular research topic; this technology has achieved state-of-the-art results in comparison with conventional approaches. Although there are many recently proposed networks with stronger representation ability and a high level of accuracy for person re-identification, there also exist some problems that should be considered and solved. These include the insufficient generalization ability of various poses, the inability to fully utilize the temporal information, and the ineffective identification of occluded objects. As a result, many scholars have researched this field and have pointed out some promising solutions to cope with the aforementioned problems.",
    "macro_domains": []
  },
  {
    "abstract": "Communication has been an important aspect of human life, civilization, and globalization for thousands of years. Biometric analysis, education, security, healthcare, and smart cities are only a few examples of speech recognition applications. Most studies have mainly concentrated on English, Spanish, Japanese, or Chinese, disregarding other low-resource languages, such as Uzbek, leaving their analysis open. In this paper, we propose an End-To-End Deep Neural Network-Hidden Markov Model speech recognition model and a hybrid Connectionist Temporal Classification (CTC)-attention network for the Uzbek language and its dialects. The proposed approach reduces training time and improves speech recognition accuracy by effectively using CTC objective function in attention model training. We evaluated the linguistic and lay-native speaker performances on the Uzbek language dataset, which was collected as a part of this study. Experimental results show that the proposed model achieved a word error rate of 14.3% using 207 h of recordings as an Uzbek language training dataset.",
    "doi": "10.3390/s22103683",
    "author_keywords": [
      "convolutional neural network",
      "CTC-attention",
      "deep learning",
      "end-to-end speech recognition",
      "hidden Markov model",
      "transformers",
      "Uzbek language"
    ],
    "contribution": "In this paper, we propose an End-To-End Deep Neural Network-Hidden Markov Model speech recognition model and a hybrid Connectionist Temporal Classification (CTC)-attention network for the Uzbek language and its dialects. The proposed approach reduces training time and improves speech recognition accuracy by effectively using CTC objective function in attention model training. We evaluated the linguistic and lay-native speaker performances on the Uzbek language dataset, which was collected as a part of this study. Experimental results show that the proposed model achieved a word error rate of 14.3% using 207 h of recordings as an Uzbek language training dataset.",
    "introduction": "Communication has been an important aspect of human life, civilization, and globalization for thousands of years. Biometric analysis, education, security, healthcare, and smart cities are only a few examples of speech recognition applications. Most studies have mainly concentrated on English, Spanish, Japanese, or Chinese, disregarding other low-resource languages, such as Uzbek, leaving their analysis open.",
    "macro_domains": []
  },
  {
    "abstract": "Cases of missing children not being found are rare, but they continue to occur. If the child is not found immediately, the parents may not be able to identify the childâ€™s appearance because they have not seen their child for a long time. Therefore, our purpose is to predict childrenâ€™s faces when they grow up and help parents search for missing children. DNA paternity testing is the most accurate way to detect whether two people have a blood relation. However, DNA paternity testing for every unidentified child would be costly. Therefore, we propose the development of the Face Prediction System for Missing Children in a Smart City Safety Network. It can predict the faces of missing children at their current age, and parents can quickly confirm the possibility of blood relations with any unidentified child. The advantage is that it can eliminate incorrect matches and narrow down the search at a low cost. Our system combines StyleGAN2 and FaceNet methods to achieve prediction. StyleGAN2 is used to style mix two face images. FaceNet is used to compare the similarity of two face images. Experiments show that the similarity between predicted and expected results is more than 75%. This means that the system can well predict childrenâ€™s faces when they grow up. Our system has more natural and higher similarity comparison results than Conditional Adversarial Autoencoder (CAAE), High Resolution Face Age Editing (HRFAE) and Identity-Preserved Conditional Generative Adversarial Networks (IPCGAN).",
    "doi": "10.3390/electronics11091440",
    "author_keywords": [
      "face aging",
      "FaceNet",
      "generative adversarial network",
      "missing child",
      "StyleGAN2"
    ],
    "contribution": "Therefore, we propose the development of the Face Prediction System for Missing Children in a Smart City Safety Network. It can predict the faces of missing children at their current age, and parents can quickly confirm the possibility of blood relations with any unidentified child. The advantage is that it can eliminate incorrect matches and narrow down the search at a low cost. Our system combines StyleGAN2 and FaceNet methods to achieve prediction. StyleGAN2 is used to style mix two face images. FaceNet is used to compare the similarity of two face images. Experiments show that the similarity between predicted and expected results is more than 75%. This means that the system can well predict childrenâ€™s faces when they grow up. Our system has more natural and higher similarity comparison results than Conditional Adversarial Autoencoder (CAAE), High Resolution Face Age Editing (HRFAE) and Identity-Preserved Conditional Generative Adversarial Networks (IPCGAN).",
    "introduction": "Cases of missing children not being found are rare, but they continue to occur. If the child is not found immediately, the parents may not be able to identify the childâ€™s appearance because they have not seen their child for a long time. Therefore, our purpose is to predict childrenâ€™s faces when they grow up and help parents search for missing children. DNA paternity testing is the most accurate way to detect whether two people have a blood relation. However, DNA paternity testing for every unidentified child would be costly.",
    "macro_domains": []
  },
  {
    "abstract": "In the last decade, substantial progress has been achieved in intelligent traffic control technologies to overcome consistent difficulties of traffic congestion and its adverse effect on smart cities. Edge computing is one such advanced progress facilitating real-time data transmission among vehicles and roadside units to mitigate congestion. An edge computing-based deep reinforcement learning system is demonstrated in this study that appropriately designs a multiobjective reward function for optimizing different objectives. The system seeks to overcome the challenge of evaluating actions with a simple numerical reward. The selection of reward functions has a significant impact on agents' ability to acquire the ideal behavior for managing multiple traffic signals in a large-scale road network. To ascertain effective reward functions, the agent is trained withusing the proximal policy optimization method in several deep neural network models, including the state-of-the-art transformer network. The system is verified using both hypothetical scenarios and real-world traffic maps. The comprehensive simulation outcomes demonstrate the potency of the suggested reward functions.",
    "doi": "10.4218/etrij.2021-0404",
    "author_keywords": [
      "DRL",
      "edge computing",
      "ITS",
      "PPO",
      "traffic signal"
    ],
    "contribution": "An edge computing-based deep reinforcement learning system is demonstrated in this study that appropriately designs a multiobjective reward function for optimizing different objectives. The system seeks to overcome the challenge of evaluating actions with a simple numerical reward. The selection of reward functions has a significant impact on agents' ability to acquire the ideal behavior for managing multiple traffic signals in a large-scale road network. To ascertain effective reward functions, the agent is trained withusing the proximal policy optimization method in several deep neural network models, including the state-of-the-art transformer network. The system is verified using both hypothetical scenarios and real-world traffic maps. The comprehensive simulation outcomes demonstrate the potency of the suggested reward functions.",
    "introduction": "In the last decade, substantial progress has been achieved in intelligent traffic control technologies to overcome consistent difficulties of traffic congestion and its adverse effect on smart cities. Edge computing is one such advanced progress facilitating real-time data transmission among vehicles and roadside units to mitigate congestion.",
    "macro_domains": []
  },
  {
    "abstract": "With the growth of urban population, a series of urban problems have emerged, and how to speed up smart city construction has received extensive attention. Remote sensing images have the advantages of wide spatial coverage and rich information, and it is suitable for use as research data for smart cities. However, due to limitations in the imaging sensor conditions and complex weather, remote sensing images face the problems of insufficient resolution and cloud occlusion, which cannot meet the resolution requirements of smart city tasks. The remote sensing image super-resolution (SR) technique can improve the details and texture information without upgrading the imaging sensor system, which becomes a feasible solution for the above problems. In this paper, we propose a novel remote sensing image super-resolution method which leverages the texture features from internal and external references to help with SR reconstruction. We introduce the transformer attention mechanism to select and extract parts of texture features with high reference values to ensure that the network is lightweight, effective, and easier to deploy on edge computing devices. In addition, our network can automatically learn and adjust the alignment angles and scales of texture features for better SR results. Extensive comparison experiments show that our proposed method achieves superior performance compared with several state-of-the-art SR methods. In addition, we also evaluate the application value of our proposed SR method in urban region function recognition in smart cities. The dataset used in this task is low-quality. The comparative experiment between the original dataset and the SR dataset generated by our proposed SR method indicates that our method can effectively improve the recognition accuracy.",
    "doi": "10.3390/electronics11071050",
    "author_keywords": [
      "remote sensing image",
      "smart cities",
      "super-resolution technique",
      "urban region function recognition"
    ],
    "contribution": "In this paper, we propose a novel remote sensing image super-resolution method which leverages the texture features from internal and external references to help with SR reconstruction. We introduce the transformer attention mechanism to select and extract parts of texture features with high reference values to ensure that the network is lightweight, effective, and easier to deploy on edge computing devices. In addition, our network can automatically learn and adjust the alignment angles and scales of texture features for better SR results. Extensive comparison experiments show that our proposed method achieves superior performance compared with several state-of-the-art SR methods. In addition, we also evaluate the application value of our proposed SR method in urban region function recognition in smart cities. The dataset used in this task is low-quality. The comparative experiment between the original dataset and the SR dataset generated by our proposed SR method indicates that our method can effectively improve the recognition accuracy.",
    "introduction": "With the growth of urban population, a series of urban problems have emerged, and how to speed up smart city construction has received extensive attention. Remote sensing images have the advantages of wide spatial coverage and rich information, and it is suitable for use as research data for smart cities. However, due to limitations in the imaging sensor conditions and complex weather, remote sensing images face the problems of insufficient resolution and cloud occlusion, which cannot meet the resolution requirements of smart city tasks. The remote sensing image super-resolution (SR) technique can improve the details and texture information without upgrading the imaging sensor system, which becomes a feasible solution for the above problems.",
    "macro_domains": []
  },
  {
    "abstract": "Vehicle re-identification (ReID) focuses on searching for images of the same vehicle across different cameras and can be considered as the most fine-grained ID-level classification task. It is fundamentally challenging due to the significant differences in appearance presented by a vehicle with the same ID (especially from different viewpoints) coupled with the subtle differences between vehicles with different IDs. Spatial attention mechanisms that have been proven to be effective in computer vision tasks also play an important role in vehicle ReID. However, they often require expensive key-point labels or suffer from noisy attention masks when trained without key-point labels. In this work, we propose a transformer-based attention network (TAN) for learning spatial attention information and hence for facilitating learning of discriminative features for vehicle ReID. Specifically, in contrast to previous studies that adopted a transformer network, we designed the attention network as an independent branch that can be flexibly utilized in various tasks. Moreover, we combined the TAN with two other branches: one to extract global features that define the image-level structures, and the other to extract the auxiliary side-attribute features that are invariant to viewpoint, such as color, car type, etc. To validate the proposed approach, experiments were conducted on two vehicle datasets (the VeRi-776 and VehicleID datasets) and a person dataset (Market-1501). The experimental results demonstrated that the proposed TAN is effective in improving the performance of both the vehicle and person ReID tasks, and the proposed method achieves state-of-the-art (SOTA) perfomance.",
    "doi": "10.3390/electronics11071016",
    "author_keywords": [
      "Smart cities",
      "Smart transportation",
      "Transformer",
      "Vehicle re-identification",
      "Vehicle search"
    ],
    "contribution": "In this work, we propose a transformer-based attention network (TAN) for learning spatial attention information and hence for facilitating learning of discriminative features for vehicle ReID. Specifically, in contrast to previous studies that adopted a transformer network, we designed the attention network as an independent branch that can be flexibly utilized in various tasks. Moreover, we combined the TAN with two other branches: one to extract global features that define the image-level structures, and the other to extract the auxiliary side-attribute features that are invariant to viewpoint, such as color, car type, etc. To validate the proposed approach, experiments were conducted on two vehicle datasets (the VeRi-776 and VehicleID datasets) and a person dataset (Market-1501). The experimental results demonstrated that the proposed TAN is effective in improving the performance of both the vehicle and person ReID tasks, and the proposed method achieves state-of-the-art (SOTA) perfomance.",
    "introduction": "Vehicle re-identification (ReID) focuses on searching for images of the same vehicle across different cameras and can be considered as the most fine-grained ID-level classification task. It is fundamentally challenging due to the significant differences in appearance presented by a vehicle with the same ID (especially from different viewpoints) coupled with the subtle differences between vehicles with different IDs. Spatial attention mechanisms that have been proven to be effective in computer vision tasks also play an important role in vehicle ReID. However, they often require expensive key-point labels or suffer from noisy attention masks when trained without key-point labels.",
    "macro_domains": []
  },
  {
    "abstract": "Occupant activities in buildings are connected by different transportation measures. For smart communities, it is possible to synergize the energy management of smart buildings with the vehicle operation/travel information available from transportation infrastructure, e.g. the intelligent transportation systems (ITS). Such information enables the prediction of upcoming building occupancy and upcoming charging load of electric vehicles (EVs). This paper presents a predictive energy management strategy for smart community, which features water-based district cooling for a cluster of buildings driven by a multi-chiller central plant, and each building hosts a number of EV charging stations. A scenario-based stochastic model predictive control (SCMPC) framework, in which the upcoming building occupancy and charging load, ambient temperature, humidity and solar irradiance are assumed to be stochastically predictable. The SCMPC targets demand response operation at community level, involving both time-of-use and demand charges, and the combined power consumption by the central plant and EV charging observing to the transformer limit as a coupled constraint. To evaluate the propagation of the above uncertain factors through the receding-horizon SCMPC process, moving-horizon probabilistic models are established for EV arrival information. By developing a functional mockup interface (FMI) based co-simulation platform developed with Modelica and Python, the proposed method is validated via simulation study, and the performance indices are evaluated.",
    "doi": "10.1016/j.enbuild.2022.111916",
    "author_keywords": [
      "Demand Response",
      "District Cooling",
      "Electric Vehicles",
      "Energy Management",
      "Functional Mockup Interface",
      "Modelica",
      "Scenario based Model Predictive Control",
      "Smart Community"
    ],
    "contribution": "This paper presents a predictive energy management strategy for smart community, which features water-based district cooling for a cluster of buildings driven by a multi-chiller central plant, and each building hosts a number of EV charging stations. A scenario-based stochastic model predictive control (SCMPC) framework, in which the upcoming building occupancy and charging load, ambient temperature, humidity and solar irradiance are assumed to be stochastically predictable. The SCMPC targets demand response operation at community level, involving both time-of-use and demand charges, and the combined power consumption by the central plant and EV charging observing to the transformer limit as a coupled constraint. To evaluate the propagation of the above uncertain factors through the receding-horizon SCMPC process, moving-horizon probabilistic models are established for EV arrival information. By developing a functional mockup interface (FMI) based co-simulation platform developed with Modelica and Python, the proposed method is validated via simulation study, and the performance indices are evaluated.",
    "introduction": "Occupant activities in buildings are connected by different transportation measures. For smart communities, it is possible to synergize the energy management of smart buildings with the vehicle operation/travel information available from transportation infrastructure, e.g. the intelligent transportation systems (ITS). Such information enables the prediction of upcoming building occupancy and upcoming charging load of electric vehicles (EVs).",
    "macro_domains": []
  },
  {
    "abstract": "Key Smart City applications such as traffic management and public security rely heavily on the intelligent processing of video and image data, often in the form of visual retrieval tasks, such as person Re-IDentification (ReID) and vehicle re-identification. For these tasks, Deep Neural Networks (DNNs) have been the dominant solution for the past decade, for their remarkable ability in learning discriminative features from images to boost retrieval performance. However, it is been discovered that DNNs are broadly vulnerable to maliciously constructed adversarial examples. By adding small perturbations to a query image, the returned retrieval results will be completely dissimilar from the query image. This poses serious challenges to vital systems in Smart City applications that depend on the DNN-based visual retrieval technology, as in the physical world, simple camouflage can be added on the subject (a few patches on the body or car), and turn the subject completely untrackable by person or vehicle Re-ID systems. To demonstrate the potential of such threats, this paper proposes a novel adversarial patch generative adversarial network (AP-GAN) to generate adversarial patches instead of modifying the entire image, which also causes the DNNs-based image retrieval models to return incorrect results. AP-GAN is trained in an unsupervised way that requires only a small amount of unlabeled data for training. Once trained, it produces query-specific perturbations for query images to form adversarial queries. Extensive experiments show that the AP-GAN achieves excellent attacking performance with various application scenarios that are based on deep features, including image retrieval, person ReID and vehicle ReID. The results of this study provide a warning that when deploying a DNNs-based image retrieval system, its security and robustness needs to be thoroughly considered.",
    "doi": "10.1007/s10707-020-00418-7",
    "author_keywords": [
      "Adversarial attack",
      "Adversarial patch",
      "GAN",
      "Image retrieval"
    ],
    "contribution": "To demonstrate the potential of such threats, this paper proposes a novel adversarial patch generative adversarial network (AP-GAN) to generate adversarial patches instead of modifying the entire image, which also causes the DNNs-based image retrieval models to return incorrect results. AP-GAN is trained in an unsupervised way that requires only a small amount of unlabeled data for training. Once trained, it produces query-specific perturbations for query images to form adversarial queries. Extensive experiments show that the AP-GAN achieves excellent attacking performance with various application scenarios that are based on deep features, including image retrieval, person ReID and vehicle ReID. The results of this study provide a warning that when deploying a DNNs-based image retrieval system, its security and robustness needs to be thoroughly considered.",
    "introduction": "Key Smart City applications such as traffic management and public security rely heavily on the intelligent processing of video and image data, often in the form of visual retrieval tasks, such as person Re-IDentification (ReID) and vehicle re-identification. For these tasks, Deep Neural Networks (DNNs) have been the dominant solution for the past decade, for their remarkable ability in learning discriminative features from images to boost retrieval performance. However, it is been discovered that DNNs are broadly vulnerable to maliciously constructed adversarial examples. By adding small perturbations to a query image, the returned retrieval results will be completely dissimilar from the query image. This poses serious challenges to vital systems in Smart City applications that depend on the DNN-based visual retrieval technology, as in the physical world, simple camouflage can be added on the subject (a few patches on the body or car), and turn the subject completely untrackable by person or vehicle Re-ID systems.",
    "macro_domains": []
  },
  {
    "abstract": "Remote sensing image scene classification is an important and challenging problem of remote sensing image interpretation. With the generation of a large number of scene-rich high-resolution remote sensing images, scene classification of remote sensing images is widely used in many fields such as smart city construction, natural disaster monitoring and land resource utilization. Due to the advancement of deep learning techniques and the establishment of large-scale scene classification datasets, scene classification methods have been significantly improved. Although the classification methods based on deep learning have achieved high classification accuracy, the supervised methods require a large number of training samples, while the unsupervised classification methods are difficult to meet the practical needs and have low classification accuracy. Meanwhile, the annotation of remote sensing images requires rich engineering skills and expert knowledge, and in remote sensing applications, only a small amount of labeled remote sensing images exist for supervised training in most cases, and a large amount of unlabeled images cannot be fully utilized. Therefore, a semi-supervised learning method that extracts effective features from a large amount of unlabeled data by learning a small amount of labeled data becomes a potential way to solve such problems. To address the problems of complex background of remote sensing images and the inability of supervised scene classification algorithms to utilize unlabeled data, a semi-supervised remote sensing image scene classification method based on generative adversarial networks, namely, residual attention generative adversarial networks, is proposed. First, to enhance the stability of training, the residual blocks with jump structure are introduced in the deep neural network. At the same time, the spectral normalization constrains the spectral norm of the weight matrix in each convolutional layer of the residual block to ensure that the input and output of each batch of data satisfy the 1-Lipschitz continuity, which makes the generative adversarial training always smooth, not only improves the training stability, but also avoids network degradation. Secondly, since the shallow features extracted by the bottom convolution contain mostly local information and low semantics, while the deep features extracted by the top convolution contain more global information but lose part of the detail information. Therefore, the shallow features are fused with the deep features extracted from the multi-layer spectral normalized residual blocks to reduce the loss of features and allow the model to learn the complementary relationships between different features, thus improving the model's representational ability. Finally, to guide the model to focus more purposefully on important features and suppress unnecessary features, an attention module that mimics the signal processing of the human brain is used. Meanwhile, in order to obtain stronger feature representation ability and capture the dependency relationship between features, a gating mechanism is introduced to form an attention module combined with gating. To verify the superiority of the method, experiments were conducted on two high-resolution remote sensing image datasets, EuroSAT and UC Merced. In the EuroSAT dataset, the highest classification accuracy reached 93.3% and 97.4% when the number of labeled features was 2 000 and 21 600, respectively. In the UC Merced dataset, the classification accuracies reached 85.7% and 91.0% when the number of labeled was 400 and 1 680, respectively. To further validate the degree of contribution of each module, ablation experiments were also conducted in the EuroSAT and UCM public datasets, and it can be concluded from the validation that the spectral normalization residual module has the largest contribution, with improvement for different number of labeled samples. The reason is that the spectral normalization ensures that the gradient of the network is limited to a certain range during backpropagation, improving the stability of the generative adversarial network, and also does not destroy the network structure in the process. The next is the attention module combined with gating, especially when the labeled sample size is greater than 10%, the classification effect is improved more because the sample size is sufficient to learn more comprehensive features. The smallest contribution is the feature fusion module, because when the sample size is very small, the network is not sufficiently trained and learned, and a part of redundant or invalid features are extracted, resulting in lower classification accuracy. The above experimental results show that the proposed residual attention generation adversarial network classification method can effectively extract more discriminative features and improve the semi-supervised classification performance for the problem of small sample size of labeled high-resolution remote sensing images, which makes it difficult to extract discriminative features.",
    "doi": "10.3788/gzxb20225103.0310003",
    "author_keywords": [
      "Attention mechanism",
      "Generative Adversarial network",
      "Remote sensing image",
      "Scene classification",
      "Semi-supervised"
    ],
    "contribution": "",
    "introduction": "Remote sensing image scene classification is an important and challenging problem of remote sensing image interpretation. With the generation of a large number of scene-rich high-resolution remote sensing images, scene classification of remote sensing images is widely used in many fields such as smart city construction, natural disaster monitoring and land resource utilization. Due to the advancement of deep learning techniques and the establishment of large-scale scene classification datasets, scene classification methods have been significantly improved. Although the classification methods based on deep learning have achieved high classification accuracy, the supervised methods require a large number of training samples, while the unsupervised classification methods are difficult to meet the practical needs and have low classification accuracy. Meanwhile, the annotation of remote sensing images requires rich engineering skills and expert knowledge, and in remote sensing applications, only a small amount of labeled remote sensing images exist for supervised training in most cases, and a large amount of unlabeled images cannot be fully utilized. Therefore, a semi-supervised learning method that extracts effective features from a large amount of unlabeled data by learning a small amount of labeled data becomes a potential way to solve such problems. To address the problems of complex background of remote sensing images and the inability of supervised scene classification algorithms to utilize unlabeled data, a semi-supervised remote sensing image scene classification method based on generative adversarial networks, namely, residual attention generative adversarial networks, is proposed. First, to enhance the stability of training, the residual blocks with jump structure are introduced in the deep neural network. At the same time, the spectral normalization constrains the spectral norm of the weight matrix in each convolutional layer of the residual block to ensure that the input and output of each batch of data satisfy the 1-Lipschitz continuity, which makes the generative adversarial training always smooth, not only improves the training stability, but also avoids network degradation. Secondly, since the shallow features extracted by the bottom convolution contain mostly local information and low semantics, while the deep features extracted by the top convolution contain more global information but lose part of the detail information. Therefore, the shallow features are fused with the deep features extracted from the multi-layer spectral normalized residual blocks to reduce the loss of features and allow the model to learn the complementary relationships between different features, thus improving the model's representational ability. Finally, to guide the model to focus more purposefully on important features and suppress unnecessary features, an attention module that mimics the signal processing of the human brain is used. Meanwhile, in order to obtain stronger feature representation ability and capture the dependency relationship between features, a gating mechanism is introduced to form an attention module combined with gating. To verify the superiority of the method, experiments were conducted on two high-resolution remote sensing image datasets, EuroSAT and UC Merced. In the EuroSAT dataset, the highest classification accuracy reached 93.3% and 97.4% when the number of labeled features was 2 000 and 21 600, respectively. In the UC Merced dataset, the classification accuracies reached 85.7% and 91.0% when the number of labeled was 400 and 1 680, respectively. To further validate the degree of contribution of each module, ablation experiments were also conducted in the EuroSAT and UCM public datasets, and it can be concluded from the validation that the spectral normalization residual module has the largest contribution, with improvement for different number of labeled samples. The reason is that the spectral normalization ensures that the gradient of the network is limited to a certain range during backpropagation, improving the stability of the generative adversarial network, and also does not destroy the network structure in the process. The next is the attention module combined with gating, especially when the labeled sample size is greater than 10%, the classification effect is improved more because the sample size is sufficient to learn more comprehensive features. The smallest contribution is the feature fusion module, because when the sample size is very small, the network is not sufficiently trained and learned, and a part of redundant or invalid features are extracted, resulting in lower classification accuracy. The above experimental results show that the proposed residual attention generation adversarial network classification method can effectively extract more discriminative features and improve the semi-supervised classification performance for the problem of small sample size of labeled high-resolution remote sensing images, which makes it difficult to extract discriminative features.",
    "macro_domains": []
  },
  {
    "abstract": "Ensuring citizens' safety and security has been identified as the number one priority for city authorities when it comes to the use of smart city technologies. Automatic understanding of the scene, and the associated provision of situational awareness for emergency situations, are able to efficiently contribute to such domains. In this study, a Video Analytics Edge Computing (VAEC) system is presented that performs real-time enhanced situation awareness for person detection in a video surveillance manner that is also able to share geolocated person detection alerts and other accompanied crucial information. The VAEC system adopts state-of-the-art object detection and tracking algorithms, and it is integrated with the proposed Distribute Edge Computing Internet of Things (DECIoT) platform. The aforementioned alerts and information are able to be shared, though the DECIoT, to smart city platforms utilizing proper middleware. To verify the utility and functionality of the VAEC system, extended experiments were performed (i) in several light conditions, (ii) using several camera sensors, and (iii) in several use cases, such as installed in fixed position of a building or mounted to a car. The results highlight the potential of VAEC system to be exploited by decision-makers or city authorities, providing enhanced situational awareness.",
    "doi": "10.3390/computation10030035",
    "author_keywords": [
      "Computer vision",
      "Edge computing",
      "Object detection",
      "Object tracking",
      "Person detection",
      "Situational awareness",
      "Smart cities",
      "Terrestrial",
      "Vehicle",
      "YOLOv5"
    ],
    "contribution": "In this study, a Video Analytics Edge Computing (VAEC) system is presented that performs real-time enhanced situation awareness for person detection in a video surveillance manner that is also able to share geolocated person detection alerts and other accompanied crucial information. The VAEC system adopts state-of-the-art object detection and tracking algorithms, and it is integrated with the proposed Distribute Edge Computing Internet of Things (DECIoT) platform. The aforementioned alerts and information are able to be shared, though the DECIoT, to smart city platforms utilizing proper middleware. To verify the utility and functionality of the VAEC system, extended experiments were performed (i) in several light conditions, (ii) using several camera sensors, and (iii) in several use cases, such as installed in fixed position of a building or mounted to a car. The results highlight the potential of VAEC system to be exploited by decision-makers or city authorities, providing enhanced situational awareness.",
    "introduction": "Ensuring citizens' safety and security has been identified as the number one priority for city authorities when it comes to the use of smart city technologies. Automatic understanding of the scene, and the associated provision of situational awareness for emergency situations, are able to efficiently contribute to such domains.",
    "macro_domains": []
  },
  {
    "abstract": "Understanding the underlying patterns of the urban mobility dynamics is essential for both the traffic state estimation and management of urban facilities and services. Due to the coupling relationship of generative factors in spatial-temporal domain, it is challenging to model the citywide traffic dynamics under a structural pattern of critical features such as hours of days, days of weeks and weather conditions. To address this challenge, this article develops a disentangled representation learning framework to learn an interpretable factorized representation of the independent data generative factors. In order to make full use of the knowledge on generative factors, this article proposes spatial-temporal generative adversarial network (ST-GAN) to assign the generative factors of traffic flow to the feature vector in latent space and reconstructs the high-dimensional citywide traffic flow from the given factors. With the help of the disentangled representations, the decomposed feature vector in latent space discloses the relationship between underlying patterns and citywide traffic dynamics. Several comprehensively experiments show that ST-GAN not only effectively improves the prediction accuracy but also promisingly characterize structural properties of the traffic evolution process.",
    "doi": "10.1109/TITS.2020.3030259",
    "author_keywords": [
      "big data",
      "deep learning",
      "disentangled representation",
      "generative adversary networks",
      "Urban computing"
    ],
    "contribution": "To address this challenge, this article develops a disentangled representation learning framework to learn an interpretable factorized representation of the independent data generative factors. In order to make full use of the knowledge on generative factors, this article proposes spatial-temporal generative adversarial network (ST-GAN) to assign the generative factors of traffic flow to the feature vector in latent space and reconstructs the high-dimensional citywide traffic flow from the given factors. With the help of the disentangled representations, the decomposed feature vector in latent space discloses the relationship between underlying patterns and citywide traffic dynamics. Several comprehensively experiments show that ST-GAN not only effectively improves the prediction accuracy but also promisingly characterize structural properties of the traffic evolution process.",
    "introduction": "Understanding the underlying patterns of the urban mobility dynamics is essential for both the traffic state estimation and management of urban facilities and services. Due to the coupling relationship of generative factors in spatial-temporal domain, it is challenging to model the citywide traffic dynamics under a structural pattern of critical features such as hours of days, days of weeks and weather conditions.",
    "macro_domains": []
  },
  {
    "abstract": "Adaptive medium access control (MAC) protocols are essential in the context of Vehicular AdHoc Networks (Vanets) because of the rapid changes in topology caused by the high mobility of nodes. In this work, we propose an adaptive version of the Slotted-ALOHA (S-ALOHA) protocol, where the transmission probability is constantly adjusted based on estimates of the number of vehicles in the coverage area. These values are computed using deep learning models for time series prediction. One challenge for implementing this approach is that the inputs to the models are noisy since they are also estimates based on the protocol's operation itself. To address this problem, we propose a new training scheme where we add noise, similar to that produced by the protocol's operation, to the inputs of the training examples as a form of regularization. Our experiments show that the regularized models perform close to the theoretical optimal where the number of vehicles in the area is always known.",
    "doi": "10.1016/j.icte.2022.02.006",
    "author_keywords": [
      "ALOHA",
      "LSTM",
      "Machine learning",
      "Transformers",
      "Vanets"
    ],
    "contribution": "In this work, we propose an adaptive version of the Slotted-ALOHA (S-ALOHA) protocol, where the transmission probability is constantly adjusted based on estimates of the number of vehicles in the coverage area. These values are computed using deep learning models for time series prediction. One challenge for implementing this approach is that the inputs to the models are noisy since they are also estimates based on the protocol's operation itself. To address this problem, we propose a new training scheme where we add noise, similar to that produced by the protocol's operation, to the inputs of the training examples as a form of regularization. Our experiments show that the regularized models perform close to the theoretical optimal where the number of vehicles in the area is always known.",
    "introduction": "Adaptive medium access control (MAC) protocols are essential in the context of Vehicular AdHoc Networks (Vanets) because of the rapid changes in topology caused by the high mobility of nodes.",
    "macro_domains": []
  },
  {
    "abstract": "Urban flow prediction plays a crucial role in public transportation management and smart city construction. Although previous studies have achieved success in integrating spatial-temporal information to some extents, those models lack thoughtful consideration on global information and positional information in the temporal dimension, which can be summarized by three aspects: a) The models do not consider the relative position information of time axis, resulting in that the position features of flow maps are not effectively learned. b) They overlook the correlation among temporal dependencies of different scales, which lead to inaccurate global information representation. c) Those models only predict the flow map at the end of time sequence other than more flow maps before that, which results in neglecting parts of temporal features in the learning process. To solve the problems, we propose a novel model, Spatial-Temporal Global Semantic representation learning for urban flow Prediction (ST-GSP) in this paper. Specifically, for a), we design a semantic flow encoder that extracts relative positional information of time. Besides, the encoder captures the spatial dependencies and external factors of urban flow at each time interval. For b), we model the correlation among temporal dependencies of different scales simultaneously by using the multi-head self-attention mechanism, which can learn the global temporal dependencies. For c), inspired by the idea of self-supervised learning, we mask an urban flow map on the time sequence and predict it to pre-train a deep bidirectional learning model to catch the representation from its context. We conduct extensive experiments on two types of urban flows in Beijing and New York City to show that the proposed method outperforms state-of-the-art methods.",
    "doi": "10.1145/3488560.3498444",
    "author_keywords": [
      "Spatial-temporal modeling",
      "Transformer",
      "Urban flow prediction"
    ],
    "contribution": "To solve the problems, we propose a novel model, Spatial-Temporal Global Semantic representation learning for urban flow Prediction (ST-GSP) in this paper. Specifically, for a), we design a semantic flow encoder that extracts relative positional information of time. Besides, the encoder captures the spatial dependencies and external factors of urban flow at each time interval. For b), we model the correlation among temporal dependencies of different scales simultaneously by using the multi-head self-attention mechanism, which can learn the global temporal dependencies. For c), inspired by the idea of self-supervised learning, we mask an urban flow map on the time sequence and predict it to pre-train a deep bidirectional learning model to catch the representation from its context. We conduct extensive experiments on two types of urban flows in Beijing and New York City to show that the proposed method outperforms state-of-the-art methods.",
    "introduction": "Urban flow prediction plays a crucial role in public transportation management and smart city construction. Although previous studies have achieved success in integrating spatial-temporal information to some extents, those models lack thoughtful consideration on global information and positional information in the temporal dimension, which can be summarized by three aspects: a) The models do not consider the relative position information of time axis, resulting in that the position features of flow maps are not effectively learned. b) They overlook the correlation among temporal dependencies of different scales, which lead to inaccurate global information representation. c) Those models only predict the flow map at the end of time sequence other than more flow maps before that, which results in neglecting parts of temporal features in the learning process.",
    "macro_domains": []
  },
  {
    "abstract": "The power grid, one of the most crucial components of smart cities, faces significant challenges in operating efficiently, dependably, and economically. One of these challenges is forecasting the demand for electricity. Grid managers can balance supply and demand properly while also minimizing operating expenses for generating and transmitting power. Thanks to accurate forecasts, while maintaining respectable system performance in terms of the limitations on the actual and reactive power output of the generator, bus voltages, shunt capacitors and reactors, transformer tap setting, and transmission line power flow. For a sustainable future and to meet the higher carbon emission standards that are being put in place, it is expected that the renewable energy sector will experience enormous development. The placement of wind turbines in a wind farm requires the use of evolutionary algorithms and power system optimization issues because the wake effect caused by upstream turbines impacts the output of downstream turbines, consequently diminishing the total power output from the wind farm. The current study using MFO determines a cost of $ 3160.0824 $/h for minimizing the cost of multiple fuels, which turns out to be the best price when compared to the legitimate results obtained by other algorithms. It results in a cost savings of 1.45% per hour when compared to the worst alternatives given by the comparison algorithm. According to simulation results on the IEEE 30-bus network with six generators, this approach might offer the best solution right away. A further study found that this method works best for medium-scale power installations.",
    "doi": "10.1049/icp.2022.2636",
    "author_keywords": [
      "Minimizing Cost",
      "Moth flow Optimizer",
      "Optimal Power Flow",
      "Power Transmission Analysis"
    ],
    "contribution": "The current study using MFO determines a cost of $ 3160.0824 $/h for minimizing the cost of multiple fuels, which turns out to be the best price when compared to the legitimate results obtained by other algorithms. It results in a cost savings of 1.45% per hour when compared to the worst alternatives given by the comparison algorithm. According to simulation results on the IEEE 30-bus network with six generators, this approach might offer the best solution right away. A further study found that this method works best for medium-scale power installations.",
    "introduction": "The power grid, one of the most crucial components of smart cities, faces significant challenges in operating efficiently, dependably, and economically. One of these challenges is forecasting the demand for electricity. Grid managers can balance supply and demand properly while also minimizing operating expenses for generating and transmitting power. Thanks to accurate forecasts, while maintaining respectable system performance in terms of the limitations on the actual and reactive power output of the generator, bus voltages, shunt capacitors and reactors, transformer tap setting, and transmission line power flow. For a sustainable future and to meet the higher carbon emission standards that are being put in place, it is expected that the renewable energy sector will experience enormous development. The placement of wind turbines in a wind farm requires the use of evolutionary algorithms and power system optimization issues because the wake effect caused by upstream turbines impacts the output of downstream turbines, consequently diminishing the total power output from the wind farm.",
    "macro_domains": []
  },
  {
    "abstract": "Self-supervision framework targets to study useful representations from unlabeled pool of data as the unlabeled data [1] is available in abundance and getting good quality labeled data tends to be costlier and time taking. The vision transformers (ViT) [2] have achieved the present state of art performance for applying self-supervision in video segmentation tasks. The literature review discusses various video segmentation frameworks using contrastive methods [3]. Similarity algorithms have been applied to get optimized attention heads to discriminate foreground and background. It involves Knowledge Distillation (KD) [4] that helps student model learn from the teacher network, in which the instructor's logits are employed to train the student. It's most recognized for being a powerful model compression technique. Data augmentation [5] method aims to obtain the accuracy by providing various aspects of the same image. Our study underlines the importance of student-teacher encoder, multi-crop training and optimal use of small patches with ViTs replicated by proposed novel distillation model which mainly concerned about the avoidance of expected trivial solutions with the help of involved predictor model and centering process. It defines the synergy between autonomous vehicle and smart cities where perceiving precise environment can be achieved with the proposed model.",
    "doi": "10.1049/icp.2023.0315",
    "author_keywords": [
      "Data Augmentation",
      "Knowledge Distillation",
      "Self-Supervised Learning",
      "Video Object Segmentation",
      "Vision Transformer"
    ],
    "contribution": "Our study underlines the importance of student-teacher encoder, multi-crop training and optimal use of small patches with ViTs replicated by proposed novel distillation model which mainly concerned about the avoidance of expected trivial solutions with the help of involved predictor model and centering process. It defines the synergy between autonomous vehicle and smart cities where perceiving precise environment can be achieved with the proposed model.",
    "introduction": "Self-supervision framework targets to study useful representations from unlabeled pool of data as the unlabeled data [1] is available in abundance and getting good quality labeled data tends to be costlier and time taking. The vision transformers (ViT) [2] have achieved the present state of art performance for applying self-supervision in video segmentation tasks. The literature review discusses various video segmentation frameworks using contrastive methods [3]. Similarity algorithms have been applied to get optimized attention heads to discriminate foreground and background. It involves Knowledge Distillation (KD) [4] that helps student model learn from the teacher network, in which the instructor's logits are employed to train the student. It's most recognized for being a powerful model compression technique. Data augmentation [5] method aims to obtain the accuracy by providing various aspects of the same image.",
    "macro_domains": []
  },
  {
    "abstract": "Global energy demand is increasing continuously due to growth in the world population and industrial developments. In a parallel dimension, the problem of decreasing CO2 emissions in smart cities is becoming a priority. Forecasting energy consumption is essential for implementing a decarbonization plan in a smart city. The energy consumption forecasting problem has some challenges because of lacking appropriate data, including energy consumption patterns in the energy sector. In such a context, in this study, we focus on short-term time series forecasting for energy consumption tasks with comprehensive data. We employed LSTM, Transformer, XGBoost, and hybrid models to predict energy consumption via time series. The models were tested on the JERICHO-E-usage Germany dataset for Berlin, DÃ¼sseldorf, and the whole of Germany. We executed an energy consumption forecasting pipeline in our experiments to summarize Information and Communication Technology and Lighting energy types. Finally, we presented a comparative analysis between state-of-art deep learning and machine learning models (e.g., LSTM, Transformer, XGBoost), and a hybrid model. The proposed energy consumption forecasting pipeline can be applied to various countries and cities based on geographical distributions.",
    "doi": "10.1109/ICAIoT57170.2022.10121846",
    "author_keywords": [
      "Deep learning",
      "Energy forecasting",
      "Time Series"
    ],
    "contribution": "In such a context, in this study, we focus on short-term time series forecasting for energy consumption tasks with comprehensive data. We employed LSTM, Transformer, XGBoost, and hybrid models to predict energy consumption via time series. The models were tested on the JERICHO-E-usage Germany dataset for Berlin, DÃ¼sseldorf, and the whole of Germany. We executed an energy consumption forecasting pipeline in our experiments to summarize Information and Communication Technology and Lighting energy types. Finally, we presented a comparative analysis between state-of-art deep learning and machine learning models (e.g., LSTM, Transformer, XGBoost), and a hybrid model. The proposed energy consumption forecasting pipeline can be applied to various countries and cities based on geographical distributions.",
    "introduction": "Global energy demand is increasing continuously due to growth in the world population and industrial developments. In a parallel dimension, the problem of decreasing CO2 emissions in smart cities is becoming a priority. Forecasting energy consumption is essential for implementing a decarbonization plan in a smart city. The energy consumption forecasting problem has some challenges because of lacking appropriate data, including energy consumption patterns in the energy sector.",
    "macro_domains": []
  },
  {
    "abstract": "The growing number of drone serving in Smart Cities make it increasingly necessary to develop new technologies to assist traffic management in low-altitude airspace. The Internet of Drones (IoD) is a layered network providing efficient and safe airways for various drone inter-operable services. Automated Drone Classification (ADC) is a prerequisite in the IoD system that not only monitors flights and avoids collisions between drones but also detects malicious drone flights. In this work, we propose a Dual-stream Convolutional Transformer (DCT) model to carry out ADC tasks based on drone remote control signals. The DCT combines the self-attention mechanism and convolution to capture long-range dependencies of different frequencies/time steps and local invariant features. We evaluated the proposed method on two public datasets and compared the results with the baseline studies. The DCT model outperforms other baselines with the improvement of 3 % accuracy in multiclass classification and reaches 94.49 % and 98.73 % on two different datasets at 30 dB signal-to-noise ratio. Furthermore, the experiments also show the great potential of DCT model on out-of-distribution by the improvement of 7 % accuracy. The above results demonstrate that the proposed method is a promising solution for supporting the ADC task in reliable, fast, and inexpensive ways.",
    "doi": "10.1109/ICTAI56018.2022.00125",
    "author_keywords": [
      "Automated Drone Classifi-cation",
      "Deep Learning",
      "Drone Remote Control Signals",
      "Internet of Drones",
      "Time-Frequency Analysis"
    ],
    "contribution": "In this work, we propose a Dual-stream Convolutional Transformer (DCT) model to carry out ADC tasks based on drone remote control signals. The DCT combines the self-attention mechanism and convolution to capture long-range dependencies of different frequencies/time steps and local invariant features. We evaluated the proposed method on two public datasets and compared the results with the baseline studies. The DCT model outperforms other baselines with the improvement of 3 % accuracy in multiclass classification and reaches 94.49 % and 98.73 % on two different datasets at 30 dB signal-to-noise ratio. Furthermore, the experiments also show the great potential of DCT model on out-of-distribution by the improvement of 7 % accuracy. The above results demonstrate that the proposed method is a promising solution for supporting the ADC task in reliable, fast, and inexpensive ways.",
    "introduction": "The growing number of drone serving in Smart Cities make it increasingly necessary to develop new technologies to assist traffic management in low-altitude airspace. The Internet of Drones (IoD) is a layered network providing efficient and safe airways for various drone inter-operable services. Automated Drone Classification (ADC) is a prerequisite in the IoD system that not only monitors flights and avoids collisions between drones but also detects malicious drone flights.",
    "macro_domains": []
  },
  {
    "abstract": "Surveillance system continuously generates massive amount of video data in the newest technological era, analysing these data is a tedious task for security specialists. With the popularization of surveillance monitoring system and the evolution of information technology, how to immediately and without human interaction detect unusual behaviours in surveillance footage is becoming more and more crucial for smart cities and public safety. Finding of abnormal footage physically in these massive video recordings is a laborious work, as they do not happen often in the real world. This clearly shows the necessity of automated anomaly detection, afterward that can detect crimes and aid investigations. The progress of anomaly detection has substantially benefited from deep learning, and much outstanding work has been published on this subject. This survey paper provides a comprehensive review of various anomaly detection and recognition methods. Researchers will get a better perspective of anomaly detection task with GAN approach, fine-tuned approach, and keyframes extraction plus shallow network approach and also their issues as well.",
    "doi": "10.1109/SMARTGENCON56628.2022.10084028",
    "author_keywords": [
      "3DConvNets",
      "anomaly detection",
      "intelligent surveillance net-works",
      "keyframe extraction",
      "spatial augmentation",
      "U-Net"
    ],
    "contribution": "This survey paper provides a comprehensive review of various anomaly detection and recognition methods. Researchers will get a better perspective of anomaly detection task with GAN approach, fine-tuned approach, and keyframes extraction plus shallow network approach and also their issues as well.",
    "introduction": "Surveillance system continuously generates massive amount of video data in the newest technological era, analysing these data is a tedious task for security specialists. With the popularization of surveillance monitoring system and the evolution of information technology, how to immediately and without human interaction detect unusual behaviours in surveillance footage is becoming more and more crucial for smart cities and public safety. Finding of abnormal footage physically in these massive video recordings is a laborious work, as they do not happen often in the real world. This clearly shows the necessity of automated anomaly detection, afterward that can detect crimes and aid investigations. The progress of anomaly detection has substantially benefited from deep learning, and much outstanding work has been published on this subject.",
    "macro_domains": []
  },
  {
    "abstract": "The area of image processing is more intensive in development and research activities for decades. The role of image processing is huge in modeling, analytics, communication, computation, information security, information forensics and smart city application. Images are ubiquitous in day to day life and images or videos play dominant role in monitoring applications. But when it comes to development of specific application, collection of data is a very challenging task. Nowadays deep learning plays a significant role for generation of data. Robust technologies like Generative Adversarial Network (GAN) and Cycle GAN play a crucial role for generating realistic images with super resolution. GAN and its associated methods used for image synthesis improve the accuracy of deep learning models. In this paper, we analyze challenges of license plate recognition in realistic situation and experiments demonstrate that GAN can generate realistic images to improve the accuracy of license plate recognition.",
    "doi": "10.1109/ICCCMLA56841.2022.9989063",
    "author_keywords": [
      "Deep Learning",
      "Generative Adversarial Network",
      "Generator",
      "Image synthesis",
      "License Plate Recognition"
    ],
    "contribution": "In this paper, we analyze challenges of license plate recognition in realistic situation and experiments demonstrate that GAN can generate realistic images to improve the accuracy of license plate recognition.",
    "introduction": "The area of image processing is more intensive in development and research activities for decades. The role of image processing is huge in modeling, analytics, communication, computation, information security, information forensics and smart city application. Images are ubiquitous in day to day life and images or videos play dominant role in monitoring applications. But when it comes to development of specific application, collection of data is a very challenging task. Nowadays deep learning plays a significant role for generation of data. Robust technologies like Generative Adversarial Network (GAN) and Cycle GAN play a crucial role for generating realistic images with super resolution. GAN and its associated methods used for image synthesis improve the accuracy of deep learning models.",
    "macro_domains": []
  },
  {
    "abstract": "Vehicle re-identification (ReID) is a critical technology in smart city and has drawn much attention. Many studies focus on single-modal (i.e., visible) vehicle re-identification, which are prone to be deteriorated under bad illumination conditions. Therefore, visible, near-infrared, and thermal-infrared multi-modal vehicle re-identification is worthy to study. This paper proposes a hybrid vision transformer (H-ViT) based multi-modal vehicle re-identification. The proposed H-ViT has two new modules: (1) modal-specific controller (MC) and (2) modal information embedding (MIE) structure. In the feature extraction process, the MC flexibly specifies modal-specific layers for different modal data and controls the sharing attribute of the position embedding to alleviate the difficulty brought by heterogeneous multi-modalities. The MIE structure learns inter- and intra-modal information to reduce feature deviations toward modal variations. Experimental results show that our H-ViT method achieves good performance on multi-modal vehicle re-identification datasets (i.e., RGBNT100 and RGBN300) by integrating MC and MIE modules, which are superior to existing algorithms.",
    "doi": "10.1007/978-3-031-20497-5_21",
    "author_keywords": [
      "Multi-modality",
      "Vehicle re-identification",
      "Vision transformer"
    ],
    "contribution": "This paper proposes a hybrid vision transformer (H-ViT) based multi-modal vehicle re-identification. The proposed H-ViT has two new modules: (1) modal-specific controller (MC) and (2) modal information embedding (MIE) structure. In the feature extraction process, the MC flexibly specifies modal-specific layers for different modal data and controls the sharing attribute of the position embedding to alleviate the difficulty brought by heterogeneous multi-modalities. The MIE structure learns inter- and intra-modal information to reduce feature deviations toward modal variations. Experimental results show that our H-ViT method achieves good performance on multi-modal vehicle re-identification datasets (i.e., RGBNT100 and RGBN300) by integrating MC and MIE modules, which are superior to existing algorithms.",
    "introduction": "Vehicle re-identification (ReID) is a critical technology in smart city and has drawn much attention. Many studies focus on single-modal (i.e., visible) vehicle re-identification, which are prone to be deteriorated under bad illumination conditions. Therefore, visible, near-infrared, and thermal-infrared multi-modal vehicle re-identification is worthy to study.",
    "macro_domains": []
  },
  {
    "abstract": "The applications of internet of things networks extensively increasing which provide ease of data communication among interconnected smart devices. IoT connected with smart devices diverse in a range of fields associated with smart cities, smart-transportation, smart-industrial, healthcare, hospitality etc. The smart devices lack with computational power, energy and inconsistent topology. Due to these factors these are most vulnerable to security attacks which affect the transmission reliability of data between nodes. An IoT network connects heterogeneous devices together and generates high volume of data. To provide security against intrusion attacks, deep neural network (DNN) techniques are adopted to detect malicious attacks. We have proposed on an anomaly Hybrid based deep learning-based approach which is Generative Adversarial Network in accordance with detecting malicious intruders. We designed a distributed IDS controller validated over dataset of NSL-KDD and proven with higher performance in detecting the DDOS Distributed-Denial-of service-attacks. Thus, Experimental Results are calculated with predefined threshold values to detect DDoS-attacks and the resultant proves that HD-GAN model offers better intrusion detection with respect to higher accuracy, recall, precision, f-measure, and lower FPR (False-Positive-Rate).",
    "doi": "10.37391/ijeer.100432",
    "author_keywords": [
      "Distributed Deep Neural Network",
      "Distributed Denial of Service (DDoS)",
      "Generative Adversarial Network (GAN)"
    ],
    "contribution": "",
    "introduction": "The applications of internet of things networks extensively increasing which provide ease of data communication among interconnected smart devices. IoT connected with smart devices diverse in a range of fields associated with smart cities, smart-transportation, smart-industrial, healthcare, hospitality etc. The smart devices lack with computational power, energy and inconsistent topology. Due to these factors these are most vulnerable to security attacks which affect the transmission reliability of data between nodes. An IoT network connects heterogeneous devices together and generates high volume of data. To provide security against intrusion attacks, deep neural network (DNN) techniques are adopted to detect malicious attacks. We have proposed on an anomaly Hybrid based deep learning-based approach which is Generative Adversarial Network in accordance with detecting malicious intruders. We designed a distributed IDS controller validated over dataset of NSL-KDD and proven with higher performance in detecting the DDOS Distributed-Denial-of service-attacks. Thus, Experimental Results are calculated with predefined threshold values to detect DDoS-attacks and the resultant proves that HD-GAN model offers better intrusion detection with respect to higher accuracy, recall, precision, f-measure, and lower FPR (False-Positive-Rate).",
    "macro_domains": []
  },
  {
    "abstract": "While smart cities have the required infrastructure for traffic prediction, underdeveloped cities lack the budget and technology to perform an accurate model. Current research uses data mining of tweets and specific posts to provide population trends, but there is no work done in social network analysis for the same end. This paper proposes an applied informatics application with social network usage to aid in the lack of data due to nonexistent traffic sensors. The Twitter API was used to download a network of users that follows traffic updates accounts and then, use a model of information diffusion (independent cascade model) to retrieve a variable that holds a metric of how the information regarding current traffic has traveled through the network. Finally, an updated traffic dataset with the new social network variable is used to train and validate an LSTM neural network to show if the new variable can be a predictor for traffic. Results show that a deterministic independent cascade model ran on a New York City-based 2-tier social network marginally improved the prediction by 0.4%. This proposal can be replicated in other information diffusion models.",
    "doi": "10.1007/978-3-031-19647-8_15",
    "author_keywords": [
      "Applied informatics",
      "Deep learning",
      "Social network",
      "Traffic prediction"
    ],
    "contribution": "This paper proposes an applied informatics application with social network usage to aid in the lack of data due to nonexistent traffic sensors. The Twitter API was used to download a network of users that follows traffic updates accounts and then, use a model of information diffusion (independent cascade model) to retrieve a variable that holds a metric of how the information regarding current traffic has traveled through the network. Finally, an updated traffic dataset with the new social network variable is used to train and validate an LSTM neural network to show if the new variable can be a predictor for traffic. Results show that a deterministic independent cascade model ran on a New York City-based 2-tier social network marginally improved the prediction by 0.4%. This proposal can be replicated in other information diffusion models.",
    "introduction": "While smart cities have the required infrastructure for traffic prediction, underdeveloped cities lack the budget and technology to perform an accurate model. Current research uses data mining of tweets and specific posts to provide population trends, but there is no work done in social network analysis for the same end.",
    "macro_domains": []
  },
  {
    "abstract": "Timely road condition inspection and maintenance are key components of infrastructure management for smart cities, as they reduce traffic congestion, accidents and repairing costs. Traditional road inspection methods that employ vibrations and/or laser scanning for detecting road deterioration use expensive equipment and dedicated municipality vehicles. Recently, computer vision techniques and artificial intelligence are emerging as alternative solutions to traditional approaches for road condition detection, offering more flexibility, higher accuracy, and overall lower cost. In this paper, we utilize convolutional neural network-based and vision transformer-based object detection models to accurately identify road deteriorations namely, potholes, cracks, and alligators. We compare four different state-of-the-art models in terms of detection accuracy and speed. Performance evaluations have shown that, on the same dataset the Swin Transformer model outperformed the other state-of-the-art methods by a substantial margin. With 74% detection accuracy, and 42 frames per second processing speed Swin Transformer exceled over EfficentDet, YOLOv4, and YOLOX. We also present a new comprehensive and balanced large-scale road condition dataset of 27,298 annotated images, captured by ordinary car cameras.",
    "doi": "10.1109/WiMob55322.2022.9941685",
    "author_keywords": [
      "Deep learning",
      "Object detection",
      "Road deterioration",
      "Swin Transformer",
      "Transmission",
      "YOLOv4",
      "YOLOX"
    ],
    "contribution": "In this paper, we utilize convolutional neural network-based and vision transformer-based object detection models to accurately identify road deteriorations namely, potholes, cracks, and alligators. We compare four different state-of-the-art models in terms of detection accuracy and speed. Performance evaluations have shown that, on the same dataset the Swin Transformer model outperformed the other state-of-the-art methods by a substantial margin. With 74% detection accuracy, and 42 frames per second processing speed Swin Transformer exceled over EfficentDet, YOLOv4, and YOLOX. We also present a new comprehensive and balanced large-scale road condition dataset of 27,298 annotated images, captured by ordinary car cameras.",
    "introduction": "Timely road condition inspection and maintenance are key components of infrastructure management for smart cities, as they reduce traffic congestion, accidents and repairing costs. Traditional road inspection methods that employ vibrations and/or laser scanning for detecting road deterioration use expensive equipment and dedicated municipality vehicles. Recently, computer vision techniques and artificial intelligence are emerging as alternative solutions to traditional approaches for road condition detection, offering more flexibility, higher accuracy, and overall lower cost.",
    "macro_domains": []
  },
  {
    "abstract": "The number of LoRaWAN networks have grown worldwide last years, offering a solution for the integration of the Internet of Things in rural and urban areas. After years of development, several performance issues and scalability limitations require to be enhanced for LoRa such as high collision rates and duty cycle limitations. Machine learning offers a chance for LoRaWAN to rise as the reference communication technology that offers the adequate communication performances for IoT. In this paper, our goal is to optimize the LoRaWAN network performances using detection mechanism and artificial intelli-gence to predict its behavior. first, we evaluate the full potential of the LoRaWAN factory setting, and we introduced a Quality of Service demanding application. Second, we constructed our proper database using available application criteria, we included a quality of service mechanism to simulate the effect of a new application connecting to a stable network and the perturbing causes. Then, we used two different methods one for classification, the second for prediction, and then the optimization. For clas-sification using Auto-Regressive and optimization it using burg algorithm and firefly algorithm, then we used the support vector machine for traffic classification, results are very promising, we were able to detect normal traffic, a normal surge, and an abnormal surge of network traffic with up to 99% accuracy. For prediction, we used a new algorithm developed by google Temporal Fusion Transformer. We were able to predict the network behaviour ahead with 14 days with 95% accuracy and up to 30 days with 80% accuracy. We were able to optimize the network to absorb the abnormal surge and return to normal in less than 60% of the normal time, uplifting the packet delivery ratio for uplink traffic by 20% and downlink traffic by 50%.",
    "doi": "10.1109/WiMob55322.2022.9941538",
    "author_keywords": [
      "channel occupancy",
      "cluster analysis",
      "LoRaWAN",
      "Machine Learning",
      "network optimization",
      "prediction analysis",
      "smart city"
    ],
    "contribution": "In this paper, our goal is to optimize the LoRaWAN network performances using detection mechanism and artificial intelli-gence to predict its behavior. first, we evaluate the full potential of the LoRaWAN factory setting, and we introduced a Quality of Service demanding application. Second, we constructed our proper database using available application criteria, we included a quality of service mechanism to simulate the effect of a new application connecting to a stable network and the perturbing causes. Then, we used two different methods one for classification, the second for prediction, and then the optimization. For clas-sification using Auto-Regressive and optimization it using burg algorithm and firefly algorithm, then we used the support vector machine for traffic classification, results are very promising, we were able to detect normal traffic, a normal surge, and an abnormal surge of network traffic with up to 99% accuracy. For prediction, we used a new algorithm developed by google Temporal Fusion Transformer. We were able to predict the network behaviour ahead with 14 days with 95% accuracy and up to 30 days with 80% accuracy. We were able to optimize the network to absorb the abnormal surge and return to normal in less than 60% of the normal time, uplifting the packet delivery ratio for uplink traffic by 20% and downlink traffic by 50%.",
    "introduction": "The number of LoRaWAN networks have grown worldwide last years, offering a solution for the integration of the Internet of Things in rural and urban areas. After years of development, several performance issues and scalability limitations require to be enhanced for LoRa such as high collision rates and duty cycle limitations. Machine learning offers a chance for LoRaWAN to rise as the reference communication technology that offers the adequate communication performances for IoT.",
    "macro_domains": []
  },
  {
    "abstract": "Commercial and research applications of artificial Intelligence (AI) are becoming increasingly important. AI is used to improve products, predict customer behavior, keep track of inventory, and analyze Big Data. AI agents are also employed to improve the performance of search engines and smartphones. There are a number of ways that AI is being considered for applications in the library, especially data analysis, supporting remote access to library services, and making the library a center for research using Big Data. AI has the potential to perform routine tasks that now require a human being, which will free up librarians to offer the in-depth expertise that is essential for advanced research.",
    "doi": "10.1080/02763877.2022.2140741",
    "author_keywords": [
      "Artificial intelligence",
      "big data",
      "library of the future",
      "mobile internet",
      "remote services",
      "search",
      "smart cities",
      "virtual personal assistant"
    ],
    "contribution": "",
    "introduction": "Commercial and research applications of artificial Intelligence (AI) are becoming increasingly important. AI is used to improve products, predict customer behavior, keep track of inventory, and analyze Big Data. AI agents are also employed to improve the performance of search engines and smartphones. There are a number of ways that AI is being considered for applications in the library, especially data analysis, supporting remote access to library services, and making the library a center for research using Big Data. AI has the potential to perform routine tasks that now require a human being, which will free up librarians to offer the in-depth expertise that is essential for advanced research.",
    "macro_domains": []
  },
  {
    "abstract": "The rapid adoption of Internet-connected devices (i.e., smart phones, smart cars, etc.) in today's society has given rise to a massive amount of data that can be harnessed by intelligent systems to learn and model the behavior of people. One useful set of such data is movement data, which can readily be obtained via GPS or motion-detection sensors, and which can be used to create models of user movement. One relevant application task based on this type of data is destination prediction, where movement data are used to form highly customized models that can forecast intended user destinations based on partially observed trajectories. In this work, we present a two-stage predictive model for destination prediction and Time-To-Destination (TTD) estimation using movement trajectories and contextual information. Our two-stage approach uses a Transformer-based architecture to predict an intended destination and a regression model to estimate how many steps must be traversed before a destination is reached. We showcase experimental results on various trajectory datasets and show that our proposed approach is able to yield significant destination prediction improvements over previous state-of-the-art methods and can also produce accurate TTD estimates.",
    "doi": "10.1109/ISC255366.2022.9922593",
    "author_keywords": [
      "deep learning",
      "Destination prediction",
      "machine learning",
      "smart city",
      "transformer"
    ],
    "contribution": "In this work, we present a two-stage predictive model for destination prediction and Time-To-Destination (TTD) estimation using movement trajectories and contextual information. Our two-stage approach uses a Transformer-based architecture to predict an intended destination and a regression model to estimate how many steps must be traversed before a destination is reached. We showcase experimental results on various trajectory datasets and show that our proposed approach is able to yield significant destination prediction improvements over previous state-of-the-art methods and can also produce accurate TTD estimates.",
    "introduction": "The rapid adoption of Internet-connected devices (i.e., smart phones, smart cars, etc.) in today's society has given rise to a massive amount of data that can be harnessed by intelligent systems to learn and model the behavior of people. One useful set of such data is movement data, which can readily be obtained via GPS or motion-detection sensors, and which can be used to create models of user movement. One relevant application task based on this type of data is destination prediction, where movement data are used to form highly customized models that can forecast intended user destinations based on partially observed trajectories.",
    "macro_domains": []
  },
  {
    "abstract": "An intelligent transportation system (ITS) is one of the core elements of smart cities, enhancing public safety and relieving traffic congestion. Detection and classification of critical vehicles, such as police cars and ambulances, passing through roadways form crucial use cases for ITS. This paper proposes a solution for detecting and classifying safety-critical vehicles on urban roadways using deep learning models. At present, a large-scale dataset for critical vehicles is not publicly available. The appearance scarcity of emergency vehicles and different coloring standards in various countries are significant challenges. To cope with the mentioned drawbacks and to address the unique requirements of our smart city project, we first generate a large-scale critical vehicle dataset, combining images retrieved from various sources with the support of the YOLO vehicle detection model. The classes of the generated dataset are: fire truck, police car, ambulance, military police car, dangerous truck, and standard vehicle. Second, we compare the performance of the Vision in Transformer (ViT) network against the traditional convolutional neural networks (CNNs) for the task of critical vehicle classification. Experimental results on our dataset reveal that the ViT-based solution reaches an average accuracy and recall of 99.39% and 99.34%, respectively.",
    "doi": "10.5220/0010968900003191",
    "author_keywords": [
      "CNN",
      "Intelligent Transportation",
      "Vehicle Classification",
      "Vehicle Detection",
      "Vision in Transformer"
    ],
    "contribution": "This paper proposes a solution for detecting and classifying safety-critical vehicles on urban roadways using deep learning models. At present, a large-scale dataset for critical vehicles is not publicly available. The appearance scarcity of emergency vehicles and different coloring standards in various countries are significant challenges. To cope with the mentioned drawbacks and to address the unique requirements of our smart city project, we first generate a large-scale critical vehicle dataset, combining images retrieved from various sources with the support of the YOLO vehicle detection model. The classes of the generated dataset are: fire truck, police car, ambulance, military police car, dangerous truck, and standard vehicle. Second, we compare the performance of the Vision in Transformer (ViT) network against the traditional convolutional neural networks (CNNs) for the task of critical vehicle classification. Experimental results on our dataset reveal that the ViT-based solution reaches an average accuracy and recall of 99.39% and 99.34%, respectively.",
    "introduction": "An intelligent transportation system (ITS) is one of the core elements of smart cities, enhancing public safety and relieving traffic congestion. Detection and classification of critical vehicles, such as police cars and ambulances, passing through roadways form crucial use cases for ITS.",
    "macro_domains": []
  },
  {
    "abstract": "Person re-identification plays an important role in the construction of the smart city. A reliable person re-identification system relieves users from the inefficient work of identifying the specific individual from enormous numbers of photos or videos captured by different surveillance devices. The most existing methods either focus on local discriminative features without global contextual information or scatter global features while ignoring the local features, resulting in ineffective attention to irregular pedestrian zones. In this article, a novel Transformer-CNN Coupling Network (TCCNet) is proposed to capture the fluctuant body region features in a heterogeneous feature-aware manner. We employ two bridging modules, the Lowlevel Feature Coupling Module (LFCM) and the High-level Feature Coupling Module (HFCM), to improve the complementary characteristics of the hybrid network. It is significantly helpful to enhance the capacity to distinguish between foreground and background features, thereby reducing the unfavorable impact of cluttered backgrounds on person re-identification. Furthermore, the duplicate loss for the two branches is employed to incorporate semantic information from distant preferences of the two branches into the resulting person representation. The experiments on two large-scale person re-identification benchmarks demonstrate that the proposed TCCNet achieves competitive results compared with several state-of-the-art approaches. The mean Average Precision (mAP) and Rank-1 identification rate on the MSMT17 dataset achieve 66.9% and 84.5%, respectively.",
    "doi": "10.7717/peerj-cs.1098",
    "author_keywords": [
      "Context information",
      "Convolutional neural networks",
      "Heterogeneous feature fusion",
      "Person re-identification",
      "Vision transformer"
    ],
    "contribution": "In this article, a novel Transformer-CNN Coupling Network (TCCNet) is proposed to capture the fluctuant body region features in a heterogeneous feature-aware manner. We employ two bridging modules, the Lowlevel Feature Coupling Module (LFCM) and the High-level Feature Coupling Module (HFCM), to improve the complementary characteristics of the hybrid network. It is significantly helpful to enhance the capacity to distinguish between foreground and background features, thereby reducing the unfavorable impact of cluttered backgrounds on person re-identification. Furthermore, the duplicate loss for the two branches is employed to incorporate semantic information from distant preferences of the two branches into the resulting person representation. The experiments on two large-scale person re-identification benchmarks demonstrate that the proposed TCCNet achieves competitive results compared with several state-of-the-art approaches. The mean Average Precision (mAP) and Rank-1 identification rate on the MSMT17 dataset achieve 66.9% and 84.5%, respectively.",
    "introduction": "Person re-identification plays an important role in the construction of the smart city. A reliable person re-identification system relieves users from the inefficient work of identifying the specific individual from enormous numbers of photos or videos captured by different surveillance devices. The most existing methods either focus on local discriminative features without global contextual information or scatter global features while ignoring the local features, resulting in ineffective attention to irregular pedestrian zones.",
    "macro_domains": []
  },
  {
    "abstract": "In smart surveillance systems, event classification and detection are essential parts, on the other hand, violent event recognition is one of the most important key elements in that systems. The use of the transformer network for video action recognition has achieved very high results, On the other hand, the transformer network needs a large amount of data to gain good accuracy therefore, a new family of video transformer networks called Data-efficient video transformer (DEVTr) came to address these problems and shows that the use of the pre-trained convolution neural network in the embedding stage can improve accuracy with the use of a small dataset for the given task. In this study, we extend the data-efficient video transformer (DEVTr) for better event detection within a small dataset and with low hardware resources. We also introduced two new video data augmentations methods (random erase from frames and frame position shifting with blurring). The model achieved 98.25% accuracy on the Real-life violence dataset (RLVS), an accuracy of 96% on the NTU CCTV-fight dataset, and accuracy of 91.803% on the UBI-Fight dataset. A comparison with previous techniques illustrated that the proposed methods provide the best result among the other research for violence event detection within a small dataset and low hardware resources.",
    "doi": "10.1109/ICIVC55077.2022.9886172",
    "author_keywords": [
      "CNN",
      "Deep Learning",
      "RLVS",
      "Smart Cities",
      "Spatio-temporal",
      "Transformer",
      "Video Classification",
      "violence Detection"
    ],
    "contribution": "In this study, we extend the data-efficient video transformer (DEVTr) for better event detection within a small dataset and with low hardware resources. We also introduced two new video data augmentations methods (random erase from frames and frame position shifting with blurring). The model achieved 98.25% accuracy on the Real-life violence dataset (RLVS), an accuracy of 96% on the NTU CCTV-fight dataset, and accuracy of 91.803% on the UBI-Fight dataset. A comparison with previous techniques illustrated that the proposed methods provide the best result among the other research for violence event detection within a small dataset and low hardware resources.",
    "introduction": "In smart surveillance systems, event classification and detection are essential parts, on the other hand, violent event recognition is one of the most important key elements in that systems. The use of the transformer network for video action recognition has achieved very high results, On the other hand, the transformer network needs a large amount of data to gain good accuracy therefore, a new family of video transformer networks called Data-efficient video transformer (DEVTr) came to address these problems and shows that the use of the pre-trained convolution neural network in the embedding stage can improve accuracy with the use of a small dataset for the given task.",
    "macro_domains": []
  },
  {
    "abstract": "Accurate multi-step citywide urban flow prediction plays a critical role in traffic management and future smart city. However, it is very challenging since urban flow is affected by complex semantic factors and has multi-scale dependencies on both spatial and temporal dimensional features. Moreover, itâ€™s difficult for most existing one-step urban flow prediction models to predict several future time steps in a short time accurately. Inspired by the success of Generative Adversarial Networks (GAN) in video prediction and image generation, in this paper we propose a Seq2Seq Spatial-Temporal Semantic Generative Adversarial Networks named STS-GAN for multi-step urban flow prediction. We regard citywide urban flow data in successive time steps as image frames of a video. Specifically, we first design a Spatial-Temporal Semantic Encoder (STSE) to capture relative semantic factors and spatial-temporal dependencies simultaneously at each time step, which consists of Residual Convolution units. Then a Seq2Seq GAN model is proposed to generate a sequence of future urban flow predictions based on historical data. Furthermore, by integrating GANâ€™s adversarial loss with prediction error, our STS-GAN can effectively address the blurry prediction issue. Extensive experiments are conducted on two large-scale urban flow datasets in Beijing and Guangzhou, which demonstrate STS-GAN achieves state-of-the-art performance compared with existing methods.",
    "doi": "10.1007/978-3-031-15934-3_63",
    "author_keywords": [
      "Generative Adversarial Networks",
      "Neural network models",
      "Spatial-temporal data mining",
      "Urban flow prediction"
    ],
    "contribution": "Inspired by the success of Generative Adversarial Networks (GAN) in video prediction and image generation, in this paper we propose a Seq2Seq Spatial-Temporal Semantic Generative Adversarial Networks named STS-GAN for multi-step urban flow prediction. We regard citywide urban flow data in successive time steps as image frames of a video. Specifically, we first design a Spatial-Temporal Semantic Encoder (STSE) to capture relative semantic factors and spatial-temporal dependencies simultaneously at each time step, which consists of Residual Convolution units. Then a Seq2Seq GAN model is proposed to generate a sequence of future urban flow predictions based on historical data. Furthermore, by integrating GANâ€™s adversarial loss with prediction error, our STS-GAN can effectively address the blurry prediction issue. Extensive experiments are conducted on two large-scale urban flow datasets in Beijing and Guangzhou, which demonstrate STS-GAN achieves state-of-the-art performance compared with existing methods.",
    "introduction": "Accurate multi-step citywide urban flow prediction plays a critical role in traffic management and future smart city. However, it is very challenging since urban flow is affected by complex semantic factors and has multi-scale dependencies on both spatial and temporal dimensional features. Moreover, itâ€™s difficult for most existing one-step urban flow prediction models to predict several future time steps in a short time accurately.",
    "macro_domains": []
  },
  {
    "abstract": "Long-term spatio-temporal prediction (LTSTP) over different resolutions plays a crucial role in planning and dispatching smart city applications, such as smart transportation and smart grid. The Transformer, which has demonstrated superiority in capturing long-term dependencies, was recently studied for spatio-temporal prediction. However, it is difficult to leverage it using both multi-resolution knowledge and spatio-temporal dependencies to aid LTSTP. The challenge typically lies in addressing two issues: (1) efficiently fusing information across multiple resolutions that demands elaborate and complicated modifications to the model, and (2) handling the necessary long-term sequence that makes concurrent space and time attentions too costly to be performed. To address these issues, we proposed a multi-resolution recursive spatio-temporal transformer (Mu2ReST). It implements a novel multi-resolution structure with recursive prediction from coarser to finer resolutions. This proposal reveals that an arduous modification of the model is not the only way to leverage multi-resolution knowledge. It further uses a redesigned lightweight space-time attention implementation to concurrently capture spatial and temporal dependencies. Experiment results using open and commercial urban datasets demonstrate that Mu2ReST outperforms existing methods for multi-resolution LTSTP tasks.",
    "doi": "10.1007/978-3-031-05933-9_6",
    "author_keywords": [
      "Long-term spatio-temporal prediction",
      "Multi-resolution",
      "Recursive prediction",
      "Spatio-temporal transformer"
    ],
    "contribution": "",
    "introduction": "Long-term spatio-temporal prediction (LTSTP) over different resolutions plays a crucial role in planning and dispatching smart city applications, such as smart transportation and smart grid. The Transformer, which has demonstrated superiority in capturing long-term dependencies, was recently studied for spatio-temporal prediction. However, it is difficult to leverage it using both multi-resolution knowledge and spatio-temporal dependencies to aid LTSTP. The challenge typically lies in addressing two issues: (1) efficiently fusing information across multiple resolutions that demands elaborate and complicated modifications to the model, and (2) handling the necessary long-term sequence that makes concurrent space and time attentions too costly to be performed. To address these issues, we proposed a multi-resolution recursive spatio-temporal transformer (Mu2ReST). It implements a novel multi-resolution structure with recursive prediction from coarser to finer resolutions. This proposal reveals that an arduous modification of the model is not the only way to leverage multi-resolution knowledge. It further uses a redesigned lightweight space-time attention implementation to concurrently capture spatial and temporal dependencies. Experiment results using open and commercial urban datasets demonstrate that Mu2ReST outperforms existing methods for multi-resolution LTSTP tasks.",
    "macro_domains": []
  },
  {
    "abstract": "The intelligent load forecasting is an important part of smart cities, used for the purpose of energy management in an efficient manner. However, there is not much research done on this aspect of energy management (EM) in smart cities, with the help of Internet of Things (IoT). In this work, a new deep learning (DL) methodology is used for predicting the amount of energy consumed within a short period of time, while maintaining proper communication between the users and energy providers. There are multiple stacked spatiotemporal modules present in the Energy-Net stack such that every module is made up of a Spatial Transformer and a Temporal Transformer (TT) sub-module. The temporal relationships are denoted in the TT model while the ST model uses the integration of convolutional layers to extract the hidden spatial information. Experimental observations on the datasets indicate that this methodology proves to be superior when compared with other existing DL methods that have an RMSE of 0.535 and 0.354. Energy Net computational complexity is suitable for IoT devices with dependable resource constraints, in collaboration with IoT cloud server to communicate with the smart grids to manage energy-related tasks.",
    "doi": "10.1109/ICSCDS53736.2022.9760925",
    "author_keywords": [
      "Deep Learning",
      "Edge Computing",
      "Energy Management",
      "Internet of Things",
      "Load Forecasting"
    ],
    "contribution": "In this work, a new deep learning (DL) methodology is used for predicting the amount of energy consumed within a short period of time, while maintaining proper communication between the users and energy providers. There are multiple stacked spatiotemporal modules present in the Energy-Net stack such that every module is made up of a Spatial Transformer and a Temporal Transformer (TT) sub-module. The temporal relationships are denoted in the TT model while the ST model uses the integration of convolutional layers to extract the hidden spatial information. Experimental observations on the datasets indicate that this methodology proves to be superior when compared with other existing DL methods that have an RMSE of 0.535 and 0.354. Energy Net computational complexity is suitable for IoT devices with dependable resource constraints, in collaboration with IoT cloud server to communicate with the smart grids to manage energy-related tasks.",
    "introduction": "The intelligent load forecasting is an important part of smart cities, used for the purpose of energy management in an efficient manner. However, there is not much research done on this aspect of energy management (EM) in smart cities, with the help of Internet of Things (IoT).",
    "macro_domains": []
  },
  {
    "abstract": "Machine Learning (ML) is a technique that employs computational statistics to learn the pattern of data and from there it tends to predict. Over last few years, abundance of data have been made available in standard format and therefore it is compelling to use ML techniques to achieve better prediction. In several instances we have witnessed 98â€“99% accuracy in prediction levels using ML techniques. In Utility Industry, one of the key parameter every DISCOM would like to forecast is Peak Load. Since HT (&gt;11 kVA) and EHT (Extra High Tension &gt; 66 kVA) customers in the designated DISCOM region demand continuous power supply, reducing interruption hours and feeder outages are two most important factors draw attentions of Utility Service Providers. It has been found that accurate prediction of Peak Load Demand for a day ahead can remarkably reduce the above two parameters. In fact, knowing the peak load in advance can help in optimizing the load distribution at substation levels. While predicting peak load, we should consider weather (Temperature), time of the day (expressed in HH:MM format), Day type (Weekdays or Weekends) and finally kWH of a DT.",
    "doi": "10.1007/978-981-16-1299-2_1",
    "author_keywords": [
      "Data modelling",
      "ETL",
      "Forecasting",
      "Neural net",
      "Real time data gathering",
      "Smart grid",
      "Smart meters",
      "Tree based methods"
    ],
    "contribution": "",
    "introduction": "Machine Learning (ML) is a technique that employs computational statistics to learn the pattern of data and from there it tends to predict. Over last few years, abundance of data have been made available in standard format and therefore it is compelling to use ML techniques to achieve better prediction. In several instances we have witnessed 98â€“99% accuracy in prediction levels using ML techniques. In Utility Industry, one of the key parameter every DISCOM would like to forecast is Peak Load. Since HT (&gt;11 kVA) and EHT (Extra High Tension &gt; 66 kVA) customers in the designated DISCOM region demand continuous power supply, reducing interruption hours and feeder outages are two most important factors draw attentions of Utility Service Providers. It has been found that accurate prediction of Peak Load Demand for a day ahead can remarkably reduce the above two parameters. In fact, knowing the peak load in advance can help in optimizing the load distribution at substation levels. While predicting peak load, we should consider weather (Temperature), time of the day (expressed in HH:MM format), Day type (Weekdays or Weekends) and finally kWH of a DT.",
    "macro_domains": []
  },
  {
    "abstract": "While the pollution is increasing resulting in green house gases and global warming, the amount of electric vehicle is predicted to increase. Most of the electric cars are design for urban use, and these vehicles need to be recharged in evening or during night, so the electric vehicles will interact with grid during this period. This process will impact the network voltage profiles and loading of grid elements. Existing Grids were designed several decades ago, so it becomes necessary to take a note of this that whether they will be able to support this increased loading, or is there a requirement of reconstruction to meet this demand. Most consumers will prefer charging during night time at their premises itself, which is LV system. And which operates at 230 V. So LV grid is taken in consideration to understand the impact of charging electric vehicles. As loads is connected to different phases, so there will be a phase asymmetry in the network. This asymmetry can be reduced by proper planning of the grid. Injection of electrical vehicle into the grid will also have an impact on power factor. As some consumers turn on or off their electric vehicles, the overall power factor changes. This has to be considered as this impact the reactive power consumption. With increase in the number of electric cars, the loading characteristics of transformer changes. For this work grid without electric vehicle and with electric vehicle is considered and Grid parameters are analysed.",
    "doi": "10.1007/978-981-16-1299-2_9",
    "author_keywords": [
      "Distribution Network",
      "Electric Vehicle (EV)",
      "Plugin Hybrid Electric Vehicle (PHEV)",
      "Power Quality",
      "Vehicle to Grid(V2G)"
    ],
    "contribution": "For this work grid without electric vehicle and with electric vehicle is considered and Grid parameters are analysed.",
    "introduction": "While the pollution is increasing resulting in green house gases and global warming, the amount of electric vehicle is predicted to increase. Most of the electric cars are design for urban use, and these vehicles need to be recharged in evening or during night, so the electric vehicles will interact with grid during this period. This process will impact the network voltage profiles and loading of grid elements. Existing Grids were designed several decades ago, so it becomes necessary to take a note of this that whether they will be able to support this increased loading, or is there a requirement of reconstruction to meet this demand. Most consumers will prefer charging during night time at their premises itself, which is LV system. And which operates at 230 V. So LV grid is taken in consideration to understand the impact of charging electric vehicles. As loads is connected to different phases, so there will be a phase asymmetry in the network. This asymmetry can be reduced by proper planning of the grid. Injection of electrical vehicle into the grid will also have an impact on power factor. As some consumers turn on or off their electric vehicles, the overall power factor changes. This has to be considered as this impact the reactive power consumption. With increase in the number of electric cars, the loading characteristics of transformer changes.",
    "macro_domains": []
  },
  {
    "abstract": "A Micro grid is a group of interconnected loads and distributed energy resources within a clearly defined electrical boundaries that act as a single controllable entity with respect to the grid. In AC and DC Micro grids multiple reverse conversions are required in an individual AC/DC loads. This may add additional losses to the system operation and make current home and office appliances more complicated. As a result, system co-ordination becomes too difficult in conventional micro grid. To overcome this drawbacks, hybrid micro grid which is an integral part of the smart grid is the most suitable solution to provide for the increasing penetration of DC-compatible energy sources, storage and loads which is recently prevalent in all Electric Power Industries. One of the most important feature of hybrid micro grid is advanced structure which can facilitate the connection of various AC, DC generation systems with optimal asset utilization and operation efficiency. It consists of both AC and DC networks connected together by multi bi-directional converters. AC sources and loads are connected to the AC networks. Similarly DC sources and loads are connected to the DC networks. Energy storage system can be connected to the DC or AC links. In this paper DC/DC converter with High frequency transformer is used to replace a normal conventional bulky transformer for bus voltage matching and galvanic isolation. Among different DHFT topologies, CLLC-TYPE has been suggested for its bidirectional power flow, seamless transition and low switching losses. DHFT open-loop control has been performed to simplify the systematic co-ordination and provide a smooth power transfer between AC/DC links. It has been designed in order to maximize the conversion efficiency and minimize the output voltage variations in different load conditions. Thus the hybrid micro grid has been simulated and analyzed using Simulink in MATLAB.",
    "doi": "10.1007/978-981-16-1299-2_3",
    "author_keywords": [
      "Bidirectional power flow",
      "CLLC converter",
      "Conversion efficiency",
      "DHFT",
      "Hybrid AC/DC micro grid"
    ],
    "contribution": "In this paper DC/DC converter with High frequency transformer is used to replace a normal conventional bulky transformer for bus voltage matching and galvanic isolation. Among different DHFT topologies, CLLC-TYPE has been suggested for its bidirectional power flow, seamless transition and low switching losses. DHFT open-loop control has been performed to simplify the systematic co-ordination and provide a smooth power transfer between AC/DC links. It has been designed in order to maximize the conversion efficiency and minimize the output voltage variations in different load conditions. Thus the hybrid micro grid has been simulated and analyzed using Simulink in MATLAB.",
    "introduction": "A Micro grid is a group of interconnected loads and distributed energy resources within a clearly defined electrical boundaries that act as a single controllable entity with respect to the grid. In AC and DC Micro grids multiple reverse conversions are required in an individual AC/DC loads. This may add additional losses to the system operation and make current home and office appliances more complicated. As a result, system co-ordination becomes too difficult in conventional micro grid. To overcome this drawbacks, hybrid micro grid which is an integral part of the smart grid is the most suitable solution to provide for the increasing penetration of DC-compatible energy sources, storage and loads which is recently prevalent in all Electric Power Industries. One of the most important feature of hybrid micro grid is advanced structure which can facilitate the connection of various AC, DC generation systems with optimal asset utilization and operation efficiency. It consists of both AC and DC networks connected together by multi bi-directional converters. AC sources and loads are connected to the AC networks. Similarly DC sources and loads are connected to the DC networks. Energy storage system can be connected to the DC or AC links.",
    "macro_domains": []
  },
  {
    "abstract": "The recent advances in electric vehicles (EVs) technologies like batteries, increase in greenhouse gas emissions and increase in fossil fuel prices have caused the more interest in using EVs. But the charging of these EVs may put an additional requirement on the existing electricity grid. Therefore, the power grid must be ready for these challenges. In order to know the type of EVs charging infrastructure required for India, the distribution feeder ratings and different charging levels should be studied. The impact of number of EVs i.e. penetration impact on Indian distribution grid will be analysed. This will lead to identification of different issues due to charging. A typical Indian distribution network will be modelled in OpenDSS. The critical infrastructure issues like voltage profile at different nodes, transformer loading, peak load and power losses will be investigated for different penetration levels. Finally, the results will be analyzed to mitigate the impacts and to suggest various measures.",
    "doi": "10.1007/978-981-16-1299-2_7",
    "author_keywords": [
      "Electric vehicle",
      "EVs charging infrastructures",
      "Loadshapes",
      "OpenDSS",
      "Supply equipment"
    ],
    "contribution": "",
    "introduction": "The recent advances in electric vehicles (EVs) technologies like batteries, increase in greenhouse gas emissions and increase in fossil fuel prices have caused the more interest in using EVs. But the charging of these EVs may put an additional requirement on the existing electricity grid. Therefore, the power grid must be ready for these challenges. In order to know the type of EVs charging infrastructure required for India, the distribution feeder ratings and different charging levels should be studied. The impact of number of EVs i.e. penetration impact on Indian distribution grid will be analysed. This will lead to identification of different issues due to charging. A typical Indian distribution network will be modelled in OpenDSS. The critical infrastructure issues like voltage profile at different nodes, transformer loading, peak load and power losses will be investigated for different penetration levels. Finally, the results will be analyzed to mitigate the impacts and to suggest various measures.",
    "macro_domains": []
  },
  {
    "abstract": "The imputation of time series traffic flow data is of great significance to the intelligent transportation, urban planning, and road emergency handling. This paper proposes a filling missing time series traffic data with Generative Adversarial Network (ST-FVGAN), which not only considers the spatio-temporal correlation and utilizes the idea of data generating of the Generative Adversarial Network, but also considers the external factors and introduces a more comprehensive loss function. Specifically, the model firstly constructs a Generator network which is composed of convolutional layer, residual block, and pixelshuffle block for the better potential distribution of the existing data, and then use the Discriminator network for the input judging. Experiments are conducted on the open-source TaxiBJ GPS dataset, and evaluated by the root mean square error (RMSE) index. The experimental results show that our model has the better accurate and reasonable performance than the traditional imputation methods.",
    "doi": "10.1080/19427867.2021.1879624",
    "author_keywords": [
      "Generative adversarial networks (GAN)",
      "spatio-temporal features processing",
      "traffic data imputation",
      "urban computing"
    ],
    "contribution": "This paper proposes a filling missing time series traffic data with Generative Adversarial Network (ST-FVGAN), which not only considers the spatio-temporal correlation and utilizes the idea of data generating of the Generative Adversarial Network, but also considers the external factors and introduces a more comprehensive loss function. Specifically, the model firstly constructs a Generator network which is composed of convolutional layer, residual block, and pixelshuffle block for the better potential distribution of the existing data, and then use the Discriminator network for the input judging. Experiments are conducted on the open-source TaxiBJ GPS dataset, and evaluated by the root mean square error (RMSE) index. The experimental results show that our model has the better accurate and reasonable performance than the traditional imputation methods.",
    "introduction": "The imputation of time series traffic flow data is of great significance to the intelligent transportation, urban planning, and road emergency handling.",
    "macro_domains": []
  },
  {
    "abstract": "Existing deep learning technologies generally learn the features of chest X-ray data generated by Generative Adversarial Networks (GAN) to diagnose COVID-19 pneumonia. However, the above methods have a critical challenge: data privacy. GAN will leak the semantic information of the training data which can be used to reconstruct the training samples by attackers, thereby this method will leak the privacy of the patient. Furthermore, for this reason, that is the limitation of the training data sample, different hospitals jointly train the model through data sharing, which will also cause privacy leakage. To solve this problem, we adopt the Federated Learning (FL) framework, a new technique being used to protect data privacy. Under the FL framework and Differentially Private thinking, we propose a Federated Differentially Private Generative Adversarial Network (FedDPGAN) to detect COVID-19 pneumonia for sustainable smart cities. Specifically, we use DP-GAN to privately generate diverse patient data in which differential privacy technology is introduced to make sure the privacy protection of the semantic information of the training dataset. Furthermore, we leverage FL to allow hospitals to collaboratively train COVID-19 models without sharing the original data. Under Independent and Identically Distributed (IID) and non-IID settings, the evaluation of the proposed model is on three types of chest X-ray (CXR)images dataset (COVID-19, normal, and normal pneumonia). A large number of truthful reports make the verification of our model can effectively diagnose COVID-19 without compromising privacy.",
    "doi": "10.1007/s10796-021-10144-6",
    "author_keywords": [
      "COVID-19",
      "Differential privacy",
      "Federated learning",
      "Generative adversarial networks",
      "Privacy protection"
    ],
    "contribution": "GAN will leak the semantic information of the training data which can be used to reconstruct the training samples by attackers, thereby this method will leak the privacy of the patient. Furthermore, for this reason, that is the limitation of the training data sample, different hospitals jointly train the model through data sharing, which will also cause privacy leakage. To solve this problem, we adopt the Federated Learning (FL) framework, a new technique being used to protect data privacy. Under the FL framework and Differentially Private thinking, we propose a Federated Differentially Private Generative Adversarial Network (FedDPGAN) to detect COVID-19 pneumonia for sustainable smart cities. Specifically, we use DP-GAN to privately generate diverse patient data in which differential privacy technology is introduced to make sure the privacy protection of the semantic information of the training dataset. Furthermore, we leverage FL to allow hospitals to collaboratively train COVID-19 models without sharing the original data. Under Independent and Identically Distributed (IID) and non-IID settings, the evaluation of the proposed model is on three types of chest X-ray (CXR)images dataset (COVID-19, normal, and normal pneumonia). A large number of truthful reports make the verification of our model can effectively diagnose COVID-19 without compromising privacy.",
    "introduction": "Existing deep learning technologies generally learn the features of chest X-ray data generated by Generative Adversarial Networks (GAN) to diagnose COVID-19 pneumonia. However, the above methods have a critical challenge: data privacy.",
    "macro_domains": []
  },
  {
    "abstract": "The timing of a disaster cannot be predicted. In particular, fires, floods, power outages, building collapses, and major accidents in local governments occur quickly and in a short time. An instantaneous fire spreads to the entire building, causing property damage as well as personal injury. From the point of view of smart city operation, one administrative goal will be achieved if the safety of citizens is maintained by using the 4th industrial technology's artificial intelligence and wired and wireless communication. In order to quickly respond to disasters in smart cities, high-rise wide-angle CCTVs that enable control from a new perspective must be able to collect image information, and continuous control using LSTM-based edge computing should be operated to quickly detect disasters and effectively respond to disasters. In this study, we discuss the disaster information acquisition design of smart city high-rise wide-angle CCTV. We explain detailed design of high-rise wide-angle CCTV installation conditions analysis, high-rise wide-angle CCTV camera selection criteria, video information network connection plan, and high-rise wide-angle CCTV installation structure construction plan. Finally, we study artificial intelligence disaster information acquisition and artificial intelligence disaster response algorithms based on GAN and LSTM, and study real-time disaster response using TensorFlow.",
    "doi": "10.7840/kics.2021.46.11.2023",
    "author_keywords": [
      "AI",
      "Algorithm",
      "Disaster Information",
      "Generative Adversarial Network",
      "High-rise CCTV",
      "Long Short Term Memory",
      "Smart City",
      "Wide-angle CCTV"
    ],
    "contribution": "In this study, we discuss the disaster information acquisition design of smart city high-rise wide-angle CCTV. We explain detailed design of high-rise wide-angle CCTV installation conditions analysis, high-rise wide-angle CCTV camera selection criteria, video information network connection plan, and high-rise wide-angle CCTV installation structure construction plan. Finally, we study artificial intelligence disaster information acquisition and artificial intelligence disaster response algorithms based on GAN and LSTM, and study real-time disaster response using TensorFlow.",
    "introduction": "The timing of a disaster cannot be predicted. In particular, fires, floods, power outages, building collapses, and major accidents in local governments occur quickly and in a short time. An instantaneous fire spreads to the entire building, causing property damage as well as personal injury. From the point of view of smart city operation, one administrative goal will be achieved if the safety of citizens is maintained by using the 4th industrial technology's artificial intelligence and wired and wireless communication. In order to quickly respond to disasters in smart cities, high-rise wide-angle CCTVs that enable control from a new perspective must be able to collect image information, and continuous control using LSTM-based edge computing should be operated to quickly detect disasters and effectively respond to disasters.",
    "macro_domains": []
  },
  {
    "abstract": "Advances in the Internet of Things have enabled the development of many smart city applications and expert systems that help citizens and authorities better understand the dynamics of the cities, and make better planning and utilisation of city resources. Smart cities are composed of complex systems that usually process and analyse big data from the Cyber, Physical, and Social worlds. Traffic event detection is an important and complex task in smart transportation modelling and management. We address this problem using semi-supervised deep learning with data of different modalities, e.g., physical sensor observations and social media data. Unlike most existing studies focusing on data of single modality, the proposed method makes use of data of multiple modalities that appear to complement and reinforce each other. Meanwhile, as the amount of labelled data in big data applications is usually extremely limited, we extend the multi-modal Generative Adversarial Network model to a semi-supervised architecture to characterise traffic events. We evaluate the model with a large, real-world dataset consisting of traffic sensor observations and social media data collected from the San Francisco Bay Area over a period of four months. The evaluation results clearly demonstrate the advantages of the proposed model in extracting and classifying traffic events.",
    "doi": "10.1016/j.eswa.2021.114939",
    "author_keywords": [
      "Deep learning",
      "Generative adversarial network",
      "Multi-modal learning",
      "Semi-supervised learning",
      "Smart transportation",
      "Traffic event detection"
    ],
    "contribution": "We address this problem using semi-supervised deep learning with data of different modalities, e.g., physical sensor observations and social media data. Unlike most existing studies focusing on data of single modality, the proposed method makes use of data of multiple modalities that appear to complement and reinforce each other. Meanwhile, as the amount of labelled data in big data applications is usually extremely limited, we extend the multi-modal Generative Adversarial Network model to a semi-supervised architecture to characterise traffic events. We evaluate the model with a large, real-world dataset consisting of traffic sensor observations and social media data collected from the San Francisco Bay Area over a period of four months. The evaluation results clearly demonstrate the advantages of the proposed model in extracting and classifying traffic events.",
    "introduction": "Advances in the Internet of Things have enabled the development of many smart city applications and expert systems that help citizens and authorities better understand the dynamics of the cities, and make better planning and utilisation of city resources. Smart cities are composed of complex systems that usually process and analyse big data from the Cyber, Physical, and Social worlds. Traffic event detection is an important and complex task in smart transportation modelling and management.",
    "macro_domains": []
  },
  {
    "abstract": "When considering the new standards of a smart city and its power systems, special focus is given to the power transformer and its control and monitoring systems as well as load management. After all, at the moment this link is most vulnerable to the factors of influence on the part of the energy source and its quality on the one hand and reasonable consumers of electricity on the other. As a result of working with the increasing load of components of a smart city, the probability of critical damage to the transformer and even its failure increases. Recent research is mostly based on the analysis of the spectral influence of current and voltage of smart network consumers on the distribution transformer. The order of definition of components of active and reactive power of the distributive transformer in the loading mode taking into account influence of nonlinear consumers of Smart Grid is offered as indicators of the state of the transformer winding. On the laboratory equipment performed modeling of the influence of Smart Grid users on the operation of a single-phase distribution transformer. The primary sequence of the experiment to study the energy performance of the distribution transformer in the mode of loading by nonlinear Smart Grid consumers has been developed. For this purpose, a model of a distribution transformer was built and the indicators of the harmonic spectra of the active and reactive power of the controlled windings were determined for all harmonics to be determined. The influence of DG on the harmonic power spectrum and its negative influence on the manifestation of harmonic monitors of components, namely harmonic components of 6th and 8th orders, is noted. The results of the study can be used as a tool that can serve as a mathematical assessment of the system of calculation and development of fault monitors based on the spectrally analyzed flow of power, current and voltage.",
    "doi": "10.1109/UKRCON53503.2021.9575647",
    "author_keywords": [
      "distribution transformer Smart city",
      "monitoring",
      "Smart Grid"
    ],
    "contribution": "The results of the study can be used as a tool that can serve as a mathematical assessment of the system of calculation and development of fault monitors based on the spectrally analyzed flow of power, current and voltage.",
    "introduction": "When considering the new standards of a smart city and its power systems, special focus is given to the power transformer and its control and monitoring systems as well as load management. After all, at the moment this link is most vulnerable to the factors of influence on the part of the energy source and its quality on the one hand and reasonable consumers of electricity on the other. As a result of working with the increasing load of components of a smart city, the probability of critical damage to the transformer and even its failure increases. Recent research is mostly based on the analysis of the spectral influence of current and voltage of smart network consumers on the distribution transformer. The order of definition of components of active and reactive power of the distributive transformer in the loading mode taking into account influence of nonlinear consumers of Smart Grid is offered as indicators of the state of the transformer winding. On the laboratory equipment performed modeling of the influence of Smart Grid users on the operation of a single-phase distribution transformer. The primary sequence of the experiment to study the energy performance of the distribution transformer in the mode of loading by nonlinear Smart Grid consumers has been developed. For this purpose, a model of a distribution transformer was built and the indicators of the harmonic spectra of the active and reactive power of the controlled windings were determined for all harmonics to be determined. The influence of DG on the harmonic power spectrum and its negative influence on the manifestation of harmonic monitors of components, namely harmonic components of 6th and 8th orders, is noted.",
    "macro_domains": []
  },
  {
    "abstract": "Although intelligent load forecasting is essential for optimal energy management (EM) in smart cities, there is a lack of current research exploring EM in well-regulated Internet-of-Things (IoT) networks. This article develops a new deep learning (DL) model for efficient forecasting of short-term energy consumption while maintaining effective communication between energy providers and users. The proposed Energy-Net stack comprises multiple stacked spatiotemporal modules, where each module consists of a temporal transformer (TT) submodule and a spatial transformer (ST) submodule. The TT models the temporal relationships in load data; and the ST submodule extracts hidden spatial information by integrating convolutional layers and includes an improved self-attention mechanism. The experimental evaluation on IHPEC and independent system operator New England (ISO-NE) data set demonstrates the superiority of Energy-Net over recent cutting-edge DL models with root mean-square error (RMSE) of 0.354 and 0.535, respectively. The computational complexity of Energy-Net is appropriate for dependable resource-constrained IoT devices (i.e., fog nodes or edge nodes) linked to a joint IoT-cloud server that interacts with connected smart grids to handle EM tasks.",
    "doi": "10.1109/JIOT.2021.3063677",
    "author_keywords": [
      "Deep learning (DL)",
      "edge computing",
      "Internet of Things (IoT)",
      "load forecasting (LF)",
      "transformers"
    ],
    "contribution": "This article develops a new deep learning (DL) model for efficient forecasting of short-term energy consumption while maintaining effective communication between energy providers and users. The proposed Energy-Net stack comprises multiple stacked spatiotemporal modules, where each module consists of a temporal transformer (TT) submodule and a spatial transformer (ST) submodule. The TT models the temporal relationships in load data; and the ST submodule extracts hidden spatial information by integrating convolutional layers and includes an improved self-attention mechanism. The experimental evaluation on IHPEC and independent system operator New England (ISO-NE) data set demonstrates the superiority of Energy-Net over recent cutting-edge DL models with root mean-square error (RMSE) of 0.354 and 0.535, respectively. The computational complexity of Energy-Net is appropriate for dependable resource-constrained IoT devices (i.e., fog nodes or edge nodes) linked to a joint IoT-cloud server that interacts with connected smart grids to handle EM tasks.",
    "introduction": "Although intelligent load forecasting is essential for optimal energy management (EM) in smart cities, there is a lack of current research exploring EM in well-regulated Internet-of-Things (IoT) networks.",
    "macro_domains": []
  },
  {
    "abstract": "The ever-expanding applications of mobile crowdsensing have made scalable environment sensing possible by exploiting the power of ubiquitous smart devices. Nevertheless, the implementation of sensing applications in urban scale meets serious challenges in terms of sensing costs and quality. For example, data sparsity will arise due to sensing ability and cost, and the measurements could contain noise or errors. Therefore, missing data inference with low-quality measurements is critical. To tackle these challenges, we design a low-cost crowdsensing system by missing data inference incorporating with active sensing grids selection. Specifically, an adversarial autoencoder (AAE)-based scheme is proposed for missing data inference. This model applies VAE to learn latent variables and generates full data and further utilizes the adversarial nets to play a min-max game with the autoencoder. Furthermore, an active learning-based method is designed to iteratively select sensing grids to further reduce the cost. The proposed scheme can handle large missing rate, both random and block missing patterns, and is robust against measurement noise. Comprehensive experiments based on three data sets are conducted to evaluate the effectiveness of the proposed system.",
    "doi": "10.1109/JIOT.2021.3060815",
    "author_keywords": [
      "Active learning (AL)",
      "adversarial autoencoder (AAE)",
      "mobile crowdsensing (MCS)",
      "smart city"
    ],
    "contribution": "",
    "introduction": "The ever-expanding applications of mobile crowdsensing have made scalable environment sensing possible by exploiting the power of ubiquitous smart devices. Nevertheless, the implementation of sensing applications in urban scale meets serious challenges in terms of sensing costs and quality. For example, data sparsity will arise due to sensing ability and cost, and the measurements could contain noise or errors. Therefore, missing data inference with low-quality measurements is critical. To tackle these challenges, we design a low-cost crowdsensing system by missing data inference incorporating with active sensing grids selection. Specifically, an adversarial autoencoder (AAE)-based scheme is proposed for missing data inference. This model applies VAE to learn latent variables and generates full data and further utilizes the adversarial nets to play a min-max game with the autoencoder. Furthermore, an active learning-based method is designed to iteratively select sensing grids to further reduce the cost. The proposed scheme can handle large missing rate, both random and block missing patterns, and is robust against measurement noise. Comprehensive experiments based on three data sets are conducted to evaluate the effectiveness of the proposed system.",
    "macro_domains": []
  },
  {
    "abstract": "The low-voltage distribution network field wiring is very complicated and there are many changes in the relationship between households and changes, which brings great difficulties to the topology identification and line loss management of the transformer area. This paper proposed an intelligence low-voltage power system based on edge computing in order to improve the automation level of low-voltage distribution area, and to solve problems such as identification inaccuracy of topological relations in the low-voltage distribution area at present and singleness of condition monitoring parameters in station area, etc. The terminal is implanted with two edge calculation models based on artificial intelligence technology, which can realize topology identification and state parameters monitoring. The multistate parameter monitoring and decision analysis provides functions of event monitoring and early warning of abnormal state for the low voltage distribution system. In the topology identification analysis, the Markov random field was applied to establish the mathematical model of non-oriented graph and the joint probability distribution to describe the correlation between the nodes in the distribution network, thus realizing topology-relation identification of nodes in respective layers of the distribution area. On this basis, taking a low-voltage station as an example, a case analysis was undertaken. It was verified via the effectiveness and accuracy of the intelligence low-voltage station, which lays a foundation for research of the intelligent and fine management of the low voltage station system.",
    "doi": "10.1088/1742-6596/1972/1/012050",
    "author_keywords": null,
    "contribution": "This paper proposed an intelligence low-voltage power system based on edge computing in order to improve the automation level of low-voltage distribution area, and to solve problems such as identification inaccuracy of topological relations in the low-voltage distribution area at present and singleness of condition monitoring parameters in station area, etc. The terminal is implanted with two edge calculation models based on artificial intelligence technology, which can realize topology identification and state parameters monitoring. The multistate parameter monitoring and decision analysis provides functions of event monitoring and early warning of abnormal state for the low voltage distribution system. In the topology identification analysis, the Markov random field was applied to establish the mathematical model of non-oriented graph and the joint probability distribution to describe the correlation between the nodes in the distribution network, thus realizing topology-relation identification of nodes in respective layers of the distribution area. On this basis, taking a low-voltage station as an example, a case analysis was undertaken. It was verified via the effectiveness and accuracy of the intelligence low-voltage station, which lays a foundation for research of the intelligent and fine management of the low voltage station system.",
    "introduction": "The low-voltage distribution network field wiring is very complicated and there are many changes in the relationship between households and changes, which brings great difficulties to the topology identification and line loss management of the transformer area.",
    "macro_domains": []
  },
  {
    "abstract": "With the continuous changes in the user-side power environment, the low-voltage distribution network has become more and more complex, which brings great challenges to the line loss management and topology identification of the transformer area. To solve the shortcomings of traditional particle swarm optimization such as poor ergodicity of population initialization and easy to fall into premature convergence, this paper proposed a K-means clustering analysis algorithm based on GA-CPSO. First, on the basis of the traditional particle swarm algorithm, the chaotic shrinkage factor was introduced and the parameters were optimized. Secondly, the genetic algorithm was combined with the chaotic particle swarm optimization algorithm, the crossover and mutation operations of the genetic algorithm were used to establish an information exchange mechanism between particles, and it was combined with the K-means clustering method. The simulation results on the test benchmark function show that the improved particle swarm optimization algorithm in this paper has significantly improved the search speed and optimization accuracy. Finally, taking an actual transformer area as an example, the method was applied to the transformer area topology recognition analysis. Using the electrical parameters such as voltage, current, and active power obtained from the monitoring terminal as sample data, a simulation analysis was carried out to verify the effectiveness and feasibility of the algorithm. The performance parameters of different algorithms had been compared and analyzed through multiple experiments, and it was proved that this method can effectively improve the accuracy of platform topology recognition, and has strong practicability and generalization.",
    "doi": "10.1088/1742-6596/1972/1/012049",
    "author_keywords": null,
    "contribution": "To solve the shortcomings of traditional particle swarm optimization such as poor ergodicity of population initialization and easy to fall into premature convergence, this paper proposed a K-means clustering analysis algorithm based on GA-CPSO. First, on the basis of the traditional particle swarm algorithm, the chaotic shrinkage factor was introduced and the parameters were optimized. Secondly, the genetic algorithm was combined with the chaotic particle swarm optimization algorithm, the crossover and mutation operations of the genetic algorithm were used to establish an information exchange mechanism between particles, and it was combined with the K-means clustering method. The simulation results on the test benchmark function show that the improved particle swarm optimization algorithm in this paper has significantly improved the search speed and optimization accuracy. Finally, taking an actual transformer area as an example, the method was applied to the transformer area topology recognition analysis. Using the electrical parameters such as voltage, current, and active power obtained from the monitoring terminal as sample data, a simulation analysis was carried out to verify the effectiveness and feasibility of the algorithm. The performance parameters of different algorithms had been compared and analyzed through multiple experiments, and it was proved that this method can effectively improve the accuracy of platform topology recognition, and has strong practicability and generalization.",
    "introduction": "With the continuous changes in the user-side power environment, the low-voltage distribution network has become more and more complex, which brings great challenges to the line loss management and topology identification of the transformer area.",
    "macro_domains": []
  },
  {
    "abstract": "The low-voltage distribution network field wiring is very complicated and there are many changes in the relationship between households and changes, which brings great difficulties to the topology identification and line loss management of the transformer area. Aiming at the problems of low-voltage distribution areas physical topology recognition method based on distorted current signal and big data analysis in safety, recognition accuracy, and recognition efficiency, a method for recognizing the physical topology of the low-voltage distribution area based on pulse current characteristics fusion analysis was proposed. The Hilbert-Huang transform method was used to extract the characteristics of the current signal. The Space-time characteristic of charge method based on edge computing was used to realize the verification of low-voltage distribution area topology results. HPLC communication technology and measurement technology were combined to develop a low-voltage distribution area topology recognition monitoring terminal. The monitoring terminal was installed at the key nodes of the low-voltage distribution area such as low-voltage outlet cabinets, branch boxes and meter boxes. The monitoring terminal receives the topology recognition command of concentrator and main distribution area through the HPLC communication channel, uploads the topology recognition results, draws physical topology map of low-voltage distribution area in the main distribution area, and realizes the hierarchical measurement of low-voltage distribution area by the measurement function. The pilot operation of the on-site high-quality distribution area has proven that the monitoring terminal using the low-voltage distribution area physical topology recognition method based on the pulse current feature fusion analysis can map the low-voltage distribution area physical topology safely, quickly and accurately. Furthermore, it can provide strong support for the fine management of the low-voltage distribution area.",
    "doi": "10.1088/1742-6596/1972/1/012013",
    "author_keywords": null,
    "contribution": "",
    "introduction": "The low-voltage distribution network field wiring is very complicated and there are many changes in the relationship between households and changes, which brings great difficulties to the topology identification and line loss management of the transformer area. Aiming at the problems of low-voltage distribution areas physical topology recognition method based on distorted current signal and big data analysis in safety, recognition accuracy, and recognition efficiency, a method for recognizing the physical topology of the low-voltage distribution area based on pulse current characteristics fusion analysis was proposed. The Hilbert-Huang transform method was used to extract the characteristics of the current signal. The Space-time characteristic of charge method based on edge computing was used to realize the verification of low-voltage distribution area topology results. HPLC communication technology and measurement technology were combined to develop a low-voltage distribution area topology recognition monitoring terminal. The monitoring terminal was installed at the key nodes of the low-voltage distribution area such as low-voltage outlet cabinets, branch boxes and meter boxes. The monitoring terminal receives the topology recognition command of concentrator and main distribution area through the HPLC communication channel, uploads the topology recognition results, draws physical topology map of low-voltage distribution area in the main distribution area, and realizes the hierarchical measurement of low-voltage distribution area by the measurement function. The pilot operation of the on-site high-quality distribution area has proven that the monitoring terminal using the low-voltage distribution area physical topology recognition method based on the pulse current feature fusion analysis can map the low-voltage distribution area physical topology safely, quickly and accurately. Furthermore, it can provide strong support for the fine management of the low-voltage distribution area.",
    "macro_domains": []
  },
  {
    "abstract": "Time series classification (TSC) is widely used in various real-world applications such as human activity recognition, smart city governance, etc. Unfortunately, due to different reasons, only part of time series could be collected which may obviously degrade the performance of time series classifiers. To alleviate this problem, time series augmentation aims to generate synthetic time series by learning useful features from collected time series. As the popular generative model, generative adversarial networks (GAN) is regarded as a promising model for time series augmentation. However, applying GAN to the time series data suffers from a challenge in which the generated instances hold low quality but the model has gotten saturation. In this paper, for time series augmentation, we proposed TSA-GAN which is a robust GAN model with a self-adaptive recovering strategy to solve this problem. On 85 datasets of the UCR 2015 archive, our proposed TSA-GAN helps time series classifiers achieve performance improvements ranging from 8.3% to 12.5%, which is far better than the baseline.",
    "doi": "10.1109/IJCNN52387.2021.9534001",
    "author_keywords": [
      "GANs",
      "time series augmentation",
      "training saturation"
    ],
    "contribution": "In this paper, for time series augmentation, we proposed TSA-GAN which is a robust GAN model with a self-adaptive recovering strategy to solve this problem. On 85 datasets of the UCR 2015 archive, our proposed TSA-GAN helps time series classifiers achieve performance improvements ranging from 8.3% to 12.5%, which is far better than the baseline.",
    "introduction": "Time series classification (TSC) is widely used in various real-world applications such as human activity recognition, smart city governance, etc. Unfortunately, due to different reasons, only part of time series could be collected which may obviously degrade the performance of time series classifiers. To alleviate this problem, time series augmentation aims to generate synthetic time series by learning useful features from collected time series. As the popular generative model, generative adversarial networks (GAN) is regarded as a promising model for time series augmentation. However, applying GAN to the time series data suffers from a challenge in which the generated instances hold low quality but the model has gotten saturation.",
    "macro_domains": []
  },
  {
    "abstract": "In smart cities, violence event detection is critical to ensure city safety. Several studies have been done on this topic with a focus on 2d-Convolutional Neural Network (2d-CNN) to detect spatial features from each frame, followed by one of the Recurrent Neural Networks (RNN) variants as a temporal features learning method. On the other hand, the transformer network has achieved a great result in many areas. The bottleneck for transformers is the need for large data set to achieve good results. In this work, we propose a data-efficient video transformer (DeVTr) based on the transformer network as a Spatio-temporal learning method with a pre-trained 2d-Convolutional neural network (2d-CNN) as an embedding layer for the input data. The model has been trained and tested on the Real-life violence dataset (RLVS) and achieved an accuracy of 96.25%. A comparison of the result for the suggested method with previous techniques illustrated that the suggested method provides the best result among all the other studies for violence event detection.",
    "doi": "10.1109/COMNETSAT53002.2021.9530829",
    "author_keywords": [
      "CNN",
      "Deep Learning",
      "RLVS",
      "Smart Cities",
      "Spatio-temporal",
      "Transformer",
      "Video Classification",
      "violence Detection"
    ],
    "contribution": "In this work, we propose a data-efficient video transformer (DeVTr) based on the transformer network as a Spatio-temporal learning method with a pre-trained 2d-Convolutional neural network (2d-CNN) as an embedding layer for the input data. The model has been trained and tested on the Real-life violence dataset (RLVS) and achieved an accuracy of 96.25%. A comparison of the result for the suggested method with previous techniques illustrated that the suggested method provides the best result among all the other studies for violence event detection.",
    "introduction": "In smart cities, violence event detection is critical to ensure city safety. Several studies have been done on this topic with a focus on 2d-Convolutional Neural Network (2d-CNN) to detect spatial features from each frame, followed by one of the Recurrent Neural Networks (RNN) variants as a temporal features learning method. On the other hand, the transformer network has achieved a great result in many areas. The bottleneck for transformers is the need for large data set to achieve good results.",
    "macro_domains": []
  },
  {
    "abstract": "The smart city makes use of information technology to integrate city systems and functions to optimize city management and services. In this paper, we treat the smart city as a Cyber-Physical-Social System (CPSS), which is a kind of heterogeneous complex network system. Since information diffusion is fundamental to complex network analysis, we would like to summarize information diffusion in CPSS, including features of information diffusion, its application in the field of smart city, and critical technologies of information diffusion modeling and analysis. Finally, we point out open research issues, challenges, and put forward the possible future direction for research of information diffusion in smart city CPSS.",
    "doi": "10.1016/j.neucom.2020.08.089",
    "author_keywords": [
      "CPSS",
      "Information diffusion",
      "Smart city"
    ],
    "contribution": "In this paper, we treat the smart city as a Cyber-Physical-Social System (CPSS), which is a kind of heterogeneous complex network system. Since information diffusion is fundamental to complex network analysis, we would like to summarize information diffusion in CPSS, including features of information diffusion, its application in the field of smart city, and critical technologies of information diffusion modeling and analysis. Finally, we point out open research issues, challenges, and put forward the possible future direction for research of information diffusion in smart city CPSS.",
    "introduction": "The smart city makes use of information technology to integrate city systems and functions to optimize city management and services.",
    "macro_domains": []
  },
  {
    "abstract": "A renewable energy power system design for electric boats is proposed. The design uses wind energy as the only power source in order to operate the AC motor. The design consists of wind turbines, synchronous condenser, asynchronous generator, 72-pulse AC to DC rectifier that contains twelve transformers and twelve diode bridges (each bridge contains six diodes) for enhancing the output DC voltage, DC voltage regulator, boost converter, DC to AC inverter, and three-phase electric motor. The proposed design is simulated using Simulink to show the performance.",
    "doi": "10.1109/ICSGSC52434.2021.9490446",
    "author_keywords": [
      "autotransformer",
      "MATLAB",
      "multi-pulse diode rectifier",
      "SIMULINK",
      "total harmic distortion reduction"
    ],
    "contribution": "",
    "introduction": "A renewable energy power system design for electric boats is proposed. The design uses wind energy as the only power source in order to operate the AC motor. The design consists of wind turbines, synchronous condenser, asynchronous generator, 72-pulse AC to DC rectifier that contains twelve transformers and twelve diode bridges (each bridge contains six diodes) for enhancing the output DC voltage, DC voltage regulator, boost converter, DC to AC inverter, and three-phase electric motor. The proposed design is simulated using Simulink to show the performance.",
    "macro_domains": []
  },
  {
    "abstract": "Combining Natural Language with Vision represents a unique and interesting challenge in the domain of Artificial Intelligence. The AI City Challenge Track 5 for Natural Language-Based Vehicle Retrieval focuses on the problem of combining visual and textual information, applied to a smart-city use case. In this paper, we present All You Can Embed (AYCE), a modular solution to correlate single-vehicle tracking sequences with natural language. The main building blocks of the proposed architecture are (i) BERT to provide an embedding of the textual descriptions, (ii) a convolutional backbone along with a Transformer model to embed the visual information. For the training of the retrieval model, a variation of the Triplet Margin Loss is proposed to learn a distance measure between the visual and language embeddings. The code is publicly available at https://github.com/cscribano/AYCE_2021.",
    "doi": "10.1109/CVPRW53098.2021.00481",
    "author_keywords": null,
    "contribution": "In this paper, we present All You Can Embed (AYCE), a modular solution to correlate single-vehicle tracking sequences with natural language. The main building blocks of the proposed architecture are (i) BERT to provide an embedding of the textual descriptions, (ii) a convolutional backbone along with a Transformer model to embed the visual information. For the training of the retrieval model, a variation of the Triplet Margin Loss is proposed to learn a distance measure between the visual and language embeddings. The code is publicly available at https://github.com/cscribano/AYCE_2021.",
    "introduction": "Combining Natural Language with Vision represents a unique and interesting challenge in the domain of Artificial Intelligence. The AI City Challenge Track 5 for Natural Language-Based Vehicle Retrieval focuses on the problem of combining visual and textual information, applied to a smart-city use case.",
    "macro_domains": []
  },
  {
    "abstract": "With the massive deployment of 5G cellular infrastructures, traffic prediction has become an indispensable part of the cellular resource management system in order to provide reliable and fast communication services that can meet the increasing quality-of-service requirements of smart city. A promising approach for handling this problem is to introduce intelligent methods to implement a highly effective and efficient cellular traffic prediction model. Meanwhile, integrating the multiaccess edge computing framework in 5G cellular networks facilitates the application of intelligent traffic prediction models by enabling their implementation at the network edge. However, the data shortage and privacy issues may still be obstacles for training a robust and accurate prediction model at the edge. To address these issues, we propose a data-augmentation-based cellular traffic prediction model (ctGAN-S2S), where an effective data augmentation submodel based on generative adversarial networks is proposed to improve the prediction performance while protecting data privacy, and a long-short-term-memory-based sequence-to-sequence submodel is used to achieve the flexible multistep cellular traffic prediction. The experimental results on a real-world city-scale cellular traffic dataset reveal that our ctGAN-S2S model achieves up to 48.49% improvement of the prediction accuracy compared to four typical reference models.",
    "doi": "10.1109/TII.2020.3009159",
    "author_keywords": [
      "Cellular networks",
      "data augmentation",
      "neural networks",
      "smart city",
      "time-series prediction"
    ],
    "contribution": "To address these issues, we propose a data-augmentation-based cellular traffic prediction model (ctGAN-S2S), where an effective data augmentation submodel based on generative adversarial networks is proposed to improve the prediction performance while protecting data privacy, and a long-short-term-memory-based sequence-to-sequence submodel is used to achieve the flexible multistep cellular traffic prediction. The experimental results on a real-world city-scale cellular traffic dataset reveal that our ctGAN-S2S model achieves up to 48.49% improvement of the prediction accuracy compared to four typical reference models.",
    "introduction": "With the massive deployment of 5G cellular infrastructures, traffic prediction has become an indispensable part of the cellular resource management system in order to provide reliable and fast communication services that can meet the increasing quality-of-service requirements of smart city. A promising approach for handling this problem is to introduce intelligent methods to implement a highly effective and efficient cellular traffic prediction model. Meanwhile, integrating the multiaccess edge computing framework in 5G cellular networks facilitates the application of intelligent traffic prediction models by enabling their implementation at the network edge. However, the data shortage and privacy issues may still be obstacles for training a robust and accurate prediction model at the edge.",
    "macro_domains": []
  },
  {
    "abstract": "Ride-hailing services have gained tremendous importance in social life today, and the amount of resources involved have been hiking up. Ride-request data has been crucial in the research of improving ride-hailing efficiency and minimizing the cost. This work aims to model human mobility patterns to generate realistic ride-requests, addressing the prevailing problem of lack of historical training data and realistic synthetic data for different hypothetical scenarios. Synthetic generation also inherently carries anonymity. In particular, our work focuses on modeling both spatial and temporal distributions jointly for ride-hailing services. A Ride-Request Wasserstein Generative Adversarial Network (RR-WGAN) is proposed to generate plausible pick-up and drop-off geolocations. The generated ride-requests are extensively evaluated under a wide range of criteria we design, giving a comprehensive understanding of how the model performs. The proposed approach has achieved better performance than state-of-the-art methods in most scenarios. We believe this approach could provide value for ride-hailing service providers, research communities, and policy-makers.",
    "doi": "10.1109/SCSP52043.2021.9447372",
    "author_keywords": null,
    "contribution": "Ride-request data has been crucial in the research of improving ride-hailing efficiency and minimizing the cost. This work aims to model human mobility patterns to generate realistic ride-requests, addressing the prevailing problem of lack of historical training data and realistic synthetic data for different hypothetical scenarios. Synthetic generation also inherently carries anonymity. In particular, our work focuses on modeling both spatial and temporal distributions jointly for ride-hailing services. A Ride-Request Wasserstein Generative Adversarial Network (RR-WGAN) is proposed to generate plausible pick-up and drop-off geolocations. The generated ride-requests are extensively evaluated under a wide range of criteria we design, giving a comprehensive understanding of how the model performs. The proposed approach has achieved better performance than state-of-the-art methods in most scenarios. We believe this approach could provide value for ride-hailing service providers, research communities, and policy-makers.",
    "introduction": "Ride-hailing services have gained tremendous importance in social life today, and the amount of resources involved have been hiking up.",
    "macro_domains": []
  },
  {
    "abstract": "These days, safe and hygiene disposal of waste via dustbins in smart cities needs a centralized and monitored system. This system monitors various bins used for rubbish and garbage collectionextent is also informed inside these garbage bins via centralized online Application. For this the system the bins are fitted specially placed ultrasonic sensors to determine the level and depth of rubbish. It incorporates an AVR based microcontroller, GSM Module, Wi-Fi modem, a buzzer for alert and LCD screen for viewing data. The voltage support is given by a 12V transformer. To determine the display status and the extent to which the rubbish bin is loaded an LCD screen is used. These LCD screens are used inside the rubbish bins. To point out the condition however the web application is designed which is used to monitor the garbage or rubbish bins. The geographical view of rubbish bins can be obtained by the web page and also these web pages indicate the colored rubbish that they can highlight",
    "doi": "10.1088/1742-6596/1916/1/012171",
    "author_keywords": null,
    "contribution": "This system monitors various bins used for rubbish and garbage collectionextent is also informed inside these garbage bins via centralized online Application. For this the system the bins are fitted specially placed ultrasonic sensors to determine the level and depth of rubbish. It incorporates an AVR based microcontroller, GSM Module, Wi-Fi modem, a buzzer for alert and LCD screen for viewing data. The voltage support is given by a 12V transformer. To determine the display status and the extent to which the rubbish bin is loaded an LCD screen is used. These LCD screens are used inside the rubbish bins. To point out the condition however the web application is designed which is used to monitor the garbage or rubbish bins. The geographical view of rubbish bins can be obtained by the web page and also these web pages indicate the colored rubbish that they can highlight",
    "introduction": "These days, safe and hygiene disposal of waste via dustbins in smart cities needs a centralized and monitored system.",
    "macro_domains": []
  },
  {
    "abstract": "Video Synopsis is a smart and efficient solution to summarize a long duration of surveillance video into short. Most of the video synopsis techniques are not suitable to address complex situations like changes in illumination, dynamic background, camera jitter, etc. These techniques firmly depend on the preprocessing results of foreground extraction and multiple objects tracking. Further, the optimization process is a vital phase for the decrement of collision rate among moving objects, where the widely used Simulated Annealing (SA) usually suffers from the issue of slow convergence rate with a high computational overhead. Taking these aforementioned facts into account for feature extraction, we formulate a foreground extraction scheme exploring the concept of multi-frame and multi-scale in Generative Adversarial Network (mFS-GANs). Further, an optimization algorithm is proposed through the hybridization of SA and Grey Wolf Optimizer (GWO), named as, HGWOSA to ensure global optimal result with a low computing overhead. The performance of the proposed scheme is evaluated through extensive simulations and compared with that of the benchmark schemes. The experiments are carried out using some standard surveillance video dataset (ChangeDetection.Net, MIT Surveillance Dataset, and UMN Dataset) and one self-generated surveillance video at IIIT Bhubaneswar. Overall analysis and experimental evaluations demonstrate that our proposed scheme outperforms the other competing schemes in terms of both the quantitative and qualitative measures. Finally, the proposed model can be substantially employed in the generation of off-line video synopsis, which is potentially applicable to video surveillance applications for smart cities.",
    "doi": "10.1016/j.dsp.2021.102988",
    "author_keywords": [
      "Deep learning",
      "Generative adversarial networks (GANs)",
      "Grey wolf optimizer (GWO)",
      "Simulated annealing (SA)",
      "Video synopsis"
    ],
    "contribution": "",
    "introduction": "Video Synopsis is a smart and efficient solution to summarize a long duration of surveillance video into short. Most of the video synopsis techniques are not suitable to address complex situations like changes in illumination, dynamic background, camera jitter, etc. These techniques firmly depend on the preprocessing results of foreground extraction and multiple objects tracking. Further, the optimization process is a vital phase for the decrement of collision rate among moving objects, where the widely used Simulated Annealing (SA) usually suffers from the issue of slow convergence rate with a high computational overhead. Taking these aforementioned facts into account for feature extraction, we formulate a foreground extraction scheme exploring the concept of multi-frame and multi-scale in Generative Adversarial Network (mFS-GANs). Further, an optimization algorithm is proposed through the hybridization of SA and Grey Wolf Optimizer (GWO), named as, HGWOSA to ensure global optimal result with a low computing overhead. The performance of the proposed scheme is evaluated through extensive simulations and compared with that of the benchmark schemes. The experiments are carried out using some standard surveillance video dataset (ChangeDetection.Net, MIT Surveillance Dataset, and UMN Dataset) and one self-generated surveillance video at IIIT Bhubaneswar. Overall analysis and experimental evaluations demonstrate that our proposed scheme outperforms the other competing schemes in terms of both the quantitative and qualitative measures. Finally, the proposed model can be substantially employed in the generation of off-line video synopsis, which is potentially applicable to video surveillance applications for smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "Aiming at the current situation of large power consumption of terminal, slow transmission speed, difficulty in upgrading and maintenance, and no security encryption in the establishment of the access network from the macro base station to the power load control management terminal using 230MHz digital radio wireless technology, a network based on 5G communication technology is proposed. The 5G embedded terminal is connected to the 5G cell base station to realize the dedicated transformer collection terminal and the power load control management terminal to connect to the main station of the power load management system. At the same time, the secure encryption terminal is used to cooperate with the secure access gateway to achieve the security encryption goal of power business data. The test results show that the upgrade and transformation scheme based on 5G embedded terminals and security encryption proposed in this paper has great advantages compared with 230MHz digital radio terminal communication, effectively reducing terminal power consumption, increasing terminal communication speed, and ensuring the data security. This application can be promoted and used in the field of power load control of the State Grid Corporation of China.",
    "doi": "10.1109/ICBAIE52039.2021.9389873",
    "author_keywords": [
      "230MHz",
      "5G",
      "embedded",
      "encryption",
      "smart city",
      "terminal"
    ],
    "contribution": "The test results show that the upgrade and transformation scheme based on 5G embedded terminals and security encryption proposed in this paper has great advantages compared with 230MHz digital radio terminal communication, effectively reducing terminal power consumption, increasing terminal communication speed, and ensuring the data security. This application can be promoted and used in the field of power load control of the State Grid Corporation of China.",
    "introduction": "Aiming at the current situation of large power consumption of terminal, slow transmission speed, difficulty in upgrading and maintenance, and no security encryption in the establishment of the access network from the macro base station to the power load control management terminal using 230MHz digital radio wireless technology, a network based on 5G communication technology is proposed. The 5G embedded terminal is connected to the 5G cell base station to realize the dedicated transformer collection terminal and the power load control management terminal to connect to the main station of the power load management system. At the same time, the secure encryption terminal is used to cooperate with the secure access gateway to achieve the security encryption goal of power business data.",
    "macro_domains": []
  },
  {
    "abstract": "Objective: Remote sensing building object segmentation is one of the important applications in image processing, which plays a vital role in smart city planning and urban change detection. However, building objects in remote sensing images have many complex characteristics, such as variable sizes, dense distributions, diverse topological shapes, complex backgrounds, and presence of occlusions and shadows. Traditional building segmentation algorithms are mainly based on manually designed features such as shapes, edges, and shadow features. These features are shallow features of the building target and cannot well express high-level semantic information, resulting in low recognition accuracy. By contrast, deep convolutional networks show excellent performance in pixel-level classification of natural images. Various fully convolutional network based image segmentation models have been continuously proposed. Most of these models use deconvolution or bilinear interpolation after feature extraction. Feature upsampling and pixel-by-pixel classification are used to segment the input image. The deep features of the building are extracted using highly nonlinear mapping and a large amount of data training, which overcomes the shortcomings of traditional algorithms. However, upsampling cannot completely compensate the information loss caused by repeated convolution and pooling operations in the deep convolutional network model. Therefore, the prediction results are relatively rough, such as small target misclassification, inaccurate boundaries, and other issues. In the field of remote sensing, public data sets are few. Training excellent deep convolutional networks is difficult, and the robustness of the network needs to be further improved. Aiming at the above problems, this paper proposes a conditional generative adversarial network (Ra-CGAN) with multilevel channel attention mechanism to segment remote sensing building objects. Method: A generative model with a multilevel channel attention mechanism is first built. The model is based on a coding and decoding structure that solves small target misses by fusing deep semantics and shallow details with attention. Second, a discriminative network is built and used to distinguish whether the input comes from the real label map or the segmentation map generated by the model. The segmentation result (accuracy and smoothness) is improved by correcting the difference between the two maps. The downsampling method without pooling is used in the discriminator to enhance the propagation of the gradient. Finally, the generated model and the discriminant model are alternately confronted for training through the constraint of the conditional variable of the labelled image. Learning the higher-order data distribution characteristics results in more continuity for the target space. The loss function uses a hybrid loss function, which comes from the cross-entropy loss function brought by the generated map and the real label map in the generation mode. The discriminator predicts the generated image as the loss value brought by the real label image. Experiments are performed on the WHU Building Dataset and Satellite Dataset II datasets. The first dataset has a dense building with many types and accurate labels, and can provide comprehensive, representative evaluation capabilities for the model. Another dataset with a higher segmentation difficulty is used to verify the robustness and scalability of the model. The lighting information and background information of the building are more complex than those of the first dataset. The experiment uses the PyTorch deep learning framework. The size of original image and the label image are unified to 512 Ã— 512 pixels for training, the learning rate of Adam is set to 0.000 2, the momentum parameter is 0.5, the batch-size is 12, and the epoch is 200 times. Acceleration is performed using NVIDIA GTX TITAN Xp. Evaluation indicators include intersection over union (IOU), precision, recall, and F1-score. Result: Experiments are performed on the WHU Building Dataset and Satellite Dataset II datasets, and the methods are compared with the latest literature. Experimental results show that in the WHU dataset, the segmentation performance of the Ra-CGAN model is substantially improved compared with models without attention mechanism and adversarial training. Space continuity and integrity of the complex building and small building, and smoothness of building edges are considerably improved. Compared with U-Net, IOU value is increased by 3.75%, and F1-score is increased by 2.52%. Compared with the second-performance model, IOU value is increased by 1.1%, and F1-score is increased by 1.1%. In the Satellite Dataset II, Ra-CGAN obtains more ideal results in terms of target integrity and smoothness than other models, especially in the case of insufficient data samples. Compared with U-Net, IOU value is increased by 7.26%, and F1-score is increased by 6.68%. Compared with the second-placed model, IOU value is increased by 1.7% and F1-score is increased by 1.6%. Conclusion: A CGAN remote sensing building object segmentation model with multilevel channel attention mechanism, which combines the advantages of multilevel channel attention mechanism generation model and conditional generative adversarial networks, is proposed. Experimental results show that our model is superior to several state-of-the-art segmentation methods. Much more accurate remote sensing building object segmentation results are obtained on different datasets, proving that the model exhibits better robustness and scalability.",
    "doi": "10.11834/jig.200059",
    "author_keywords": [
      "Attention mechanism",
      "Conditional generative adversarial network (CGAN)",
      "Deep convolutional neural network",
      "Multi-scale feature fusion",
      "Remote sensing image segmentation"
    ],
    "contribution": "Aiming at the above problems, this paper proposes a conditional generative adversarial network (Ra-CGAN) with multilevel channel attention mechanism to segment remote sensing building objects. Method: A generative model with a multilevel channel attention mechanism is first built. The model is based on a coding and decoding structure that solves small target misses by fusing deep semantics and shallow details with attention. Second, a discriminative network is built and used to distinguish whether the input comes from the real label map or the segmentation map generated by the model. The segmentation result (accuracy and smoothness) is improved by correcting the difference between the two maps. The downsampling method without pooling is used in the discriminator to enhance the propagation of the gradient. Finally, the generated model and the discriminant model are alternately confronted for training through the constraint of the conditional variable of the labelled image. Learning the higher-order data distribution characteristics results in more continuity for the target space. The loss function uses a hybrid loss function, which comes from the cross-entropy loss function brought by the generated map and the real label map in the generation mode. The discriminator predicts the generated image as the loss value brought by the real label image. Experiments are performed on the WHU Building Dataset and Satellite Dataset II datasets. The first dataset has a dense building with many types and accurate labels, and can provide comprehensive, representative evaluation capabilities for the model. Another dataset with a higher segmentation difficulty is used to verify the robustness and scalability of the model. The lighting information and background information of the building are more complex than those of the first dataset. The experiment uses the PyTorch deep learning framework. The size of original image and the label image are unified to 512 Ã— 512 pixels for training, the learning rate of Adam is set to 0.000 2, the momentum parameter is 0.5, the batch-size is 12, and the epoch is 200 times. Acceleration is performed using NVIDIA GTX TITAN Xp. Evaluation indicators include intersection over union (IOU), precision, recall, and F1-score. Result: Experiments are performed on the WHU Building Dataset and Satellite Dataset II datasets, and the methods are compared with the latest literature. Experimental results show that in the WHU dataset, the segmentation performance of the Ra-CGAN model is substantially improved compared with models without attention mechanism and adversarial training. Space continuity and integrity of the complex building and small building, and smoothness of building edges are considerably improved. Compared with U-Net, IOU value is increased by 3.75%, and F1-score is increased by 2.52%. Compared with the second-performance model, IOU value is increased by 1.1%, and F1-score is increased by 1.1%. In the Satellite Dataset II, Ra-CGAN obtains more ideal results in terms of target integrity and smoothness than other models, especially in the case of insufficient data samples. Compared with U-Net, IOU value is increased by 7.26%, and F1-score is increased by 6.68%. Compared with the second-placed model, IOU value is increased by 1.7% and F1-score is increased by 1.6%. Conclusion: A CGAN remote sensing building object segmentation model with multilevel channel attention mechanism, which combines the advantages of multilevel channel attention mechanism generation model and conditional generative adversarial networks, is proposed. Experimental results show that our model is superior to several state-of-the-art segmentation methods. Much more accurate remote sensing building object segmentation results are obtained on different datasets, proving that the model exhibits better robustness and scalability.",
    "introduction": "Objective: Remote sensing building object segmentation is one of the important applications in image processing, which plays a vital role in smart city planning and urban change detection. However, building objects in remote sensing images have many complex characteristics, such as variable sizes, dense distributions, diverse topological shapes, complex backgrounds, and presence of occlusions and shadows. Traditional building segmentation algorithms are mainly based on manually designed features such as shapes, edges, and shadow features. These features are shallow features of the building target and cannot well express high-level semantic information, resulting in low recognition accuracy. By contrast, deep convolutional networks show excellent performance in pixel-level classification of natural images. Various fully convolutional network based image segmentation models have been continuously proposed. Most of these models use deconvolution or bilinear interpolation after feature extraction. Feature upsampling and pixel-by-pixel classification are used to segment the input image. The deep features of the building are extracted using highly nonlinear mapping and a large amount of data training, which overcomes the shortcomings of traditional algorithms. However, upsampling cannot completely compensate the information loss caused by repeated convolution and pooling operations in the deep convolutional network model. Therefore, the prediction results are relatively rough, such as small target misclassification, inaccurate boundaries, and other issues. In the field of remote sensing, public data sets are few. Training excellent deep convolutional networks is difficult, and the robustness of the network needs to be further improved.",
    "macro_domains": []
  },
  {
    "abstract": "Rapid developments in urbanization and smart city environments have accelerated the need to deliver safe, sustainable, and effective resource utilization and service provision and have thereby enhanced the need for intelligent, real-time video surveillance. Recent advances in machine learning and deep learning have the capability to detect and localize salient objects in surveillance video streams; however, several practical issues remain unaddressed, such as diverse weather conditions, recording conditions, and motion blur. In this context, image de-raining is an important issue that has been investigated extensively in recent years to provide accurate and quality surveillance in the smart city domain. Existing deep convolutional neural networks have obtained great success in image translation and other computer vision tasks; however, image de-raining is ill posed and has not been addressed in real-time, intelligent video surveillance systems. In this work, we propose to utilize the generative capabilities of recently introduced conditional generative adversarial networks (cGANs) as an image de-raining approach. We utilize the adversarial loss in GANs that provides an additional component to the loss function, which in turn regulates the final output and helps to yield better results. Experiments on both real and synthetic data show that the proposed method outperforms most of the existing state-of-the-art models in terms of quantitative evaluations and visual appearance.",
    "doi": "10.3390/app11052214",
    "author_keywords": [
      "Deep learning",
      "Generative adversarial networks",
      "Image de-raining",
      "Traffic surveillance image processing"
    ],
    "contribution": "In this work, we propose to utilize the generative capabilities of recently introduced conditional generative adversarial networks (cGANs) as an image de-raining approach. We utilize the adversarial loss in GANs that provides an additional component to the loss function, which in turn regulates the final output and helps to yield better results. Experiments on both real and synthetic data show that the proposed method outperforms most of the existing state-of-the-art models in terms of quantitative evaluations and visual appearance.",
    "introduction": "Rapid developments in urbanization and smart city environments have accelerated the need to deliver safe, sustainable, and effective resource utilization and service provision and have thereby enhanced the need for intelligent, real-time video surveillance. Recent advances in machine learning and deep learning have the capability to detect and localize salient objects in surveillance video streams; however, several practical issues remain unaddressed, such as diverse weather conditions, recording conditions, and motion blur. In this context, image de-raining is an important issue that has been investigated extensively in recent years to provide accurate and quality surveillance in the smart city domain. Existing deep convolutional neural networks have obtained great success in image translation and other computer vision tasks; however, image de-raining is ill posed and has not been addressed in real-time, intelligent video surveillance systems.",
    "macro_domains": []
  },
  {
    "abstract": "On the one hand, smart cities have brought about various changes, aiming to revolutionize people's lives. On the other hand, while smart cities bring better life experiences and great convenience to people's lives, there are more hidden dangers of cyber security, including information leakage and malicious cyber attacks. The current cyber security development cannot keep up with the eager adoption of global smart city technologies so correct design based on deep learning methods is essential to protect smart city cyber. This paper summarizes the knowledge and interpretation of Smart Cities (SC), Cyber Security (CS), and Deep Learning (DL) concepts as well as discussed existing related work on IoT security in smart cities. Specifically, we briefly reviewed several deep learning models, including Boltzmann machines, restricted Boltzmann machines, deep belief networks, recurrent neural networks, convolutional neural networks, and generative adversarial networks. Then we introduced cyber security applications and use cases based on deep learning technology in smart cities. Finally, we describe the future development trend of smart city cyber security.",
    "doi": "10.1016/j.scs.2020.102655",
    "author_keywords": [
      "A review",
      "Cyber security",
      "Deep learning",
      "Smart cities"
    ],
    "contribution": "This paper summarizes the knowledge and interpretation of Smart Cities (SC), Cyber Security (CS), and Deep Learning (DL) concepts as well as discussed existing related work on IoT security in smart cities. Specifically, we briefly reviewed several deep learning models, including Boltzmann machines, restricted Boltzmann machines, deep belief networks, recurrent neural networks, convolutional neural networks, and generative adversarial networks. Then we introduced cyber security applications and use cases based on deep learning technology in smart cities. Finally, we describe the future development trend of smart city cyber security.",
    "introduction": "On the one hand, smart cities have brought about various changes, aiming to revolutionize people's lives. On the other hand, while smart cities bring better life experiences and great convenience to people's lives, there are more hidden dangers of cyber security, including information leakage and malicious cyber attacks. The current cyber security development cannot keep up with the eager adoption of global smart city technologies so correct design based on deep learning methods is essential to protect smart city cyber.",
    "macro_domains": []
  },
  {
    "abstract": "The importance of transformer-less inverters has been increased since these are highly efficient, less costly, reduced in weight compared to conventional inverters for PV systems connected to grid. This fact led researchers to propose various topologies of transformer-less inverters, which have been validated for only injection of real power towards grid. However, recently new regulation has been imposed by all international power regulatory agency is that these PV inverters integrated with grid should have the capability of handling flow of a certain quantity of reactive power. By considering this point, a noble topology of transformer-less inverter has been developed for grid integrated PV system. Unlike previous topologies during reactive power injection, the new topology does not face reverse recovery issues, which helps to enhance the efficiency of the proposed inverter by exploiting MOSFET switches. Moreover, leakage current becomes low by keeping the common mode (CM) voltage at input DC voltage's midpoint.",
    "doi": "10.1088/1755-1315/673/1/012016",
    "author_keywords": null,
    "contribution": "",
    "introduction": "The importance of transformer-less inverters has been increased since these are highly efficient, less costly, reduced in weight compared to conventional inverters for PV systems connected to grid. This fact led researchers to propose various topologies of transformer-less inverters, which have been validated for only injection of real power towards grid. However, recently new regulation has been imposed by all international power regulatory agency is that these PV inverters integrated with grid should have the capability of handling flow of a certain quantity of reactive power. By considering this point, a noble topology of transformer-less inverter has been developed for grid integrated PV system. Unlike previous topologies during reactive power injection, the new topology does not face reverse recovery issues, which helps to enhance the efficiency of the proposed inverter by exploiting MOSFET switches. Moreover, leakage current becomes low by keeping the common mode (CM) voltage at input DC voltage's midpoint.",
    "macro_domains": []
  },
  {
    "abstract": "Power transformer has an important role in a transmission system. One factor that can reduce efficiency in the transmission system is transmission losses. Efficiency can be increased by reducing losses in the power transformer. The biggest influence determining the losses on the transformer is the material characteristic used by the transformer itself. To get maximum efficiency, it is necessary to optimize the materials on the transformer to get the lowest losses. The study is conducted by measuring core losses and copper losses on the 60 MVA 150/20 kV power transformer with the specified specifications. Furthermore, the transformer materials are changed into several types and the losses calculations are done. The calculation results are compared to get the most effective material. The results show that in the calculation of core losses, the core material type with the lowest core loss value is NK E-core of 0,49 Watt/kg. While in the calculation of copper losses, the winding material type with the lowest loss value is Continuously Transposed Conductor.",
    "doi": "10.1088/1755-1315/673/1/012008",
    "author_keywords": null,
    "contribution": "The study is conducted by measuring core losses and copper losses on the 60 MVA 150/20 kV power transformer with the specified specifications. Furthermore, the transformer materials are changed into several types and the losses calculations are done. The calculation results are compared to get the most effective material. The results show that in the calculation of core losses, the core material type with the lowest core loss value is NK E-core of 0,49 Watt/kg. While in the calculation of copper losses, the winding material type with the lowest loss value is Continuously Transposed Conductor.",
    "introduction": "Power transformer has an important role in a transmission system. One factor that can reduce efficiency in the transmission system is transmission losses. Efficiency can be increased by reducing losses in the power transformer. The biggest influence determining the losses on the transformer is the material characteristic used by the transformer itself. To get maximum efficiency, it is necessary to optimize the materials on the transformer to get the lowest losses.",
    "macro_domains": []
  },
  {
    "abstract": "Pedestrian gender recognition plays an important role in smart city. To effectively improve the pedestrian gender recognition performance, a new method, called cascading scene and viewpoint feature learning (CSVFL), is proposed in this article. The novelty of the proposed CSVFL lies on the joint consideration of two crucial challenges in pedestrian gender recognition, namely, scene and viewpoint variation. For that, the proposed CSVFL starts with the scene transfer (ST) scheme, followed by the viewpoint adaptation (VA) scheme in a cascading manner. Specifically, the ST scheme exploits the key pedestrian segmentation network to extract the key pedestrian masks for the subsequent key pedestrian transfer generative adversarial network, with the goal of encouraging the input pedestrian image to have the similar style to the target scene while preserving the image details of the key pedestrian as much as possible. Afterward, the obtained scene-transferred pedestrian images are fed to train the deep feature learning network with the VA scheme, in which each neuron will be enabled/disabled for different viewpoints depending on whether it has contribution on the corresponding viewpoint. Extensive experiments conducted on the commonly used pedestrian attribute data sets have demonstrated that the proposed CSVFL approach outperforms multiple recently reported pedestrian gender recognition methods.",
    "doi": "10.1109/JIOT.2020.3021763",
    "author_keywords": [
      "Cascading feature learning",
      "pedestrian gender recognition",
      "scene variation",
      "viewpoint variation"
    ],
    "contribution": "To effectively improve the pedestrian gender recognition performance, a new method, called cascading scene and viewpoint feature learning (CSVFL), is proposed in this article. The novelty of the proposed CSVFL lies on the joint consideration of two crucial challenges in pedestrian gender recognition, namely, scene and viewpoint variation. For that, the proposed CSVFL starts with the scene transfer (ST) scheme, followed by the viewpoint adaptation (VA) scheme in a cascading manner. Specifically, the ST scheme exploits the key pedestrian segmentation network to extract the key pedestrian masks for the subsequent key pedestrian transfer generative adversarial network, with the goal of encouraging the input pedestrian image to have the similar style to the target scene while preserving the image details of the key pedestrian as much as possible. Afterward, the obtained scene-transferred pedestrian images are fed to train the deep feature learning network with the VA scheme, in which each neuron will be enabled/disabled for different viewpoints depending on whether it has contribution on the corresponding viewpoint. Extensive experiments conducted on the commonly used pedestrian attribute data sets have demonstrated that the proposed CSVFL approach outperforms multiple recently reported pedestrian gender recognition methods.",
    "introduction": "Pedestrian gender recognition plays an important role in smart city.",
    "macro_domains": []
  },
  {
    "abstract": "Applications related to smart cities require virtual cities in the experimental development stage. To build a virtual city that are close to a real city, a large number of various types of human models need to be created. To reduce the cost of acquiring models, this paper proposes a method to reconstruct 3D human meshes from single images captured using a normal camera. It presents a method for reconstructing the complete mesh of the human body from a single RGB image and a generative adversarial network consisting of a newly designed shapeâ€“pose-based generator (based on deep convolutional neural networks) and an enhanced multi-source discriminator. Using a machine learning approach, the reliance on multiple sensors is reduced and 3D human meshes can be recovered using a single camera, thereby reducing the cost of building smart cities. The proposed method achieves an accuracy of 92.1% in body shape recovery; it can also process 34 images per second. The method proposed in this paper approach significantly improves the performance compared with previous state-of-the-art approaches. Given a single view image of various humans, our results can be used to generate various 3D human models, which can facilitate 3D human modeling work to simulate virtual cities. Since our method can also restore the poses of the humans in the image, it is possible to create various human poses by given corresponding images with specific human poses.",
    "doi": "10.3390/s21041350",
    "author_keywords": [
      "3D human model",
      "Artificial intelligence",
      "Deep learning",
      "GAN",
      "Image processing",
      "Smart cities"
    ],
    "contribution": "To reduce the cost of acquiring models, this paper proposes a method to reconstruct 3D human meshes from single images captured using a normal camera. It presents a method for reconstructing the complete mesh of the human body from a single RGB image and a generative adversarial network consisting of a newly designed shapeâ€“pose-based generator (based on deep convolutional neural networks) and an enhanced multi-source discriminator. Using a machine learning approach, the reliance on multiple sensors is reduced and 3D human meshes can be recovered using a single camera, thereby reducing the cost of building smart cities. The proposed method achieves an accuracy of 92.1% in body shape recovery; it can also process 34 images per second. The method proposed in this paper approach significantly improves the performance compared with previous state-of-the-art approaches. Given a single view image of various humans, our results can be used to generate various 3D human models, which can facilitate 3D human modeling work to simulate virtual cities. Since our method can also restore the poses of the humans in the image, it is possible to create various human poses by given corresponding images with specific human poses.",
    "introduction": "Applications related to smart cities require virtual cities in the experimental development stage. To build a virtual city that are close to a real city, a large number of various types of human models need to be created.",
    "macro_domains": []
  },
  {
    "abstract": "Obtaining key and rich visual information under sophisticated road conditions is one of the key requirements for advanced driving assistance. In this paper, a newfangled end-to-end model is proposed for advanced driving assistance based on the fusion of infrared and visible images, termed as FusionADA. In our model, we are committed to extracting and fusing the optimal texture details and salient thermal targets from the source images. To achieve this goal, our model constitutes an adversarial framework between the generator and the discriminator. Specifically, the generator aims to generate a fused image with basic intensity information together with the optimal texture details from source images, while the discriminator aims to force the fused image to restore the salient thermal targets from the source infrared image. In addition, our FusionADA is a fully end-to-end model, solving the issues of manually designing complicated activity level measurements and fusion rules existing in traditional methods. Qualitative and quantitative experiments on publicly available datasets RoadScene and TNO demonstrate the superiority of our FusionADA over the state-of-the-art approaches.",
    "doi": "10.3390/e23020239",
    "author_keywords": [
      "Advanced driving assistance",
      "Generative adversarial network",
      "Infrared and visible image fusion",
      "Smart city"
    ],
    "contribution": "In this paper, a newfangled end-to-end model is proposed for advanced driving assistance based on the fusion of infrared and visible images, termed as FusionADA. In our model, we are committed to extracting and fusing the optimal texture details and salient thermal targets from the source images. To achieve this goal, our model constitutes an adversarial framework between the generator and the discriminator. Specifically, the generator aims to generate a fused image with basic intensity information together with the optimal texture details from source images, while the discriminator aims to force the fused image to restore the salient thermal targets from the source infrared image. In addition, our FusionADA is a fully end-to-end model, solving the issues of manually designing complicated activity level measurements and fusion rules existing in traditional methods. Qualitative and quantitative experiments on publicly available datasets RoadScene and TNO demonstrate the superiority of our FusionADA over the state-of-the-art approaches.",
    "introduction": "Obtaining key and rich visual information under sophisticated road conditions is one of the key requirements for advanced driving assistance.",
    "macro_domains": []
  },
  {
    "abstract": "The electrical infrastructure has certain assets which have been underused, commonly named as dead assets, such as the light, distribution, and transformer poles. This infrastructure can be exploited with short-range 5G base stations, a technology which is expected to arrive soon, as a strategy to implement new 5G IoT networks and new smart city services. This project proposes the development of a smart city Hub which uses the dead electrical infrastructure with the purpose of offering technological services based on 5G. The Hub 5G is intended to integrate applications from different domains and industries, and at the same time, use open data sources to expose integrated services to the community where the Hub is located. The Hub provides a smart digital ecosystem for connected people, data, things, and services, a requirement for nowadaysâ€™ solutions. This initiative enables the application of technologies for society and the reinforcement of collaborative strategies between different industries and public and private sectors.",
    "doi": "10.1007/978-3-030-80126-7_71",
    "author_keywords": [
      "5G",
      "Integrated services",
      "IoT",
      "Smart city"
    ],
    "contribution": "",
    "introduction": "The electrical infrastructure has certain assets which have been underused, commonly named as dead assets, such as the light, distribution, and transformer poles. This infrastructure can be exploited with short-range 5G base stations, a technology which is expected to arrive soon, as a strategy to implement new 5G IoT networks and new smart city services. This project proposes the development of a smart city Hub which uses the dead electrical infrastructure with the purpose of offering technological services based on 5G. The Hub 5G is intended to integrate applications from different domains and industries, and at the same time, use open data sources to expose integrated services to the community where the Hub is located. The Hub provides a smart digital ecosystem for connected people, data, things, and services, a requirement for nowadaysâ€™ solutions. This initiative enables the application of technologies for society and the reinforcement of collaborative strategies between different industries and public and private sectors.",
    "macro_domains": []
  },
  {
    "abstract": "In view of the lack of intrusion detection data and the slow update of mainstream detection methods, an intrusion detection data generation method based on a generative adversarial network is proposed. First, the overall data is digitized and normalized to maintain the integrity of the data; Then use the ACGAN model to learn the hidden features of the data and generate new data; Finally, evaluate the similarity and validity of the generated data from multiple perspectives. Experimental results show that the data generated by this method has similar characteristics to the original data, and can be used to enhance the original data set to meet the needs of intrusion detection systems.",
    "doi": "10.1109/CCDC52312.2021.9602568",
    "author_keywords": [
      "Cyber Security",
      "Generative Adversarial Network",
      "Intrusion Detection Data",
      "Smart City"
    ],
    "contribution": "Experimental results show that the data generated by this method has similar characteristics to the original data, and can be used to enhance the original data set to meet the needs of intrusion detection systems.",
    "introduction": "In view of the lack of intrusion detection data and the slow update of mainstream detection methods, an intrusion detection data generation method based on a generative adversarial network is proposed. First, the overall data is digitized and normalized to maintain the integrity of the data; Then use the ACGAN model to learn the hidden features of the data and generate new data; Finally, evaluate the similarity and validity of the generated data from multiple perspectives.",
    "macro_domains": []
  },
  {
    "abstract": "Smart grids have gained attention in recent years in the field of smart cities as a key parameter for the electrical power service, adapted to the new forms of generation and processes associated with the use of electricity. In this sense, the diagnosis of the state of the infrastructure is important to ensure its operation, in which the power transformer is the key element. For this reason, this article presents an Asset Management methodology based on prediction and fuzzy logic to identify the condition of the transformer fleet from the National Laboratory of Smart Grids (LAB+i), considering its conditions. First, the forecasting system is presented together with the base parameters of the fuzzy logic system. Then an implementation analysis is performed with real data. This development allowed identifying the opportunity of using this system in different scenarios, with the challenges and benefits of the prediction methods in the Asset Management framework.",
    "doi": "10.1109/ICSCGE53744.2021.9654425",
    "author_keywords": [
      "asset management",
      "classification",
      "monitoring",
      "power assets",
      "smart grids"
    ],
    "contribution": "For this reason, this article presents an Asset Management methodology based on prediction and fuzzy logic to identify the condition of the transformer fleet from the National Laboratory of Smart Grids (LAB+i), considering its conditions. First, the forecasting system is presented together with the base parameters of the fuzzy logic system. Then an implementation analysis is performed with real data. This development allowed identifying the opportunity of using this system in different scenarios, with the challenges and benefits of the prediction methods in the Asset Management framework.",
    "introduction": "Smart grids have gained attention in recent years in the field of smart cities as a key parameter for the electrical power service, adapted to the new forms of generation and processes associated with the use of electricity. In this sense, the diagnosis of the state of the infrastructure is important to ensure its operation, in which the power transformer is the key element.",
    "macro_domains": []
  },
  {
    "abstract": "Removal of multiple weather-induced effects in a single image remains an open problem, although several methods addressing single effect removal have been proposed. We present a single method for removing multiple weather-induced effects that are fog, haze, rain streaks, and snowflakes. The proposed method is a unified model, based on context encoder and conditional generative adversarial network, with a single set of parameters. We demonstrate that our model is effective at improving visibility in weather degraded images. Though the training is done on synthetic data the model generalizes on real images during testing.",
    "doi": "10.1109/ICRAI54018.2021.9651370",
    "author_keywords": [
      "Conditional adversarial network",
      "Context encoders",
      "Smart cities",
      "Street views",
      "Visibility improvement",
      "Weather effects"
    ],
    "contribution": "We present a single method for removing multiple weather-induced effects that are fog, haze, rain streaks, and snowflakes. The proposed method is a unified model, based on context encoder and conditional generative adversarial network, with a single set of parameters. We demonstrate that our model is effective at improving visibility in weather degraded images. Though the training is done on synthetic data the model generalizes on real images during testing.",
    "introduction": "Removal of multiple weather-induced effects in a single image remains an open problem, although several methods addressing single effect removal have been proposed.",
    "macro_domains": []
  },
  {
    "abstract": "With the spread of the number of smart devices in the context of Smart City, Software Defined Networking (SDN) is considered as a vital principle to manage a large-scale heterogeneous network within centralized controller. To deal with cyberattacks against such networks, intrusion detection system (IDS) is built to recognize and alert to the system administrator for further appropriate response. Currently, machine learning-based IDS (ML-IDS) has been explored and is still being developed. However, these systems give a high rate of false alert and are easily deceived by sophisticated attacks such as variants of attacks containing perturbation. Therefore, it is necessary to continuously evaluate and improve these systems by simulating mutation of real-world network attack. Relied on the Generative Discriminative Networks (GANs), we introduce DIGFuPAS, a framework that generates data flow of cyberattacks capable of bypassing ML-IDS. It can generate malicious data streams that mutate from real attack traffic making the IDS undetectable. The generated traffic flow is used to retrain ML-IDS, for improving the robustness of IDS in detecting sophisticated attacks. The experiments are performed and evaluated through 2 criteria: Detection rate (DR) and F1 Score (F1) on the public dataset, named CICIDS2017. DIGFuPAS can be used for continuously pentesting and evaluating IDS's capability once integrated as an automated sustainability test pipeline for SDN-enabled networks.",
    "doi": "10.1109/RIVF51545.2021.9642111",
    "author_keywords": [
      "Adversarial Attacks",
      "Generative Adversarial Networks",
      "IDS",
      "Machine Learning IDS"
    ],
    "contribution": "Relied on the Generative Discriminative Networks (GANs), we introduce DIGFuPAS, a framework that generates data flow of cyberattacks capable of bypassing ML-IDS. It can generate malicious data streams that mutate from real attack traffic making the IDS undetectable. The generated traffic flow is used to retrain ML-IDS, for improving the robustness of IDS in detecting sophisticated attacks. The experiments are performed and evaluated through 2 criteria: Detection rate (DR) and F1 Score (F1) on the public dataset, named CICIDS2017. DIGFuPAS can be used for continuously pentesting and evaluating IDS's capability once integrated as an automated sustainability test pipeline for SDN-enabled networks.",
    "introduction": "With the spread of the number of smart devices in the context of Smart City, Software Defined Networking (SDN) is considered as a vital principle to manage a large-scale heterogeneous network within centralized controller. To deal with cyberattacks against such networks, intrusion detection system (IDS) is built to recognize and alert to the system administrator for further appropriate response. Currently, machine learning-based IDS (ML-IDS) has been explored and is still being developed. However, these systems give a high rate of false alert and are easily deceived by sophisticated attacks such as variants of attacks containing perturbation. Therefore, it is necessary to continuously evaluate and improve these systems by simulating mutation of real-world network attack.",
    "macro_domains": []
  },
  {
    "abstract": "Face Morphing has emerged as a pervasive attack of Facial Recognition Systems. The rapid growth of Generative Adversarial Networks takes it to a complete new level. Deepfake or deep neural network based face morphing, a.k.a deep-morph attack, presents a significant threat to Facial Recognition System. In this paper, we propose a novel Convolutional Neural Network based detection method of deep morphed deepfake images which is suitable for IoT environments in smart cities. A high accuracy of 94.83% has been achieved for the DeepfakeTIMIT HQ dataset. This lightweight and fast network is a natural choice for IoT environments.",
    "doi": "10.1109/OCIT53463.2021.00039",
    "author_keywords": [
      "Convolutional Neural Network",
      "Deep Learning",
      "Deep-fake",
      "Deep-Morph",
      "Facial recognition System",
      "Smart City"
    ],
    "contribution": "In this paper, we propose a novel Convolutional Neural Network based detection method of deep morphed deepfake images which is suitable for IoT environments in smart cities. A high accuracy of 94.83% has been achieved for the DeepfakeTIMIT HQ dataset. This lightweight and fast network is a natural choice for IoT environments.",
    "introduction": "Face Morphing has emerged as a pervasive attack of Facial Recognition Systems. The rapid growth of Generative Adversarial Networks takes it to a complete new level. Deepfake or deep neural network based face morphing, a.k.a deep-morph attack, presents a significant threat to Facial Recognition System.",
    "macro_domains": []
  },
  {
    "abstract": "The development of Internet of Things (IoT) infrastructure in the city leads to the emergence of the concept of smart city, an integrated solution to provide convenience for various applications in our daily life by understanding and analyzing the collected data from multi-sources. However, the collection of facial images collected from various IoT devices such as surveillance cameras, wearable, and mobile devices increases the risk of an individual's privacy leak. The facial recognition models augment this risk. These models retrieve facial data collected from IoT devices stored in smart city databases to get personal identity information. With extensive utilization of such IoT devices, which serve as a visual data collector, we compromise the person's identity. Therefore, to protect the privacy of image data from a database, we propose a Sensitivity Map Noise-Adding model based on generative adversarial networks to provide privacy for facial images against the malicious use of the face recognition models. The proposed models work as a black-box model that does not require any architectural information or the parameters of the target model. Additionally, the model runs at a real-time speed and the average run time for one operation is less than 12 milliseconds. The protection can be deployed for both local images and streaming videos. The data privacy protection is based on our proposed concept of the Sensitivity Maps, which summarizes the effectiveness and efficiency of adding noises on each pixel on the original image to interfere with the target model's performance. We have built a new dataset of facial images containing 102 celebrities for the proposed model to be trained and evaluated. The experimental results prove the advantage of the proposed method against protecting the identity information in facial images.",
    "doi": "10.1109/SWC50871.2021.00053",
    "author_keywords": [
      "Face Recognition",
      "GAN",
      "Privacy"
    ],
    "contribution": "Therefore, to protect the privacy of image data from a database, we propose a Sensitivity Map Noise-Adding model based on generative adversarial networks to provide privacy for facial images against the malicious use of the face recognition models. The proposed models work as a black-box model that does not require any architectural information or the parameters of the target model. Additionally, the model runs at a real-time speed and the average run time for one operation is less than 12 milliseconds. The protection can be deployed for both local images and streaming videos. The data privacy protection is based on our proposed concept of the Sensitivity Maps, which summarizes the effectiveness and efficiency of adding noises on each pixel on the original image to interfere with the target model's performance. We have built a new dataset of facial images containing 102 celebrities for the proposed model to be trained and evaluated. The experimental results prove the advantage of the proposed method against protecting the identity information in facial images.",
    "introduction": "The development of Internet of Things (IoT) infrastructure in the city leads to the emergence of the concept of smart city, an integrated solution to provide convenience for various applications in our daily life by understanding and analyzing the collected data from multi-sources. However, the collection of facial images collected from various IoT devices such as surveillance cameras, wearable, and mobile devices increases the risk of an individual's privacy leak. The facial recognition models augment this risk. These models retrieve facial data collected from IoT devices stored in smart city databases to get personal identity information. With extensive utilization of such IoT devices, which serve as a visual data collector, we compromise the person's identity.",
    "macro_domains": []
  },
  {
    "abstract": "The past decade has seen a notable increase in air pollution that directly damages health, animals, and plants worldwide. To mitigate such negative effects, several research groups have been working on predicting air quality using deep learning. However, the lack of high-quality air quality datasets is a major obstacle encountered to achieve high accuracy prediction. In this paper, we introduce an air monitoring data generator powered by learning distributed real sequences using the generative adversarial network (GAN), namely AirGen. An unsupervised adversarial loss is also employed in the network to minimize the difference between generated synthetic and original data in the training process. Experiments on real datasets indicate that the data generated by Airgen could significantly increase the prediction accuracy performed by deep learning models. The mean square error (MSE) is remarkably reduced from 0.024 to 0.015.",
    "doi": "10.1109/RTSI50628.2021.9597364",
    "author_keywords": [
      "air pollution data",
      "IoT",
      "smart city",
      "synthetic data generation"
    ],
    "contribution": "In this paper, we introduce an air monitoring data generator powered by learning distributed real sequences using the generative adversarial network (GAN), namely AirGen. An unsupervised adversarial loss is also employed in the network to minimize the difference between generated synthetic and original data in the training process. Experiments on real datasets indicate that the data generated by Airgen could significantly increase the prediction accuracy performed by deep learning models. The mean square error (MSE) is remarkably reduced from 0.024 to 0.015.",
    "introduction": "The past decade has seen a notable increase in air pollution that directly damages health, animals, and plants worldwide. To mitigate such negative effects, several research groups have been working on predicting air quality using deep learning. However, the lack of high-quality air quality datasets is a major obstacle encountered to achieve high accuracy prediction.",
    "macro_domains": []
  },
  {
    "abstract": "In the interest of our society, for example in Smart City but also in other specific backgrounds, environmental monitoring is an essential activity to measure the quality of different ecosystems. In fact, the need to obtain accurate and extended measurements in space and time has considerably become relevant. In very large environments, such as marine ones, technological solutions are required for the use of smart, automatic, and self-powered devices in order to reduce human maintenance service. This work presents a simple and innovative layout for a small self-powered floating buoy, with the aim of measuring and transmitting the detected data for visualization, storage and/or elaboration. The power supply was obtained using a cantilever harvester, based on piezoelectric patches, converting the motion of ripple waves. Such type of waves is characterized by frequencies between 1.50 Hz and 2.50 Hz with oscillation between 5.0 Â° and 7.0 Â°. Specifically, a dedicated experimental setup was created to simulate the motion of ripple waves and to evaluate the suitability of the proposed design and the performance of the used harvester. Furthermore, a dynamic analytical model for the harvester has been defined and the uncertainty correlated to the harvested power has been evaluated. Finally, the harvested voltage and power have shown how the presented buoy behaves like a frequency transformer. Hence, although the used cantilever harvester does not work in its resonant frequency, the harvested electricity undergoes a significant increase.",
    "doi": "10.21014/acta_imeko.v10i4.1161",
    "author_keywords": [
      "Motion frequency transformer",
      "Piezoelectric patch",
      "Ripples waves",
      "Uncertainty estimation"
    ],
    "contribution": "This work presents a simple and innovative layout for a small self-powered floating buoy, with the aim of measuring and transmitting the detected data for visualization, storage and/or elaboration. The power supply was obtained using a cantilever harvester, based on piezoelectric patches, converting the motion of ripple waves. Such type of waves is characterized by frequencies between 1.50 Hz and 2.50 Hz with oscillation between 5.0 Â° and 7.0 Â°. Specifically, a dedicated experimental setup was created to simulate the motion of ripple waves and to evaluate the suitability of the proposed design and the performance of the used harvester. Furthermore, a dynamic analytical model for the harvester has been defined and the uncertainty correlated to the harvested power has been evaluated. Finally, the harvested voltage and power have shown how the presented buoy behaves like a frequency transformer. Hence, although the used cantilever harvester does not work in its resonant frequency, the harvested electricity undergoes a significant increase.",
    "introduction": "In the interest of our society, for example in Smart City but also in other specific backgrounds, environmental monitoring is an essential activity to measure the quality of different ecosystems. In fact, the need to obtain accurate and extended measurements in space and time has considerably become relevant. In very large environments, such as marine ones, technological solutions are required for the use of smart, automatic, and self-powered devices in order to reduce human maintenance service.",
    "macro_domains": []
  },
  {
    "abstract": "In contrast with the condition that the trajectory dataset of floating cars (taxis) can be easily obtained from the Internet, it is hard to get the trajectory data of social vehicles (private vehicles) because of personal privacy and government policies. This paper absorbs the idea of game theory, considers the influence of individuals in the group, and proposes a decision behavior based dataset generation (DBDG) model of vehicles to predict future inter-regional traffic. In addition, we adopt simulation tools and generative adversarial networks to train the trajectory prediction model so that the private vehicle trajectory dataset conforming to social rules (e.g., collisionless) is generated. Finally, we construct from macroscopic and microscopic perspectives to verify dataset generation methods proposed in this paper. The results show that the generated data not only has high accuracy and is valuable but can provide strong data support for the Internet of Vehicles and transportation research work.",
    "doi": "10.1007/978-3-030-87571-8_10",
    "author_keywords": [
      "Dataset generation",
      "Generative adversarial networks",
      "Smart cities",
      "Spatial-temporal interaction"
    ],
    "contribution": "This paper absorbs the idea of game theory, considers the influence of individuals in the group, and proposes a decision behavior based dataset generation (DBDG) model of vehicles to predict future inter-regional traffic. In addition, we adopt simulation tools and generative adversarial networks to train the trajectory prediction model so that the private vehicle trajectory dataset conforming to social rules (e.g., collisionless) is generated. Finally, we construct from macroscopic and microscopic perspectives to verify dataset generation methods proposed in this paper. The results show that the generated data not only has high accuracy and is valuable but can provide strong data support for the Internet of Vehicles and transportation research work.",
    "introduction": "In contrast with the condition that the trajectory dataset of floating cars (taxis) can be easily obtained from the Internet, it is hard to get the trajectory data of social vehicles (private vehicles) because of personal privacy and government policies.",
    "macro_domains": []
  },
  {
    "abstract": "Making accurate traffic forecasting is of great importance in smart city-related researches. However, as the traffic features like traffic speed have a complex spatial-temporal characteristics, how to build an accurate traffic prediction model is still an open challenge. In this work, we propose TSTNet, a Sequence to Sequence (Seq2Seq) spatial-temporal traffic prediction model. TSTNet adopts Graph Attention Network (GAT), which can learn the spatial feature aggregation, to build spatial dependency. For temporal dependency, TSTNet applies a Seq2Seq Transformer structure to establish temporal dependency. As a GAT layerâ€™s operation only aggregate the attribute information for neighbor nodes, it does not involve any spatial positional information. Similarly, if we apply the Transformer model on sequence learning tasks, the Transformer model also does not involve any temporal positional information as it does not know the exact time slot of different inputs. To solve the above problems, TSTNet implements a spatial-temporal embedding method to obtain the spatial-temporal positional representation for each input data. We evaluate TSTNet on traffic speed prediction tasks with other baselines upon two real-world datasets, the results show that TSTNet outperforms all the baseline models.",
    "doi": "10.1007/978-3-030-86362-3_28",
    "author_keywords": [
      "Sequence to sequence model",
      "Spatial-temporal forecasting",
      "Time series data"
    ],
    "contribution": "In this work, we propose TSTNet, a Sequence to Sequence (Seq2Seq) spatial-temporal traffic prediction model. TSTNet adopts Graph Attention Network (GAT), which can learn the spatial feature aggregation, to build spatial dependency. For temporal dependency, TSTNet applies a Seq2Seq Transformer structure to establish temporal dependency. As a GAT layerâ€™s operation only aggregate the attribute information for neighbor nodes, it does not involve any spatial positional information. Similarly, if we apply the Transformer model on sequence learning tasks, the Transformer model also does not involve any temporal positional information as it does not know the exact time slot of different inputs. To solve the above problems, TSTNet implements a spatial-temporal embedding method to obtain the spatial-temporal positional representation for each input data. We evaluate TSTNet on traffic speed prediction tasks with other baselines upon two real-world datasets, the results show that TSTNet outperforms all the baseline models.",
    "introduction": "Making accurate traffic forecasting is of great importance in smart city-related researches. However, as the traffic features like traffic speed have a complex spatial-temporal characteristics, how to build an accurate traffic prediction model is still an open challenge.",
    "macro_domains": []
  },
  {
    "abstract": "Currently, the world is in a period of urbanization that will accelerate the processes of land-use cover and ecological change. Thus, establishing a land-use and land-cover change (LUCC) prediction and simulation model is of great significance for understanding the process of urban change and assessing its ecological impact. In previous studies, LUCC prediction models have been mainly based on cellular automata structures that calculate a future state pixel by pixel through transition rules. Because these transition rules are usually based on the global state and each pixel is calculated according to these fixed rules, the results of these methods have room for improvement in terms of generating details and heterogeneity. In this article, a generative adversarial network (GAN)-based LUCC prediction model using multiscale local spatial information is proposed. The model is based on a pix2pix GAN and an attention structure that predicts future land use through multiscale local spatial information. To validate our model, Shenzhen, a region that is experiencing rapid urbanization, was chosen as the source of the experimental data. The results indicate that the proposed method achieved the highest accuracy in both short-time interval and long-time interval scenarios. In addition, the results of the proposed method were also closest to the ground truth from the perspective of the landscape pattern.",
    "doi": "10.1109/JSTARS.2021.3106481",
    "author_keywords": [
      "Deep learning",
      "Generative adversarial network (GAN)",
      "LUCC simulation",
      "Remote sensing",
      "Smart city"
    ],
    "contribution": "In this article, a generative adversarial network (GAN)-based LUCC prediction model using multiscale local spatial information is proposed. The model is based on a pix2pix GAN and an attention structure that predicts future land use through multiscale local spatial information. To validate our model, Shenzhen, a region that is experiencing rapid urbanization, was chosen as the source of the experimental data. The results indicate that the proposed method achieved the highest accuracy in both short-time interval and long-time interval scenarios. In addition, the results of the proposed method were also closest to the ground truth from the perspective of the landscape pattern.",
    "introduction": "Currently, the world is in a period of urbanization that will accelerate the processes of land-use cover and ecological change. Thus, establishing a land-use and land-cover change (LUCC) prediction and simulation model is of great significance for understanding the process of urban change and assessing its ecological impact. In previous studies, LUCC prediction models have been mainly based on cellular automata structures that calculate a future state pixel by pixel through transition rules. Because these transition rules are usually based on the global state and each pixel is calculated according to these fixed rules, the results of these methods have room for improvement in terms of generating details and heterogeneity.",
    "macro_domains": []
  },
  {
    "abstract": "The electrical infrastructure has certain assets which have been underused, commonly named as dead assets, such as the light, distribution, and transformer poles. This infrastructure can be exploited with short-range 5G base stations, a technology which is expected to arrive soon, as a strategy to implement new 5G IoT networks and new smart city services. This project proposes the development of a smart city Hub which uses the dead electrical infrastructure with the purpose of offering technological services based on 5G. The Hub 5G is intended to integrate applications from different domains and industries, and at the same time, use open data sources to expose integrated services to the community where the Hub is located. The Hub provides a smart digital ecosystem for connected people, data, things, and services, a requirement for nowadaysâ€™ solutions. This initiative enables the application of technologies for society and the reinforcement of collaborative strategies between different industries and public and private sectors.",
    "doi": "10.1007/978-3-030-80126-7_71",
    "author_keywords": [
      "5G",
      "Integrated services",
      "IoT",
      "Smart city"
    ],
    "contribution": "",
    "introduction": "The electrical infrastructure has certain assets which have been underused, commonly named as dead assets, such as the light, distribution, and transformer poles. This infrastructure can be exploited with short-range 5G base stations, a technology which is expected to arrive soon, as a strategy to implement new 5G IoT networks and new smart city services. This project proposes the development of a smart city Hub which uses the dead electrical infrastructure with the purpose of offering technological services based on 5G. The Hub 5G is intended to integrate applications from different domains and industries, and at the same time, use open data sources to expose integrated services to the community where the Hub is located. The Hub provides a smart digital ecosystem for connected people, data, things, and services, a requirement for nowadaysâ€™ solutions. This initiative enables the application of technologies for society and the reinforcement of collaborative strategies between different industries and public and private sectors.",
    "macro_domains": []
  },
  {
    "abstract": "Since the last decades, deep neural models have been pushing forward the frontiers of artificial intelligence. Applications that in the recent past were considered no more than utopian dreams, now appear to be feasible. The best example is autonomous driving. Despite the growing research aimed at implementing autonomous driving, no artificial intelligence can claim to have reached or closely approached the driving performance of humans, yet. While the early forms of artificial neural networks were aimed at simulating and understanding human cognition, contemporary deep neural networks are totally indifferent to cognitive studies, they are designed with pure engineering goals in mind. Several scholars, we included, argue that it urges to reconnect artificial modeling with an updated knowledge of how complex tasks are realized by the human mind and brain. In this paper, we will first try to distill concepts within neuroscience and cognitive science relevant for the driving behavior. Then, we will identify possible algorithmic counterparts of such concepts, and finally build an artificial neural model exploiting these components for the visual perception task of an autonomous vehicle. More specifically, we will point to four neurocognitive theories: the simulation theory of cognition; the Convergenceâ€“divergence Zones hypothesis; the transformational abstraction hypothesis; the freeâ€“energy predictive theory. Our proposed model tries to combine a number of existing algorithms that most closely resonate with the assumptions of these four neurocognitive theories.",
    "doi": "10.1007/978-3-030-68028-2_6",
    "author_keywords": [
      "Autonomous driving",
      "Convergenceâ€“divergence Zones",
      "Deep learning",
      "Free energy",
      "Variational autoencoder"
    ],
    "contribution": "In this paper, we will first try to distill concepts within neuroscience and cognitive science relevant for the driving behavior. Then, we will identify possible algorithmic counterparts of such concepts, and finally build an artificial neural model exploiting these components for the visual perception task of an autonomous vehicle. More specifically, we will point to four neurocognitive theories: the simulation theory of cognition; the Convergenceâ€“divergence Zones hypothesis; the transformational abstraction hypothesis; the freeâ€“energy predictive theory. Our proposed model tries to combine a number of existing algorithms that most closely resonate with the assumptions of these four neurocognitive theories.",
    "introduction": "Since the last decades, deep neural models have been pushing forward the frontiers of artificial intelligence. Applications that in the recent past were considered no more than utopian dreams, now appear to be feasible. The best example is autonomous driving. Despite the growing research aimed at implementing autonomous driving, no artificial intelligence can claim to have reached or closely approached the driving performance of humans, yet. While the early forms of artificial neural networks were aimed at simulating and understanding human cognition, contemporary deep neural networks are totally indifferent to cognitive studies, they are designed with pure engineering goals in mind. Several scholars, we included, argue that it urges to reconnect artificial modeling with an updated knowledge of how complex tasks are realized by the human mind and brain.",
    "macro_domains": []
  },
  {
    "abstract": "Sensor-based human activity recognition (HAR) is having a significant impact in a wide range of applications in smart city, smart home, and personal healthcare. Such wide deployment of HAR systems often faces the annotation-scarcity challenge; that is, most of the HAR techniques, especially the deep learning techniques, require a large number of training data while annotating sensor data is very time- and effort-consuming. Unsupervised domain adaptation has been successfully applied to tackle this challenge, where the activity knowledge from a well-annotated domain can be transferred to a new, unlabelled domain. However, these existing techniques do not perform well on highly heterogeneous domains. This article proposes shift-GAN that integrate bidirectional generative adversarial networks (Bi-GAN) and kernel mean matching (KMM) in an innovative way to learn intrinsic, robust feature transfer between two heterogeneous domains. Bi-GAN consists of two GANs that are bound by a cyclic constraint, which enables more effective feature transfer than a classic, single GAN model. KMM is a powerful non-parametric technique to correct covariate shift, which further improves feature space alignment. Through a series of comprehensive, empirical evaluations, shift-GAN has not only achieved its superior performance over 10 state-of-the-art domain adaptation techniques but also demonstrated its effectiveness in learning activity-independent, intrinsic feature mappings between two domains, robustness to sensor noise, and less sensitivity to training data.",
    "doi": "10.1109/ACCESS.2021.3053704",
    "author_keywords": [
      "covariate shift",
      "domain adaptation",
      "ensemble learning",
      "generative adversarial networks",
      "Human activity recognition",
      "kernel mean matching"
    ],
    "contribution": "This article proposes shift-GAN that integrate bidirectional generative adversarial networks (Bi-GAN) and kernel mean matching (KMM) in an innovative way to learn intrinsic, robust feature transfer between two heterogeneous domains. Bi-GAN consists of two GANs that are bound by a cyclic constraint, which enables more effective feature transfer than a classic, single GAN model. KMM is a powerful non-parametric technique to correct covariate shift, which further improves feature space alignment. Through a series of comprehensive, empirical evaluations, shift-GAN has not only achieved its superior performance over 10 state-of-the-art domain adaptation techniques but also demonstrated its effectiveness in learning activity-independent, intrinsic feature mappings between two domains, robustness to sensor noise, and less sensitivity to training data.",
    "introduction": "Sensor-based human activity recognition (HAR) is having a significant impact in a wide range of applications in smart city, smart home, and personal healthcare. Such wide deployment of HAR systems often faces the annotation-scarcity challenge; that is, most of the HAR techniques, especially the deep learning techniques, require a large number of training data while annotating sensor data is very time- and effort-consuming. Unsupervised domain adaptation has been successfully applied to tackle this challenge, where the activity knowledge from a well-annotated domain can be transferred to a new, unlabelled domain. However, these existing techniques do not perform well on highly heterogeneous domains.",
    "macro_domains": []
  },
  {
    "abstract": "Face recognition technology has attracted attention as people pay more and more attention to facial information, and has become a hot research topic. In this experiment, the training learning rate is set to 0.0004, 64 images are randomly loaded in a single loop, and then noise is added to start training. The cyclic process can be described as: First, the generator G generates output, and then the discriminator D performs the discrimination, and the generation loss and the discrimination loss are calculated by the output of the generator G and the discriminator D. Experimental data shows that a face database is formed through feature extraction and training of the face database. Then, randomly extract images for detection and recognition, and finally match the features in the feature library. The experimental results show that the accuracy of face recognition is 88.11% when the original data is used for 1000 iterations. The data filled with samples generated by GAN is used for training, and the accuracy of face recognition is 93.76%. There is a significant increase. At present, face verification and recognition still have difficulties in the application of computer science, and the generative confrontation network has made certain breakthroughs in the description of image generation.",
    "doi": "10.1007/978-981-33-4572-0_72",
    "author_keywords": [
      "Dual-path confrontation generation network",
      "Face recognition image",
      "GAN technology"
    ],
    "contribution": "",
    "introduction": "Face recognition technology has attracted attention as people pay more and more attention to facial information, and has become a hot research topic. In this experiment, the training learning rate is set to 0.0004, 64 images are randomly loaded in a single loop, and then noise is added to start training. The cyclic process can be described as: First, the generator G generates output, and then the discriminator D performs the discrimination, and the generation loss and the discrimination loss are calculated by the output of the generator G and the discriminator D. Experimental data shows that a face database is formed through feature extraction and training of the face database. Then, randomly extract images for detection and recognition, and finally match the features in the feature library. The experimental results show that the accuracy of face recognition is 88.11% when the original data is used for 1000 iterations. The data filled with samples generated by GAN is used for training, and the accuracy of face recognition is 93.76%. There is a significant increase. At present, face verification and recognition still have difficulties in the application of computer science, and the generative confrontation network has made certain breakthroughs in the description of image generation.",
    "macro_domains": []
  },
  {
    "abstract": "In view of the problems of polysemy and overlapping relations of Chinese tea text. In this paper, we present a joint model BERT-LCM-Tea for extraction of entities and relations, which combines the Bidirectional Encoder Representations from Transformers (BERT) and the last character matching (LCM) algorithm. This model uses BERT to fine-tuning character embedding through contextual information, the problem of polysemy is solved and the performance of entity recognition of Chinese tea text is improved. In addition, the model uses last character matching algorithm, the problem of overlapping relations is solved and the accuracy of relation extraction of Chinese tea text is improved.The experimental results show that BERT-LCM-Tea F1 score to 86.8% in entity recognition task and F1score to 77.1% in relation extraction task, which is higher than the currently popular Bi-RNN-CRF, Bi-LSTM-CRF and Bi-GRU-CRF. Thus, the BERT-LCM-Tea is more suitable for the entity recognition and relation extraction of Chinese tea text, and provides a basis for future research on the construction of tea knowledge graph.",
    "doi": "10.1145/3446999.3447027",
    "author_keywords": [
      "BERT",
      "Chinese tea text",
      "Entity recognition",
      "Relation extraction"
    ],
    "contribution": "In this paper, we present a joint model BERT-LCM-Tea for extraction of entities and relations, which combines the Bidirectional Encoder Representations from Transformers (BERT) and the last character matching (LCM) algorithm. This model uses BERT to fine-tuning character embedding through contextual information, the problem of polysemy is solved and the performance of entity recognition of Chinese tea text is improved. In addition, the model uses last character matching algorithm, the problem of overlapping relations is solved and the accuracy of relation extraction of Chinese tea text is improved.The experimental results show that BERT-LCM-Tea F1 score to 86.8% in entity recognition task and F1score to 77.1% in relation extraction task, which is higher than the currently popular Bi-RNN-CRF, Bi-LSTM-CRF and Bi-GRU-CRF. Thus, the BERT-LCM-Tea is more suitable for the entity recognition and relation extraction of Chinese tea text, and provides a basis for future research on the construction of tea knowledge graph.",
    "introduction": "In view of the problems of polysemy and overlapping relations of Chinese tea text.",
    "macro_domains": []
  },
  {
    "abstract": "Air pollution is becoming a rising and serious environmental problem, especially in urban areas affected by an increasing migration rate. The large availability of sensor data enables the adoption of analytical tools to provide decision support capabilities. Employing sensors facilitates air pollution monitoring, but the lack of predictive capability limits such systemsâ€™ potential in practical scenarios. On the other hand, forecasting methods offer the opportunity to predict the future pollution in specific areas, potentially suggesting useful preventive measures. To date, many works tackled the problem of air pollution forecasting, most of which are based on sequence models. These models are trained with raw pollution data and are subsequently utilized to make predictions. This paper proposes a novel approach evaluating four different architectures that utilize camera images to estimate the air pollution in those areas. These images are further enhanced with weather data to boost the classification accuracy. The proposed approach exploits generative adversarial networks combined with data augmentation techniques to mitigate the class imbalance problem. The experiments show that the proposed method achieves robust accuracy of up to 0.88, which is comparable to sequence models and conventional models that utilize air pollution data. This is a remarkable result considering that the historic air pollution data is directly related to the outputâ€”future air pollution data, whereas the proposed architecture uses camera images to recognize the air pollutionâ€”which is an inherently much more difficult problem.",
    "doi": "10.3390/rs12244142",
    "author_keywords": [
      "Air pollution prediction",
      "Convolutional neural networks",
      "Deep learning",
      "Generative adversarial networks",
      "Smart city"
    ],
    "contribution": "This paper proposes a novel approach evaluating four different architectures that utilize camera images to estimate the air pollution in those areas. These images are further enhanced with weather data to boost the classification accuracy. The proposed approach exploits generative adversarial networks combined with data augmentation techniques to mitigate the class imbalance problem. The experiments show that the proposed method achieves robust accuracy of up to 0.88, which is comparable to sequence models and conventional models that utilize air pollution data. This is a remarkable result considering that the historic air pollution data is directly related to the outputâ€”future air pollution data, whereas the proposed architecture uses camera images to recognize the air pollutionâ€”which is an inherently much more difficult problem.",
    "introduction": "Air pollution is becoming a rising and serious environmental problem, especially in urban areas affected by an increasing migration rate. The large availability of sensor data enables the adoption of analytical tools to provide decision support capabilities. Employing sensors facilitates air pollution monitoring, but the lack of predictive capability limits such systemsâ€™ potential in practical scenarios. On the other hand, forecasting methods offer the opportunity to predict the future pollution in specific areas, potentially suggesting useful preventive measures. To date, many works tackled the problem of air pollution forecasting, most of which are based on sequence models. These models are trained with raw pollution data and are subsequently utilized to make predictions.",
    "macro_domains": []
  },
  {
    "abstract": "The Internet of Things (IoT) enables the automation of data collection and processing functions but exposes a huge amount of data to the cyberattacks risk. To tackle this issue, anomaly detection allows to identify data points, events, and/or observations that deviate from a dataset's normal behaviour indicating eventual critical incidents. In this paper, we focus on the imbalance data and the minority classes problem where the number of abnormal samples is much less than normal (secure) samples. In particular, this paper presents a new equilibrium model based on a Genetic Algorithm to improve Generative Adversarial networks (GANs). This model addresses the problem of class imbalance to anomaly detection system performance. The proposed approach use is illustrated by a case study: An intelligent transport system-based scenario.",
    "doi": "10.1109/HPCC-SmartCity-DSS50907.2020.00148",
    "author_keywords": [
      "Anomaly detection",
      "Generative Adversarial Network (GAN)",
      "Genetic Algorithm",
      "Machine Learning",
      "Multi-Objective algorithms"
    ],
    "contribution": "In this paper, we focus on the imbalance data and the minority classes problem where the number of abnormal samples is much less than normal (secure) samples. In particular, this paper presents a new equilibrium model based on a Genetic Algorithm to improve Generative Adversarial networks (GANs). This model addresses the problem of class imbalance to anomaly detection system performance. The proposed approach use is illustrated by a case study: An intelligent transport system-based scenario.",
    "introduction": "The Internet of Things (IoT) enables the automation of data collection and processing functions but exposes a huge amount of data to the cyberattacks risk. To tackle this issue, anomaly detection allows to identify data points, events, and/or observations that deviate from a dataset's normal behaviour indicating eventual critical incidents.",
    "macro_domains": []
  },
  {
    "abstract": "The latest research on smart city technologies mainly focuses on utilizing citiesâ€™ resources to improve the quality of the lives of citizens. Diverse kinds of control signals from massive systems and devices such as adaptive traffic light systems in smart cities can be collected and utilized. Unfortunately, it is difficult to collect a massive dataset of control signals as doing so in the real-world requires significant effort and time. This paper proposes a deep generative model which integrates a long short-term memory model with generative adversarial network (LSTM-GAN) to generate agent control signals based on the words extracted from newspaper articles to solve the problem of collecting massive signals. The discriminatory network in the LSTM-GAN takes continuous word embedding vectors as inputs generated by a pre-trained Word2Vec model. The agent control signals of sequential actions are simultaneously predicted by the LSTM-GAN in real time. Specifically, to collect the training data of smart city simulations, the LSTM-GAN is trained based on the Corpus of Contemporary American English (COCA) newspaper dataset, which contains 5,317,731 sentences, for a total of 93,626,203 word tokens, from written texts. To verify the proposed method, agent control signals were generated and validated. In the training of the LSTM-GAN, the accuracy of the discriminator converged to 50%. In addition, the losses of the discriminator and the generator converged from 4527.04 and 4527.94 to 2.97 and 1.87, respectively.",
    "doi": "10.1186/s13673-020-00252-8",
    "author_keywords": [
      "Control signal",
      "LSTM-GAN",
      "Simulation",
      "Smart city",
      "Word2Vec"
    ],
    "contribution": "This paper proposes a deep generative model which integrates a long short-term memory model with generative adversarial network (LSTM-GAN) to generate agent control signals based on the words extracted from newspaper articles to solve the problem of collecting massive signals. The discriminatory network in the LSTM-GAN takes continuous word embedding vectors as inputs generated by a pre-trained Word2Vec model. The agent control signals of sequential actions are simultaneously predicted by the LSTM-GAN in real time. Specifically, to collect the training data of smart city simulations, the LSTM-GAN is trained based on the Corpus of Contemporary American English (COCA) newspaper dataset, which contains 5,317,731 sentences, for a total of 93,626,203 word tokens, from written texts. To verify the proposed method, agent control signals were generated and validated. In the training of the LSTM-GAN, the accuracy of the discriminator converged to 50%. In addition, the losses of the discriminator and the generator converged from 4527.04 and 4527.94 to 2.97 and 1.87, respectively.",
    "introduction": "The latest research on smart city technologies mainly focuses on utilizing citiesâ€™ resources to improve the quality of the lives of citizens. Diverse kinds of control signals from massive systems and devices such as adaptive traffic light systems in smart cities can be collected and utilized. Unfortunately, it is difficult to collect a massive dataset of control signals as doing so in the real-world requires significant effort and time.",
    "macro_domains": []
  },
  {
    "abstract": "Using deep convolutional neural network (CNN) to intelligently extract buildings from remote sensing images is of great significance for digital city construction, disaster detection and land management. The color difference between multi-temporal remote sensing images will lead to the decrease of generalization ability of building semantic segmentation model. In view of this, this paper proposes the attention-guided color consistency adversarial network (ACGAN). The algorithm takes the reference color style images and the images to be corrected in the same area and different phases as the training set and adopts the consistency adversarial network with the U-shaped attention mechanism to train the color consistency model. In the prediction stage, this model converts the hue of the images to that of the reference color style image, which is based on the reasoning ability of the deep learning model, instead of the corresponding reference color style image. This model transforms the hue of the images to be corrected into that of the reference color style images. This stage is based on the reasoning ability of the deep learning model, and the corresponding reference color style image is no longer needed. In order to verify the effectiveness of the algorithm, firstly, we compare the algorithm of this paper with the traditional image processing algorithm and other consistency adversarial network. The results show that the images after ACGAN color consistency processing are more similar to that of the reference color style images. Secondly, we carried out the building semantic segmentation experiment on the images processed by the above different color consistency algorithms, which proved that the method in this paper is more conducive to the impro-vement of the generalization ability of multi-temporal remote sensing image semantic segmentation model.",
    "doi": "10.11947/j.AGCS.2020.20190439",
    "author_keywords": [
      "Attention mechanism",
      "Color consistency",
      "Generative adversarial networks",
      "Multi-temporal remote sensing imagery",
      "Semantic segmentation"
    ],
    "contribution": "In view of this, this paper proposes the attention-guided color consistency adversarial network (ACGAN). The algorithm takes the reference color style images and the images to be corrected in the same area and different phases as the training set and adopts the consistency adversarial network with the U-shaped attention mechanism to train the color consistency model. In the prediction stage, this model converts the hue of the images to that of the reference color style image, which is based on the reasoning ability of the deep learning model, instead of the corresponding reference color style image. This model transforms the hue of the images to be corrected into that of the reference color style images. This stage is based on the reasoning ability of the deep learning model, and the corresponding reference color style image is no longer needed. In order to verify the effectiveness of the algorithm, firstly, we compare the algorithm of this paper with the traditional image processing algorithm and other consistency adversarial network. The results show that the images after ACGAN color consistency processing are more similar to that of the reference color style images. Secondly, we carried out the building semantic segmentation experiment on the images processed by the above different color consistency algorithms, which proved that the method in this paper is more conducive to the impro-vement of the generalization ability of multi-temporal remote sensing image semantic segmentation model.",
    "introduction": "Using deep convolutional neural network (CNN) to intelligently extract buildings from remote sensing images is of great significance for digital city construction, disaster detection and land management. The color difference between multi-temporal remote sensing images will lead to the decrease of generalization ability of building semantic segmentation model.",
    "macro_domains": []
  },
  {
    "abstract": "The main focus of object detection, one of the most challenging problems in computer vision (CV), is to predict a set of bounding boxes and category labels for each object of interest in an image or in a point cloud. As such, object detection has a variety of exciting downstream applications such as self-driving cars, checkout-less shopping, smart cities, cancer detection, and more. This field has been revolutionized by deep learning over the past five years, where during this time, two-stage approaches to object detection have given way to simpler, more efficient, one-stage models. Mean average precision (mAP) on benchmark problems such as the COCO Object Detection dataset has improved almost 4X over the course of five years from 15% (Fast RCNN, a two-stage approach) to 55% (EfficientDet7x, a one-stage approach). This tutorial looks under the hood of state-of-the-art object detection systems, such as two-stage, one-stage, and also more recent approaches based upon transformers. It builds out some of their associated detection pipelines in a Jupyter Notebook using Python, OpenCV, PyTorch, Keras and Tensorflow. While the primary focus is on object detection in digital images from cameras and videos, this tutorial will also introduce object detection in 3D point clouds.",
    "doi": "10.1145/3340531.3412177",
    "author_keywords": [
      "computer vision",
      "deep learning",
      "detr",
      "efficientdet",
      "faster r-cnn",
      "object detection",
      "point clouds",
      "retinanet",
      "ssd",
      "yolo"
    ],
    "contribution": "",
    "introduction": "The main focus of object detection, one of the most challenging problems in computer vision (CV), is to predict a set of bounding boxes and category labels for each object of interest in an image or in a point cloud. As such, object detection has a variety of exciting downstream applications such as self-driving cars, checkout-less shopping, smart cities, cancer detection, and more. This field has been revolutionized by deep learning over the past five years, where during this time, two-stage approaches to object detection have given way to simpler, more efficient, one-stage models. Mean average precision (mAP) on benchmark problems such as the COCO Object Detection dataset has improved almost 4X over the course of five years from 15% (Fast RCNN, a two-stage approach) to 55% (EfficientDet7x, a one-stage approach). This tutorial looks under the hood of state-of-the-art object detection systems, such as two-stage, one-stage, and also more recent approaches based upon transformers. It builds out some of their associated detection pipelines in a Jupyter Notebook using Python, OpenCV, PyTorch, Keras and Tensorflow. While the primary focus is on object detection in digital images from cameras and videos, this tutorial will also introduce object detection in 3D point clouds.",
    "macro_domains": []
  },
  {
    "abstract": "Anomaly detection is critical in the Internet of Things (IoT) systems due to its wide applications for building smart cities, such as quality control in manufacturing, intrusion detection in system security, fault detection in system monitoring. Many existing schemes are problem specific and supervised approaches, which require domain knowledge and tremendous data labeling efforts. In this paper, we investigate unsupervised anomaly detection on multidimensional time series data in IoT systems, and develops a GRU-based Gaussian Mixture VAE scheme, called GGM-VAE. In particular, we employ Gated Recurrent Unit (GRU) cells to discover the correlations among time series data, and use Gaussian Mixture priors in the latent space to characterize the multimodal data. Several previous works assume simple distributions for Gaussian Mixture priors, resulting in insufficient ability to fully capture the data patterns. To overcome this issue, we design a model selection mechanism during the training process under the guidance of Bayesian Inference Criterion (BIC) to find the model which can well estimate the distribution in the Gaussian Mixture latent space. We conduct extensive simulations on four datasets and observe that our proposed scheme outperforms the state-of-the-art anomaly detection schemes and achieves up to 47.88% improvement in F1 scores on average.",
    "doi": "10.1109/TNSE.2020.3027543",
    "author_keywords": [
      "Gated Recurrent Unit (GRU)",
      "Gaussian Mixture Model (GMM)",
      "iot",
      "smart cities.",
      "unsupervised anomaly detection",
      "Variational Autoencoder(VAE)"
    ],
    "contribution": "In this paper, we investigate unsupervised anomaly detection on multidimensional time series data in IoT systems, and develops a GRU-based Gaussian Mixture VAE scheme, called GGM-VAE. In particular, we employ Gated Recurrent Unit (GRU) cells to discover the correlations among time series data, and use Gaussian Mixture priors in the latent space to characterize the multimodal data. Several previous works assume simple distributions for Gaussian Mixture priors, resulting in insufficient ability to fully capture the data patterns. To overcome this issue, we design a model selection mechanism during the training process under the guidance of Bayesian Inference Criterion (BIC) to find the model which can well estimate the distribution in the Gaussian Mixture latent space. We conduct extensive simulations on four datasets and observe that our proposed scheme outperforms the state-of-the-art anomaly detection schemes and achieves up to 47.88% improvement in F1 scores on average.",
    "introduction": "Anomaly detection is critical in the Internet of Things (IoT) systems due to its wide applications for building smart cities, such as quality control in manufacturing, intrusion detection in system security, fault detection in system monitoring. Many existing schemes are problem specific and supervised approaches, which require domain knowledge and tremendous data labeling efforts.",
    "macro_domains": []
  },
  {
    "abstract": "Data mining on check-in data inlocation based social networks (LBSNs) is an important research direction of urban computing and smart city, and a critical task is to infer location semantic. The study of location semantics has attracted increasing attention in diverse fields due to its wide applications such as location retrieval, location recommendation, data preprocessing and so on. Established inference approaches tend to manually discover the spatiotemporal pattern of unique location as features for training classifiers. However, extracting valuable spatiotemporal patterns or features is a non-trivial task. In this paper, we propose a novel location semantic inference with graph convolutional networks (SI-GCN). We introduce node2vec and variational autoencoder to learn spatial and temporal features of location, respectively. Furthermore, we leverage graph convolutional networks to capture high order relations in user's check-in activity with building a user-location bipartite network. And leveraging self-attention mechanism is allowed to distinguish contributions of the different nodes. Extensive experiments on several real-world check-in data sets show that our proposed framework outperforms than three state-of-art algorithms.",
    "doi": "10.12178/1001-0548.2020152",
    "author_keywords": [
      "Data mining",
      "GCN",
      "LBSNs",
      "Self-attention mechanism",
      "Semantics inference"
    ],
    "contribution": "The study of location semantics has attracted increasing attention in diverse fields due to its wide applications such as location retrieval, location recommendation, data preprocessing and so on. Established inference approaches tend to manually discover the spatiotemporal pattern of unique location as features for training classifiers. However, extracting valuable spatiotemporal patterns or features is a non-trivial task. In this paper, we propose a novel location semantic inference with graph convolutional networks (SI-GCN). We introduce node2vec and variational autoencoder to learn spatial and temporal features of location, respectively. Furthermore, we leverage graph convolutional networks to capture high order relations in user's check-in activity with building a user-location bipartite network. And leveraging self-attention mechanism is allowed to distinguish contributions of the different nodes. Extensive experiments on several real-world check-in data sets show that our proposed framework outperforms than three state-of-art algorithms.",
    "introduction": "Data mining on check-in data inlocation based social networks (LBSNs) is an important research direction of urban computing and smart city, and a critical task is to infer location semantic.",
    "macro_domains": []
  },
  {
    "abstract": "Electricity theft is a notable aspect of power distribution utilities due to advance in the non-technical loss. It results imbalance between power supply and demand. It consequence overload of the distribution network and extraneous tariff invoke on legally connected consumers. The advance metering infrastructure is useful for an energy audit of every distribution transformer due to a communication facility. However, direct hooking on distribution overhead line or tapping from underground cables remains an interminable issue which has to be rigorously decimated. The objective of this study is to present real-time electricity theft detection and prevention scheme (ETDPS) with the available infrastructure in the field. The proposed ETDPS is based on programmable logic control; it identifies the pilferage locations and estimates the power stolen by illegal consumers. The prototype is tested in the laboratory and the results demonstrate that the ETDPS works satisfactorily under diversified operating conditions. The proposed scheme is implemented as a part of their Smart City Pilot Project by Maharashtra State Electricity Distribution Company Limited, Nagpur (India) and the performance demonstrates its feasibility.",
    "doi": "10.1049/iet-smc.2020.0045",
    "author_keywords": [
      "advance metering infrastructure",
      "automatic meter reading",
      "communication facility",
      "demand side management",
      "direct hooking",
      "distribution network",
      "distribution overhead line",
      "distribution transformer",
      "electricity supply industry",
      "energy audit",
      "ETDPS",
      "extraneous tariff",
      "illegal consumers",
      "legally connected consumers",
      "Maharashtra State Electricity Distribution Company Limited",
      "nontechnical loss",
      "overload",
      "power distribution economics",
      "power distribution lines",
      "power distribution reliability",
      "power distribution utilities",
      "power engineering computing",
      "power overhead lines",
      "power supply and demand",
      "power system measurement",
      "programmable controllers",
      "programmable logic control",
      "real-time electricity theft detection and prevention scheme",
      "real-time systems",
      "smart cities",
      "Smart City Pilot Project",
      "tariffs",
      "underground cables",
      "underground cables"
    ],
    "contribution": "The objective of this study is to present real-time electricity theft detection and prevention scheme (ETDPS) with the available infrastructure in the field. The proposed ETDPS is based on programmable logic control; it identifies the pilferage locations and estimates the power stolen by illegal consumers. The prototype is tested in the laboratory and the results demonstrate that the ETDPS works satisfactorily under diversified operating conditions. The proposed scheme is implemented as a part of their Smart City Pilot Project by Maharashtra State Electricity Distribution Company Limited, Nagpur (India) and the performance demonstrates its feasibility.",
    "introduction": "Electricity theft is a notable aspect of power distribution utilities due to advance in the non-technical loss. It results imbalance between power supply and demand. It consequence overload of the distribution network and extraneous tariff invoke on legally connected consumers. The advance metering infrastructure is useful for an energy audit of every distribution transformer due to a communication facility. However, direct hooking on distribution overhead line or tapping from underground cables remains an interminable issue which has to be rigorously decimated.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic forecasting has recently attracted increasing interest due to the popularity of online navigation services, ridesharing and smart city projects. Owing to the non-stationary nature of road traffic, forecasting accuracy is fundamentally limited by the lack of contextual information. To address this issue, we propose the Hybrid Spatio-Temporal Graph Convolutional Network (H-STGCN), which is able to \"deduce\" future travel time by exploiting the data of upcoming traffic volume. Specifically, we propose an algorithm to acquire the upcoming traffic volume from an online navigation engine. Taking advantage of the piecewise-linear flow-density relationship, a novel transformer structure converts the upcoming volume into its equivalent in travel time. We combine this signal with the commonly-utilized travel-time signal, and then apply graph convolution to capture the spatial dependency. Particularly, we construct a compound adjacency matrix which reflects the innate traffic proximity. We conduct extensive experiments on real-world datasets. The results show that H-STGCN remarkably outperforms state-of-the-art methods in various metrics, especially for the prediction of non-recurring congestion.",
    "doi": "10.1145/3394486.3403358",
    "author_keywords": [
      "deep learning",
      "graph convolution",
      "navigation",
      "spatio-temporal dependency",
      "traffic forecasting",
      "traffic simulation"
    ],
    "contribution": "To address this issue, we propose the Hybrid Spatio-Temporal Graph Convolutional Network (H-STGCN), which is able to \"deduce\" future travel time by exploiting the data of upcoming traffic volume. Specifically, we propose an algorithm to acquire the upcoming traffic volume from an online navigation engine. Taking advantage of the piecewise-linear flow-density relationship, a novel transformer structure converts the upcoming volume into its equivalent in travel time. We combine this signal with the commonly-utilized travel-time signal, and then apply graph convolution to capture the spatial dependency. Particularly, we construct a compound adjacency matrix which reflects the innate traffic proximity. We conduct extensive experiments on real-world datasets. The results show that H-STGCN remarkably outperforms state-of-the-art methods in various metrics, especially for the prediction of non-recurring congestion.",
    "introduction": "Traffic forecasting has recently attracted increasing interest due to the popularity of online navigation services, ridesharing and smart city projects. Owing to the non-stationary nature of road traffic, forecasting accuracy is fundamentally limited by the lack of contextual information.",
    "macro_domains": []
  },
  {
    "abstract": "Micro-grids are small-scaled power grids, with local clean energy generation and intelligent management units. Micro-grids equipped with PV panels, wind turbines and batteries are known as hybrid power systems. Since these systems are a promising solution to build the future smart city, different designs were proposed and implemented. The present study compares two micro-grid-connected PMSG designs, with PV panels and batteries, based on system performance and power quality. In the first design, the wind turbine is connected to the common DC bus through a rectifier, while in the second configuration, it is connected to the 3-phase AC circuit via a transformer. The comparison is carried-out under different weather and system conditions. According to simulation results, the first design is less affected by voltage harmonics and has a better power quality, while the second design is robust to inverter or transformer failures and supports more loads.",
    "doi": "10.1007/s12667-019-00334-2",
    "author_keywords": [
      "Hybrid power system",
      "Inverter",
      "Micro-grid",
      "Permanent magnet synchronous generator",
      "Power factor",
      "Power quality",
      "Total harmonic distortion"
    ],
    "contribution": "The present study compares two micro-grid-connected PMSG designs, with PV panels and batteries, based on system performance and power quality. In the first design, the wind turbine is connected to the common DC bus through a rectifier, while in the second configuration, it is connected to the 3-phase AC circuit via a transformer. The comparison is carried-out under different weather and system conditions. According to simulation results, the first design is less affected by voltage harmonics and has a better power quality, while the second design is robust to inverter or transformer failures and supports more loads.",
    "introduction": "Micro-grids are small-scaled power grids, with local clean energy generation and intelligent management units. Micro-grids equipped with PV panels, wind turbines and batteries are known as hybrid power systems. Since these systems are a promising solution to build the future smart city, different designs were proposed and implemented.",
    "macro_domains": []
  },
  {
    "abstract": "Large cities around the world continue to grow larger. This is also the case of Bucharest, the capital city of Romania and one of the largest and most densely populated locations in Eastern Europe. In this article authors present an overview of the development of Bucharest as the largest electricity consumer amongst the Romanian municipalities and analyse possible solutions for the refurbishment of the HV (High Voltage) grid. This process needs to help the city development and its transition to a Smart City. At first authors present the strategy of local authorities for improving the living standard and decrease the environmental pollution. The impact of this strategy on the electrical energy demand is further analysed. Possible technologies are presented for substations and electrical lines starting from the current situation of the transmission network. All these can contribute to a decrease of the environmental impact and to an increase in the continuity of the power supply. Technical and economical evaluation of the refurbished grid is further presented along with a sensitivity analysis. The evaluation of the investment is made by taking into consideration the demand forecast. Lines and transformers are sized and chosen with the best available technology. For the economic analysis authors used criteria accepted by funding sources, banks especially, such as NPV and IRR. The sensitivity of the project economics is tested and discussed. As conclusions authors present the environmental benefits of gradually changing the technology used for electricity transmission in a large city such as Bucharest, mainly regarding land occupancy with switchgear and line routes and soil pollution.",
    "doi": "10.1051/e3sconf/202018004008",
    "author_keywords": null,
    "contribution": "In this article authors present an overview of the development of Bucharest as the largest electricity consumer amongst the Romanian municipalities and analyse possible solutions for the refurbishment of the HV (High Voltage) grid. This process needs to help the city development and its transition to a Smart City. At first authors present the strategy of local authorities for improving the living standard and decrease the environmental pollution. The impact of this strategy on the electrical energy demand is further analysed. Possible technologies are presented for substations and electrical lines starting from the current situation of the transmission network. All these can contribute to a decrease of the environmental impact and to an increase in the continuity of the power supply. Technical and economical evaluation of the refurbished grid is further presented along with a sensitivity analysis. The evaluation of the investment is made by taking into consideration the demand forecast. Lines and transformers are sized and chosen with the best available technology. For the economic analysis authors used criteria accepted by funding sources, banks especially, such as NPV and IRR. The sensitivity of the project economics is tested and discussed. As conclusions authors present the environmental benefits of gradually changing the technology used for electricity transmission in a large city such as Bucharest, mainly regarding land occupancy with switchgear and line routes and soil pollution.",
    "introduction": "Large cities around the world continue to grow larger. This is also the case of Bucharest, the capital city of Romania and one of the largest and most densely populated locations in Eastern Europe.",
    "macro_domains": []
  },
  {
    "abstract": "The concept of smart city strives for greener technology to reduce carbon emission to ameliorate the global warming. Following this footprint, the transportation sector is experiencing a paradigm shift and the transition to electric vehicles (EVs) has prodigious plausibility in reducing carbon emission. However, the anticipated EV penetration is hindered by several challenges, among them are their shorter driving range, slower charging rate and the lack of ubiquitous availability of charging locations, which collectively contribute to range anxieties for EVs' drivers. Meanwhile, the expected immense EV load onto the power distribution network may degrade the voltage stability. To reduce the range anxiety, we present a two-stage solution to provision and dimension a DC fast charging station (CS) network for the anticipated energy demand and that minimizes the deployment cost while ensuring a certain quality of experience for charging e.g., acceptable waiting time and shorter travel distance to charge. This solution also maintains the voltage stability by considering the distribution grid capacity, determining transformers' rating to support peak demand of EV charging and adding a minimum number of voltage regulators based on the impact over the power distribution network. We propose, evaluate and compare two CS network expansion models to determine a cost-effective and adaptive CSs provisioning solution that can efficiently expand the CS network to accommodate future EV charging and conventional load demands. We also propose two heuristic methods and compare our solution with them. Finally, a custom built Python-based discrete event simulator is developed to test our outcomes.",
    "doi": "10.1109/TVT.2020.2993509",
    "author_keywords": [
      "Charging station",
      "electric vehicle",
      "queuing theory",
      "voltage stability"
    ],
    "contribution": "To reduce the range anxiety, we present a two-stage solution to provision and dimension a DC fast charging station (CS) network for the anticipated energy demand and that minimizes the deployment cost while ensuring a certain quality of experience for charging e.g., acceptable waiting time and shorter travel distance to charge. This solution also maintains the voltage stability by considering the distribution grid capacity, determining transformers' rating to support peak demand of EV charging and adding a minimum number of voltage regulators based on the impact over the power distribution network. We propose, evaluate and compare two CS network expansion models to determine a cost-effective and adaptive CSs provisioning solution that can efficiently expand the CS network to accommodate future EV charging and conventional load demands. We also propose two heuristic methods and compare our solution with them. Finally, a custom built Python-based discrete event simulator is developed to test our outcomes.",
    "introduction": "The concept of smart city strives for greener technology to reduce carbon emission to ameliorate the global warming. Following this footprint, the transportation sector is experiencing a paradigm shift and the transition to electric vehicles (EVs) has prodigious plausibility in reducing carbon emission. However, the anticipated EV penetration is hindered by several challenges, among them are their shorter driving range, slower charging rate and the lack of ubiquitous availability of charging locations, which collectively contribute to range anxieties for EVs' drivers. Meanwhile, the expected immense EV load onto the power distribution network may degrade the voltage stability.",
    "macro_domains": []
  },
  {
    "abstract": "The deployment of a charging infrastructure to cover the increasing demand of electric vehicles (EVs) has become a crucial problem in smart cities. Additionally, the penetration of the EV will increase once the users can have enough charging stations. In this work, we tackle the problem of locating a set of charging stations in a smart city considering heterogeneous data sources such as open data city portals, geo-located social network data, and energy transformer substations. We use a multi-objective genetic algorithm to optimize the charging station locations by maximizing the utility and minimizing the cost. Our proposal is validated through a case study and several experimental results.",
    "doi": "10.1016/j.future.2020.03.001",
    "author_keywords": [
      "Charging station",
      "Deap",
      "Electric vehicle",
      "Energy",
      "Evolutionary algorithm",
      "Genetic algorithm",
      "Multi-objective",
      "Peru",
      "Smart city"
    ],
    "contribution": "In this work, we tackle the problem of locating a set of charging stations in a smart city considering heterogeneous data sources such as open data city portals, geo-located social network data, and energy transformer substations. We use a multi-objective genetic algorithm to optimize the charging station locations by maximizing the utility and minimizing the cost. Our proposal is validated through a case study and several experimental results.",
    "introduction": "The deployment of a charging infrastructure to cover the increasing demand of electric vehicles (EVs) has become a crucial problem in smart cities. Additionally, the penetration of the EV will increase once the users can have enough charging stations.",
    "macro_domains": []
  },
  {
    "abstract": "Traffic flow analysis, prediction and management are keystones for building smart cities in the new era. With the help of deep neural networks and big traffic data, we can better understand the latent patterns hidden in the complex transportation networks. The dynamic of the traffic flow on one road not only depends on the sequential patterns in the temporal dimension but also relies on other roads in the spatial dimension. Although there are existing works on predicting the future traffic flow, the majority of them have certain limitations on modeling spatial and temporal dependencies. In this paper, we propose a novel spatial temporal graph neural network for traffic flow prediction, which can comprehensively capture spatial and temporal patterns. In particular, the framework offers a learnable positional attention mechanism to effectively aggregate information from adjacent roads. Meanwhile, it provides a sequential component to model the traffic flow dynamics which can exploit both local and global temporal dependencies. Experimental results on various real traffic datasets demonstrate the effectiveness of the proposed framework.",
    "doi": "10.1145/3366423.3380186",
    "author_keywords": [
      "Dynamic",
      "Graph Neural Networks",
      "Recurrent Neural Network",
      "Spatial Temporal Model",
      "Traffic Prediction",
      "Transformer"
    ],
    "contribution": "In this paper, we propose a novel spatial temporal graph neural network for traffic flow prediction, which can comprehensively capture spatial and temporal patterns. In particular, the framework offers a learnable positional attention mechanism to effectively aggregate information from adjacent roads. Meanwhile, it provides a sequential component to model the traffic flow dynamics which can exploit both local and global temporal dependencies. Experimental results on various real traffic datasets demonstrate the effectiveness of the proposed framework.",
    "introduction": "Traffic flow analysis, prediction and management are keystones for building smart cities in the new era. With the help of deep neural networks and big traffic data, we can better understand the latent patterns hidden in the complex transportation networks. The dynamic of the traffic flow on one road not only depends on the sequential patterns in the temporal dimension but also relies on other roads in the spatial dimension. Although there are existing works on predicting the future traffic flow, the majority of them have certain limitations on modeling spatial and temporal dependencies.",
    "macro_domains": []
  },
  {
    "abstract": "In the era of big data, it is easy for us collect a huge number of image and text data. However, we frequently face the real-world problems with only small (labeled) data in some domains, such as healthcare and urban computing. The challenge is how to make machine learn algorithms still work well with small data? To solve this challenge, in this tutorial, we will cover the state-of-the-art machine learning techniques to handle small data issue. In particular, we focus on the following three aspects: (1) Providing a comprehensive review of recent advances in exploring the power of knowledge transfer, especially focusing on meta-learning; (2) introducing the cutting-edge techniques of incorporating human/expert knowledge into machine learning models; and (3) identifying the open challenges to data augmentation techniques, such as generative adversarial networks. We believe this is an emerging and potentially high-impact topic in computational data science, which will attract both researchers and practitioners from academia and industry.",
    "doi": "10.1145/3336191.3371874",
    "author_keywords": [
      "Generative models",
      "Knowledge regularization",
      "Meta-learning",
      "Transfer learning"
    ],
    "contribution": "",
    "introduction": "In the era of big data, it is easy for us collect a huge number of image and text data. However, we frequently face the real-world problems with only small (labeled) data in some domains, such as healthcare and urban computing. The challenge is how to make machine learn algorithms still work well with small data? To solve this challenge, in this tutorial, we will cover the state-of-the-art machine learning techniques to handle small data issue. In particular, we focus on the following three aspects: (1) Providing a comprehensive review of recent advances in exploring the power of knowledge transfer, especially focusing on meta-learning; (2) introducing the cutting-edge techniques of incorporating human/expert knowledge into machine learning models; and (3) identifying the open challenges to data augmentation techniques, such as generative adversarial networks. We believe this is an emerging and potentially high-impact topic in computational data science, which will attract both researchers and practitioners from academia and industry.",
    "macro_domains": []
  },
  {
    "abstract": "Relevance. Outdated tools and instruments for development and governance prevent the effective use of data and digital platforms in Russian cities, thus creating obstacles for the implementation of smart new solutions. Moreover, the established system of smart city evaluation is â€˜overloadedâ€™ with indicators. For these reasons, the smart city concept is inadequate for todayâ€™s reality of most Russian municipalities, making it difficult for them to meet the national goals for the digitalization of the countryâ€™s economy. The relevance of this study is determined by the need to adjust the smart city concept for municipal economy in Russia and to propose a modified version of this concept. Research objective. This study aims at creating a modified smart city concept by changing evaluation criteria and using a simulation model of municipal economy. Results. The study found that the established smart city concept is not entirely suitable for implementation in Russian municipalities. The lack of adequate methodology of smart city evaluation impedes efficient economic development of municipalities. Data and methods. The study applies a simulation model of municipal economy, which is built by using simulation modelling methods and the Bass diffusion model. Conclusions. The proposed modifications of the smart city concept can provide a springboard for economic development of Russian municipalities to achieve the goals of national digital strategies.",
    "doi": "10.15826/recon.2020.6.4.026",
    "author_keywords": [
      "change management",
      "digitalization",
      "municipal economy",
      "risk",
      "simulation",
      "smart city concept"
    ],
    "contribution": "The relevance of this study is determined by the need to adjust the smart city concept for municipal economy in Russia and to propose a modified version of this concept. Research objective. This study aims at creating a modified smart city concept by changing evaluation criteria and using a simulation model of municipal economy. Results. The study found that the established smart city concept is not entirely suitable for implementation in Russian municipalities. The lack of adequate methodology of smart city evaluation impedes efficient economic development of municipalities. Data and methods. The study applies a simulation model of municipal economy, which is built by using simulation modelling methods and the Bass diffusion model. Conclusions. The proposed modifications of the smart city concept can provide a springboard for economic development of Russian municipalities to achieve the goals of national digital strategies.",
    "introduction": "Relevance. Outdated tools and instruments for development and governance prevent the effective use of data and digital platforms in Russian cities, thus creating obstacles for the implementation of smart new solutions. Moreover, the established system of smart city evaluation is â€˜overloadedâ€™ with indicators. For these reasons, the smart city concept is inadequate for todayâ€™s reality of most Russian municipalities, making it difficult for them to meet the national goals for the digitalization of the countryâ€™s economy.",
    "macro_domains": []
  },
  {
    "abstract": "Urban data is a imperative resource for urban computing, which can promote the establishment of urban knowledge, the collection of urban information and the construction of smart cities. Seen that the urban data collected through hardware sensors and crowdsourcing has the limitations of uneven information distribution, poor data comprehensiveness and high resource costs, we turn to the Internet resources of real-time updates and extensive information coverage. Therefore, we propose an approach to Sensing Urban text Data from Internet Resources (SUDIR). We put forward innovative work on two key issues: Urban data recognition for Chinese context and urban data sensing for multi-source web resources. On one hand, we design a Chinese urban data recognition model based on Whole Word Masking for Bidirectional Encoder Representations from Transformers (BERT-WWM) embedding model and Bidirectional Long-Short Term Memory with a Conditional Random Field (BLSTM-CRF) sequence labeling model. We introduce Chinese Word Segmentaion (CWS) concept in BERT embedding model to make the text embedding effect better represent semantic information on Chinese context. BLSTM-CRF model based on deep learning is used to achieve high-quality coding and prediction. On the other hand, we propose a method of Extracting Urban text data based on Web page features and Clustering operation (EUWC). EUWC is used to correct the false negative samples labeled by BERT-WWM+BLSTM-CRF recognition model and enable SUDIR to sense more accurate and comprehensive city data from multi-source web resources. The experimental results show that our work outperforms the other baseline methods, and it also proves that SUDIR using Internet resources and deep learning technology has the advantages of low-cost, high-quality urban data sensing.",
    "doi": "10.1109/ACCESS.2020.3040408",
    "author_keywords": [
      "Chinese text",
      "deep learning",
      "Internet resources",
      "urban computing",
      "Urban data sensing",
      "web page features"
    ],
    "contribution": "Therefore, we propose an approach to Sensing Urban text Data from Internet Resources (SUDIR). We put forward innovative work on two key issues: Urban data recognition for Chinese context and urban data sensing for multi-source web resources. On one hand, we design a Chinese urban data recognition model based on Whole Word Masking for Bidirectional Encoder Representations from Transformers (BERT-WWM) embedding model and Bidirectional Long-Short Term Memory with a Conditional Random Field (BLSTM-CRF) sequence labeling model. We introduce Chinese Word Segmentaion (CWS) concept in BERT embedding model to make the text embedding effect better represent semantic information on Chinese context. BLSTM-CRF model based on deep learning is used to achieve high-quality coding and prediction. On the other hand, we propose a method of Extracting Urban text data based on Web page features and Clustering operation (EUWC). EUWC is used to correct the false negative samples labeled by BERT-WWM+BLSTM-CRF recognition model and enable SUDIR to sense more accurate and comprehensive city data from multi-source web resources. The experimental results show that our work outperforms the other baseline methods, and it also proves that SUDIR using Internet resources and deep learning technology has the advantages of low-cost, high-quality urban data sensing.",
    "introduction": "Urban data is a imperative resource for urban computing, which can promote the establishment of urban knowledge, the collection of urban information and the construction of smart cities. Seen that the urban data collected through hardware sensors and crowdsourcing has the limitations of uneven information distribution, poor data comprehensiveness and high resource costs, we turn to the Internet resources of real-time updates and extensive information coverage.",
    "macro_domains": []
  },
  {
    "abstract": "Predicting urban traffic is of great importance to smart city systems and public security; however, it is a very challenging task because of several dynamic and complex factors, such as patterns of urban geographical location, weather, seasons, and holidays. To tackle these challenges, we are stimulated by the deep-learning method proposed to unlock the power of knowledge from urban computing and proposed a deep-learning model based on neural network, entitled Capsules TCN Network, to predict the traffic flow in local areas of the city at once. Capsules TCN Network employs a Capsules Network and Temporal Convolutional Network as the basic unit to learn the spatial dependence, time dependence, and external factors of traffic flow prediction. In specific, we consider some particular scenarios that require accurate traffic flow prediction (e.g., smart transportation, business circle analysis, and traffic flow assessment) and propose a GAN-based superresolution reconstruction model. Extensive experiments were conducted based on real-world datasets to demonstrate the superiority of Capsules TCN Network beyond several state-of-the-art methods. Compared with HA, ARIMA, RNN, and LSTM classic methods, respectively, the method proposed in the paper achieved better results in the experimental verification.",
    "doi": "10.1155/2020/6896579",
    "author_keywords": null,
    "contribution": "Compared with HA, ARIMA, RNN, and LSTM classic methods, respectively, the method proposed in the paper achieved better results in the experimental verification.",
    "introduction": "Predicting urban traffic is of great importance to smart city systems and public security; however, it is a very challenging task because of several dynamic and complex factors, such as patterns of urban geographical location, weather, seasons, and holidays. To tackle these challenges, we are stimulated by the deep-learning method proposed to unlock the power of knowledge from urban computing and proposed a deep-learning model based on neural network, entitled Capsules TCN Network, to predict the traffic flow in local areas of the city at once. Capsules TCN Network employs a Capsules Network and Temporal Convolutional Network as the basic unit to learn the spatial dependence, time dependence, and external factors of traffic flow prediction. In specific, we consider some particular scenarios that require accurate traffic flow prediction (e.g., smart transportation, business circle analysis, and traffic flow assessment) and propose a GAN-based superresolution reconstruction model. Extensive experiments were conducted based on real-world datasets to demonstrate the superiority of Capsules TCN Network beyond several state-of-the-art methods.",
    "macro_domains": []
  },
  {
    "abstract": "The grid denotes the electric grid which consists of communication lines, control stations, transformers, and distributors that aids in supplying power from the electrical plant to the consumers. Presently, the electric grid constitutes humongous power production units which generates millions of megawatts of power distributed across several demographic regions. There is a dire need to efficiently manage this power supplied to the various consumer domains such as industries, smart cities, household and organizations. In this regard, a smart grid with intelligent systems is being deployed to cater the dynamic power requirements. A smart grid system follows the Cyber-Physical Systems (CPS) model, in which Information Technology (IT) infrastructure is integrated with physical systems. In the scenario of the smart grid embedded with CPS, the Machine Learning (ML) module is the IT aspect and the power dissipation units are the physical entities. In this research, a novel Multidirectional Long Short-Term Memory (MLSTM) technique is being proposed to predict the stability of the smart grid network. The results obtained are evaluated against other popular Deep Learning approaches such as Gated Recurrent Units (GRU), traditional LSTM and Recurrent Neural Networks (RNN). The experimental results prove that the MLSTM approach outperforms the other ML approaches.",
    "doi": "10.1109/ACCESS.2020.2991067",
    "author_keywords": [
      "cyber physical systems (CPS)",
      "machine learning (ML)",
      "Multidirectional long short-term memory (MLSTM)",
      "smart grid (SG)"
    ],
    "contribution": "In this research, a novel Multidirectional Long Short-Term Memory (MLSTM) technique is being proposed to predict the stability of the smart grid network. The results obtained are evaluated against other popular Deep Learning approaches such as Gated Recurrent Units (GRU), traditional LSTM and Recurrent Neural Networks (RNN). The experimental results prove that the MLSTM approach outperforms the other ML approaches.",
    "introduction": "The grid denotes the electric grid which consists of communication lines, control stations, transformers, and distributors that aids in supplying power from the electrical plant to the consumers. Presently, the electric grid constitutes humongous power production units which generates millions of megawatts of power distributed across several demographic regions. There is a dire need to efficiently manage this power supplied to the various consumer domains such as industries, smart cities, household and organizations. In this regard, a smart grid with intelligent systems is being deployed to cater the dynamic power requirements. A smart grid system follows the Cyber-Physical Systems (CPS) model, in which Information Technology (IT) infrastructure is integrated with physical systems. In the scenario of the smart grid embedded with CPS, the Machine Learning (ML) module is the IT aspect and the power dissipation units are the physical entities.",
    "macro_domains": []
  },
  {
    "abstract": "Rail transport has always been one of the greatest economic boosters of several world nations, allowing the freight and passenger transport. In addition, it is the most secure and economic land transportation mode. From the energetic perspective, the electric locomotives emerge as one of the most efficient land transportation mode, as well as allow a more sustainable development. However, when an electric locomotive is connected to the three-phase power grid, power quality (PQ) deterioration arise, leading to the distortion and unbalance of the three-phase power grid currents and voltages which imply higher operational costs, raising economic and functional issues. In order to overcome the PQ deterioration phenomena, several solutions based power electronics technology have been studied and developed. These solutions vary in terms of control, functionality, implementation costs and complexity. One of the existing solutions is a static synchronous compensator (STATCOM), which compensates the three-phase currents imbalance and harmonics. In this paper, a comprehensive review of the electrified railway systems is carried out, identifying the electric PQ phenomena which may appear due to the non-linear dynamic traction loads. Following this topic, a computational simulation of the STATCOM is presented, making analysis of its behavior regarding the PQ improvement in electrified railway systems. Two case studies are presented: (i) a traction power system fed with V/V power transformer; (ii) a traction power system fed with Scott power transformer.",
    "doi": "10.1007/978-3-030-45694-8_2",
    "author_keywords": [
      "Scott power transformer",
      "STATCOM",
      "V/V power transformer"
    ],
    "contribution": "In this paper, a comprehensive review of the electrified railway systems is carried out, identifying the electric PQ phenomena which may appear due to the non-linear dynamic traction loads. Following this topic, a computational simulation of the STATCOM is presented, making analysis of its behavior regarding the PQ improvement in electrified railway systems. Two case studies are presented: (i) a traction power system fed with V/V power transformer; (ii) a traction power system fed with Scott power transformer.",
    "introduction": "Rail transport has always been one of the greatest economic boosters of several world nations, allowing the freight and passenger transport. In addition, it is the most secure and economic land transportation mode. From the energetic perspective, the electric locomotives emerge as one of the most efficient land transportation mode, as well as allow a more sustainable development. However, when an electric locomotive is connected to the three-phase power grid, power quality (PQ) deterioration arise, leading to the distortion and unbalance of the three-phase power grid currents and voltages which imply higher operational costs, raising economic and functional issues. In order to overcome the PQ deterioration phenomena, several solutions based power electronics technology have been studied and developed. These solutions vary in terms of control, functionality, implementation costs and complexity. One of the existing solutions is a static synchronous compensator (STATCOM), which compensates the three-phase currents imbalance and harmonics.",
    "macro_domains": []
  },
  {
    "abstract": "Electrification of the transportation sector can play a vital role in reshaping smart cities. With an increasing number of electric vehicles (EVs) on the road, deployment of well-planned and efficient charging infrastructure is highly desirable. Unlike level 1 and level 2 charging stations, level 3 chargers are super-fast in charging EVs. However, their installation at every possible site is not techno-economically justifiable because level 3 chargers may cause violation of critical system parameters due to their high power consumption. In this paper, we demonstrate an optimized combination of all three types of EV chargers for efficiently managing the EV load while minimizing installation cost, losses, and distribution transformer loading. Effects of photovoltaic (PV) generation are also incorporated in the analysis. Due to the uncertain nature of vehicle users, EV load is modeled as a stochastic process. Particle swarm optimization (PSO) is used to solve the constrained nonlinear stochastic problem. MATLAB and OpenDSS are used to simulate the model. The proposed idea is validated on the real distribution system of the National University of Sciences and Technology (NUST) Pakistan. Results show that an optimized combination of chargers placed at judicious locations can greatly reduce cost from $3.55 million to $1.99 million, daily losses from 787kWh to 286kWh and distribution transformer congestion from 58% to 22% when compared to scenario of optimized placement of level 3 chargers for 20% penetration level in commercial feeders. In residential feeder, these statistics are improved from $2.52 to $0.81 million, from 2167kWh to 398kWh and from 106% to 14%, respectively. It is also realized that the integration of PV improves voltage profile and reduces the negative impact of EV load. Our optimization model can work for commercial areas such as offices, university campuses, and industries as well as residential colonies.",
    "doi": "10.1109/ACCESS.2020.2984127",
    "author_keywords": [
      "Charging stations placement",
      "distribution system",
      "electric vehicles (EVs)",
      "optimization"
    ],
    "contribution": "In this paper, we demonstrate an optimized combination of all three types of EV chargers for efficiently managing the EV load while minimizing installation cost, losses, and distribution transformer loading. Effects of photovoltaic (PV) generation are also incorporated in the analysis. Due to the uncertain nature of vehicle users, EV load is modeled as a stochastic process. Particle swarm optimization (PSO) is used to solve the constrained nonlinear stochastic problem. MATLAB and OpenDSS are used to simulate the model. The proposed idea is validated on the real distribution system of the National University of Sciences and Technology (NUST) Pakistan. Results show that an optimized combination of chargers placed at judicious locations can greatly reduce cost from $3.55 million to $1.99 million, daily losses from 787kWh to 286kWh and distribution transformer congestion from 58% to 22% when compared to scenario of optimized placement of level 3 chargers for 20% penetration level in commercial feeders. In residential feeder, these statistics are improved from $2.52 to $0.81 million, from 2167kWh to 398kWh and from 106% to 14%, respectively. It is also realized that the integration of PV improves voltage profile and reduces the negative impact of EV load. Our optimization model can work for commercial areas such as offices, university campuses, and industries as well as residential colonies.",
    "introduction": "Electrification of the transportation sector can play a vital role in reshaping smart cities. With an increasing number of electric vehicles (EVs) on the road, deployment of well-planned and efficient charging infrastructure is highly desirable. Unlike level 1 and level 2 charging stations, level 3 chargers are super-fast in charging EVs. However, their installation at every possible site is not techno-economically justifiable because level 3 chargers may cause violation of critical system parameters due to their high power consumption.",
    "macro_domains": []
  },
  {
    "abstract": "With the increasing number of electrical equipment in the home, the safety of household appliances, electricity statistics and remote transmission of information are becoming more and more important. In order to solve this problem, this paper uses STM32F103C8T6 single chip microcomputer as the main control chip to design an intelligent socket system which can measure the power consumption, and display the power consumption information locally, and control the wireless communication with the mobile phone through GSM. The intelligent socket system adopts low power supply, and the collection of power consumption is completed by current transformer ZMCT103C. The communication mode of the system is GSM communication, and the user can plug in the intelligent plug through the mobile phone APP at any place. The system sends text messages to control on-off and timing, so as to achieve the need to save electricity. In this paper, the system software is designed, and the mainstream diagram of the system and the flow chart of the main control modules are given. Finally, the measurement and actual power consumption data of the system are given, and the physical diagram of the system is given. After various tests, the system has the advantages of high reliability and strong measurement and control function, and can be widely used in smart home control system.",
    "doi": "10.1007/978-981-15-2568-1_116",
    "author_keywords": [
      "AC transformer",
      "Intelligent outlet",
      "Wireless communication"
    ],
    "contribution": "In order to solve this problem, this paper uses STM32F103C8T6 single chip microcomputer as the main control chip to design an intelligent socket system which can measure the power consumption, and display the power consumption information locally, and control the wireless communication with the mobile phone through GSM. The intelligent socket system adopts low power supply, and the collection of power consumption is completed by current transformer ZMCT103C. The communication mode of the system is GSM communication, and the user can plug in the intelligent plug through the mobile phone APP at any place. The system sends text messages to control on-off and timing, so as to achieve the need to save electricity. In this paper, the system software is designed, and the mainstream diagram of the system and the flow chart of the main control modules are given. Finally, the measurement and actual power consumption data of the system are given, and the physical diagram of the system is given. After various tests, the system has the advantages of high reliability and strong measurement and control function, and can be widely used in smart home control system.",
    "introduction": "With the increasing number of electrical equipment in the home, the safety of household appliances, electricity statistics and remote transmission of information are becoming more and more important.",
    "macro_domains": []
  },
  {
    "abstract": "The traditional time series analysis and prediction methods do not take into account the prior information of samples and parameters, resulting in a large deviation between the prediction results and the actual data, and the Bayesian parameter estimation method can make full use of the prior information of the parameters. The variance of the estimated parameters is smaller, the estimated results are more accurate, and the predicted results are more real. In order to correctly analyze and predict the changing trend of RMB exchange rate, this paper selects exchange rate data of 995 working days from August 1, 2015 to August 30, 2019 to model the exchange rate of RMB against US dollar in time series autoregressive model. By using the MCMC method, I carry out the model parameters with Gibbs sampling estimation, which makes the prediction of the model more accurate.",
    "doi": "10.1007/978-981-15-2568-1_133",
    "author_keywords": [
      "Autoregressive model",
      "Bayesian parameter estimation",
      "Gibbs sampling",
      "MCMC method"
    ],
    "contribution": "In order to correctly analyze and predict the changing trend of RMB exchange rate, this paper selects exchange rate data of 995 working days from August 1, 2015 to August 30, 2019 to model the exchange rate of RMB against US dollar in time series autoregressive model. By using the MCMC method, I carry out the model parameters with Gibbs sampling estimation, which makes the prediction of the model more accurate.",
    "introduction": "The traditional time series analysis and prediction methods do not take into account the prior information of samples and parameters, resulting in a large deviation between the prediction results and the actual data, and the Bayesian parameter estimation method can make full use of the prior information of the parameters. The variance of the estimated parameters is smaller, the estimated results are more accurate, and the predicted results are more real.",
    "macro_domains": []
  },
  {
    "abstract": "The synchronous condenser is used to supply reactive power for HVDC converter station through the power transformer. The DC power that invades the power transformer biases the operating point of the magnetic field and produces harmonic components on the side of the synchronous condenser. In this paper, the analysis method of big data is adopted to analyze rotor loss of synchronous condenser under the DC bias of the transformer for the goal of accurate calculation of rotor loss. Lots of high-frequency harmonics in terminal voltage of synchronous condenser are generated by DC-bias of transformer. The rotor loss is calculated and compared under lagging phase and leading phase of synchronous condenser. The big data method is used to analyze the harmonic which produce the largest rotor loss. Some conclusions about the rotor loss caused by stator harmonic current are obtained.",
    "doi": "10.1007/978-981-15-2568-1_113",
    "author_keywords": [
      "DC bias",
      "Rotor loss",
      "Synchronous condenser",
      "The big data"
    ],
    "contribution": "In this paper, the analysis method of big data is adopted to analyze rotor loss of synchronous condenser under the DC bias of the transformer for the goal of accurate calculation of rotor loss. Lots of high-frequency harmonics in terminal voltage of synchronous condenser are generated by DC-bias of transformer. The rotor loss is calculated and compared under lagging phase and leading phase of synchronous condenser. The big data method is used to analyze the harmonic which produce the largest rotor loss. Some conclusions about the rotor loss caused by stator harmonic current are obtained.",
    "introduction": "The synchronous condenser is used to supply reactive power for HVDC converter station through the power transformer. The DC power that invades the power transformer biases the operating point of the magnetic field and produces harmonic components on the side of the synchronous condenser.",
    "macro_domains": []
  },
  {
    "abstract": "The Indian government has set an ambitious goal of having an all-electric vehicle fleet by 2030. However, limiting factors related to technology, market and policy could impede their adoption. The objective of this research is to forecast how the diffusion of electric vehicles (EVs) will happen in India and the crucial elements that would influence adoption. The research outcomes are expected to help policy makers to optimally phase investments and incentives earmarked for public charging infrastructure. â€˜Bass diffusion modelâ€™ has been used as the base for preparing a system dynamics model using Vensim software to forecast the diffusion of EVâ€™s from 2017 to 2030. Consumer willingness to purchase EVâ€™s has been elicited through a survey conducted among 50 respondents, who drive 4-wheelers. Adoption has been modeled considering the effect of 4 parameters on consumer willingness to purchase EV, namely- price differential between EVâ€™s and ICE vehicles, range, recharge time and charging infrastructure density. The model output indicates an S-shaped diffusion curve with saturation near the 50th month. Out of the four parameters, adoption is found to be highly sensitive to charging infrastructure density. The paper concludes that there is a high scope of optimizing government investment in charging infrastructure which would require a detailed view of technical, policy and market related aspects.",
    "doi": "10.1007/978-981-32-9119-5_32",
    "author_keywords": [
      "Consumer willingness",
      "Diffusion",
      "Electric vehicle",
      "Price differential",
      "Recharge time"
    ],
    "contribution": "The objective of this research is to forecast how the diffusion of electric vehicles (EVs) will happen in India and the crucial elements that would influence adoption. The research outcomes are expected to help policy makers to optimally phase investments and incentives earmarked for public charging infrastructure. â€˜Bass diffusion modelâ€™ has been used as the base for preparing a system dynamics model using Vensim software to forecast the diffusion of EVâ€™s from 2017 to 2030. Consumer willingness to purchase EVâ€™s has been elicited through a survey conducted among 50 respondents, who drive 4-wheelers. Adoption has been modeled considering the effect of 4 parameters on consumer willingness to purchase EV, namely- price differential between EVâ€™s and ICE vehicles, range, recharge time and charging infrastructure density. The model output indicates an S-shaped diffusion curve with saturation near the 50th month. Out of the four parameters, adoption is found to be highly sensitive to charging infrastructure density. The paper concludes that there is a high scope of optimizing government investment in charging infrastructure which would require a detailed view of technical, policy and market related aspects.",
    "introduction": "The Indian government has set an ambitious goal of having an all-electric vehicle fleet by 2030. However, limiting factors related to technology, market and policy could impede their adoption.",
    "macro_domains": []
  },
  {
    "abstract": "Power Transformers (PT) are one of the most critical components of a Transmission & Distribution (T & D) Utility in terms of its impact on network availability. Apart from criticality, it is one of the costliest equipment in a substation comprising up to 60% of total investment. Multiple operational and environmental factors such as overloading, moisture, heat, progressive ageing, and so on lead to deterioration of insulation (winding and bushing), oil quality and so on result in decreasing PT operational efficiency and lifespan. It is crucial to assess the health condition of such PTs continuously to realize improved efficiency, early fault detection & diagnostics, prediction of maintenance requirements, and reinvestment strategy. The solution is developed to monitor and predict the performance of PT. Data Historian/Cloud Platform acts as a data lake and model repository to fetch online parameters and offline test results integrating with multiple data sources such as SCADA, online Dissolved Gas Analyzer device, Bushing monitor and the Enterprise Resource Planning (ERP) system. Asset Health Index (AHI) for PT is calculated using a multi-criteria analysis approach to derive a quantifiable figure which represents the condition based health of the PT. AHI calculation not only considers online parameters such as DGA, Load, Bushing tan delta capacitance, but also the offline test results such as power factor, Degree of Polymerization, Polarization Index, Winding Resistance and so on. Duval Triangle and IEC Ratio techniques employed in the solution for detecting the incipient fault and diagnosing nature (thermal/electrical) and location (paper/oil) of fault when it occurs. The deployed solution can help the Utilities in: (1) Adopting condition based maintenance strategy moving away from schedule based maintenance; (2) preventing unwanted breakdowns; and (3) Prioritize planning to achieve optimal balance between maintenance and replacement strategy. This paper discusses about the challenges faced by the Utilities in managing the PTs, which has crossed significant life span and the solution to resolve the challenges, taking into consideration maintenance practice followed in Utilities, availability of measurement/test data in Utilities and recommendations of international standards.",
    "doi": "10.1007/978-981-32-9119-5_7",
    "author_keywords": [
      "Asset health index",
      "Asset performance management",
      "DGA",
      "Duval triangle",
      "IEC ratio",
      "Power transformer"
    ],
    "contribution": "This paper discusses about the challenges faced by the Utilities in managing the PTs, which has crossed significant life span and the solution to resolve the challenges, taking into consideration maintenance practice followed in Utilities, availability of measurement/test data in Utilities and recommendations of international standards.",
    "introduction": "Power Transformers (PT) are one of the most critical components of a Transmission & Distribution (T & D) Utility in terms of its impact on network availability. Apart from criticality, it is one of the costliest equipment in a substation comprising up to 60% of total investment. Multiple operational and environmental factors such as overloading, moisture, heat, progressive ageing, and so on lead to deterioration of insulation (winding and bushing), oil quality and so on result in decreasing PT operational efficiency and lifespan. It is crucial to assess the health condition of such PTs continuously to realize improved efficiency, early fault detection & diagnostics, prediction of maintenance requirements, and reinvestment strategy. The solution is developed to monitor and predict the performance of PT. Data Historian/Cloud Platform acts as a data lake and model repository to fetch online parameters and offline test results integrating with multiple data sources such as SCADA, online Dissolved Gas Analyzer device, Bushing monitor and the Enterprise Resource Planning (ERP) system. Asset Health Index (AHI) for PT is calculated using a multi-criteria analysis approach to derive a quantifiable figure which represents the condition based health of the PT. AHI calculation not only considers online parameters such as DGA, Load, Bushing tan delta capacitance, but also the offline test results such as power factor, Degree of Polymerization, Polarization Index, Winding Resistance and so on. Duval Triangle and IEC Ratio techniques employed in the solution for detecting the incipient fault and diagnosing nature (thermal/electrical) and location (paper/oil) of fault when it occurs. The deployed solution can help the Utilities in: (1) Adopting condition based maintenance strategy moving away from schedule based maintenance; (2) preventing unwanted breakdowns; and (3) Prioritize planning to achieve optimal balance between maintenance and replacement strategy.",
    "macro_domains": []
  },
  {
    "abstract": "Generative adversarial networks (GANs) have been promising for many computer vision problems due to their powerful capabilities to enhance the data for training and test. In this paper, we leveraged GANs and proposed a new architecture with a cascaded Single Shot Detector (SSD) for pedestrian detection at distance, which is yet a challenge due to the varied sizes of pedestrians in videos at distance. To overcome the low-resolution issues in pedestrian detection at distance, DCGAN is employed to improve the resolution first to reconstruct more discriminative features for a SSD to detect objects in images or videos. A crucial advantage of our method is that it learns a multi-scale metric to distinguish multiple objects at different distances under one image, while DCGAN serves as an encoder-decoder platform to generate parts of an image that contain better discriminative information. To measure the effectiveness of our proposed method, experiments were carried out on the Canadian Institute for Advanced Research (CIFAR) dataset, and it was demonstrated that the proposed new architecture achieved a much better detection rate, particularly on vehicles and pedestrians at distance, making it highly suitable for smart cities applications that need to discover key objects or pedestrians at distance.",
    "doi": "10.1007/978-3-030-29513-4_43",
    "author_keywords": [
      "Deep neural networks",
      "Object detection",
      "Smart cities",
      "Smart homecare"
    ],
    "contribution": "In this paper, we leveraged GANs and proposed a new architecture with a cascaded Single Shot Detector (SSD) for pedestrian detection at distance, which is yet a challenge due to the varied sizes of pedestrians in videos at distance. To overcome the low-resolution issues in pedestrian detection at distance, DCGAN is employed to improve the resolution first to reconstruct more discriminative features for a SSD to detect objects in images or videos. A crucial advantage of our method is that it learns a multi-scale metric to distinguish multiple objects at different distances under one image, while DCGAN serves as an encoder-decoder platform to generate parts of an image that contain better discriminative information. To measure the effectiveness of our proposed method, experiments were carried out on the Canadian Institute for Advanced Research (CIFAR) dataset, and it was demonstrated that the proposed new architecture achieved a much better detection rate, particularly on vehicles and pedestrians at distance, making it highly suitable for smart cities applications that need to discover key objects or pedestrians at distance.",
    "introduction": "Generative adversarial networks (GANs) have been promising for many computer vision problems due to their powerful capabilities to enhance the data for training and test.",
    "macro_domains": []
  },
  {
    "abstract": "The last two decades have shown an increasing need for GaN-based laser diodes (LDs), which are currently only grown on bulk GaN substrates, which remain to date very expensive and/or only available in small sizes. The ever growing laser market will expand in the coming years, thanks to the development of automotive laser lighting, high-speed Li-Fi optical data transmission, LiDAR sensing for autonomous vehicles and smart cities, head-up displays, and AR/VR systems, in addition to biomedical and further industrial applications. These emerging technologies demand for mass-production of GaN-based lasers to be produced on large-size, low-cost, and industrially compatible substrates. To address this issue, we demonstrate the first electrically injected semipolar 440 nm LD on high-quality and low-defect-density (11-22) GaN templates grown on scalable and low-cost sapphire substrates. The LDs exhibit a threshold current density of 17 kA/cm2, a single facet output power of more than 200 mW at 2 A with a slope efficiency of 0.85 W/A, and a TE polarization having a ratio of 97.6%. These results enable the advancement of ultra-low-cost LDs while benefiting from the inherent advantages of semipolar GaN properties.",
    "doi": "10.1021/acsami.9b17525",
    "author_keywords": [
      "GaN",
      "laser diodes",
      "scalable",
      "semipolar",
      "templates"
    ],
    "contribution": "To address this issue, we demonstrate the first electrically injected semipolar 440 nm LD on high-quality and low-defect-density (11-22) GaN templates grown on scalable and low-cost sapphire substrates. The LDs exhibit a threshold current density of 17 kA/cm2, a single facet output power of more than 200 mW at 2 A with a slope efficiency of 0.85 W/A, and a TE polarization having a ratio of 97.6%. These results enable the advancement of ultra-low-cost LDs while benefiting from the inherent advantages of semipolar GaN properties.",
    "introduction": "The last two decades have shown an increasing need for GaN-based laser diodes (LDs), which are currently only grown on bulk GaN substrates, which remain to date very expensive and/or only available in small sizes. The ever growing laser market will expand in the coming years, thanks to the development of automotive laser lighting, high-speed Li-Fi optical data transmission, LiDAR sensing for autonomous vehicles and smart cities, head-up displays, and AR/VR systems, in addition to biomedical and further industrial applications. These emerging technologies demand for mass-production of GaN-based lasers to be produced on large-size, low-cost, and industrially compatible substrates.",
    "macro_domains": []
  },
  {
    "abstract": "There has been an exponential growth in the microelectronics industry over the last 70 years with a consistent miniaturization of transistors' size and increase in the speed and on-chip transistors density with reasonable power consumption, as seen in Figure 1 [1]. This trend will saturate soon especially due to the unintended thermal noise that is dissipated, as the density of transistors on the chips increase and as the corresponding electronics approach their physical limits. There is a need to implement new processing and computing techniques [2] with more compact size, lower power consumption and enhanced performance. Neuromorphic computing mimics the parallel processing of the mammalian brain and the quantum decoherence within the neurons, and seems to be promising for future applications and needs high speed electronics [3]. Quantum computing could enhance the functionalities, storage capabilities, and data manipulation and transmission, for the next generation of devices. Spintronics is an enabling technology to meet the speed, power, and scalability requirements for quantum information and neuromorphic computing [4 , 5]. The non-volatile nature of spintronic memory could help to tackle power efficiency challenges of microelectronics. Spin of a material is directly related with magnetic, electrical, and optical properties. It is necessary to investigate materials and understand their properties to control and manipulate their spin and use for spintronic applications. However, most materials show conducive properties for spintronics at cryogenic temperatures, which limits their practical applications. There is a need to investigate spintronic materials for quantum applications at room temperature (RT).",
    "doi": "10.1109/HONET.2019.8908100",
    "author_keywords": null,
    "contribution": "",
    "introduction": "There has been an exponential growth in the microelectronics industry over the last 70 years with a consistent miniaturization of transistors' size and increase in the speed and on-chip transistors density with reasonable power consumption, as seen in Figure 1 [1]. This trend will saturate soon especially due to the unintended thermal noise that is dissipated, as the density of transistors on the chips increase and as the corresponding electronics approach their physical limits. There is a need to implement new processing and computing techniques [2] with more compact size, lower power consumption and enhanced performance. Neuromorphic computing mimics the parallel processing of the mammalian brain and the quantum decoherence within the neurons, and seems to be promising for future applications and needs high speed electronics [3]. Quantum computing could enhance the functionalities, storage capabilities, and data manipulation and transmission, for the next generation of devices. Spintronics is an enabling technology to meet the speed, power, and scalability requirements for quantum information and neuromorphic computing [4 , 5]. The non-volatile nature of spintronic memory could help to tackle power efficiency challenges of microelectronics. Spin of a material is directly related with magnetic, electrical, and optical properties. It is necessary to investigate materials and understand their properties to control and manipulate their spin and use for spintronic applications. However, most materials show conducive properties for spintronics at cryogenic temperatures, which limits their practical applications. There is a need to investigate spintronic materials for quantum applications at room temperature (RT).",
    "macro_domains": []
  },
  {
    "abstract": "Detecting phytoplankton that causes red tide is an urgent task. However, the live phytoplankton images are scarce and difficult to obtain. This paper aims to discover a mapping between live and dead phytoplankton. We propose PhytoGAN, a Generative Adversarial Network for the unpaired dead-tolive phytoplankton translation. We design a new PCALoss by extracting the principal component of the image to enhance the contour of the generated image. The addition of PCALoss can significantly improve the integrity of images. The experiments are carried out on the existing phytoplankton dataset. A series of experiments are discussed in the paper to demonstrate the performance of the domain transformation and the proposed loss functions. The experimental results indicate that PhytoGAN can produce more integral images of phytoplankton while completing the domain transformation compared with the existing methods.",
    "doi": "10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00109",
    "author_keywords": [
      "Contour",
      "PCALoss",
      "PhytoGAN",
      "Phytoplankton"
    ],
    "contribution": "This paper aims to discover a mapping between live and dead phytoplankton. We propose PhytoGAN, a Generative Adversarial Network for the unpaired dead-tolive phytoplankton translation. We design a new PCALoss by extracting the principal component of the image to enhance the contour of the generated image. The addition of PCALoss can significantly improve the integrity of images. The experiments are carried out on the existing phytoplankton dataset. A series of experiments are discussed in the paper to demonstrate the performance of the domain transformation and the proposed loss functions. The experimental results indicate that PhytoGAN can produce more integral images of phytoplankton while completing the domain transformation compared with the existing methods.",
    "introduction": "Detecting phytoplankton that causes red tide is an urgent task. However, the live phytoplankton images are scarce and difficult to obtain.",
    "macro_domains": []
  },
  {
    "abstract": "Primal Wasserstein GANs are a variant of Generative Adversarial Networks (i.e., GANs), which optimize the primal form of empirical Wasserstein distance directly. However, the high computational complexity and training instability are the main challenges of this framework. Accordingly, to address these problems, we propose several procedures for improving the training of Primal Wasserstein GANs. We test the effectiveness of our proposed procedures on MNIST, CIFAR-10, LSUN-Bedroom and ImageNet-Dog category datasets, and the extensive experimental results confirm that our method is capable of generating high-quality images and obtaining high inception score. Importantly, we demonstrate that our method is more time efficient compared with other generative model techniques.",
    "doi": "10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00286",
    "author_keywords": [
      "Computational complexity",
      "Empirical wasserstein distance",
      "Primal GANS",
      "Training instability"
    ],
    "contribution": "However, the high computational complexity and training instability are the main challenges of this framework. Accordingly, to address these problems, we propose several procedures for improving the training of Primal Wasserstein GANs. We test the effectiveness of our proposed procedures on MNIST, CIFAR-10, LSUN-Bedroom and ImageNet-Dog category datasets, and the extensive experimental results confirm that our method is capable of generating high-quality images and obtaining high inception score. Importantly, we demonstrate that our method is more time efficient compared with other generative model techniques.",
    "introduction": "Primal Wasserstein GANs are a variant of Generative Adversarial Networks (i.e., GANs), which optimize the primal form of empirical Wasserstein distance directly.",
    "macro_domains": []
  },
  {
    "abstract": "Since the rate at which new content is uploaded to the Internet has reached unprecedented marks, knowing the popularity of online content, especially video, is of importance for network management, recommendation schemes, service design, advertising planning, and so on. Despite the fact that various models have been developed, few of them address the short-term popularity prediction. Toward this goal, we exploit the self-attention mechanism of the Transformer, a state-of-the-art model in neural machine translation, to forecast the values of multiple time series in the near future. Specifically, we propose an attention-based non-recursive neural network, a novel model that entirely dispenses with recurrence and convolutions, for time series prediction. Since our model is the combination of the input attention mechanism in the dual-stage attention-based recurrent neural network (DA-RNN) and the self-attention of Transformer, it is able to adaptively select the most relevant input sequences as well as capture the long-term dependencies across previous time steps to make the prediction. The experiments show the root mean square errors (RMSEs) achieved by our model are only 6.06 and 3.60 when testing on the NASDAQ 100 dataset and the views count of the top most popular videos on Youtube respectively, while the RMSEs of DA-RNN are 8.52 and 12.31. Hence, our model outperforms the baseline not only in time series prediction but also in contents popularity prediction aspect.",
    "doi": "10.1109/HPCC/SmartCity/DSS.2019.00058",
    "author_keywords": [
      "Deep learning",
      "Time series prediction",
      "Transformer",
      "Youtube video"
    ],
    "contribution": "Specifically, we propose an attention-based non-recursive neural network, a novel model that entirely dispenses with recurrence and convolutions, for time series prediction. Since our model is the combination of the input attention mechanism in the dual-stage attention-based recurrent neural network (DA-RNN) and the self-attention of Transformer, it is able to adaptively select the most relevant input sequences as well as capture the long-term dependencies across previous time steps to make the prediction. The experiments show the root mean square errors (RMSEs) achieved by our model are only 6.06 and 3.60 when testing on the NASDAQ 100 dataset and the views count of the top most popular videos on Youtube respectively, while the RMSEs of DA-RNN are 8.52 and 12.31. Hence, our model outperforms the baseline not only in time series prediction but also in contents popularity prediction aspect.",
    "introduction": "Since the rate at which new content is uploaded to the Internet has reached unprecedented marks, knowing the popularity of online content, especially video, is of importance for network management, recommendation schemes, service design, advertising planning, and so on. Despite the fact that various models have been developed, few of them address the short-term popularity prediction. Toward this goal, we exploit the self-attention mechanism of the Transformer, a state-of-the-art model in neural machine translation, to forecast the values of multiple time series in the near future.",
    "macro_domains": []
  },
  {
    "abstract": "The challenges of natural language processing (NLP) lie in the polysemy and insufficiency of human-labeled training data. Bidirectional Encoder Representations from Transformers (BERT) facilitates pre-training deep bidirectional representations on large-scale unannotated text on the web and has created state-of-the-art performance on various NLP tasks after simple fine-tuning. The representation and application of semantic knowledge are important steps in the entire process of NLP tasks. In this work, for the encoder of our model, we encode an input sequence into contextual representations using pre-trained language model and design a new model that combines neural network with BERT. Experimental results show that our method achieves new state-of-the-art.",
    "doi": "10.1109/HPCC/SmartCity/DSS.2019.00297",
    "author_keywords": [
      "BERT",
      "LSTM CRF",
      "word embeddings"
    ],
    "contribution": "In this work, for the encoder of our model, we encode an input sequence into contextual representations using pre-trained language model and design a new model that combines neural network with BERT. Experimental results show that our method achieves new state-of-the-art.",
    "introduction": "The challenges of natural language processing (NLP) lie in the polysemy and insufficiency of human-labeled training data. Bidirectional Encoder Representations from Transformers (BERT) facilitates pre-training deep bidirectional representations on large-scale unannotated text on the web and has created state-of-the-art performance on various NLP tasks after simple fine-tuning. The representation and application of semantic knowledge are important steps in the entire process of NLP tasks.",
    "macro_domains": []
  },
  {
    "abstract": "Collaborative air-ground robotic system has recently emerged as an important research area and shown great potential in many practical applications of smart cities. This work aims to use such system to transform the aerial images from UAVs into terrain map exploited by UGVs to perform ground path planning or navigation tasks. We propose a novel GAN-based active terrain mapping (GAN-ATM) algorithm which integrates Active Learning (AL) strategy into Generative Adversarial Network (GAN) framework to build the terrain map efficiently with a very limited number of labeled data. The empirical results show that the proposed algorithm achieves the highest predictive accuracy of 90.35%. Due to a more accurate terrain map, the UAV using GAN-ATM can plan the shortest trajectory among all existing counterparts.",
    "doi": "10.1109/ICARM.2019.8833919",
    "author_keywords": [
      "Active Learning",
      "Collaborative Air-Ground Robotic System",
      "Convolutional Neural Networks (CNN)",
      "Generative Adversarial Networks (GAN)"
    ],
    "contribution": "This work aims to use such system to transform the aerial images from UAVs into terrain map exploited by UGVs to perform ground path planning or navigation tasks. We propose a novel GAN-based active terrain mapping (GAN-ATM) algorithm which integrates Active Learning (AL) strategy into Generative Adversarial Network (GAN) framework to build the terrain map efficiently with a very limited number of labeled data. The empirical results show that the proposed algorithm achieves the highest predictive accuracy of 90.35%. Due to a more accurate terrain map, the UAV using GAN-ATM can plan the shortest trajectory among all existing counterparts.",
    "introduction": "Collaborative air-ground robotic system has recently emerged as an important research area and shown great potential in many practical applications of smart cities.",
    "macro_domains": []
  },
  {
    "abstract": "CLP Power Hong Kong Limited (CLP Power), as one of Asia's leading power companies, is at the forefront of implementing new technology to transform its conventional power grid into a smart grid to enhance the grid performance and to support the vision for Hong Kong as a leading smart city of the future.Driven by increasing maturity of digitalisation and technological innovation to the methodologies of equipment condition monitoring system, CLP Power grasped the opportunity in rendering optimisation of the maintenance strategies. Implementation of structured Condition-Based Maintenance (CBM) is an initiative of CLP Power to enhance the asset performance in the power system, with transmission transformers, reactors and switchgears. One of the critical success factors for CBM is having a sound decision support system in place. The condition of the individual equipment can be assessed with the aid of condition monitoring facilities collecting the operating and health data by on-line and off-line means.This paper shares CLP Power's experience in application of condition monitoring technologies with associated decision support system in transmission and distribution power grid asset management to ensure a cost effective and reliable energy supply to enhance the performance of major switchgears and transformers.",
    "doi": "10.1109/GTDAsia.2019.8716003",
    "author_keywords": [
      "Condition Monitoring",
      "Condition-Based Maintenance (CBM)",
      "Multi-gas On-line Dissolved Gas Analysis (MODGA) system",
      "Switchgear Monitoring (SGM) for 132kV and 400kV switchgears"
    ],
    "contribution": "The condition of the individual equipment can be assessed with the aid of condition monitoring facilities collecting the operating and health data by on-line and off-line means.This paper shares CLP Power's experience in application of condition monitoring technologies with associated decision support system in transmission and distribution power grid asset management to ensure a cost effective and reliable energy supply to enhance the performance of major switchgears and transformers.",
    "introduction": "CLP Power Hong Kong Limited (CLP Power), as one of Asia's leading power companies, is at the forefront of implementing new technology to transform its conventional power grid into a smart grid to enhance the grid performance and to support the vision for Hong Kong as a leading smart city of the future.Driven by increasing maturity of digitalisation and technological innovation to the methodologies of equipment condition monitoring system, CLP Power grasped the opportunity in rendering optimisation of the maintenance strategies. Implementation of structured Condition-Based Maintenance (CBM) is an initiative of CLP Power to enhance the asset performance in the power system, with transmission transformers, reactors and switchgears. One of the critical success factors for CBM is having a sound decision support system in place.",
    "macro_domains": []
  },
  {
    "abstract": "Smart Grid is a major element of the Smart City concept that enables two-way communication of energy data between electric utilities and their consumers. These communication technologies are going through sharp modernization to meet future demand growth and to achieve reliability, security, and efficiency of the electric grid. In this paper, we implement an IPv6 based two-way communication system between the transformer agent (TA), installed at local electric transformer and various customer agents (CAs), connected to customer's smart meter. Various homes share their energy usage with the TA which in turn sends the utility's recommendations to the CAs. Raspberry Pi is used as hardware for all the CAs and the TA. We implement a self-healing mesh network between all nodes using OpenLab IEEE 802.15.4 chips and Routing Protocol for Low-Power and Lossy Networks (RPL), and the data is secured by RSA/AES keys. Several tests have been conducted in real environments, inside and outside of Carleton University, to test the performance of this communication network in various obstacle settings. In this paper, we highlight the details behind the implementation of this IPv6-based smart grid communication system, the related challenges, and the proposed solutions.",
    "doi": "10.1109/WCNC.2019.8885625",
    "author_keywords": [
      "IEEE 2030.5",
      "IoT",
      "IPv6",
      "Mesh Network",
      "RPL",
      "Smart Grid",
      "Two-Way Communication"
    ],
    "contribution": "In this paper, we implement an IPv6 based two-way communication system between the transformer agent (TA), installed at local electric transformer and various customer agents (CAs), connected to customer's smart meter. Various homes share their energy usage with the TA which in turn sends the utility's recommendations to the CAs. Raspberry Pi is used as hardware for all the CAs and the TA. We implement a self-healing mesh network between all nodes using OpenLab IEEE 802.15.4 chips and Routing Protocol for Low-Power and Lossy Networks (RPL), and the data is secured by RSA/AES keys. Several tests have been conducted in real environments, inside and outside of Carleton University, to test the performance of this communication network in various obstacle settings. In this paper, we highlight the details behind the implementation of this IPv6-based smart grid communication system, the related challenges, and the proposed solutions.",
    "introduction": "Smart Grid is a major element of the Smart City concept that enables two-way communication of energy data between electric utilities and their consumers. These communication technologies are going through sharp modernization to meet future demand growth and to achieve reliability, security, and efficiency of the electric grid.",
    "macro_domains": []
  },
  {
    "abstract": "Autonomous robots for smart homes and smart cities mostly require depth perception in order to interact with their environments. However, depth maps are usually captured in a lower resolution as compared to RGB color images due to the inherent limitations of the sensors. Naively increasing its resolution often leads to loss of sharpness and incorrect estimates, especially in the regions with depth discontinuities or depth boundaries. In this paper, we propose a novel Generative Adversarial Network (GAN)-based framework for depth map super-resolution that is able to preserve the smooth areas, as well as the sharp edges at the boundaries of the depth map. Our proposed model is trained on two different modalities, namely color images and depth maps. However, at test time, our model only requires the depth map in order to produce a higher resolution version. We evaluated our model both quantitatively and qualitatively, and our experiments show that our method performs better than existing state-of-the-art models.",
    "doi": "10.3390/s19071587",
    "author_keywords": [
      "Depth upsampling",
      "Encoder-decoder networks",
      "Generative adversarial networks"
    ],
    "contribution": "In this paper, we propose a novel Generative Adversarial Network (GAN)-based framework for depth map super-resolution that is able to preserve the smooth areas, as well as the sharp edges at the boundaries of the depth map. Our proposed model is trained on two different modalities, namely color images and depth maps. However, at test time, our model only requires the depth map in order to produce a higher resolution version. We evaluated our model both quantitatively and qualitatively, and our experiments show that our method performs better than existing state-of-the-art models.",
    "introduction": "Autonomous robots for smart homes and smart cities mostly require depth perception in order to interact with their environments. However, depth maps are usually captured in a lower resolution as compared to RGB color images due to the inherent limitations of the sensors. Naively increasing its resolution often leads to loss of sharpness and incorrect estimates, especially in the regions with depth discontinuities or depth boundaries.",
    "macro_domains": []
  },
  {
    "abstract": "Depth has been a valuable piece of information for perception tasks such as robot grasping, obstacle avoidance, and navigation, which are essential tasks for developing smart homes and smart cities. However, not all applications have the luxury of using depth sensors or multiple cameras to obtain depth information. In this paper, we tackle the problem of estimating the per-pixel depths from a single image. Inspired by the recent works on generative neural network models, we formulate the task of depth estimation as a generative task where we synthesize an image of the depth map from a single Red, Green, and Blue (RGB) input image. We propose a novel generative adversarial network that has an encoder-decoder type generator with residual transposed convolution blocks trained with an adversarial loss. Quantitative and qualitative experimental results demonstrate the effectiveness of our approach over several depth estimation works.",
    "doi": "10.3390/s19071708",
    "author_keywords": [
      "Depth estimation",
      "Encoder-decoder networks",
      "Generative adversarial networks"
    ],
    "contribution": "In this paper, we tackle the problem of estimating the per-pixel depths from a single image. Inspired by the recent works on generative neural network models, we formulate the task of depth estimation as a generative task where we synthesize an image of the depth map from a single Red, Green, and Blue (RGB) input image. We propose a novel generative adversarial network that has an encoder-decoder type generator with residual transposed convolution blocks trained with an adversarial loss. Quantitative and qualitative experimental results demonstrate the effectiveness of our approach over several depth estimation works.",
    "introduction": "Depth has been a valuable piece of information for perception tasks such as robot grasping, obstacle avoidance, and navigation, which are essential tasks for developing smart homes and smart cities. However, not all applications have the luxury of using depth sensors or multiple cameras to obtain depth information.",
    "macro_domains": []
  },
  {
    "abstract": "Because of frequent extreme weather conditions, accelerated disaster reconnaissance has become extremely important. In particular, surveying traffic sign damage and conditions has become essential for determining and prioritizing necessary repair/replacement. Under the research project sponsored by the National Academy of Sciences NCHRP-IDEA program, a conventional sign detection algorithm based on color, shape, and texture has been developed to process the images of signs. The developed algorithm has been enhanced by digital image processing and deep-learning methods, such as convolutional neural networks (CNN), generative adversarial networks (GAN), and region-based convolutional neural networks (RCNN). In this paper, a method is designed to process the images obtained using unmanned aerial vehicles (UAV), employing a model UAV, to further develop of our current research. The preliminary test shows that it is promising to use a UAV and machine learning to develop an expedited infrastructure condition evaluation following natural disasters because of its automatic and non-contact nature. The preliminary outcomes show the detection rates have satisfying FN rates and very low FP rates. Besides, the designed algorithm and data-gathering method provides a real-time and on-site computation capability that reduces the quantity of data to be stored by filtering out unnecessary data instantly.",
    "doi": "10.1061/9780784482445.052",
    "author_keywords": null,
    "contribution": "Under the research project sponsored by the National Academy of Sciences NCHRP-IDEA program, a conventional sign detection algorithm based on color, shape, and texture has been developed to process the images of signs. The developed algorithm has been enhanced by digital image processing and deep-learning methods, such as convolutional neural networks (CNN), generative adversarial networks (GAN), and region-based convolutional neural networks (RCNN). In this paper, a method is designed to process the images obtained using unmanned aerial vehicles (UAV), employing a model UAV, to further develop of our current research. The preliminary test shows that it is promising to use a UAV and machine learning to develop an expedited infrastructure condition evaluation following natural disasters because of its automatic and non-contact nature. The preliminary outcomes show the detection rates have satisfying FN rates and very low FP rates. Besides, the designed algorithm and data-gathering method provides a real-time and on-site computation capability that reduces the quantity of data to be stored by filtering out unnecessary data instantly.",
    "introduction": "Because of frequent extreme weather conditions, accelerated disaster reconnaissance has become extremely important. In particular, surveying traffic sign damage and conditions has become essential for determining and prioritizing necessary repair/replacement.",
    "macro_domains": []
  }
]