[
    {
        "title": "An interactive address matching method based on a graph attention mechanism",
        "authors": "Li M.",
        "journal": "International Journal of Cognitive Computing in Engineering",
        "doi": "10.1016/j.ijcce.2024.12.003",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213870668",
        "scopus_id": "85213870668",
        "abstract": "Problem: Modernizing and standardizing place names and addresses is a key challenge in the development of smart cities. Purpose: This paper proposes a solution to address matching challenges, such as incomplete descriptions, reversed word order, and the diverse descriptions often found in Chinese addresses. Method: Leveraging the hierarchical structure of Chinese addresses, this study introduces the interactive address matching graph attention model (IAMGAM). In the IAMGAM, an attention-based feature interaction method (AFIM) is employed. To reflect the hierarchical nature of address elements, a directed graph is used to model the address data, and the model is trained and tested using a graph attention mechanism. Results: Experiments demonstrate that the IAMGAM achieves an accuracy and F1-score of 99.61%. Compared with the existing address matching methods, the IAMGAM improves the accuracy by 0.66% to 2.57%, and the F1-score by 0.68% to 2.55%, outperforming baseline models. Additionally, ablation experiments confirm the effectiveness of each component within the model. Furthermore, when fine-tuned using ChatGLM2-6B, the results show that the IAMGAM still outperforms ChatGLM2-6B. Conclusion: IAMGAM demonstrates excellent performance in Chinese address matching tasks, and the Large Language Model (LLM)-based methods, such as ChatGLM2-6B, show great potential for future development in this area.",
        "author_keywords": [
            "Address matching",
            "Attention-based feature interaction method",
            "Directed graph",
            "Interactive address matching graph attention model"
        ],
        "subject_areas": [
            "Information Systems",
            "Engineering (miscellaneous)",
            "Computer Science Applications",
            "Information Systems and Management"
        ]
    },
    {
        "title": "Intelligent pattern design using 3D modelling technology for urban sculpture designing",
        "authors": "Wan W.",
        "journal": "Systems and Soft Computing",
        "doi": "10.1016/j.sasc.2024.200176",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85212000320",
        "scopus_id": "85212000320",
        "abstract": "3D modeling is actuality hired more and more by cities to improve urban planning and cultural protection. Sculptures in settlements are the main goal of this investigate into a novel 3D-Sculpture Architecture Estimation (3D-SAE) model. This model exploits Generative Adversarial Networks (GANs) to improve images, CNNs to extract features, and LDDNN–HGS-ROA, a Novel Lightweight Deep Neural Network mutual with the Hunger Games Search and Remora Optimization Method, to categorize images. The GAN-based image development module reestablishes incapacitated or low-resolution sculpture photos, and the pre-trained CNN usages transfer learning to retrieve thorough features. The LDNN, tuned via HGS and ROA, brands sculpture image classification together effective and precise. This innovative method not only improves the precision of 3D reconstruction, but it also proposals a general tool for art conservationists, urban planners, and the general public in sympathetic and taking in urban sculptures. Participating these cutting-edge tools delivers a solid basis for investigating and interpreting public art, which potentials to improve cultural asset management, art conservation, and urban planning.",
        "author_keywords": [
            "3D modelling, Urban sculpture designing",
            "3D-SAE (3D-Sculpture Analysis and Estimation)",
            "Convolutional neural networks (CNNs)",
            "generative adversarial networks (GANs)",
            "Novel Lightweight Deep Neural Network integrated with Hunger Games Search and Remora Optimization Algorithm (LDNN-HGS-ROA)"
        ],
        "subject_areas": [
            "Software",
            "Theoretical Computer Science",
            "Computer Science Applications",
            "Computational Theory and Mathematics"
        ]
    },
    {
        "title": "GeoAvatar: A big mobile phone positioning data-driven method for individualized pseudo personal mobility data generation",
        "authors": "Li P.",
        "journal": "Computers, Environment and Urban Systems",
        "doi": "10.1016/j.compenvurbsys.2025.102252",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000553754",
        "scopus_id": "86000553754",
        "abstract": "The importance of personal mobility data is widely recognized in various fields. However, the utilization of real personal mobility data raises privacy concerns. Therefore, it is crucial to generate pseudo personal mobility data that accurately reflects real-world mobility patterns while safeguarding user privacy. Nevertheless, existing methods for generating pseudo mobility data, mostly focusing on trip or trajectory generation, have limitations in capturing sufficient individual heterogeneity. To address these gaps, taking pseudo-person(avatar) as ground-zero, a novel individual-based human mobility generator named GeoAvatar has been proposed – which considering individual heterogeneity in spatial and temporal decision-making, incorporates demographic characteristics. Our method utilizes a deep generative model to generate heterogeneous individual life patterns, a variation inference model for inferring individual demographic characteristics, and a Bayesian-based approach for generating spatial choices considering individual demographic characteristics. Through our method, we have achieved generating realistic pseudo personal human mobility data - we evaluated the proposed method based on physical features – obeying common law of human mobility, activity features – showing diverse and realistic activities, and spatial-temporal characteristics – presenting high-accuracy in terms of temporal grid population and od-count, demonstrating its good performance, with both a big mobile phone GPS trajectory dataset from Tokyo Metropolis and a big mobile phone CDR dataset from Shanghai. Furthermore, this method maintains extensibility for broader applications, making it a promising framework for generating pseudo personal human mobility data.",
        "author_keywords": [
            "Big mobility data",
            "Generative model",
            "GIS",
            "Mahince learning",
            "Smart City"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Ecological Modeling",
            "Environmental Science (all)",
            "Urban Studies"
        ]
    },
    {
        "title": "Demystifying SAR with attention",
        "authors": "Patnaik N.",
        "journal": "Expert Systems with Applications",
        "doi": "10.1016/j.eswa.2025.127182",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000797212",
        "scopus_id": "86000797212",
        "abstract": "Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the ability to capture data under challenging conditions such as cloud cover and darkness. However, its grayscale format and speckle noise hinder interpretability and pose significant challenges for traditional processing methods. This study introduces an innovative framework for SAR image colorization, leveraging an Attention-Based WGAN-GP (Wasserstein GAN with Gradient Penalty). The model incorporates multi-head self-attention mechanisms to enhance feature extraction, capture long-range dependencies, and dynamically suppress noise through a novel variance-based attention adjustment mechanism. Extensive evaluations on Sentinel-1 and Sentinel-2 datasets across diverse terrains, including agriculture, urban areas, barren land, and grasslands, demonstrate the model's superiority over existing approaches. It achieves an LPIPS score of 0.27, SSIM of 0.76, and an average inference time of 0.22 s, showcasing its ability to preserve spatial coherence and perceptual quality even in complex, noisy environments. This capability enables real-time applications in disaster management, flood monitoring, and urban planning, providing actionable insights and advancing the state-of-the-art in SAR image processing.",
        "author_keywords": [
            "Attention",
            "Deep learning",
            "Generative adversarial networks",
            "Image colorization",
            "Image restoration",
            "Multihead attention",
            "Noise",
            "SAR",
            "Sentinel"
        ],
        "subject_areas": [
            "Engineering (all)",
            "Computer Science Applications",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "STV AE : Skip connection driven Two-stream property fusion Variational AutoEncoder for cross-region wastewater treatment plant semantic segmentation",
        "authors": "Li Y.",
        "journal": "Information Fusion",
        "doi": "10.1016/j.inffus.2025.102960",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216015347",
        "scopus_id": "85216015347",
        "abstract": "Wastewater treatment plant (WWTP) plays a crucial role in achieving social sustainable development goals. Precise information on WWTPs obtained through advanced semantic segmentation technologies benefits multiple applications, including urban planning, environmental protection and public health. However, the diverse architectural styles, scales and surroundings of WWTPs across regions, influenced by climate, topography and regional economic conditions, bring challenges in generalizing segmentation algorithms. Thus, fusing the knowledge learned from different regions can form a more powerful knowledge representation. In this paper, we propose a Skip connection driven Two-stream property fusion Variational AutoEncoder (STVAE) for cross-region WWTP semantic segmentation. Our motivation is to increase the generalization capability of STVAE by capturing and fusing generative probabilistic features, inherent region properties and multi-scale properties. Specifically, STVAE captures the generative probabilistic features by constructing an attention-driven variational encoder. These features make STVAE more adaptable to the cross-domain changes, improving the segmentation robustness and performance. This attention-driven structure contributes to learning local details and limiting the effect of weak semantic information. Furthermore, a two-stream parallel decoder is considered to adapt distributions from different perspectives. The inherent region properties are introduced in this decoder to highlight the spatial consistency of the results. The unsupervised inherent region information and multi-scale features, which are extracted by this decoder, are fused through an entropy-wise mechanism. Additionally, a unique adversarial strategy is utilized to align the distributions of different domains. Based on OpenStreetMap (OSM) data and Microsoft Bing Maps Very High Resolution (VHR) satellite images, multiple experiments conducted on three tasks illustrate the effectiveness of STVAE compared with several state-of-the-art techniques qualitatively and quantitatively. STVAE effectively expands its application scope.",
        "author_keywords": [
            "Cross-region semantic segmentation",
            "Domain adaptation",
            "Property fusion",
            "Remote sensing",
            "Wastewater treatment plant"
        ],
        "subject_areas": [
            "Software",
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture"
        ]
    },
    {
        "title": "Creating visualizations using generative AI to guide decision-making in street designs: A viewpoint",
        "authors": "Valença G.",
        "journal": "Journal of Urban Mobility",
        "doi": "10.1016/j.urbmob.2025.100104",
        "publication_date": "2025",
        "document_type": "Note",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215407224",
        "scopus_id": "85215407224",
        "abstract": "Architecture software tools are usually used to illustrate new street design layouts (e.g., Computer-Aided Design). However, these tools are not appropriate for the co-creation of street design solutions mainly due to the demanding work to create complex designs, the lack of multi-user interfaces, and the inability to create visualizations in real-time. Recently, a few generative AI tools such as UrbanistAI, PlacemakingAI, and Laneform have been developed to overcome these limitations, generating real-time street layout visualizations. These tools aim to enhance stakeholder and citizen involvement in street design processes by allowing citizens to easily modify street layouts and visualize how the street could be in the future. Even though these tools may increase efficiency in design generation, their possible impacts and integration into urban planning practices are poorly questioned and studied. This viewpoint aims to outline a research agenda, discussing the challenges and potential positive and negative effects of using generative AI in participatory decision-making for street designs. To the best of our knowledge, this is the first paper that discusses the possible benefits and impacts of these generative AI tools for generating future street design. We believe that integrating generative AI street design participation tools into urban planning processes has yet to be thoroughly understood, particularly in their impact on people's creativity and problem-solving, adaptability to different contexts, alignment with recent AI regulations, and implications for equity.",
        "author_keywords": [
            "Generative AI",
            "Participatory planning",
            "Road space allocation",
            "Street design",
            "Urban space distribution",
            "Visualization"
        ],
        "subject_areas": [
            "Transportation",
            "Geography, Planning and Development"
        ]
    },
    {
        "title": "MiM-UNet: An efficient building image segmentation network integrating state space models",
        "authors": "Liu D.",
        "journal": "Alexandria Engineering Journal",
        "doi": "10.1016/j.aej.2025.02.035",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218637730",
        "scopus_id": "85218637730",
        "abstract": "With the advancement of remote sensing technology, the analysis of complex terrain images has become crucial for urban planning and geographic information extraction. However, existing models face significant challenges in processing intricate building structures: Transformer-based models suffer from high computational complexity and memory demands, while Convolutional Neural Networks (CNNs) often struggle to capture features across multiple scales and hierarchical levels. To address these limitations, we propose a novel architecture, Mamba-in-Mamba U-Net (MiM-UNet), which integrates the design principles of state–space models (SSMs) to enhance both computational efficiency and feature extraction capacity. Specifically, MiM-UNet refines the traditional encoder–decoder framework by introducing Mamba-in-Mamba blocks, enabling precise multi-scale feature capture and efficient information fusion. Experimental results demonstrate that MiM-UNet outperforms state-of-the-art models in segmentation accuracy on the Massachusetts building dataset, while substantially reducing computational overhead, highlighting its superior performance and promising potential for practical applications.",
        "author_keywords": [
            "Building segmentation",
            "Complex terrain",
            "Deep learning",
            "Remote sensing images",
            "State space models"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "What is a Digital Twin anyway? Deriving the definition for the built environment from over 15,000 scientific publications",
        "authors": "Abdelrahman M.",
        "journal": "Building and Environment",
        "doi": "10.1016/j.buildenv.2025.112748",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85219499715",
        "scopus_id": "85219499715",
        "abstract": "The concept of Digital Twins (DT) has attracted significant attention across various domains, particularly within the built environment. However, there is a sheer volume of definitions and the terminological consensus remains out of reach. The lack of a universally accepted definition leads to ambiguities in their conceptualization and implementation, and may cause miscommunication for both researchers and practitioners. We employed Natural Language Processing (NLP) techniques to systematically extract and analyze definitions of DTs from a corpus of more than 15,000 full-text articles spanning diverse disciplines. The study compares these findings with insights from an expert survey that included 52 experts. The study identifies concurrence on the components that comprise a “Digital Twin” from a practical perspective across various domains, contrasting them with those that do not, to identify deviations. We investigate the evolution of digital twin definitions over time and across different scales, including manufacturing, building, and urban/geospatial perspectives. We extracted the main components of Digital Twins using Text Frequency Analysis and N-gram analysis. Subsequently, we identified components that appeared in the literature and conducted a Chi-square test to assess the significance of each component in different domains. Our analysis identified key components of digital twins and revealed significant variations in definitions based on application domains, such as manufacturing, building, and urban contexts. The analysis of DT components reveal two major groups of DT types: High-Performance Real-Time (HPRT) DTs, and Long-Term Decision Support (LTDS) DTs. Contrary to common assumptions, we found that components such as simulation, AI/ML, real-time capabilities, and bi-directional data flow are not yet fully mature in the digital twins of the built environment. We derived two definitions for the Building/Architecture DT and the City/Urban DTs. Both definitions have a must-have components (such as spatial and temporal data updates) and good-to-have components such as prediction, AI, bi-directional data flow, and Real-time data exchange. One of the key findings is that the definition of digital twins has not yet reached its equilibrium phase, highlighting the need for ongoing revisions as technologies emerge or existing ones become obsolete. To address this, we introduce a novel, reproducible methodology that enables researchers to refine and adapt the current definitions in response to technological advancements or deprecations.",
        "author_keywords": [
            "Building digital twin",
            "City digital twin",
            "Digital twin",
            "LLMs",
            "NLP",
            "Terminology",
            "Urban digital twin"
        ],
        "subject_areas": [
            "Environmental Engineering",
            "Civil and Structural Engineering",
            "Geography, Planning and Development",
            "Building and Construction"
        ]
    },
    {
        "title": "POI Extraction From Digital City: An Engineering Exploration With Large-Language Models",
        "authors": "Sun M.",
        "journal": "Expert Systems",
        "doi": "10.1111/exsy.70001",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85219323485",
        "scopus_id": "85219323485",
        "abstract": "Point-of-interest (POI) extraction aims to extract text POIs from real-world data. Existing POI methods, such as social media-based user generating and web crawling, either require massive human resources or cannot guarantee integrity and reliability. Therefore, in this paper, an end-to-end POI extraction framework based on digital city is proposed. It is built of digital models, textures, tiles and other digital assets collected by aircraft. The extraction process for POIs consists of segmenting it into four sequential stages: collecting, segmentation, recognition and cleaning, each enhanced through fine-tuning on a proposed specialised digital scene dataset or via the development of tailored algorithms. Specifically, in the last stage, the application of large language model (LLM) is explored in the POI data cleaning field. By testing several LLMs of different scales using diverse chain-of-thought (CoT) strategies, the relatively optimal prompt scheme for different LLMs is identified regarding noise handling, formatted output and overall cleaning capability. Ultimately, POIs extracted through the proposed methodology exhibit superior quality and accuracy, surpassing the comprehensiveness of existing public commercial POI datasets, with the F1-score increased by 19.6%, 21.1% and 23.8% on Amap, Baidu and Google POI datasets, respectively.",
        "author_keywords": [
            "artificial intelligence",
            "data cleaning",
            "large language models",
            "point-of-interest"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Theoretical Computer Science",
            "Computational Theory and Mathematics",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Strengthening security in IoT-based smart cities utilizing cycle-consistent generative adversarial networks for attack detection and secure data transmission",
        "authors": "W A.",
        "journal": "Peer-to-Peer Networking and Applications",
        "doi": "10.1007/s12083-024-01838-0",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218153640",
        "scopus_id": "85218153640",
        "abstract": "The main purpose of Smart Environments (SE) is to conveniently improve the human's daily life. Internet of Things (IoT) is a developing network for smart objects. Privacy-based security is a significant issue in any real-world smart environments centered on the IoT system. Security susceptibility in the IoT-centered systems provides a risk of security affecting smart environment applications. In this manuscript, Strengthening Security in IoT-Based Smart Cities utilizing Cycle-Consistent Generative Adversarial Networks for Attack Detection and Secure Data Transmission (IoT-SC-CCGAN-ADSDT) is proposed. Here, input information is gathered from NSL-KDD. The NSL-KDD input is pre-processed. Then, the important features of the pre-processed data are selected by using Wild horse optimizer (WHO). After feature selection, the chosen features are provided to cycle-consistent generative adversarial network classifier for classifying the attack and normal data. The selected features are sent to the use after the prediction of outcomes using Advanced Encryption Standard (AES). The AES is optimized using Chameleon Swarm Algorithm for transmitting the data in a safer way. After transmitting the data securely, the normal data outcomes obviously shown in LCD monitor. To show these results, major problems in the smart cities are simply detected. The proposed model is activated using java. The efficiency is examined with performance metrics, like precision, sensitivity, specificity, accuracy, computational time, encryption time, decryption time, security level. The proposed IoT-SC-CCGAN-ADSDT approach provides 96.68%, 7.142%, 94.65%, and 97.58% greater accuracy compared to the existing DL-IOT-SCA, IoT-SC-PCA, IoT-SCA-DL methods respectively.",
        "author_keywords": [
            "Advanced encryption standard",
            "Attack detection",
            "Chameleon swarm algorithm",
            "Internet of Things",
            "Smart cities",
            "Wild horse optimizer"
        ],
        "subject_areas": [
            "Software",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Urban attractiveness according to ChatGPT: Contrasting AI and human insights",
        "authors": "Malekzadeh M.",
        "journal": "Computers, Environment and Urban Systems",
        "doi": "10.1016/j.compenvurbsys.2024.102243",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85212830252",
        "scopus_id": "85212830252",
        "abstract": "The attractiveness of urban environments significantly impacts residents' satisfaction with their living spaces and their overall mood, which in turn, affects their health and well-being. Given the resource-intensive nature of gathering evaluations on urban attractiveness through surveys or inquiries from residents, there is a constant quest for automated solutions to streamline this process and support spatial planning. In this study, we applied an off-the-shelf AI model to automate the analysis of urban attractiveness, using over 1800 Google Street View images of Helsinki, Finland. By incorporating the GPT-4 model, we assessed these images through three criteria-based prompts. Simultaneously, 24 participants, categorised into residents and non-residents, were asked to rate the images. To gain insights into the non-transparent decision-making processes of GPT-4, we employed semantic segmentation to explore how the model uses different image features. Our results demonstrated a strong alignment between GPT-4 and participant ratings, although geographic disparities were noted. Specifically, GPT-4 showed a preference for suburban areas with significant greenery, contrasting with participants who found these areas less attractive. Conversely, in the city centre and densely populated urban regions of Helsinki, GPT-4 assigned lower attractiveness scores than participant ratings. The semantic segmentation analysis revealed that GPT-4's ratings were primarily influenced by physical features like vegetation, buildings, and sidewalk. While there was general agreement between AI and human assessments across various locations, GPT-4 struggled to incorporate contextual nuances into its ratings, unlike participants, who considered both context and features of the urban environment. The study suggests that leveraging AI models like GPT-4 allows spatial planners to gather insights into the attractiveness of different areas efficiently. However, caution is necessary, while we used an off-the-shelf model, it is crucial to develop models specifically trained to understand the local context. Although AI models provide valuable insights, human perspectives are essential for a comprehensive understanding of urban attractiveness.",
        "author_keywords": [
            "AI-human comparison",
            "Multimodal large language models",
            "Spatial planning",
            "Street view imagery",
            "Urban design"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Ecological Modeling",
            "Environmental Science (all)",
            "Urban Studies"
        ]
    },
    {
        "title": "MBGPIN: Multi-Branch Generative Prior Integration Network for Super-Resolution Satellite Imagery",
        "authors": "Safarov F.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs17050805",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000775114",
        "scopus_id": "86000775114",
        "abstract": "Achieving super-resolution with satellite images is a critical task for enhancing the utility of remote sensing data across various applications, including urban planning, disaster management, and environmental monitoring. Traditional interpolation methods often fail to recover fine details, while deep-learning-based approaches, including convolutional neural networks (CNNs) and generative adversarial networks (GANs), have significantly advanced super-resolution performance. Recent studies have explored large-scale models, such as Transformer-based architectures and diffusion models, demonstrating improved texture realism and generalization across diverse datasets. However, these methods frequently have high computational costs and require extensive datasets for training, making real-world deployment challenging. We propose the multi-branch generative prior integration network (MBGPIN) to address these limitations. This novel framework integrates multiscale feature extraction, hybrid attention mechanisms, and generative priors derived from pretrained VQGAN models. The dual-pathway architecture of the MBGPIN includes a feature extraction pathway for spatial features and a generative prior pathway for external guidance, dynamically fused using an adaptive generative prior fusion (AGPF) module. Extensive experiments on benchmark datasets such as UC Merced, NWPU-RESISC45, and RSSCN7 demonstrate that the MBGPIN achieves superior performance compared to state-of-the-art methods, including large-scale super-resolution models. The MBGPIN delivers a higher peak signal-to-noise ratio (PSNR) and higher structural similarity index measure (SSIM) scores while preserving high-frequency details and complex textures. The model also achieves significant computational efficiency, with reduced floating point operations (FLOPs) and faster inference times, making it scalable for real-world applications.",
        "author_keywords": [
            "adaptive generative prior fusion",
            "high-frequency detail recovery",
            "multi-branch generative prior integration network",
            "remote sensing",
            "satellite image super-resolution"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Building Change Detection in Aerial Imagery Using End-to-End Deep Learning Semantic Segmentation Techniques",
        "authors": "Teo T.A.",
        "journal": "Buildings",
        "doi": "10.3390/buildings15050695",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000578375",
        "scopus_id": "86000578375",
        "abstract": "Automatic building change detection is essential for updating geospatial data, urban planning, and land use management. The objective of this study is to propose a transformer-based UNet-like framework for end-to-end building change detection, integrating multi-temporal and multi-source data to improve efficiency and accuracy. Unlike conventional methods that focus on either spectral imagery or digital surface models (DSMs), the proposed method combines RGB color imagery, DSMs, and building vector maps in a three-branch Siamese architecture to enhance spatial, spectral, and elevation-based feature extraction. We chose Hsinchu, Taiwan as the experimental site and used 1:1000 digital topographic maps and airborne imagery from 2017, 2020, and 2023. The experimental results demonstrated that the data fusion model significantly outperforms other data combinations, achieving higher accuracy and robustness in detecting building changes. The RGB images provide spectral and texture details, DSMs offer structural and elevation context, and the building vector map enhances semantic consistency. This research advances building change detection by introducing a fully transformer-based model for end-to-end change detection, incorporating diverse geospatial data sources, and improving accuracy over traditional CNN-based methods. The proposed framework offers a scalable and automated solution for modern mapping workflows, contributing to more efficient geospatial data updating and urban monitoring.",
        "author_keywords": [
            "buildings",
            "change detection",
            "deep learning",
            "map updating"
        ],
        "subject_areas": [
            "Architecture",
            "Civil and Structural Engineering",
            "Building and Construction"
        ]
    },
    {
        "title": "Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin",
        "authors": "Huang J.",
        "journal": "Environmental Science and Ecotechnology",
        "doi": "10.1016/j.ese.2025.100526",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216848180",
        "scopus_id": "85216848180",
        "abstract": "Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.",
        "author_keywords": [
            "Foundation models",
            "Generative artificial intelligence",
            "Generative spatial artificial intelligence",
            "Large flow model",
            "Sustainable smart cities",
            "Urban digital twin",
            "Urban planning and design"
        ],
        "subject_areas": [
            "Environmental Engineering",
            "Ecology",
            "Environmental Science (miscellaneous)"
        ]
    },
    {
        "title": "Urban Chatter: Exploring the potential of ChatGPT-like and generative AI in enhancing planning support",
        "authors": "Jiang H.",
        "journal": "Cities",
        "doi": "10.1016/j.cities.2025.105701",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214128166",
        "scopus_id": "85214128166",
        "abstract": "Historically, Planning Support Systems (PSS) have grappled with an implementation gap stemming from a mismatch between supply and demand. Despite the growing availability of diverse and potentially beneficial planning support tools, practitioners exhibit reluctance in purchasing, implementing, or utilizing them. This phenomenon raises significant questions regarding the perceived value of these readily accessible tools. This paper evaluates the potential of emerging ChatGPT-like and generative AI models in addressing PSS gaps and enhancing planning support in AI urbanism. It reviews literature and considers recent technological advancements, emphasizing implications for urban planning. ChatGPT-like models show promise in improving PSS quality by improving data processing, creative generation, and decision support, and promoting user acceptance through increased public engagement, outreach, and superior communication and education. This enhancement would improve the selectivity in applying planning support technologies in actual planning practice and extend beyond the implementation gap. However, overcoming challenges like data privacy, bias, and feasibility is vital. Urban planners and policymakers are encouraged to adopt these AI models while addressing PSS challenges through research, equitable integration, and responsible practices.",
        "author_keywords": [
            "AI models",
            "Equitable planning",
            "Implementation gap",
            "Planning support systems",
            "Transformer architecture"
        ],
        "subject_areas": [
            "Development",
            "Sociology and Political Science",
            "Urban Studies",
            "Tourism, Leisure and Hospitality Management"
        ]
    },
    {
        "title": "Can we realize seamless traffic safety at smart intersections by predicting and preventing impending crashes?",
        "authors": "Hassan Anik B.M.T.",
        "journal": "Accident Analysis and Prevention",
        "doi": "10.1016/j.aap.2024.107908",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213567305",
        "scopus_id": "85213567305",
        "abstract": "Intersections are frequently identified as crash hotspots for roadways in major cities, leading to significant human casualties. We propose crash likelihood prediction as an effective strategy to proactively prevent intersection crashes. So far, no reliable models have been developed for intersections that effectively account for the variation in crash types and the cyclical nature of Signal Phasing and Timing (SPaT) and traffic flow. Moreover, the limited research available has primarily relied on sampling techniques to address data imbalance, without exploring alternative solutions. We develop an anomaly detection framework by integrating Generative Adversarial Networks (GANs) and Transformers to predict the likelihood of cycle-level crashes at intersections. The model is built using high-resolution event data extracted from Automated Traffic Signal Performance Measures (ATSPM), including SPaT and traffic flow insights from 11 intersections in Seminole County, Florida. Our framework demonstrates a sensitivity of 76% in predicting crash events using highly imbalanced crash data along with real-world SPaT and traffic data, highlighting its potential for deployment at smart intersections. Overall, the results provide a roadmap for city-wide implementation at smart intersections, with the potential for multiple real-time solutions for impending crashes. These include adjustments in signal timing, driver warnings using various means, and more efficient emergency response, all with major implications for creating more livable and safe cities.",
        "author_keywords": [
            "Anomaly detection",
            "Crash likelihood prediction",
            "GANs",
            "Proactive safety measures",
            "Smart cities",
            "Smart intersections",
            "Transformers"
        ],
        "subject_areas": [
            "Human Factors and Ergonomics",
            "Safety, Risk, Reliability and Quality",
            "Public Health, Environmental and Occupational Health",
            "Law"
        ]
    },
    {
        "title": "Edge Implicit Weighting with graph transformers for robust intrusion detection in Internet of Things network",
        "authors": "Karpagavalli C.",
        "journal": "Computers and Security",
        "doi": "10.1016/j.cose.2024.104299",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85212849609",
        "scopus_id": "85212849609",
        "abstract": "In recent years, the Internet of Things devices have progressively deployed in various applications including smart cities, intelligent transportation, healthcare, and agriculture. However, this widespread adaptation of the Internet of Things networks has been vulnerable to several attacks. Lack of security protocols, unauthorized access, and improper device updates lead the Internet of Things environment to several attacks, which impact network security and confidentiality of users. This paper develops an innovative approach that integrates Edge Implicit Weighting and Aggregated Graph Transformer architecture for accurate and timely intrusion detection. The proposed technique aggregates information from both one-hop and two-hop neighbors to derive immediate and extended relational context thereby improving the detection of complex attacks. This approach designs an Edge Implicit Weighting mechanism that allows the model to prioritize structurally significant relationships and enhance the accuracy of attack detection. The multi-head attention mechanism is introduced to enhance the detection of relevant patterns even in highly variable traffic scenarios. Further, the proposed framework incorporates the Synthetic Minority Over-sampling Technique to generate synthetic samples of minority classes to reduce class imbalance problems and attain balanced detection performance across all classes. The performance of the proposed detection technique is analyzed using multiple datasets with standard evaluation parameters. The proposed technique achieves outstanding performance results including an accuracy of 98.87% and a recall of 98.36%. From this experimental validation, it's clear that the proposed framework provides robust performance under diverse network conditions and handles imbalanced data effectively.",
        "author_keywords": [
            "Class imbalance",
            "Dual aggregation",
            "Edge Implicit Weighting",
            "Graph transformer",
            "Internet of Things",
            "Intrusion detection system",
            "Multi-head attention mechanism",
            "Network security"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Law"
        ]
    },
    {
        "title": "Learning to sculpt neural cityscapes",
        "authors": "Zhu J.",
        "journal": "Visual Computer",
        "doi": "10.1007/s00371-024-03528-7",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85198419104",
        "scopus_id": "85198419104",
        "abstract": "We introduce a system that learns to sculpt 3D models of massive urban environments. The majority of humans live their lives in urban environments, using detailed virtual models for applications as diverse as virtual worlds, special effects, and urban planning. Generating such 3D models from exemplars manually is time-consuming, while 3D deep learning approaches have high memory costs. In this paper, we present a technique for training 2D neural networks to repeatedly sculpt a plane into a large-scale 3D urban environment. An initial coarse depth map is created by a GAN model, from which we refine 3D normal and depth using an image translation network regularized by a linear system. The networks are trained using real-world data to allow generative synthesis of meshes at scale. We exploit sculpting from multiple viewpoints to generate a highly detailed, concave, and water-tight 3D mesh. We show cityscapes at scales of 100×1600 meters with more than 2 million triangles, and demonstrate that our results are objectively and subjectively similar to our exemplars.",
        "author_keywords": [
            "Deep learning",
            "Linear programming",
            "Mesh deformation",
            "Terrain mesh"
        ],
        "subject_areas": [
            "Software",
            "Computer Vision and Pattern Recognition",
            "Computer Graphics and Computer-Aided Design"
        ]
    },
    {
        "title": "Intelligent generation and interpretability analysis of shear wall structure design by learning from multidimensional to high-dimensional features",
        "authors": "Yu Y.",
        "journal": "Engineering Structures",
        "doi": "10.1016/j.engstruct.2024.119472",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211970583",
        "scopus_id": "85211970583",
        "abstract": "The intelligent design of shear wall structures is a critical aspect of smart construction, with a high demand for research and applications. Accurately predicting the shear wall ratio (i.e., the shear wall area-to-floor area ratio) during cost estimation and rapidly generating shear wall layouts during early design is essential. However, the unclear influences of numerous design feature parameters hinder the enhancement of generative AI design. This affects both the prediction of shear wall ratios from multidimensional features and the generation of shear wall layouts from high-dimensional features. Therefore, a method for generating key structural design features using machine learning (ML) and generative adversarial networks (GANs), along with model interpretation, is proposed in this study. Existing shear wall design data are collected, and features such as the architectural plan geometry, seismic design conditions, and shear wall ratios are extracted to establish a dataset. Key shear wall ratio parameters are predicted using an ML model with multidimensional design features as inputs, and interpretability analysis is conducted using Shapley Additive Explanations (SHAP). Concurrently, a GAN model is built to generate shear wall designs using fused image-text high-dimensional features, and the influence patterns of design features are explained through sensitivity analysis. The analysis results indicate that the prediction accuracy is effectively enhanced by ML-based multidimensional feature learning, shear wall designs are effectively generated by GAN-based high-dimensional feature learning, and seismic design intensity and structural height are revealed as significant factors through interpretability analysis. Furthermore, when high-dimensional feature inputs are available, the generation of comprehensive features should be prioritized for shear wall structural designs.",
        "author_keywords": [
            "Generative adversarial networks",
            "Intelligent structural design",
            "Interpretable machine learning",
            "Multi- and high-dimensional feature analysis",
            "Shear wall structure"
        ],
        "subject_areas": [
            "Civil and Structural Engineering"
        ]
    },
    {
        "title": "C 3 -GAN+: Complex-Condition-Controlled Generative Adversarial Networks with Enhanced Embedding",
        "authors": "Zhang Y.",
        "journal": "ACM Transactions on Knowledge Discovery from Data",
        "doi": "10.1145/3712264",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000616277",
        "scopus_id": "86000616277",
        "abstract": "Given historical traffic distributions and associated urban conditions observed in a city, the conditional urban traffic estimation problem aims at estimating realistic future projections of the traffic under a set of new urban conditions, e.g., new bus routes, rainfall intensity, and travel demands. The problem is important in reducing traffic congestion, improving public transportation efficiency, and facilitating urban planning. However, solving this problem is challenging due to the strong spatial dependencies of traffic patterns and the complex relations between the traffic and urban conditions. Recently, we proposed a Complex-Condition-Controlled Generative Adversarial Network (C3-GAN), which tackles both of the challenges and solves the urban traffic estimation problem under various complex conditions by adding a fixed embedding network and an inference network on top of the standard conditional GAN model. The randomly chosen embedding network transforms the complex conditions to latent vectors, and the inference network enhances the connections between the embedded vectors and the traffic data. However, a randomly chosen embedding network cannot always successfully extract features of complex urban conditions, which indicates C3-GAN is unable to uniquely map different urban conditions to proper latent distributions. Thus, C3-GAN would fail in certain traffic estimation tasks. Besides, C3-GAN is hard to train due to vanishing gradients and mode collapse problems. To address these issues, in this article, we extend our prior work by introducing a new deep generative model, namely, C3-GAN+, which significantly improves the estimation performance and model stability. C3-GAN+ has new objective, architecture, and training algorithm. The new objective applies Wasserstein loss to the conditional generation case to encourage stable training. Shared convolutional layers between the discriminator and the inference network help to capture spatial dependencies of traffic more efficiently, part of the shared convolutional layers are used to update the embedding network periodically aiming to encourage good representation and avoid model divergence. Extensive experiments on real-world datasets demonstrate that our C3-GAN+ produces high-quality traffic estimations and outperforms state-of-the-art baseline methods.",
        "author_keywords": [
            "Generative adversarial networks",
            "urban traffic estimation"
        ],
        "subject_areas": [
            "Computer Science (all)"
        ]
    },
    {
        "title": "The Effect of Generating Synthetic Data in Smart City Network Systems",
        "authors": "Čech P.",
        "journal": "SN Computer Science",
        "doi": "10.1007/s42979-025-03673-3",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85219672490",
        "scopus_id": "85219672490",
        "abstract": "This study examines the effect of synthetic data generation for balancing class distributions on the performance of classification algorithms in smart city network systems. Contrary to the assumption that data balancing improves classification performance, the analysis reveals a more complex impact. Using three publicly available network traffic benchmark datasets and four different balancing techniques, the study evaluates the performance of five classifiers on 65 classification tasks. The findings indicate that, for smaller datasets, classifiers that achieved the highest accuracy on unbalanced data did not benefit from synthetic data generation for minority classes. Although neural network-based classifiers showed improved performance with balanced data, these improvements came at the cost of lower overall classification scores. For larger datasets, balancing through random oversampling of minority classes and undersampling of majority classes helped improve classification. However, these improvements were limited to precision, with no significant gains in recall. The study offers valuable insights into using synthetic data for intrusion detection, emphasizing the challenges of intricate dependencies in network traffic data for generative models. The results align with previous research showing mixed effects of data balancing on classifier performance, contributing to a broader understanding of the limited efficacy of synthetic data in real-world network contexts. This experimental study highlights the need for a systematic benchmarking framework for synthetic data research, ensuring consistency in data balancing and classification processes. This work contributes to the ongoing discourse on the intersection of machine learning and cybersecurity, emphasizing the critical role of data in developing resilient intrusion detection systems.",
        "author_keywords": [
            "Attack classification",
            "Generative adversarial networks",
            "Imbalanced datasets",
            "Intrusion detection"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Computer Science Applications",
            "Computer Networks and Communications",
            "Computer Graphics and Computer-Aided Design",
            "Computational Theory and Mathematics",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "AI Agent-Based Intelligent Urban Digital Twin (I-UDT): Concept, Methodology, and Case Studies",
        "authors": "Choi S.",
        "journal": "Smart Cities",
        "doi": "10.3390/smartcities8010028",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218882823",
        "scopus_id": "85218882823",
        "abstract": "Highlights: What are the main findings? In the developed AI agent-based intelligent digital twin (I-DT), UBEM overcomes the limitations of the traditional UBEM approach and enables efficient analysis of urban building energy. GPT-based UBEM effectively performed the core functions of UBEM, serving as a key technology in I-UDT applications and services. What are the implications of the main findings? The I-UDT enables more accurate and comprehensive urban energy management, supporting the development of sustainable cities and carbon-neutral strategies. Implementing I-UDTs enables urban policymakers to make data-driven decisions, improve energy efficiency, and enhance the scalability of digital twin applications. The concept of digital twins (DTs) has expanded to encompass buildings and cities, with urban building energy modeling (UBEM) playing a crucial role in predicting urban-scale energy consumption via modeling individual energy use and interactions. As a virtual model within urban digital twins (UDTs), UBEM offers the potential for managing energy in sustainable cities. However, UDTs face challenges with regard to integrating large-scale data and relying on bottom-up UBEM approaches. In this study, we propose an AI agent-based intelligent urban digital twin (I-UDT) to enhance DTs’ technical realization and UBEM’s service functionality. Integrating GPT within the UDT enabled the efficient integration of fragmented city-scale data and the extraction of building features, addressing the limitations of the service realization of traditional UBEM. This framework ensures continuous updates of the virtual urban model and the streamlined provision of updated information to users in future studies. This research establishes the concept of an I-UDT and lays a foundation for future implementations. The case studies include (1) data analysis, (2) prediction, (3) feature engineering, and (4) information services for 3500 buildings in Seoul. Through these case studies, the I-UDT was integrated and analyzed scattered data, predicted energy consumption, derived conditioned areas, and evaluated buildings on benchmark.",
        "author_keywords": [
            "AI (artificial intelligence) agent",
            "digital twins (DTs)",
            "generative pre-trained transformers (GPTs)",
            "OpenAI",
            "urban building energy modeling (UBEM)",
            "urban building informatics",
            "urban digital twins (UDTs)"
        ],
        "subject_areas": [
            "Urban Studies",
            "Artificial Intelligence",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Exploring the Ambient in Relation to Urban Life and AI",
        "authors": "McKenna H.P.",
        "journal": "Urban Science",
        "doi": "10.3390/urbansci9020026",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218864818",
        "scopus_id": "85218864818",
        "abstract": "The purpose of this paper is to explore the nature of the ambient in an era of artificial intelligence (AI), focusing on the urban context. As such, this paper explores evolving understandings of the ambient in everyday life encompassing a range of elements such as awareness, computing, experiences, information, and intelligence in relation to rapidly evolving and emerging applications of AI and generative AI in urban environments. A review of the research and practice literature for the ambient in relation to urban AI is provided in this paper enabling formulation of a conceptual framework to guide the exploration. A poll conducted online using the Whova platform during a hybrid (e.g., virtual and in person) conference event provides insight into the awareness element in the context of AI from the perspective of researchers, students, practitioners, and other conference participants and attendees (e.g., government business, etc.). Implications for urban life, smart cities, learning cities, and future cities are discussed, giving rise to challenges and opportunities for research and practice going forward. This work is significant in that a range of perspectives across a variety of domains emerge for the ambient in relation to everyday life and AI and to urban AI.",
        "author_keywords": [
            "ambient awareness",
            "ambient computing",
            "ambient engineering",
            "ambient experiences",
            "ambient information",
            "artificial intelligence",
            "awareness",
            "generative AI",
            "learning cities",
            "smart cities"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Environmental Science (miscellaneous)",
            "Waste Management and Disposal",
            "Urban Studies",
            "Pollution"
        ]
    },
    {
        "title": "LLM Agents for Smart City Management: Enhancing Decision Support Through Multi-Agent AI Systems",
        "authors": "Kalyuzhnaya A.",
        "journal": "Smart Cities",
        "doi": "10.3390/smartcities8010019",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218862736",
        "scopus_id": "85218862736",
        "abstract": "Highlights: What are the main findings? For smart city management, LLM-based multi-agent systems achieve 94–99% accuracy in routing urban queries and demonstrate significant improvements in response quality (G-Eval scores of 0.68–0.74) compared to standalone LLMs (0.30–0.38). Achievement of high scores in routing queries and response accuracy is possible with middle-size LLM models rather than the biggest LLM models. What is the implication of the main findings? The multi-agent LLM approach enables efficient processing of complex urban planning tasks while maintaining high relevance in responses, making it practical for real-world city management applications. LLM agents can effectively augment human decision making in urban planning by reducing task completion time from days to hours while maintaining accuracy and accountability in complex scenarios. This study investigates the implementation of LLM agents in smart city management, leveraging both the inherent language processing abilities of LLMs and the distributed problem solving capabilities of multi-agent systems for the improvement of urban decision making processes. A multi-agent system architecture combines LLMs with existing urban information systems to process complex queries and generate contextually relevant responses for urban planning and management. The research is focused on three main hypotheses testing: (1) LLM agents’ capability for effective routing and processing diverse urban queries, (2) the effectiveness of Retrieval-Augmented Generation (RAG) technology in improving response accuracy when working with local knowledge and regulations, and (3) the impact of integrating LLM agents with existing urban information systems. Our experimental results, based on a comprehensive validation dataset of 150 question–answer pairs, demonstrate significant improvements in decision support capabilities. The multi-agent system achieved pipeline selection accuracy of 94–99% across different models, while the integration of RAG technology improved response accuracy by 17% for strategic development queries and 55% for service accessibility questions. The combined use of document databases and service APIs resulted in the highest performance metrics (G-Eval scores of 0.68–0.74) compared to standalone LLM responses (0.30–0.38). Using St. Petersburg’s Digital Urban Platform as a testbed, we demonstrate the practical applicability of this approach to create integrated city management systems with support complex urban decision making processes. This research contributes to the growing field of AI-enhanced urban management by providing empirical evidence of LLM agents’ effectiveness in processing heterogeneous urban data and supporting strategic planning decisions. Our findings suggest that LLM-based multi-agent systems can significantly enhance the efficiency and accuracy of urban decision making while maintaining high relevance in responses.",
        "author_keywords": [
            "data-driven management",
            "large language model",
            "LLM",
            "LLM agent",
            "multi-agent system",
            "smart city management",
            "strategic management"
        ],
        "subject_areas": [
            "Urban Studies",
            "Artificial Intelligence",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Responsible Artificial Intelligence Hyper-Automation with Generative AI Agents for Sustainable Cities of the Future",
        "authors": "De Silva D.",
        "journal": "Smart Cities",
        "doi": "10.3390/smartcities8010034",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218853363",
        "scopus_id": "85218853363",
        "abstract": "Highlights: What are the main findings? Smart Cities as Hyper-Connected Digital Environments generate large and diverse data streams and repositories that do not consistently translate into insights and decisions. A Responsible AI Hyper-Automation framework with Generative AI agents is developed and evaluated to address these complex challenges. What are the implications of the main findings? The developed AI framework is effective when grounded on five core technical capabilities with an independent cognitive engine for hyper-automated agentic AI that feeds into human-in-the-loop processes. The framework provides a prototypical setting for university cities of the future to provide direction, guidance, and standards for sustainable and safe smart cities of the future. Smart cities are Hyper-Connected Digital Environments (HCDEs) that transcend the boundaries of natural, human-made, social, virtual, and artificial environments. Human activities are no longer confined to a single environment as our presence and interactions are represented and interconnected across HCDEs. The data streams and repositories of HCDEs provide opportunities for the responsible application of Artificial Intelligence (AI) that generates unique insights into the constituent environments and the interplay across constituents. The translation of data into insights poses several complex challenges originating in data generation and then propagating through the computational layers to decision outcomes. To address these challenges, this article presents the design and development of a Hyper-Automated AI framework with Generative AI agents for sustainable smart cities. The framework is empirically evaluated in the living lab setting of a ‘University City of the Future’. The developed AI framework is grounded on the core capabilities of acquisition, preparation, orchestration, dissemination, and retrospection, with an independent cognitive engine for hyper-automation of these AI capabilities using Generative AI. Hyper-automation output feeds into a human-in-the-loop process prior to decision-making outcomes. More broadly, this framework aims to provide a validated pathway for university cities of the future to take up the role of prototypes that deliver evidence-based guidelines for the development and management of sustainable smart cities.",
        "author_keywords": [
            "artificial intelligence",
            "generative AI",
            "hyper-automation",
            "smart cities",
            "university city of the future"
        ],
        "subject_areas": [
            "Urban Studies",
            "Artificial Intelligence",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Generative AI-Enhanced Cybersecurity Framework for Enterprise Data Privacy Management",
        "authors": "Nadella G.S.",
        "journal": "Computers",
        "doi": "10.3390/computers14020055",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218696082",
        "scopus_id": "85218696082",
        "abstract": "This study presents a Generative AI-Enhanced Cybersecurity Framework designed to strengthen enterprise data privacy management while improving threat detection accuracy and scalability. By leveraging Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and traditional anomaly detection methods, the framework generates synthetic datasets that mimic real-world data, ensuring privacy and regulatory compliance. At its core, the anomaly detection engine integrates machine learning models, such as Random Forest and Support Vector Machines (SVMs), alongside deep learning techniques like Long Short-Term Memory (LSTM) networks, delivering robust performance across diverse domains. Experimental results demonstrate the framework’s adaptability and high performance in the financial sector (accuracy: 94%, recall: 95%), healthcare (accuracy: 96%, precision: 93%), and smart city infrastructures (accuracy: 91%, F1 score: 90%). The framework achieves a balanced trade-off between accuracy (0.96) and computational efficiency (processing time: 1.5 s per transaction), making it ideal for real-time enterprise deployments. Unlike analog systems that achieve > 0.99 accuracy at the cost of higher resource consumption and limited scalability, this framework emphasizes practical applications in diverse sectors. Additionally, it employs differential privacy, encryption, and data masking to ensure data security while addressing modern cybersecurity challenges. Future work aims to enhance real-time scalability further and explore reinforcement learning to advance proactive threat mitigation measures. This research provides a scalable, adaptive, and practical solution for enterprise-level cybersecurity and data privacy management.",
        "author_keywords": [
            "cybersecurity",
            "data privacy management",
            "deep learning (DL)",
            "machine learning (ML)"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Intelligent Virtual Reality and Augmented Reality Technologies: An Overview",
        "authors": "Lampropoulos G.",
        "journal": "Future Internet",
        "doi": "10.3390/fi17020058",
        "publication_date": "2025",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218643526",
        "scopus_id": "85218643526",
        "abstract": "The research into artificial intelligence (AI), the metaverse, and extended reality (XR) technologies, such as augmented reality (AR), virtual reality (VR), and mixed reality (MR), has been expanding over the recent years. This study aims to provide an overview regarding the combination of AI with XR technologies and the metaverse through the examination of 880 articles using different approaches. The field has experienced a 91.29% increase in its annual growth rate, and although it is still in its infancy, the outcomes of this study highlight the potential of these technologies to be effectively combined and applied in various domains transforming and enriching them. Through content analysis and topic modeling, the main topics and areas in which this combination is mostly being researched and applied are as follows: (1) “Education/Learning/Training”, (2) “Healthcare and Medicine”, (3) “Generative artificial intelligence/Large language models”, (4) “Virtual worlds/Virtual avatars/Virtual assistants”, (5) “Human-computer interaction”, (6) “Machine learning/Deep learning/Neural networks”, (7) “Communication networks”, (8) “Industry”, (9) “Manufacturing”, (10) “E-commerce”, (11) “Entertainment”, (12) “Smart cities”, and (13) “New technologies” (e.g., digital twins, blockchain, internet of things, etc.). The study explores the documents through various dimensions and concludes by presenting the existing limitations, identifying key challenges, and providing suggestions for future research.",
        "author_keywords": [
            "AI",
            "artificial intelligence",
            "augmented reality",
            "bibliometric analysis",
            "extended reality",
            "metaverse",
            "mixed reality",
            "review",
            "scientific mapping",
            "topic modeling",
            "virtual reality"
        ],
        "subject_areas": [
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "A comprehensive investigation of variational auto-encoders for population synthesis",
        "authors": "Sané A.R.",
        "journal": "Journal of Computational Social Science",
        "doi": "10.1007/s42001-024-00332-0",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211479520",
        "scopus_id": "85211479520",
        "abstract": "The use of synthetic populations has grown considerably over the recent years, in revolutionizing studies conducted within various fields, including social science research, urban planning, public health and transportation modeling. These synthetic populations prove to be valuable, as substitutes for the often missing or sensitive real data, and moreover are capable of preserving both privacy and representativeness. They are typically constructed from aggregate and/or sample data. Recently, new methods for generating synthetic populations based on deep learning, notably Variational Autoencoders (VAEs), have been developed. Such methods serve to overcome the limitations of traditional methods, such as Iterative Proportional Fitting (IPF), which are unable to generate agents with cross-modalities not found in the sample data. As such, IPF requires large samples to generate a synthetic population closely resembling the actual one. Conversely, the advantage of VAE lies in their ability to generate agents not found in the sample data, albeit with the risk of creating agents not existing in the actual population. However, the practical documentation as well as detailed analyses of the architectures and results from implementation of these deep learning approaches, in particular VAE, are limited, thus making these methods difficult to appropriate for practitioners. This paper focuses on generating synthetic populations using VAE. First, an in-depth and accessible theoretical explanation of how VAEs function is provided. Next, a detailed study of these methods is carried out by testing the various architectures, parameters, sample sizes and evaluation indicators necessary to guarantee high-quality results. Highlighted herein is the ability of VAEs to generate large datasets with a small training sample, in addition to VAE performance in generating new realistic individuals not present in the learning base. Certain limitations are identified, including the difficulties encountered by VAEs in managing numerical attributes and the need for post-processing to eliminate unrealistic individuals. In conclusion, despite a number of limitations, VAE constitutes a very promising methodology for generating synthetic populations, in offering practitioners numerous advantages. This paper is accompanied by a Python notebook to assist interested readers implement this new methodology.",
        "author_keywords": [
            "Deep generative model",
            "Machine learning",
            "Sampling zeros",
            "Structural zeros",
            "Synthetic population",
            "Variational autoencoders"
        ],
        "subject_areas": [
            "Transportation",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Leveraging patent classification based on deep learning: The case study on smart cities and industrial Internet of Things",
        "authors": "Li M.",
        "journal": "Journal of Informetrics",
        "doi": "10.1016/j.joi.2024.101616",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210141126",
        "scopus_id": "85210141126",
        "abstract": "With the trends of technology convergence and technology interdisciplinarity, technology-field (TF) resolution and classification of patents have gradually been challenged. Whether for patent applicants or for patent examiners, more precisely labeling the TF for a certain patent is important for technological searches. However, determining the TF of a patent may be difficult and may even involve the strategic behavior of patenting, which can cause noise in patent classification systems (PCSs). In addition, some specific patents could contain more TFs than claimed or be assigned questionable IPC codes; subsequently, in a regular search for technology/patents, information could be missed. Considering the advantages of deep learning compared with traditional machine learning algorithms in areas such as natural language processing (NLP), text classification and text sentiment analysis, this paper investigates several popular deep learning models and proposes a large-scale multilabel regression (MLR) model to handle specific patent analyses under situations of small sample learning. To verify the proposed MLR model for patent classification, the case study on smart cities and industrial Internet of Things (IIoT) is conducted. The MLR experiments on the TF resolution of smart cities and IIoT have yielded moderate results compared with those of the latest patent classification studies, which also rely on deep learning and the large language models (LLMs), which include RCNN, Bi-LSTM, BERT and GPT-4 etc. Therefore, the proposed MLR model with a customized loss function could be moderately effective for patent classification within a specific technology theme, could have implications for patent classification and the TF resolution of patents, and could further enrich methodologies for patent mining and informetrics based on artificial intelligence (AI).",
        "author_keywords": [
            "Deep learning",
            "GPT-4",
            "Industrial Internet of Things",
            "Loss function",
            "Patent classification",
            "Semantic analysis",
            "Smart cities",
            "Technology-field resolution"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Library and Information Sciences"
        ]
    },
    {
        "title": "A rapid approach to urban traffic noise mapping with a generative adversarial network",
        "authors": "Yang X.",
        "journal": "Applied Acoustics",
        "doi": "10.1016/j.apacoust.2024.110268",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203849001",
        "scopus_id": "85203849001",
        "abstract": "With rapid urbanisation and the accompanying increase in traffic density, traffic noise has become a major concern in urban planning. However, traditional grid noise mapping methods have limitations in terms of time consumption, software costs, and a lack of parameter integration interfaces. These limitations hinder their ability to meet the need for iterative updates and rapid performance feedback in the early design stages of street-scale urban planning. Herein, we developed a rapid urban traffic noise mapping technique that leverages generative adversarial networks (GANs) as a surrogate model. This approach enables the rapid assessment of urban traffic noise distribution by using urban elements such as roads and buildings as the input. The mean values for the mean squared error (RMSE) and structural similarity index (SSIM) are 0.3024 dB(A) and 0.8528, respectively, for the validation dataset. The trained model is integrated into Grasshopper as a tool, facilitating the rapid generation of traffic noise maps. This integration allows urban designers and planners, even those without expertise in acoustics, to easily anticipate changes in acoustics impacts caused by design in the early design stages.",
        "author_keywords": [
            "Generative adversarial networks",
            "Noise mapping",
            "pix2pix",
            "Urban spatial feature"
        ],
        "subject_areas": [
            "Acoustics and Ultrasonics"
        ]
    },
    {
        "title": "Destination intention estimation-based convolutional encoder-decoder for pedestrian trajectory multimodality forecast",
        "authors": "Wang R.",
        "journal": "Measurement: Journal of the International Measurement Confederation",
        "doi": "10.1016/j.measurement.2024.115470",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200963033",
        "scopus_id": "85200963033",
        "abstract": "Forecasting pedestrian trajectory is a vital area of research in smart urban mobility, which can be applied to intelligent transportation and intelligent surveillance. Current approaches employ conditional variational autoencoders to model future trajectory multimodality. However, these methods generate multi-modal trajectories for one single destination, ignoring the trajectory multimodality caused by the uncertainty of the pedestrians’ destination intention. Besides, they can lead to mode collapse and training instability. To address this issue, we propose a novel destination intention estimation-based convolutional encoder-decoder framework for multimodal trajectory forecast. Specially, we design a destination intention estimator to forecast pedestrian future destination intentions at the last time step. Then, we devise a trajectory decoder module to forecast pedestrian trajectories at each time step with the assistance of the destination intentions. To evaluate our method, we perform experiments on publicly available benchmark datasets and demonstrate that our proposed method achieves the superior results compared with state-of-the-art approaches.",
        "author_keywords": [
            "Encoder-decoder",
            "Graph convolution",
            "Smart urban mobility",
            "Social interactions",
            "Trajectory multimodality"
        ],
        "subject_areas": [
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Adaptive Cyber Defence: Leveraging GANs for Simulating and Mitigating Advanced Network Attacks in IoT Environments",
        "authors": "Rao P.K.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-981-97-9762-2_19",
        "publication_date": "2025",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000713763",
        "scopus_id": "86000713763",
        "abstract": "The progressive dissemination of the Internet of Things (IoT) and Wireless Sensor Networks (WSNs) has ushered in a new era of connectivity, with vast applications spanning from medicare to smart city infrastructure. However, this expansion has been paralleled by a corresponding increase in the sophistication and variety of cyber threats targeting these networks. Traditional cyber security measures, designed for a less dynamic threat landscape, are proving increasingly insufficient in protecting against the innovative and varied attack methods now in commonplace. This study introduces an innovative application of Generative Adversarial Networks (GANs) to address this challenge, presenting a novel framework for the simulation and mitigation of advanced network attacks, particularly focusing on Distributed Denial of Service (DDoS) and spoofing attacks which pose significant threats in IoT environments. Generative Adversarial Networks (GANs), comprising two neural networks-the generator and the discriminator compete in a game-theoretic scenario, facilitating a deep understanding of attack patterns through the generation of realistic, synthetic cyber-attack scenarios. This research exploits GANs to bridge the gap between the static nature of traditional security protocols and the dynamic, evolving landscape of cyber threats. By training on a comprehensive dataset of known attacks and normal network activities, our proposed model, the Dynamic Adaptive Threat Simulation GAN (DATS-GAN), is capable of producing varied and realistic attack scenarios. These simulations serve a dual purpose: they not only enhance the detection capabilities and responsiveness of current security systems but also provide a basis for the development of new, adaptive security mechanisms capable of dynamically responding to the ever-changing cyber threat landscape. The effectiveness of DATS-GAN is demonstrated through extensive empirical analysis, highlighting significant improvements in the detection precision and reaction times of security frameworks within WSNs. Moreover, the generated synthetic attack scenarios provide a valuable resource for training machine learning models, leading to the advancement of adaptive security solutions that maintain a high readiness level against emerging cyber threats. The outcomes of this research hold substantial promise for the cyber security domain, showcasing the potential of GANs to revolutionize network defenses against sophisticated cyber threats in IoT and WSN environments.",
        "author_keywords": [
            "Adaptive security mechanisms",
            "AI in cyber defence",
            "Cybersecurity in WSN",
            "DDoS attack mitigation",
            "Generative Adversarial Networks (GANs)",
            "IoT security",
            "Network attack simulation"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Super-Resolution of Satellite Images Using Landsat Data",
        "authors": "Sharshov I.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-981-96-1904-7_8",
        "publication_date": "2025",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000712634",
        "scopus_id": "86000712634",
        "abstract": "In the field of remote sensing (RS), improving the spatial resolution of satellite imagery is critical for a variety of applications, including environmental monitoring, urban planning and forestry. With the recent advancements in deep learning, new opportunities have emerged for enhancing the spatial resolution of RS data. However, these models have been proved ineffective for tree detection tasks. In this paper, we present the GISSRGAN model, an extension of the ESRGAN architecture designed for single-image super-resolution (SISR) tasks involving satellite imagery. The model integrates auxiliary geospatial datasets, such as Landsat 7 ETM+ and Landsat 8–9 OLI/TIRS, to enhance super-resolution performance in forestry aimed tasks.",
        "author_keywords": [
            "generative adversarial networks (GAN)",
            "remote sensing images",
            "super-resolution"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "Smart Energy Management: From Conventional Optimization to Generative AI Techniques",
        "authors": "Mongaillard T.",
        "journal": "Lecture Notes in Intelligent Transportation and Infrastructure",
        "doi": "10.1007/978-3-031-72959-1_15",
        "publication_date": "2025",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000657801",
        "scopus_id": "86000657801",
        "abstract": "This chapter explores the evolution of power consumption scheduling in smart cities, focusing on smart homes and electric vehicle charging. It discusses the transition from classical optimization techniques to heuristic methods like genetic algorithms and swarm optimization for addressing complex energy management problems. The chapter also highlights the growing importance of machine learning, particularly artificial neural networks and reinforcement learning, in predicting energy demand and optimizing scheduling decisions. Additionally, it delves into the potential of generative AI, including generative adversarial networks and large language models, to revolutionize power scheduling by generating realistic scenarios, improving user interaction, and enabling more personalized and efficient energy management strategies.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Harnessing the Power of Large Language Models for Sustainable and Intelligent Transportation Systems in the Electric Vehicle Era",
        "authors": "Abraham A.",
        "journal": "Lecture Notes in Intelligent Transportation and Infrastructure",
        "doi": "10.1007/978-3-031-72959-1_5",
        "publication_date": "2025",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000600826",
        "scopus_id": "86000600826",
        "abstract": "Urban ecosystems in the midst of digital transformation utilize technologies like Internet of Things (IoT), big data, and artificial intelligence (AI) to elevate citizens’ well-being and champion sustainable development. Notably, LLMs such as GPT-3 or GPT-4, crafted by OpenAI, and Google’s AI tools like Gemini and Bard, stand as pivotal components, holding immense potential to revolutionize EVs in smart city initiatives. Generative AI and LLM integration prove influential in optimizing EV functionalities, enhancing security, and fortifying data privacy. This chapter delves into battery technology, battery capacities, energy storage, charging infrastructure optimization, autonomous driving, educational outreach, energy management, and predictive maintenance. In particular, LLMs address EV challenges by optimizing routes, speeds, and behaviors, reducing energy usage and emissions. They facilitate the smart integration of EVs and renewable energy sources, managing charging schedules based on availability and grid demands. Additionally, LLMs contribute to public education on EV benefits, environmental impact, cost savings, and sustainable transportation promotion. The chapter explores synergies between LLMs and EVs, focusing on potential applications and challenges, propelling progress in ITSs. Similarly, Multimodal Large Language Models (MLLMs) and their potential applications in the era of the EV represent a promising frontier in this landscape, offering enhanced capabilities to interpret and generate multimodal data, further enriching the EV ecosystem.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Towards General-Purpose Video Reconstruction through Synergy of Grid-Splicing Diffusion and Large Language Models",
        "authors": "Liu J.",
        "journal": "IEEE Transactions on Circuits and Systems for Video Technology",
        "doi": "10.1109/TCSVT.2025.3545795",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000441300",
        "scopus_id": "86000441300",
        "abstract": "Various forms of degradation, including noise, blur, and adverse weather conditions (e.g., rain, snow, and fog), significantly compromise video quality and system reliability across critical domains ranging from surveillance and medical imaging to entertainment. Previous research mainly focuses on network models tailored to specific degradation types, while recent unified frameworks and foundation models still face critical challenges in temporal consistency, automated degradation recognition, and detail preservation. Despite recent advances in foundation models, current approaches rely heavily on predefined degradation labels and remain focused on image-level operations, limiting their generalization to real-world scenarios and struggling with preserving fine-grained details. To address these challenges, we propose Grid Splicing Diffusion Model (GSDiff), a general framework for video reconstruction that leverages a novel grid splicing execution alongside instruction-tuned Large Language Model (LLM). GSDiff introduces three key innovative modules: (1) a LLM-driven degradation recognition module that enables automatic and fine-grained restoration guidance through zero-shot degradation analysis, (2) a Grid Splicing Module that organizes multiple frames into a unified grid structure to facilitate spatiotemporal feature processing, and (3) a Detail Preservation Module integrated with a Tail Refine Network to enhance fine-grained details during diffusion and post-processing. Extensive experiments demonstrate that GSDiff delivers state-of-the-art performance across a wide range of reconstruction tasks, including deraining, desnowing, denoising, and deblurring, propelling advancements in medical diagnostics and smart city applications.",
        "author_keywords": [
            "Detail Preservation",
            "Grid Splicing",
            "Large Language Models",
            "Unified Video Reconstruction"
        ],
        "subject_areas": [
            "Media Technology",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "STCDM: Spatio-Temporal Contrastive Diffusion Model for Check-In Sequence Generation",
        "authors": "Gong L.",
        "journal": "IEEE Transactions on Knowledge and Data Engineering",
        "doi": "10.1109/TKDE.2025.3525718",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000434640",
        "scopus_id": "86000434640",
        "abstract": "Analyzing and comprehending check-in sequences is crucial for various applications in smart cities. However, publicly available check-in datasets are often limited in scale due to privacy concerns. This poses a significant obstacle to academic research and downstream applications. Thus, it is urgent to generate realistic check-in datasets. The denoising diffusion probabilistic model (DDPM) as one of the most capable generation methods is a good choice to achieve this goal. However, generating check-in sequences using DDPM is not an easy feat. The difficulties lie in handling check-in sequences of variable lengths and capturing the correlation from check-in sequences’ distinct characteristics. This paper addresses the challenges by proposing a Spatio-Temporal Contrastive Diffusion Model (STCDM). This model introduces a novel spatio-temporal lossless encoding method that effectively encodes check-in sequences into a suitable format with equal length. Furthermore, we capture the spatio-temporal correlations with two disentangled diffusion modules to reduce the impact of the difference between spatial and temporal characteristics. Finally, we incorporate contrastive learning to enhance the relationship between diffusion modules. We generate four realistic datasets in different scenarios using STCDM and design four metrics for comparison. Experiments demonstrate that our generated datasets are more realistic and free of privacy leakage.",
        "author_keywords": [
            "check-in sequence",
            "contrastive learning",
            "diffusion model",
            "sequence generation",
            "Spatio-temporal data mining"
        ],
        "subject_areas": [
            "Information Systems",
            "Computer Science Applications",
            "Computational Theory and Mathematics"
        ]
    },
    {
        "title": "YOLO-SIFD: YOLO with Sliced Inference and Fractal Dimension Analysis for Improved Fire and Smoke Detection",
        "authors": "Ishtiaq M.",
        "journal": "Computers, Materials and Continua",
        "doi": "10.32604/cmc.2025.061466",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000362674",
        "scopus_id": "86000362674",
        "abstract": "Fire detection has held stringent importance in computer vision for over half a century. The development of early fire detection strategies is pivotal to the realization of safe and smart cities, inhabitable in the future. However, the development of optimal fire and smoke detection models is hindered by limitations like publicly available datasets, lack of diversity, and class imbalance. In this work, we explore the possible ways forward to overcome these challenges posed by available datasets. We study the impact of a class-balanced dataset to improve the fire detection capability of state-of-the-art (SOTA) vision-based models and propose the use of generative models for data augmentation, as a future work direction. First, a comparative analysis of two prominent object detection architectures, You Only Look Once version 7 (YOLOv7) and YOLOv8 has been carried out using a balanced dataset, where both models have been evaluated across various evaluation metrics including precision, recall, and mean Average Precision (mAP). The results are compared to other recent fire detection models, highlighting the superior performance and efficiency of the proposed YOLOv8 architecture as trained on our balanced dataset. Next, a fractal dimension analysis gives a deeper insight into the repetition of patterns in fire, and the effectiveness of the results has been demonstrated by a windowing-based inference approach. The proposed Slicing-Aided Hyper Inference (SAHI) improves the fire and smoke detection capability of YOLOv8 for real-life applications with a significantly improved mAP performance over a strict confidence threshold. YOLOv8 with SAHI inference gives a mAP:50-95 improvement of more than 25% compared to the base YOLOv8 model. The study also provides insights into future work direction by exploring the potential of generative models like deep convolutional generative adversarial network (DCGAN) and diffusion models like stable diffusion, for data augmentation.",
        "author_keywords": [
            "class-balanced dataset",
            "diffusion models",
            "Fire detection",
            "fractal dimension",
            "generative adversarial network (GAN)",
            "slicing-aided hyper inference (SAHI)",
            "smoke detection",
            "you only look once (YOLO)"
        ],
        "subject_areas": [
            "Biomaterials",
            "Modeling and Simulation",
            "Mechanics of Materials",
            "Computer Science Applications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Large language model empowered smart city mobility",
        "authors": "Chen Y.",
        "journal": "Frontiers of Engineering Management",
        "doi": "10.1007/s42524-025-4213-0",
        "publication_date": "2025",
        "document_type": "Note",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000221064",
        "scopus_id": "86000221064",
        "abstract": "Smart city mobility faces mounting challenges as urban mobility systems grow increasingly complex. Large language models (LLMs) have promise in interpreting and processing multi-modal urban data, but issues like model instability, computational inefficiency, and concerns about reliability hinder their implementations. In this Comment, we outline feasible LLM application scenarios, critically evaluate existing challenges, and highlight avenues for advancing LLM-based mobility systems through multi-modal data integration and developing robust, lightweight models.",
        "author_keywords": [
            "large language model",
            "smart city mobility",
            "transportation",
            "urban computing"
        ],
        "subject_areas": [
            "Decision Sciences (miscellaneous)",
            "Management Science and Operations Research"
        ]
    },
    {
        "title": "RS-MoE: A Vision-Language Model with Mixture of Experts for Remote Sensing Image Captioning and Visual Question Answering",
        "authors": "Lin H.",
        "journal": "IEEE Transactions on Geoscience and Remote Sensing",
        "doi": "10.1109/TGRS.2025.3547988",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000134550",
        "scopus_id": "86000134550",
        "abstract": "Remote Sensing Image Captioning (RSIC) presents unique challenges and plays a critical role in applications such as environmental monitoring, urban planning, and disaster management. Traditional RSIC methods often struggle to produce rich and diverse descriptions. Recently, with significant advancements in Vision-Language Models (VLMs), efforts have emerged to integrate these models into the remote sensing domain and to introduce richly descriptive datasets specifically designed to enhance VLM training. However, most current RSIC models generally apply only fine-tuning to these datasets without developing models tailored to the unique characteristics of remote sensing imagery. This paper proposes RS-MoE, the first Mixture of Expert based VLM specifically customized for remote sensing domain. Unlike traditional MoE models, the core of RS-MoE is the MoE Block, which incorporates a novel Instruction Router and multiple lightweight Large Language Models (LLMs) as expert models. The Instruction Router is designed to generate specific prompts tailored for each corresponding LLM, guiding them to focus on distinct aspects of the RSIC task. This design not only allows each expert LLM to concentrate on a specific subset of the task, thereby enhancing the specificity and accuracy of the generated captions, but also improves the scalability of the model by facilitating parallel processing of sub-tasks. Additionally, we present a two-stage training strategy for tuning our RS-MoE model to prevent performance degradation due to sparsity. We fine-tuned our model on the RSICap dataset using our proposed training strategy. Experimental results on the RSICap dataset, along with evaluations on other traditional datasets where no additional fine-tuning was applied, demonstrate that our model achieves state-of-the-art performance in generating precise and contextually relevant captions. Notably, our RS-MoE-1B variant achieves performance comparable to 13B VLMs, demonstrating the efficiency of our model design. Moreover, our model demonstrates promising generalization capabilities by consistently achieving state-of-the-art performance on the Remote Sensing Visual Question Answering (RSVQA) task.",
        "author_keywords": [
            "Mixture of Experts (MoE)",
            "Multi-modal Large Language Model (MLLM)",
            "Remote Sensing",
            "Vision Language Model (VLM)"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Research on extraction and application of elements of suzhou subway public art design based on deep learning",
        "authors": "Huang Y.",
        "journal": "Salud, Ciencia y Tecnologia - Serie de Conferencias",
        "doi": "10.56294/sctconf20251482",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000124515",
        "scopus_id": "86000124515",
        "abstract": "Introduction: Public art in urban spaces enhances aesthetics, reflects cultural identity, fosters community engagement, and contributes to place making, transforming everyday environments into meaningful, interactive public experiences. Limitations include a lack of deep learning applications in extracting public art elements, limited exploration of cultural integration, and insufficient focus on interactive design methods. Method: The proposed Great Cane Rat Algorithm-Tuned Scalable Generative Adversarial Network (GCR-SGAN) optimizes SGAN performance using GCRO for generating high-quality public art designs. The dataset includes images of public art, featuring murals, sculptures, and design elements for training and analysis. Histogram equalization will enhance image contrast, improving details, while Visual Geometry Group 16 (VGG16) feature extraction will capture high-level visual patterns and features, creating a robust representation for subsequent analysis and model training. The proposed work integrates SGAN for generating high-quality public art designs with GCR optimization to enhance GAN training, improving convergence stability, generation quality, and scalability for effective art design generation and analysis. Results: The results demonstrate that the GCR-SGAN model had accuracy of 0,98, which efficiently generates high-quality public art designs, optimizing both visual appeal and training stability. Conclusion: The approach effectively advances the generation of diverse, scalable art for real-world applications. Conclusions: This research is to apply deep learning techniques to extract and analyze elements of public art in Suzhou Subway, exploring their cultural significance, design patterns, and potential applications in urban planning, enhancing the aesthetic and functional aspects of subway spaces",
        "author_keywords": [
            "Deep Learning",
            "Great Cane Rat Algorithm",
            "Public Art Design",
            "Public Art Design",
            "Scalable Generative Adversarial Network"
        ],
        "subject_areas": [
            "Multidisciplinary"
        ]
    },
    {
        "title": "Generative AI for Drone Obstacle Detection and Path Planning",
        "authors": "Muhuri A.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-981-97-7178-3_16",
        "publication_date": "2025",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000006159",
        "scopus_id": "86000006159",
        "abstract": "Generative AI is revitalizing drone navigation by apprehending two critical challenges: obstacle detection and path planning. By ingesting a different variety of information, AI models can “look” beyond conventional sensors, forecasting obscured obstacles and ensuring safe flight in complicated environments. The paper reveals a novel drone navigation framework based on Generative AI. They aim at increasing obstacle detection and path-planning efficiency. The framework integrates GANs and CNNs, enabling drones to have precise spatial awareness and depth perception capabilities to navigate around obstacles in dynamic environments. The algorithm of adaptive flight path planning, which is right at the orbit centerpiece of innovations in it, gets adjusted to real-time predictions and allows proactive reactions to new trends. It also addresses issues with implementation and looks at use cases in search-and-rescue, agriculture operations, and urban planning development which further makes it the groundbreaking advancement for AI-controlled way finding by drones.",
        "author_keywords": [
            "GANs and CNNs",
            "Obstacle detection",
            "Path planning"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Person Re-identification Method Based on Hybrid Real-Synthetic Data",
        "authors": "Qi L.",
        "journal": "Jisuanji Yanjiu yu Fazhan/Computer Research and Development",
        "doi": "10.7544/issn1000-1239.202330718",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218939768",
        "scopus_id": "85218939768",
        "abstract": "In recent years, the rapid urbanization and development of the social economy have led to a growing focus on public safety issues. Governments across the world are increasingly promoting the construction of smart cities and intelligent security systems to safeguard the lives and property of citizens and maintain social stability. Person re-identification (ReID) is an essential technology for building smart cities, with significant implications for security monitoring and criminal investigation applications. The goal of person re-identification is to accurately identify specific individuals captured under different cameras. However, due to intra-class differences resulting from various factors such as illumination, viewpoint, occlusion, and pose, person re-identification remains a challenging task in the field of computer vision. Although existing fully supervised person re-identification methods have made significant progress, the scarcity of data and labels poses a bottleneck for further improving model performance. To address this challenge, we introduce a more complex and diverse synthetic dataset with easy-to-obtain labels for auxiliary training, and propose a novel camera-aware asymmetric adversarial learning (CAAL) method that overcomes intra-class variation among multiple cameras and the domain-shift between real data and synthetic data, enabling the learning of camera-invariant feature representations from diverse data sources. Furthermore, to mitigate the impact of misleading information carried by synthetic datasets and prevent the model from overfitting to synthetic data during adversarial training, we propose using an auxiliary network trained on real-world data to constrain the training of the backbone network. Finally, we conduct extensive experiments on two public datasets to demonstrate the effectiveness of the proposed method.",
        "author_keywords": [
            "adversarial learning",
            "computer vision",
            "image retrieval",
            "knowledge distillation",
            "person re-identification"
        ],
        "subject_areas": [
            "Software",
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "An energy consumption prediction approach in smart cities by CNN-LSTM network improved with game theory and Namib Beetle Optimization (NBO) algorithm",
        "authors": "Chahardoli M.",
        "journal": "Journal of Supercomputing",
        "doi": "10.1007/s11227-024-06811-5",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85217673954",
        "scopus_id": "85217673954",
        "abstract": "One of the challenges of the Internet of Things and smart cities is energy consumption and energy theft. An accurate approach to predicting energy consumption and detecting energy theft in smart cities increases efficiency and energy efficiency. Forecasting energy consumption makes energy production based on the needs of consumers, and detecting energy theft makes energy consumption forecasting models more accurate. In this manuscript, in the first step, the data set is balanced using the generative adversarial network based on game theory and the synthetic minority oversampling based on sample density method. In the second step, the basic features of the samples are selected with the Namib beetle optimization (NBO) algorithm to reduce the input of the CNN-LSTM model. In the third step, the hyperparameters of the CNN-LSTM model are optimized to reduce the prediction and classification error rate with the NBO algorithm. In the Benin Electricity Company dataset, the proposed method has fewer errors in predicting energy consumption than the LSTM, GRU, ARIMA-LSTM, and ARIMA-GRU methods. On the Individual Household Electric-Power Consumption dataset, the proposed method provides lower energy consumption prediction errors than convolutional neural network (CNN), long short-term memory (LSTM), and CNN-LSTM. The NBO algorithm optimizer CNN-LSTM hyperparameters more accurately than Coati optimization algorithm, jellyfish search optimization, Harris hawks optimization (HHO), and African vultures optimization algorithm. Experiments on the State Grid Corporation of China dataset showed that the proposed method's accuracy, sensitivity, and precision in predicting energy theft are 98.93, 98.32, and 96.78%. The proposed method is more accurate than CNN, DeepCNN, CNN-LSTM, and the gated recurrent unit (GRU) method.",
        "author_keywords": [
            "Convolutional neural networks",
            "Energy consumption",
            "Generative adversarial network",
            "Long short-term memory",
            "Namib beetle optimization algorithm",
            "Smart cities"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Software",
            "Information Systems",
            "Hardware and Architecture"
        ]
    },
    {
        "title": "TepiSense: A Social Computing-Based Real-Time Epidemic Surveillance System Using Artificial Intelligence",
        "authors": "Tahir B.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2025.3537168",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85217008047",
        "scopus_id": "85217008047",
        "abstract": "Artificial Intelligence (AI) technologies have enabled researchers to develop tools to monitor real-world events and user behavior using social media platforms. Twitter is particularly useful for gathering invaluable information related to diseases and public health to build real-time disease surveillance systems. Such systems offer a cost-effective and efficient alternative to the passive, expensive, and time-consuming process of using data from healthcare organizations and hospitals. In this paper, we propose a novel system of TepiSense to automatically perform disease surveillance of epidemic-prone diseases. Our system classifies tweets related to diseases and further identifies 'indication' tweets that highlight the presence of patients. Our system consists of four distinct modules of pre-processor, feature extractor, classifier, and evaluator. TepiSense compares the performance of 3 feature extraction techniques, 9 machine/deep learning models, and 3 Large Language Models (LLMs). To test the performance of our system, we build a dataset of Twitter Epidemic Surveillance Corpus (TESC) containing 23.9K English and 13K labelled Urdu tweets related to six diseases: COVID19, hepatitis, malaria, flu, dengue, and HIV/AIDS. Our results show that mBERT LLM achieves the highest F-measure values of 0.96 and 0.83 for topic and indication tweets classification, respectively. Furthermore, we compute the correlation of signals generated by our system with real-world cases to test the efficacy on COVID19 disease. We notice that real-world cases have a correlation of 0.58-0.63 with the indication category tweets. Finally, we develop an interactive and user-friendly dashboard to disseminate the analytics of our system. Overall, our system offers a powerful tool for real-time disease surveillance using social media with potential implications for public health policy and decision-making.",
        "author_keywords": [
            "data mining",
            "e-health",
            "epidemic intelligence",
            "Natural language processing",
            "public health",
            "smart city"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "Introduction: AI for and in Urban Planning",
        "authors": "Wang T.",
        "journal": "Urban Planning",
        "doi": "10.17645/up.9417",
        "publication_date": "2025",
        "document_type": "Editorial",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216960085",
        "scopus_id": "85216960085",
        "abstract": "As a tool serving other disciplines of enquiry, artificial intelligence (AI) offers the potential of a potent discovery, a design and analysis paradigm to address (new) questions in urban planning. This thematic issue raises a forum for cross‐disciplinary dialogues at the intersection of urban planning and AI. Nine articles discuss both emerging use cases in urban planning practice and the relevant AI techniques being used and developed, as well as articulate the challenges associated. Future development of AI in urban planning shall address the ethical, inclusive, and just implications of AI applications for urban planning while navigating human and AI agents’ interactions and intra‐actions to facilitate a better understanding of the intentions of AI development and use, and the impacts on the behaviour of designers and users in complex urban planning practices.",
        "author_keywords": [
            "artificial intelligence",
            "development and evaluation needs",
            "social‐technical evaluations",
            "urban planning practices"
        ],
        "subject_areas": [
            "Urban Studies"
        ]
    },
    {
        "title": "Implementing traffic agent based on LangGraph",
        "authors": "Chen H.",
        "journal": "Proceedings of SPIE - The International Society for Optical Engineering",
        "doi": "10.1117/12.3050639",
        "publication_date": "2025",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216935804",
        "scopus_id": "85216935804",
        "abstract": "As urbanization accelerates, the rapid increase in urban populations and vehicle numbers poses unprecedented challenges to city traffic. The demand for intelligent transportation systems, a key component of smart city construction, is growing day by day. This system is a highly integrated interdisciplinary field that combines complex computer algorithms, which to some extent limits its extensive application. The emergence of large language middleware has reduced the deployment barriers for related applications. This article proposes an innovative intelligent transportation system that combines a large language model (LLM) with Amap API through LangGraph, providing strong support for urban traffic. This system not only assists users in making travel decisions through natural language dialogue based on the superior reasoning and planning capabilities of LLM, but also enhances the semantic understanding ability of LLM by constructing a graph structure through LangGraph,it improves the capture capability for urban traffic tasks and implements a self-feedback mechanism for the large language model.This innovative approach offers a more convenient and efficient method for the application of large language models in the field of Intelligent Traffic System.",
        "author_keywords": [
            "Amap",
            "ITS",
            "LangGraph",
            "Large Language Models"
        ],
        "subject_areas": [
            "Electronic, Optical and Magnetic Materials",
            "Condensed Matter Physics",
            "Computer Science Applications",
            "Applied Mathematics",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Exploring Pure 4G Diffusion in India and its Connect with Human Development and Urbanization",
        "authors": "Jha A.",
        "journal": "Information Systems Frontiers",
        "doi": "10.1007/s10796-024-10569-9",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216906663",
        "scopus_id": "85216906663",
        "abstract": "Although many countries have already forayed into 5G deployment, 4G still comprises the largest share of mobile subscribers, especially in emerging economies such as India. In this paper, we quantitatively assess the diffusion characteristics of ‘pure’ 4G mobile communication in India using popular nonlinear diffusion models, and scrutinize the association of two external factors, namely Human Development and Urbanization, with formal and informal communication channels of diffusion, in the context of 4G. Our findings highlight the crucial role external factors play in the speed and pattern of 4G diffusion across India. Notably, the 4G diffusion is predominantly driven by informal communication channels, such as word of mouth and interpersonal signalling. Typically, in regions with lower levels of Human Development and Urbanization, the informal communication channels have a greater influence on the diffusion. However, as the levels of Human Development and Urbanization go up, the formal communication channels start gathering momentum. Thus, our preliminary study sheds light on how Human Development and Urbanization interact with formal and informal communication channels to shape the diffusion of 4G in emerging economies. Our findings could furnish valuable perspectives for policymakers and stakeholders toward refining their strategies concerning infrastructure deployment, socio-economic development, and regulatory interventions.",
        "author_keywords": [
            "4G",
            "Diffusion",
            "Human Development",
            "India",
            "Telecom",
            "Urbanization"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Software",
            "Information Systems",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "A 3D Self-Awareness Diffusion Network for Multimodal Classification",
        "authors": "Ma M.",
        "journal": "IEEE Transactions on Multimedia",
        "doi": "10.1109/TMM.2025.3535295",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216858184",
        "scopus_id": "85216858184",
        "abstract": "As imaging sensor technology in remote sensing has advanced quickly, multimodal fusion classification has become an important research direction in land cover and urban planning classification tasks. While generative models and image classification have greatly benefited from diffusion models, the present ones primarily concentrate on single-modality-driven diffusion processes. Therefore, this paper presents a 3D self-awareness diffusion network (3DSA-DiffNet) for multispectral (MS) and panchromatic (PAN) image fusion classification, which would make it easier to classify heterogeneous data from various sensors. First, in order to model the relationship between multi-channel spectra and multi-pixel spatial distributions as well as samples, respectively, a spatial-spectral joint denoising network (S2 JD-Net) is proposed. It can incorporate the diffusion process into the neural network to enhance the quality of diffusion features. Secondly, to imitate the brain's spatial-spectral coexistence learning mechanism, this work offers a 3D self-awareness module (3DSA-Module) that can learn the weight of each pixel in 3D space, resulting in extraordinarily high feature representation capabilities. Finally, experimental verification demonstrates that the 3D self-awareness diffusion fusion network driven by brain inspiration outperforms more sophisticated approaches on the Xi'an, Huhhot, and Muufl datasets.",
        "author_keywords": [
            "3D self-attention mechanism",
            "Diffusion model",
            "fusion classification",
            "multimodal",
            "remote sensing images"
        ],
        "subject_areas": [
            "Signal Processing",
            "Media Technology",
            "Computer Science Applications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "TomoSAR 3D reconstruction: Cascading adversarial strategy with sparse observation trajectory",
        "authors": "Zhu X.",
        "journal": "IET Computer Vision",
        "doi": "10.1049/cvi2.70001",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216789668",
        "scopus_id": "85216789668",
        "abstract": "Synthetic aperture radar tomography (TomoSAR) has shown significant potential for the 3D Reconstruction of buildings, especially in critical areas such as topographic mapping, urban planning, and disaster monitoring. In practical applications, the constraints of observation trajectories frequently lead to the acquisition of a limited dataset of sparse SAR images, presenting challenges for TomoSAR 3D Reconstruction and affecting its signal-to-noise ratio and elevation resolution performance. The study introduces a cascade adversarial strategy based on the Conditional Generative Adversarial Network (CGAN), optimised explicitly for sparse observation trajectories. In the preliminary phase of the CGAN, the U-Net architecture was employed to capture more global information and enhance image detail recovery capability, which is subsequently utilised in the cascade refinement network. The ResNet34 residual network in the advanced network stage was adopted to bolster feature extraction and image generation capabilities further. Based on experimental validation performed on the curated TomoSAR 3D super-resolution dataset tailored for buildings, the findings reveal that the methodology yields a notable enhancement in image quality and accuracy compared to other techniques.",
        "author_keywords": [
            "computer vision",
            "learning (artificial intelligence)",
            "remote sensing"
        ],
        "subject_areas": [
            "Software",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "title": "Mobile Crowdsensing and Remote Sensing in Smart Cities: An Introduction",
        "authors": "Tony Santhosh G.",
        "journal": "Internet of Things",
        "doi": "10.1007/978-3-031-72732-0_1",
        "publication_date": "2025",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216380647",
        "scopus_id": "85216380647",
        "abstract": "The concept of smart cities has emerged as a transformative approach to urban planning and management, leveraging cutting-edge technologies to enhance the quality of life for urban residents. Two pivotal technologies driving the smart city revolution are mobile crowdsensing and remote sensing. This book chapter provides a comprehensive exploration of these technologies and their integration within the context of smart cities. Mobile crowdsensing harnesses the ubiquity of smartphones and wearable devices to gather real-time data from citizens. This data encompasses various aspects of urban life, including traffic patterns, air quality, noise levels, and more. The chapter delves into the intricacies of mobile crowdsensing, from task design and participant recruitment to data collection, fusion, and analysis. It highlights the role of citizens as active contributors to urban data generation and the impact of this approach on informed decision-making by city planners. Remote sensing, on the other hand, offers a bird’s-eye view of urban landscapes through satellites, drones, and other sensor-equipped platforms. This technology provides valuable insights into land use, environmental conditions, infrastructure, and more. The chapter explores the deployment of remote sensing in urban environments, covering sensor placement, data collection, transmission, processing, and interpretation. It underscores the significance of remote sensing in monitoring urban sprawl, environmental changes, and sustainable development. A major focus of the chapter is the integration of mobile crowdsensing and remote sensing within the smart city framework. By combining real-time, citizen-generated data with comprehensive remote sensing insights, cities can gain a holistic understanding of their complex ecosystems. This integrated approach empowers city planners, policymakers, and environmental agencies to make informed decisions regarding urban development, resource allocation, and emergency response. Throughout the chapter, practical examples and case studies illustrate the real-world applications of mobile crowdsensing and remote sensing in smart cities. These examples showcase how cities worldwide are leveraging these technologies to optimize transportation systems, manage public spaces, monitor pollution levels, and respond to urban challenges effectively. In conclusion, this book chapter provides a thorough exploration of mobile crowdsensing and remote sensing as fundamental pillars of smart city development. It emphasizes the role of these technologies in shaping sustainable and efficient urban landscapes, promoting citizen engagement, and enabling data-driven decision-making. The chapter serves as a valuable resource for researchers, urban planners, policymakers, and anyone interested in the dynamic field of smart cities and the technologies that drive them.",
        "author_keywords": [
            "Algorithm optimization",
            "Feature extraction",
            "Mobile crowdsensing",
            "Remote sensing",
            "Sensor fusion",
            "Ubiquitous mobile devices",
            "Urban planning"
        ],
        "subject_areas": [
            "Signal Processing",
            "Instrumentation",
            "Computer Science Applications",
            "Computer Networks and Communications",
            "Computational Theory and Mathematics",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Research and Application of Text-to-Image Technology Based on Al Foundation Models",
        "authors": "Zhang X.",
        "journal": "Journal of Geo-Information Science",
        "doi": "10.12082/dqxxkx.2025.240657",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216304685",
        "scopus_id": "85216304685",
        "abstract": "[Objectives] To systematically review recent advancements in text-to-image generation technology driven by large-scale AI models and explore its potential applications in urban and rural planning. [Discussion] This study provides a comprehensive review of the development of text-to-image generation technology from the perspectives of training datasets, model architectures, and evaluation methods, highlighting the key factors contributing to its success. While this technology has achieved remarkable progress in general computer science, its application in urban and rural planning remains constrained by several critical challenges. These include the lack of high-quality domain-specific data, limited controllability and reliability of generated content, and the absence of constraints informed by geoscience expertise. To address these challenges, this paper proposes several research strategies, including domain-specific data augmentation techniques, text-to-image generation models enhanced with spatial information through instruction-based extensions, and locally editable models guided by induced layouts. Furthermore, through multiple case studies, the paper demonstrates the value and potential of text-to-image generation technology in facilitating innovative practices in urban and rural planning and design. [Prospect] With continued technological advancements and interdisciplinary integration, text-to-image generation technology holds promise as a significant driver of innovation in urban and rural planning and design. It is expected to support more efficient and intelligent design practices, paving the way for groundbreaking applications in this field.",
        "author_keywords": [
            "AIGC",
            "artificial intelligence",
            "diffusion model",
            "foundation model",
            "generative AI",
            "image generation",
            "text-to-image"
        ],
        "subject_areas": [
            "Information Systems",
            "Computer Science Applications",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "From Geographic Information System to Geographic Intelligent Agent",
        "authors": "Luo B.",
        "journal": "Journal of Geo-Information Science",
        "doi": "10.12082/dqxxkx.2025.240658",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216276155",
        "scopus_id": "85216276155",
        "abstract": "[Objectives] The geographic system is an integrated framework encompassing natural and human phenomena and their interrelationships on the Earth's surface. While Geographic Information Systems (GIS) can digitally process these geographic elements, they face challenges in addressing rapidly changing geographic contexts with complex 3D structures. This is primarily due to the lack of bi-directional interactions between physical and informational spaces, as well as their reliance on predefined rules and historical data. In this paper, we propose the concept of a“Geographic Intelligent Agent”as an advanced form of GIS, which integrates embodied intelligence, self-supervised learning, and multimodal language modeling to improve environmental perception, spatial understanding, and autonomous decision-making. [Methods] The architecture of the geographic intelligent agent consists of three core components: multimodal perception, an intelligent hub, and an action manipulation module. These components collectively acquire comprehensive environmental information through sensor networks, perform complex situatio reasoning using knowledge graphs and generative models, and enable real-time control and multilevel planning of the physical environment. To adapt to differences between virtual and real environments, the geographic intelligent agent is tested using the earth simulator and a test field platform, equipping it with stronger autonomous capabilities in complex and dynamic geographic contexts. [Results] This paper also demonstrates the implementation of geographic intelligent agent in spatial intelligence applications using the virtual digital human“EarthSage”as an example. [Conclusions] As a prototype of the geographic intelligent agent, \"EarthSage\" integrates modules such as the spatiotemporal Knowledge Ggraph (GeoKG) and a Cognitive Map Generation Model (GeoGPT), assisting users in obtaining intelligent spatial decision-making support in fields such as emergency management, urban planning, and ecological monitoring. This work exemplifies the transformation of GIS from a traditional information processing tool to an autonomous spatial intelligent system, marking a significant advancement in the field.",
        "author_keywords": [
            "embodied intelligence",
            "geographic intelligent agent",
            "intelligent geographic system",
            "knowledge graph",
            "large model",
            "multimodal perception",
            "self-supervised learning",
            "spatial intelligence"
        ],
        "subject_areas": [
            "Information Systems",
            "Computer Science Applications",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Integrating LLMs With ITS: Recent Advances, Potentials, Challenges, and Future Directions",
        "authors": "Mahmud D.",
        "journal": "IEEE Transactions on Intelligent Transportation Systems",
        "doi": "10.1109/TITS.2025.3528116",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216263322",
        "scopus_id": "85216263322",
        "abstract": "Intelligent Transportation Systems (ITS) are crucial for the development and operation of smart cities, addressing key challenges in efficiency, productivity, and environmental sustainability. This paper comprehensively reviews the transformative potential of Large Language Models (LLMs) in optimizing ITS. Initially, we provide an extensive overview of ITS, highlighting its components, operational principles, and overall effectiveness. We then delve into the theoretical background of various LLM techniques, such as GPT, T5, CTRL, and BERT, elucidating their relevance to ITS applications. Following this, we examine the wide-ranging applications of LLMs within ITS, including traffic flow prediction, vehicle detection and classification, autonomous driving, traffic sign recognition, and pedestrian detection. Our analysis reveals how these advanced models can significantly enhance traffic management and safety. Finally, we explore the challenges and limitations LLMs face in ITS, such as data availability, computational constraints, and ethical considerations. We also present several future research directions and potential innovations to address these challenges. This paper aims to guide researchers and practitioners through the complexities and opportunities of integrating LLMs in ITS, offering a roadmap to create more efficient, sustainable, and responsive next-generation transportation systems.",
        "author_keywords": [
            "autonomous driving",
            "Intelligent transportation systems",
            "large language models",
            "traffic flow optimization",
            "traffic management"
        ],
        "subject_areas": [
            "Automotive Engineering",
            "Mechanical Engineering",
            "Computer Science Applications"
        ]
    },
    {
        "title": "Advanced Deep Learning Algorithms for Energy Optimization of Smart Cities",
        "authors": "Rojek I.",
        "journal": "Energies",
        "doi": "10.3390/en18020407",
        "publication_date": "2025",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216084894",
        "scopus_id": "85216084894",
        "abstract": "Advanced deep learning algorithms play a key role in optimizing energy usage in smart cities, leveraging massive datasets to increase efficiency and sustainability. These algorithms analyze real-time data from sensors and IoT devices to predict energy demand, enabling dynamic load balancing and reducing waste. Reinforcement learning models optimize power distribution by learning from historical patterns and adapting to changes in energy usage in real time. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) facilitate detailed analysis of spatial and temporal data to better predict energy usage. Generative adversarial networks (GANs) are used to simulate energy usage scenarios, supporting strategic planning and anomaly detection. Federated learning ensures privacy-preserving data sharing in distributed energy systems, promoting collaboration without compromising security. These technologies are driving the transformation towards sustainable and energy-efficient urban environments, meeting the growing demands of modern smart cities. However, there is a view that if the pace of development is maintained with large amounts of data, the computational/energy costs may exceed the benefits. The article aims to conduct a comparative analysis and assess the development potential of this group of technologies, taking into account energy efficiency.",
        "author_keywords": [
            "artificial intelligence",
            "deep learning",
            "energetic optimization",
            "energy management",
            "Internet of Things (IoT)",
            "smart buildings",
            "smart city"
        ],
        "subject_areas": [
            "Renewable Energy, Sustainability and the Environment",
            "Fuel Technology",
            "Engineering (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Energy (miscellaneous)",
            "Control and Optimization",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Diffusion-Based Semantic Communication Assisted Low-Altitude Intelligent Service for IoT",
        "authors": "Fan J.",
        "journal": "IEEE Internet of Things Journal",
        "doi": "10.1109/JIOT.2025.3530462",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216024569",
        "scopus_id": "85216024569",
        "abstract": "Unmanned aerial vehicles (UAVs), as the key Internet of Things (IoT) devices, play a dominant position in low-altitude environments. Semantic communication (SC), as the next-generation communication technology, serves as a bridge for surpassing the Shannon limit toward the 6G wireless network. Establishing air-ground SC to provide intelligent IoT services is a crucial initiative for building future smart cities. In this paper, we propose a UAV-based SC framework, named diffusion joint source-channel coding (D-JSCC). Abandoning traditional convolutional neural networks, we use transformers as the backbone and innovatively incorporate the diffusion model (DM) for image enhancement, achieving an optimal balance between image distortion and human perception. To accurately capture the numerical and perceptual loss induced by wireless channels and seamlessly amalgamate the DM with SC, we integrate channel states as strong prior information to refine the sampling process. Furthermore, we employ the gradient guidance strategy, which counteracts the randomness of sampling ensuring high robustness in harsh communication conditions. Additionally, we strike a balance between performance and sampling steps, ensuring both efficient computation and high-quality image enhancement. Comprehensive experiments demonstrate the advantages of D-JSCC across different communication environments.",
        "author_keywords": [
            "diffusion model",
            "generative artificial intelligence",
            "Semantic communication",
            "wireless image transmission"
        ],
        "subject_areas": [
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Research Progress on Spatial Clustering Pattern Discovery: Concepts, Methods and Applications",
        "authors": "Qin W.",
        "journal": "Journal of Geo-Information Science",
        "doi": "10.12082/dqxxkx.2025.240683",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215993301",
        "scopus_id": "85215993301",
        "abstract": "[Significance] The spatial patterns of geographic features have a profound impact on the natural environment and human activities. Mining and discovering typical feature patterns from spatial-temporal data is a prerequisite for morphological analysis and planning, which can provide basic support for urban planning and watershed planning. Spatial clustering pattern is a significant and repeated orderly arrangement or combination of relationships between geographic features, which shows a significant distribution pattern and spatial morphology. The discovery of spatial clustering pattern of features is facilitated by spatial analysis, data mining, pattern recognition, and other related technical methods. This process helps to build a perception of the laws of the arrangement and combination of features within a complex and irregular collection of feature sets. Through analytical reasoning, it uncovers the spatial clustering and morphological structure of features with specific semantics. This discovery is of great significance in revealing the spatial distribution law of features, explaining the formation mechanism of geographic phenomena, and understanding the interaction process between humans and space. [Progress] On the basis of elaborating the connotation of spatial clustering patterns of features, this paper summarizes two types of methods for spatial clustering pattern discovery, including rule-oriented pattern extraction and data-driven pattern recognition. The rule-oriented pattern extraction methods rely on expert knowledge to summarize pattern characteristics. They express, constrain and guide the pattern discovery process with formal explicit rules, and extract the features of the specified spatial clustering patterns from the spatial data set. The data-driven pattern recognition methods draw knowledge from both 'experts' and 'data'. They learn the pattern characteristics of features from multiple scales and perspectives through a large number of samples automatically under the guidance of expert knowledge, and perform category prediction on a set of features in order to identify the spatial clustering patterns of the features. Subsequently, the spatial clustering pattern discovery of three types of typical features, namely buildings, roads and water systems, is reviewed. The data-driven approach represented by graph deep learning is usually superior to the rule-oriented pattern extraction approach in terms of pattern discovery accuracy due to its powerful pattern learning capability. In terms of the overall trend, spatial clustering pattern discovery of features is shifting from traditional methods to close integration with deep learning methods. [Prospect] In the future, knowledge aggregation of the rule base and sample set for feature spatial clustering pattern discovery, active discovery techniques for clustering patterns, graph deep learning models for efficient clustering pattern discovery, and pattern discovery based on generative AI will become the main research directions.",
        "author_keywords": [
            "building",
            "clustering",
            "deep learning",
            "pattern discovery",
            "road",
            "spatial clustering pattern",
            "water system"
        ],
        "subject_areas": [
            "Information Systems",
            "Computer Science Applications",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "When Generative AI Meets Semantic Communication: Optimizing Radio Map Construction and Distribution in Future Mobile Networks",
        "authors": "Zhou L.",
        "journal": "IEEE Network",
        "doi": "10.1109/MNET.2025.3529513",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215866894",
        "scopus_id": "85215866894",
        "abstract": "With the rapid development of the internet of things and smart cities, the demand for effective spectrum collaboration has grown significantly. Radio maps play a crucial role in understanding the spatial radio environment, which is essential for wireless applications such as cell planning and radio resource management. However, generating radio maps is a resource-intensive task, as the construction process is complex and the distribution process consumes substantial bandwidth. This article proposes a method that combines semantic communication (SemCom) and generative artificial intelligence (GAI) to optimize the construction and distribution processes of radio maps. By incorporating SemCom, our method transmits only key semantic information during the distribution process, significantly reducing bandwidth usage while ensuring accurate and efficient information transfer. While the diverse generative capabilities of GAI introduce some instability, which could be a limitation in radio map construction, this article achieves precise content decoding through prompts based on multi-modal semantic information, enabling accurate construction and restoration of radio maps. By utilizing SemCom and GAI technologies, the cost of applications of radio maps can be significantly reduced, which is beneficial for stimulating the pace of intelligence evolution in future mobile networks.",
        "author_keywords": [
            "diffusion models",
            "generative AI",
            "radio map",
            "semantic communication"
        ],
        "subject_areas": [
            "Software",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Semi-Supervised Change Detection with Data Augmentation and Adaptive Thresholding for High-Resolution Remote Sensing Images",
        "authors": "Zhang W.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs17020178",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215769768",
        "scopus_id": "85215769768",
        "abstract": "Change detection (CD) is an important research direction in the field of remote sensing, which aims to analyze the changes in the same area over different periods and is widely used in urban planning and environmental protection. While supervised learning methods in change detection have demonstrated substantial efficacy, they are often hindered by the rising costs associated with data annotation. Semi-supervised methods have attracted increasing interest, offering promising results with limited data labeling. These approaches typically employ strategies such as consistency regularization, pseudo-labeling, and generative adversarial networks. However, they usually face the problems of insufficient data augmentation and unbalanced quality and quantity of pseudo-labeling. To address the above problems, we propose a semi-supervised change detection method with data augmentation and adaptive threshold updating (DA-AT) for high-resolution remote sensing images. Firstly, a channel-level data augmentation (CLDA) technique is designed to enhance the strong augmentation effect and improve consistency regularization so as to address the problem of insufficient feature representation. Secondly, an adaptive threshold (AT) is proposed to dynamically adjust the threshold during the training process to balance the quality and quantity of pseudo-labeling so as to optimize the self-training process. Finally, an adaptive class weight (ACW) mechanism is proposed to alleviate the impact of the imbalance between the changed classes and the unchanged classes, which effectively enhances the learning ability of the model for the changed classes. We verify the effectiveness and robustness of the proposed method on two high-resolution remote sensing image datasets, WHU-CD and LEVIR-CD. We compare our method to five state-of-the-art change detection methods and show that it achieves better or comparable results.",
        "author_keywords": [
            "adaptive threshold",
            "consistency regularization",
            "pseudo-labeling",
            "semi-supervised change detection",
            "unbalanced"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "AI-Based Malicious Encrypted Traffic Detection in 5G Data Collection and Secure Sharing",
        "authors": "Han G.",
        "journal": "Electronics (Switzerland)",
        "doi": "10.3390/electronics14010051",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214533890",
        "scopus_id": "85214533890",
        "abstract": "With the development and widespread application of network information, new technologies led by 5G are emerging, resulting in an increasingly complex network security environment and more diverse attack methods. Unlike traditional networks, 5G networks feature higher connection density, faster data transmission speeds, and lower latency, which are widely applied in scenarios such as smart cities, the Internet of Things, and autonomous driving. The vast amounts of sensitive data generated by these applications become primary targets during the processes of collection and secure sharing, and unauthorized access or tampering could lead to severe data breaches and integrity issues. However, as 5G networks extensively employ encryption technologies to protect data transmission, attackers can hide malicious content within encrypted communication, rendering traditional content-based traffic detection methods ineffective for identifying malicious encrypted traffic. To address this challenge, this paper proposes a malicious encrypted traffic detection method based on reconstructive domain adaptation and adversarial hybrid neural networks. The proposed method integrates generative adversarial networks with ResNet, ResNeXt, and DenseNet to construct an adversarial hybrid neural network, aiming to tackle the challenges of encrypted traffic detection. On this basis, a reconstructive domain adaptation module is introduced to reduce the distribution discrepancy between the source domain and the target domain, thereby enhancing cross-domain detection capabilities. By preprocessing traffic data from public datasets, the proposed method is capable of extracting deep features from encrypted traffic without the need for decryption. The generator utilizes the adversarial hybrid neural network module to generate realistic malicious encrypted traffic samples, while the discriminator achieves sample classification through high-dimensional feature extraction. Additionally, the domain classifier within the reconstructive domain adaptation module further improves the model’s stability and generalization across different network environments and time periods. Experimental results demonstrate that the proposed method significantly improves the accuracy and efficiency of malicious encrypted traffic detection in 5G network environments, effectively enhancing the detection performance of malicious traffic in 5G networks.",
        "author_keywords": [
            "adversarial generative networks",
            "deep learning",
            "domain adaptation",
            "encrypt malicious traffic",
            "hybrid neural networks"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Identification and Analysis on Surface Deformation in the Urban Area of Nanchang Based on PS-InSAR Method",
        "authors": "Zhang M.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs17010157",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214511179",
        "scopus_id": "85214511179",
        "abstract": "Interferometric Synthetic Aperture Radar (InSAR) technology has emerged as a vital tool for monitoring surface deformation due to its high accuracy and spatial resolution. With the rapid economic development of Nanchang, extensive infrastructure development and construction activities have significantly altered the urban landscape. Underground excavation and groundwater extraction in the region are potential contributors to surface deformation. This study utilized Sentinel-1 satellite data, acquired between September 2018 and May 2023, and applied the Permanent Scatterer Interferometric Synthetic Aperture Radar (PS-InSAR) technique to monitor surface deformation in Nanchang’s urban area. The findings revealed that surface deformation rates in the study area range from −10 mm/a to 6 mm/a, with the majority of regions remaining relatively stable. Approximately 99.9% of the monitored points exhibited deformation rates within −5 mm/a to 5 mm/a. However, four significant subsidence zones were identified along the Gan River and its downstream regions, with a maximum subsidence rate reaching 9.7 mm/a. Historical satellite imagery comparisons indicated that certain subsidence areas are potentially associated with construction activities. Further analysis integrating subsidence data, monthly precipitation, and groundwater depth revealed a negative correlation between surface deformation in Region A and rainfall, with subsidence trends aligning with groundwater level fluctuations. However, such a correlation was not evident in the other three regions. Additionally, water level data from the Xingzi Station of Poyang Lake showed that only Region A’s subsidence trend closely corresponds with water level variations. We conducted a detailed analysis of the spatial distribution of soil types in Nanchang and found that the soil types in areas of surface deformation are primarily Semi-hydromorphic Soils and Anthropogenic Soils. These soils exhibit high compressibility, making them prone to compaction and significantly influencing surface deformation. This study concludes that localized surface deformation in Nanchang is primarily driven by urban construction activities and the compaction of artificial fill soils, while precipitation also has an impact in certain areas.",
        "author_keywords": [
            "Nanchang",
            "permanent scatterer interferometry",
            "surface deformation",
            "time-series deformation"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Attentive Dual Residual Generative Adversarial Network for Energy-Aware Routing Through Golden Search Optimization Algorithm in Wireless Sensor Network Utilizing Cluster Head Selection",
        "authors": "Ravikumar K.",
        "journal": "Transactions on Emerging Telecommunications Technologies",
        "doi": "10.1002/ett.70035",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214409653",
        "scopus_id": "85214409653",
        "abstract": "Wireless Sensor Networks (WSNs) are extensively used in event monitoring and tracking, particularly in scenarios that require minimal human intervention. However, a key challenge in WSNs is the short lifespan of sensor nodes (SN), as continuous sensing leads to rapid battery depletion. In high-traffic areas, sensors located near the sink node exhaust their energy quickly, creating an energy-hole issue. As a result, optimizing energy usage is a significant challenge for WSN-assisted applications. To address this, this paper proposes an Energy-aware Routing and Cluster Head Selection in Wireless Sensor Network through an Attentive Dual Residual Generative Adversarial Network for Golden Search Optimization Algorithm in Wireless Sensor Network (EAR-WSN-ADRGAN-GSOA). This method involves selecting the Cluster Head (CH) using Attentive Dual Residual Generative Adversarial Network (ADRGAN), minimizing energy consumption, and reducing a number of dead sensor nodes. Subsequently, Golden Search Optimization Algorithm (GSOA) is employed to determine an optimal path for data transmission to the sink node, maximizing energy efficiency, and elongating sensor node lifespan. The proposed EAR-WSN-ADRGAN-GSOA method is simulated in MATLAB. The performance metrics, such as network lifetime, number of alive nodes, number of dead nodes, throughput, energy consumption, and packet delivery ratio is examined. The proposed EAR-WSN-ADRGAN-GSOA demonstrates improved performance, achieving a higher average throughput of 0.93 Mbps, and lower average energy consumption of 0.39 mJ compared with the existing methods. These improvements have significant real-world implications for enhancing the efficiency and longevity of WSNs in applications, such as environmental monitoring, smart cities, and industrial automation.",
        "author_keywords": [
            "Attentive Dual Residual Generative Adversarial Network",
            "cluster head",
            "Golden Search Optimization Algorithm",
            "nodes",
            "optimal routing and wireless sensor network"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Intelligent Agent Based Clustering and Optimal Multipath Routing for Energy-Efficient Wireless Sensor Networks in Smart City Applications: A Distributed AI-Driven Approach",
        "authors": "Patra B.K.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-3-031-75170-7_22",
        "publication_date": "2025",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214109518",
        "scopus_id": "85214109518",
        "abstract": "The study proposes an innovative approach to enhance energy efficiency in Wireless Sensor Networks (WSNs) for smart city applications. The primary focus is on leveraging distributed artificial intelligence (AI) and multipath routing techniques to address challenges such as unequal clustering, poor cluster head selection, and excessive power consumption within WSNs. The approach uses agent-based clustering, where autonomous AI agents dynamically form clusters of sensor nodes based on real-time data characteristics. These clusters are then used for multipath routing, optimizing energy consumption, reliability, and congestion reduction. The distributed nature of AI agents allows for adaptive cluster formations. This algorithm aims to address issues related to uneven clustering, inefficient cluster head selection, and excessive power consumption. Additionally, the integration of agent-based clustering is proposed, involving the deployment of autonomous AI agents that dynamically cluster sensor nodes based on real-time data properties. These AI agents facilitate self-organization and adaptability, ensuring that clusters accurately reflect the evolving data landscape in urban environments. The approach also employs sophisticated energy management strategies at the sensor node level, such as duty cycling, adaptive transmission power control, and sleep-wake scheduling. Simulations in a smart city environment show significant improvements in energy efficiency, prolonging the network’s operational lifespan and improving service quality by mitigating data loss and latency issues. This approach contributes to the sustainable development and performance optimization of smart city infrastructure.",
        "author_keywords": [
            "Clustering",
            "Distributed Artificial Intelligence",
            "Energy Efficiency",
            "Multipath Routing",
            "Smart Cities",
            "Wireless Sensor Networks"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "GIS Cartography A Guide to Effective Map Design",
        "authors": "Peterson G.N.",
        "journal": "GIS Cartography A Guide to Effective Map Design",
        "doi": "10.1201/9781003531302",
        "publication_date": "2025",
        "document_type": "Book",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213912301",
        "scopus_id": "85213912301",
        "abstract": "The new edition of this well-established introductory cartography textbook is updated to respond to the demand for critical engagement with new technologies, the passion for inclusive design, and for preparing students to build competence in fundamental skills. Written in a friendly style, it is enjoyable to read and includes over 200 figures and maps, explaining everything from layout design to dynamic cartography issues. A new chapter discusses the role of artificial intelligence (AI) in cartography, and a significant expansion to 3D cartography has been incorporated into existing chapters. A new chapter on accessibility provides a thorough understanding of universal design. Additional updates include placements and best practices for digital map elements, global labeling techniques including language support, hybrid map styling, multiscale map testing, and information on 4D mapping. New in the Fourth Edition: Exploration of geospatial AI and generative AI in cartography and how they can already make an impact on workflows. New material on vision, motor, and cognitive accessibility techniques in map design. Expanded discussion on 3D cartography. All chapters are updated with new data and important new developments in cartography, including the importance of accessible design to ensure inclusivity for all users. Updated study questions and exercises to enhance student engagement and comprehension. New discussions of techniques such as aquarium cutaways, integrated north arrows, joy plots, hybrid satellite maps, crafted hachuring, as well as updated information on resolution and file types. This book is written as a go-to guide for learning the art and science of mapmaking. It is for undergraduate and graduate students taking courses in GIS and cartography and studying fields such as geography, geophysics, environmental engineering, urban planning, and so on. It is also a valuable resource for professionals interested in learning techniques and technologies for creating maps and visualizing geospatial datasets.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "DreamCar: Leveraging Car-Specific Prior for In-the-Wild 3D Car Reconstruction",
        "authors": "Du X.",
        "journal": "IEEE Robotics and Automation Letters",
        "doi": "10.1109/LRA.2024.3523231",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213724701",
        "scopus_id": "85213724701",
        "abstract": "Self-driving industries usually employ professional artists to build exquisite 3D cars. However, it is expensive to craft large-scale digital assets. Since there are already numerous datasets available that contain a vast number of images of cars, we focus on reconstructing high-quality 3D car models from these datasets. However, these datasets only contain one side of cars in the forward-moving scene. We try to use the existing generative models to provide more supervision information, but they struggle to generalize well in cars since they are trained on synthetic datasets not car-specific. In addition, The reconstructed 3D car texture misaligns due to a large error in camera pose estimation when dealing with in-the-wild images. These restrictions make it challenging for previous methods to reconstruct complete 3D cars. To address these problems, we propose a novel method, named DreamCar, which can reconstruct high-quality 3D cars given a few images even a single image. To generalize the generative model, we collect a car dataset, named Car360, with over 5,600 vehicles. With this dataset, we make the generative model more robust to cars. We use this generative prior specific to the car to guide its reconstruction via Score Distillation Sampling. To further complement the supervision information, we utilize the geometric and appearance symmetry of cars. Finally, we propose a pose optimization method that rectifies poses to tackle texture misalignment. Extensive experiments demonstrate that our method significantly outperforms existing methods in reconstructing high-quality 3D cars.",
        "author_keywords": [
            "automation technologies for smart cities",
            "autonomous agents",
            "Visual learning"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Biomedical Engineering",
            "Human-Computer Interaction",
            "Mechanical Engineering",
            "Computer Vision and Pattern Recognition",
            "Computer Science Applications",
            "Control and Optimization",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "UP-Diff: Latent Diffusion Model for Remote Sensing Urban Prediction",
        "authors": "Wang Z.",
        "journal": "IEEE Geoscience and Remote Sensing Letters",
        "doi": "10.1109/LGRS.2024.3520133",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213040539",
        "scopus_id": "85213040539",
        "abstract": "Remote sensing (RS) technology has become essential for monitoring urban development, including applications like population growth analysis, transportation congestion forecasting, and climate change detection (CD). However, its potential for future urban planning (UP), particularly in predicting future urban layouts remains largely unexplored. This study introduces UP-Diff, a novel method leveraging generative models for UP, to address this gap. UP-Diff leverages information from current urban layouts and planned change maps to predict future urban configurations. Key challenges addressed include the integration of urban layouts and change maps into latent diffusion model (LDM) through careful architecture improvements and the mitigation of limited training data by employing a pretrained stable diffusion (SD) model with fixed weights, trainable ConvNeXt, and trainable cross-attention layers. Our method significantly streamlines the UP process by automating layout predictions, thus reducing the time and effort required compared to traditional manual methods. Comprehensive evaluations on the learning, vision, and RS dataset (LEVIR-CD) and Sun Yat-Sen University dataset (SYSU-CD) validate that UP-Diff achieves high-fidelity predictions of future urban layouts, demonstrating its effectiveness and potential for advancing RS-based UP methodologies. Our code and model weights are available at https://github.com/zeyuwang-zju/UP-Diff.",
        "author_keywords": [
            "Cross-attention",
            "latent diffusion model (LDM)",
            "remote sensing (RS)",
            "UP-Diff",
            "urban planning (UP)"
        ],
        "subject_areas": [
            "Geotechnical Engineering and Engineering Geology",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Forecasting land surface drought in urban environments based on machine learning model",
        "authors": "Chen J.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2024.106048",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85212344455",
        "scopus_id": "85212344455",
        "abstract": "Urban drought, a subtype of socio-economic drought, has received limited attention compared to other types. Given the shifts in water supply patterns due to global climate change and ongoing urbanization, understanding and predicting how urban design affects drought is crucial for sustainable human settlements. Previous research has primarily focused on large-scale predictive modeling, making it difficult for architects and urban designers to address potential drought risks. This study addresses that issue by proposing an urban planning prediction model based on generative adversarial networks that integrates temperature vegetation dryness index (TVDI) maps. The model is trained on relevant datasets by using Guangzhou as a case study, including land cover, land surface temperature, and normalized difference vegetation index data. TVDI maps are generated from untrained image pairs based on urban planning parameters. Model validation, including accuracy analysis and scenario simulations, is conducted to assess the model's ability to predict urban land surface drought resulting from changes in urban planning. This approach highlights its proactive capacity to anticipate and reveal long-term or gradually unfolding drought trends, offering valid tools for urban design and planning.",
        "author_keywords": [
            "Generative Adversarial Networks (GAN)",
            "Machine learning",
            "Temperature Vegetation Dryness Index (TVDI)",
            "Urban drought"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Method and Spatiotemporal Analysis for Impervious Surface Extraction Based on an Improved DeepLabV3+ Model",
        "authors": "Wang X.",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "doi": "10.1109/JSTARS.2024.3511625",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211985455",
        "scopus_id": "85211985455",
        "abstract": "As global urbanization accelerates, accurate extraction of urban impervious surfaces has become crucial for urban planning, resource management, and environmental protection. However, existing methods face significant challenges handling high-resolution remote sensing images, especially in distinguishing impervious surfaces from regions with complex building structures and similar texture features. These challenges often lead to omission, misclassification, and blurred boundaries, affecting the accuracy and reliability of segmentation results. To address these issues, this study proposes an improved model based on CSW-DeepLabV3+. The model incorporates the cross-shaped window transformer architecture to enable the exchange of information and integration of global features across different scales, enhancing the model's performance in complex scenarios. Additionally, a coordinate attention mechanism is employed to preserve global information while improving the processing of finer details. The experimental results show that the CSW-DeepLabV3+ model not only significantly outperforms existing models such as DeepLabV3+, FCN-8s, U-net, and PSP-net in terms of extraction accuracy but also excels in capturing global information and ensuring edge clarity. The MIoU, OA, Precision, Recall, and F1 scores reached 92.99%, 92.76%, 95.24%, 94.57%, and 94.87%, respectively. Additionally, the model demonstrated excellent computational efficiency and inference speed, providing a more precise tool for urban spatial planning and optimization. Lastly, based on this model's application, a spatiotemporal analysis of impervious surfaces in the Greater Bay Area from 2017 to 2023 was conducted. Results revealed a continuous expansion of impervious surfaces during this period, mainly concentrated in the urban core and surrounding areas, with significant development toward the southeast.",
        "author_keywords": [
            "CSW-DeepLabV3+",
            "deep learning",
            "Greater Pearl River Delta urban cluster",
            "impervious surfaces"
        ],
        "subject_areas": [
            "Computers in Earth Sciences",
            "Atmospheric Science"
        ]
    },
    {
        "title": "GroundUp: Rapid Sketch-Based 3D City Massing",
        "authors": "Ünlü G.E.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-73209-6_13",
        "publication_date": "2025",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210022862",
        "scopus_id": "85210022862",
        "abstract": "We propose GroundUp, the first sketch-based ideation tool for 3D city massing of urban areas. We focus on early-stage urban design, where sketching is a common tool and the design starts from balancing building volumes (masses) and open spaces. With Human-Centered AI in mind, we aim to help architects quickly revise their ideas by easily switching between 2D sketches and 3D models, allowing for smoother iteration and sharing of ideas. Inspired by feedback from architects and existing workflows, our system takes as a first input a user sketch of multiple buildings in a top-down view. The user then draws a perspective sketch of the envisioned site. Our method is designed to exploit the complementarity of information in the two sketches and allows users to quickly preview and adjust the inferred 3D shapes. Our model has two main components. First, we propose a novel sketch-to-depth prediction network for perspective sketches that exploits top-down sketch shapes. Second, we use depth cues derived from the perspective sketch as a condition to our diffusion model, which ultimately completes the geometry in a top-down view. Thus, our final 3D geometry is represented as a heightfield, allowing users to construct the city “from the ground up”. The code, datasets, and interface are available at visual.cs.ucl.ac.uk/pubs/groundup.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "A Hybrid CNN-Transformer Network for Object Detection in Optical Remote Sensing Images: Integrating Local and Global Feature Fusion",
        "authors": "Huang Y.",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "doi": "10.1109/JSTARS.2024.3483253",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85207453637",
        "scopus_id": "85207453637",
        "abstract": "Remote sensing images (RSIs) object detection is important in natural disaster management, urban planning and resource exploration. However, due to the large differences between RSIs and natural images (NIs), most of the existing object detectors for NIs cannot be directly used to process RSIs. Most existing models based on convolutional neural networks (CNNs) require additional design of specific attentional modules to relate small targets in RSIs to global positional relationships. In contrast, transformer-based models had to add modules to obtain more detailed information. This imposes additional computational overheads for deployment on edge devices. To solve the above-mentioned problem, we propose a hybrid CNN and transformer model (DConvTrans-LKA) to enhance the model's ability to acquire features and design a fusion of local and global attention mechanisms to fuse local features and global location information. To better fuse the feature and location information extracted by the model, we introduce a feature residual pyramid network to enhance the model's ability to fuse multiscale feature maps. Finally, we conduct experiments in three representative optical RSI datasets (NWPU VHR-10, HRRSD, and DIOR) to verify the effectiveness of our proposed DConvTrans-LKA method. The experimental results show that our proposed method reaches 61.7%, 82.1%, and 61.3% at mAP at 0.5, respectively, further demonstrating the potential of our proposed method in RSI object detection tasks.",
        "author_keywords": [
            "Convolutional neural networks (CNNs)",
            "feature fusion",
            "local and global attention (LGA)",
            "optical remote sensing images (RSIs)",
            "vision transformer"
        ],
        "subject_areas": [
            "Computers in Earth Sciences",
            "Atmospheric Science"
        ]
    },
    {
        "title": "Building usage prediction in complex urban scenes by fusing text and facade features from street view images using deep learning",
        "authors": "Ramalingam S.P.",
        "journal": "Building and Environment",
        "doi": "10.1016/j.buildenv.2024.112174",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206071722",
        "scopus_id": "85206071722",
        "abstract": "Building usage maps are inputs to many urban planning applications, however, the existing methods and the available data have limitations in generating instance-level high-resolution usage maps. In this study we tackle this problem by utilizing Street View Images (SVIs) and proposing a novel ensemble learning architecture that leverages building facade features and text extracted from hoardings, posters, etc. on buildings to predict the usage class. A pre-trained object detection model i.e., Grounding DINO, is implemented to efficiently identify buildings. A novel manually labeled training data of detected buildings corresponding to their usage is used to extract features from building facades across diverse Indian cities (Hyderabad, Mumbai, Bangalore, Delhi) using Vision Transformer (ViT) model. Following this, CLIPSeg a pre-trained segmentation model is used to recognizes text specifically on building elements like signs, posters, and banners. We then leverage GPT-3.5 Turbo, a Large Language Model (LLM), fine-tuned with a specifically designed few-shot prompting method, to infer building usage from the recognized text. To achieve optimal performance, the proposed ensemble linear metaclassifier combines predictions from ViT and LLM model. The predicted building usages are attributed to their corresponding locations to develop spatial maps. An analysis of our framework compared against ground truth data collected from various Indian cities reveals significantly accurate outcomes. Our findings highlight the utility of textual information in classifying utilities and commercial buildings, while features extracted from vision models prove more informative for residential buildings. Our approach can automate the generation of roadside building attributes and usage details on a larger scale.",
        "author_keywords": [
            "Building text",
            "Building usage map",
            "GIS",
            "LLM",
            "Multi-modal deep learning",
            "Street view image"
        ],
        "subject_areas": [
            "Environmental Engineering",
            "Civil and Structural Engineering",
            "Geography, Planning and Development",
            "Building and Construction"
        ]
    },
    {
        "title": "Multimodal Large Language Models as Built Environment Auditing Tools",
        "authors": "Jang K.M.",
        "journal": "Professional Geographer",
        "doi": "10.1080/00330124.2024.2404894",
        "publication_date": "2025",
        "document_type": "Note",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205928657",
        "scopus_id": "85205928657",
        "abstract": "This research showcases the transformative potential of large language models (LLMs) for built environment auditing from street-view images. By empirically testing the performances of two multimodal LLMs, ChatGPT and Gemini, we confirmed that LLM-based audits strongly agree with virtual audits processed by a conventional deep learning-based method (DeepLabv3+), which has been widely adopted by existing studies on urban visual analytics. Unlike conventional field or virtual audits that require labor-intensive manual inspection or technical expertise to run computer vision algorithms, our results show that LLMs can offer an intuitive tool despite the user’s level of technical proficiency. This would allow a broader range of policy and planning stakeholders to employ LLM-based built environment auditing instruments for smart urban infrastructure management.",
        "author_keywords": [
            "audit",
            "built environment",
            "ChatGPT",
            "Gemini",
            "street-view images"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Earth-Surface Processes"
        ]
    },
    {
        "title": "MSGFormer: Revolutionizing Traffic Flow Prediction With Multiscale and Gated Transformer Architecture",
        "authors": "Li W.",
        "journal": "IEEE Internet of Things Journal",
        "doi": "10.1109/JIOT.2024.3465559",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205021550",
        "scopus_id": "85205021550",
        "abstract": "Traffic flow prediction has emerged as a critical component in advancing smart cities. Nevertheless, precisely forecasting traffic flow remains a formidable challenge, attributable to the intricate and dynamic spatiotemporal interdependencies inherent within traffic data. Contemporary methodologies often overlook the different impacts exerted at each timestamp and treat temporal correlations, rendering them incapable of extracting temporal patterns at multiple scales. Furthermore, these approaches fail to account for the neighboring and functional relationships among nodes within the spatial module. In this work, we introduce an innovative Multiscale and Gated transFormer (MSGFormer) architecture, MSGFormer, to overcome the inherent limitations for accurate traffic flow estimation. We have introduced a multiscale sampling strategy wherein we sample from the original data at three scales: 1) recent; 2) daily; and 3) weekly. This approach enables the generation of corresponding subsequences that encapsulate temporal information across different granularities. Subsequently, each generated subsequence is projected into a latent space and systematically combined with positional, temporal, and spatial embeddings. The positional embedding comprises relative positional embedding and time stamp embedding corresponding to days and weeks, aiming at capturing the sequential and cyclical characteristics of the data. Furthermore, at the inception of the transformer encoder, a gated unit, composed of a neighboring mask and a functioning mask, is employed to capture both static and dynamic spatial correlations effectively. Comprehensive experiments have been conducted on four real-world traffic data sets. The experimental results robustly validate that our model attains significantly higher predictive accuracy in comparison to other baseline models.",
        "author_keywords": [
            "Data mining",
            "gated mechanism",
            "spatiotemporal sequence",
            "traffic flow prediction",
            "transformer"
        ],
        "subject_areas": [
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Deep learning for cross-domain data fusion in urban computing: Taxonomy, advances, and outlook",
        "authors": "Zou X.",
        "journal": "Information Fusion",
        "doi": "10.1016/j.inffus.2024.102606",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200647039",
        "scopus_id": "85200647039",
        "abstract": "As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.",
        "author_keywords": [
            "Data fusion",
            "Deep learning",
            "Large language models",
            "Multi-modal data",
            "Sustainable development",
            "Urban computing"
        ],
        "subject_areas": [
            "Software",
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture"
        ]
    },
    {
        "title": "Generative AI-Driven Semantic Communication Networks: Architecture, Technologies, and Applications",
        "authors": "Liang C.",
        "journal": "IEEE Transactions on Cognitive Communications and Networking",
        "doi": "10.1109/TCCN.2024.3435524",
        "publication_date": "2025",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200237377",
        "scopus_id": "85200237377",
        "abstract": "Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse content intelligently and automatically. To support such artificial intelligence-generated content (AIGC) services, future communication systems must fulfill stringent requirements, including high data rates, throughput, and low latency, while efficiently utilizing limited spectrum resources. Semantic communication (SemCom) has been deemed as a revolutionary communication scheme to tackle this challenge by conveying the meaning of messages instead of bit reproduction. GAI algorithms serve as the foundation for enabling intelligent and efficient SemCom systems in terms of model pre-training and fine-tuning, knowledge base construction, and resource allocation. Conversely, SemCom can provide AIGC services with low latency and high reliability due to its ability to perform semantic-aware encoding and compression of data, as well as knowledge- and context-based reasoning. In this survey, we break new ground by investigating the architecture, wireless communication schemes, and network management of GAI-driven SemCom networks. We first introduce a novel architecture for GAI-driven SemCom networks, comprising the data plane, physical infrastructure, and network control plane. In turn, we provide an in-depth analysis of the transceiver design and semantic effectiveness calculation of end-to-end GAI-driven SemCom systems. Subsequently, we present innovative generation level and knowledge management strategies in the proposed networks, including knowledge construction, update, and sharing, ensuring accurate and timely knowledge-based reasoning. Finally, we explore several promising use cases, i.e., autonomous driving, smart cities, and the Metaverse, to provide a comprehensive understanding and future direction of GAI-driven SemCom networks.",
        "author_keywords": [
            "AIGC",
            "generative AI",
            "intelligent wireless networks",
            "knowledge management",
            "Semantic communication"
        ],
        "subject_areas": [
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction",
        "authors": "Tang P.",
        "journal": "2nd ACM SIGSPATIAL International Workshop on the Human Mobility Prediction Challenge, HuMob-Challenge 2024",
        "doi": "10.1145/3681771.3699908",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215500320",
        "scopus_id": "85215500320",
        "abstract": "Human mobility prediction plays a critical role in applications such as disaster response, urban planning, and epidemic forecasting. Traditional methods often rely on designing crafted, domain-specific models, and typically focus on short-term predictions, which struggle to generalize across diverse urban environments. In this study, we introduce Llama-3-8B-Mob, a large language model fine-tuned with instruction tuning, for long-term citywide mobility prediction—in a Q&A manner. We validate our approach using large-scale human mobility data from four metropolitan areas in Japan, focusing on predicting individual trajectories over the next 15 days. The results demonstrate that Llama-3-8B-Mob excels in modeling long-term human mobility—surpassing the state-of-the-art on multiple prediction metrics. It also displays strong zero-shot generalization capabilities—effectively generalizing to other cities even when fine-tuned only on limited samples from a single city. Source codes are available at https://github.com/TANGHULU6/Llama3-8B-Mob.",
        "author_keywords": [
            "Human Mobility",
            "Large Language Model",
            "Long-term Forecasting",
            "Transfer Learning"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Control and Systems Engineering",
            "Transportation"
        ]
    },
    {
        "title": "Large language model as parking planning agent in the context of mixed period of autonomous vehicles and Human-Driven vehicles",
        "authors": "Jin Y.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2024.105940",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85208127887",
        "scopus_id": "85208127887",
        "abstract": "Autonomous vehicles (AVs) are anticipated to revolutionize future transportation, necessitating updates to traffic infrastructure, particularly parking facilities, due to the unique characteristics of AVs compared to Human-Driven Vehicles (HDVs). During the transition period in which AVs and HDVs coexist, adaptable infrastructure is essential to accommodate both vehicle types. Traditional research, typically reliant on complex mathematical models and simulations, faces challenges in adapting to diverse urban settings, requiring substantial time and resources. To address these challenges, a government-level framework was developed, enabling urban planners to quickly and accurately evaluate and optimize existing parking facilities for future AV and HDV coexistence scenarios. The framework integrates a Large Language Model (LLM) to enhance flexibility and efficiency in parking planning throughout the transitional period. Structured guidance is incorporated to enhance decision-making precision and reduce LLM hallucination risks. The flexibility, robustness, and accuracy of the framework were validated through step-by-step and end-to-end testing using real-world datasets. Specifically, the framework achieved 91.1 % comprehensiveness and 70.2 % consistency in Indicator Selection Module testing, a 68.9 % success rate in the Single Indicator Calculation Module, and a 66.7 % success rate in end-to-end testing, demonstrating its practical value in supporting cities during AV integration. Finally, the success rates of different LLM agent modules were further explored, along with a comparison of multiple LLMs and an analysis of key issues related to LLM trustworthiness in urban planning applications. The research highlights the potential of LLMs in advancing urban planning processes and optimizing existing infrastructure, contributing to smarter and more adaptable urban environments.",
        "author_keywords": [
            "Autonomous vehicles",
            "Large Language Models",
            "Parking facility Planning"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Evaluating a global citizenship course on developing business students' AI literacy skills",
        "authors": "Ching A.C.H.",
        "journal": "Effective Practices in AI Literacy Education: Case Studies and Reflections",
        "doi": "10.1108/978-1-83608-852-320241010",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213116018",
        "scopus_id": "85213116018",
        "abstract": "Nowadays, as organisations and companies increasingly harness the power of artificial intelligence (AI), there is a growing need to ensure future professionals in fields such as business and management can possess relevant necessary knowledge, skills, and mindset for navigating the ethical and social implications of AI technologies. This study evaluated the effects of a specialised AI literacy course designed for business students at a university in Hong Kong. The course aimed to equip participants with a basic understanding of AI concepts via self-paced materials, hands-on activities, case study discussion, and design thinking activities. Through a mixed-methods approach involving evaluation surveys and student and teacher reflections, this case study examined how effectively the course developed the students' AI literacies as future business leaders and global digital citizens. AI competencies include understanding basic AI and generative AI (GenAI), using AI applications ethically, critically analysing AI-powered systems, identifying potential societal risks, and making data-driven decisions while upholding ethical principles. The findings provide valuable insights into the role of targeted AI education in preparing the next generation of business professionals for navigating the evolving data landscape and contributing to the responsible advancement of these transformative technologies.",
        "author_keywords": [
            "AI competency",
            "AI literacy",
            "Business",
            "Digital citizenship",
            "Generative AI",
            "Smart city"
        ],
        "subject_areas": [
            "Social Sciences (all)"
        ]
    },
    {
        "title": "Arabic Opinion Classification of Customer Service Conversations Using Data Augmentation and Artificial Intelligence",
        "authors": "Al-Mutawa R.F.",
        "journal": "Big Data and Cognitive Computing",
        "doi": "10.3390/bdcc8120196",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213437065",
        "scopus_id": "85213437065",
        "abstract": "Customer satisfaction is not just a significant factor but a cornerstone for smart cities and their organizations that offer services to people. It enhances the organization’s reputation and profitability and drastically raises the chances of returning customers. Unfortunately, customer support service through online chat is often not rated by customers to help improve the service. This study employs artificial intelligence and data augmentation to predict customer satisfaction ratings from conversations by analyzing the responses of customers and service providers. For the study, the authors obtained actual conversations between customers and real agents from the call center database of Jeddah Municipality that were rated by customers on a scale of 1–5. They trained and tested five prediction models with approaches based on logistic regression, random forest, and ensemble-based deep learning, and fine-tuned two pre-trained recent models: ArabicT5 and SaudiBERT. Then, they repeated training and testing models after applying a data augmentation technique using the generative artificial intelligence, GPT-4, to improve the unbalance in customer conversation data. The study found that the ensemble-based deep learning approach best predicts the five-, three-, and two-class classifications. Moreover, data augmentation improved accuracy using the ensemble-based deep learning model with a 1.69% increase and the logistic regression model with a 3.84% increase. This study contributes to the advancement of Arabic opinion mining, as it is the first to report the performance of determining customer satisfaction levels using Arabic conversation data. The implications of this study are significant, as the findings can be applied to improve customer service in various organizations.",
        "author_keywords": [
            "Arabic conversation",
            "artificial intelligence",
            "automation",
            "customer satisfaction",
            "data analysis",
            "data augmentation",
            "opinion mining",
            "rating prediction",
            "sentiment analysis",
            "smart cities"
        ],
        "subject_areas": [
            "Management Information Systems",
            "Information Systems",
            "Computer Science Applications",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Integrating Large Language Models and Optimization in Semi- Structured Decision Making: Methodology and a Case Study",
        "authors": "Ghiani G.",
        "journal": "Algorithms",
        "doi": "10.3390/a17120582",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213421656",
        "scopus_id": "85213421656",
        "abstract": "Semi-structured decisions, which fall between highly structured and unstructured decision types, rely on human intuition and experience for the final choice, while using data and analytical models to generate tentative solutions. These processes are traditionally iterative and time-consuming, requiring cycles of data gathering, analysis, and option evaluation. In this study, we propose a novel framework that integrates Large Language Models (LLMs) with optimization techniques to streamline such decision-making processes. In our approach, LLMs leverage their capabilities in data interpretation, common-sense reasoning, and mathematical modeling to assist decision makers by reducing cognitive load. They achieve this by automating aspects of information processing and option evaluation, while preserving human oversight as a crucial component of the final decision-making process. Another significant strength of our framework lies in its potential to drive the evolution of a new generation of decision support systems (DSSs). Unlike traditional systems that rely on rigid and inflexible interfaces, our approach enables users to express their preferences in a more natural, intuitive, and adaptable manner, substantially enhancing both usability and accessibility. A case study on last-mile delivery system design in a smart city demonstrates the practical application of this framework. The results suggest that our approach has the potential to simplify the decision-making process and improve efficiency by reducing cognitive load, enhancing user experience, and facilitating more intuitive interactions.",
        "author_keywords": [
            "human-in-the-loop",
            "knowledge discovery",
            "large language models",
            "last-mile logistics",
            "semi-structured decisions"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Numerical Analysis",
            "Computational Theory and Mathematics",
            "Computational Mathematics"
        ]
    },
    {
        "title": "Investigating the Performance of Open-Vocabulary Classification Algorithms for Pathway and Surface Material Detection in Urban Environments",
        "authors": "de Moraes Vestena K.",
        "journal": "ISPRS International Journal of Geo-Information",
        "doi": "10.3390/ijgi13120422",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213246629",
        "scopus_id": "85213246629",
        "abstract": "Mapping pavement types, especially in sidewalks, is essential for urban planning and mobility studies. Identifying pavement materials is a key factor in assessing mobility, such as walkability and wheelchair usability. However, satellite imagery in this scenario is limited, and in situ mapping can be costly. A promising solution is to extract such geospatial features from street-level imagery. This study explores using open-vocabulary classification algorithms to segment and identify pavement types and surface materials in this scenario. Our approach uses large language models (LLMs) to improve the accuracy of classifying different pavement types. The methodology involves two experiments: the first uses free prompting with random street-view images, employing Grounding Dino and SAM algorithms to assess performance across categories. The second experiment evaluates standardized pavement classification using the Deep Pavements dataset and a fine-tuned CLIP algorithm optimized for detecting OSM-compliant pavement categories. The study presents open resources, such as the Deep Pavements dataset and a fine-tuned CLIP-based model, demonstrating a significant improvement in the true positive rate (TPR) from 56.04% to 93.5%. Our findings highlight both the potential and limitations of current open-vocabulary algorithms and emphasize the importance of diverse training datasets. This study advances urban feature mapping by offering a more intuitive and accurate approach to geospatial data extraction, enhancing urban accessibility and mobility mapping.",
        "author_keywords": [
            "open-vocabulary algorithms",
            "pavement segmentation",
            "street-view imagery",
            "surface material detection",
            "urban mobility"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Integrating Spatiotemporal and Travel-Related Information for Accurate Urban Passenger Profiling Using GANs",
        "authors": "Duan X.",
        "journal": "Land",
        "doi": "10.3390/land13122178",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213227350",
        "scopus_id": "85213227350",
        "abstract": "The elaborate description of passenger travel profiles is of significant importance in urban planning, socioeconomic structural design, and individual travel preference analysis. Traditional models often lack consideration of personalized features and exhibit suboptimal performance in constructing spatiotemporal dependencies. To address these issues, this paper proposes a method that integrates spatiotemporal information with travel-related information and employs generative adversarial networks (GANs) for adversarial training. This method accurately fits the true distribution of user travel data, thereby providing detailed profiles of public transportation passengers’ travel behavior. Specifically, the proposed approach considers the complete travel chain of individuals, establishes a spatiotemporal constraint representation model, and utilizes GANs to simulate the distribution of passenger travel, obtaining more compact and high-level travel vector features. The empirical results demonstrate that the proposed method accurately captures passengers’ travel patterns in both the temporal and spatial dimensions, offering technical support for urban transportation planning.",
        "author_keywords": [
            "adversarial learning",
            "passenger travel profile",
            "smart card data",
            "spatiotemporal dependency relationship",
            "urban sustainable development"
        ],
        "subject_areas": [
            "Global and Planetary Change",
            "Ecology",
            "Nature and Landscape Conservation"
        ]
    },
    {
        "title": "Artificial Intelligence-Enabled Metaverse for Sustainable Smart Cities: Technologies, Applications, Challenges, and Future Directions",
        "authors": "Lifelo Z.",
        "journal": "Electronics (Switzerland)",
        "doi": "10.3390/electronics13244874",
        "publication_date": "2024",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213202921",
        "scopus_id": "85213202921",
        "abstract": "Rapid urbanisation has intensified the need for sustainable solutions to address challenges in urban infrastructure, climate change, and resource constraints. This study reveals that Artificial Intelligence (AI)-enabled metaverse offers transformative potential for developing sustainable smart cities. AI techniques, such as machine learning, deep learning, generative AI (GAI), and large language models (LLMs), enhance the metaverse’s capabilities in data analysis, urban decision making, and personalised user experiences. The study further examines how these advanced AI models facilitate key metaverse technologies such as big data analytics, natural language processing (NLP), computer vision, digital twins, Internet of Things (IoT), Edge AI, and 5G/6G networks. Applications across various smart city domains—environment, mobility, energy, health, governance, and economy, and real-world use cases of virtual cities like Singapore, Seoul, and Lisbon are presented, demonstrating AI’s effectiveness in the metaverse for smart cities. However, AI-enabled metaverse in smart cities presents challenges related to data acquisition and management, privacy, security, interoperability, scalability, and ethical considerations. These challenges’ societal and technological implications are discussed, highlighting the need for robust data governance frameworks and AI ethics guidelines. Future directions emphasise advancing AI model architectures and algorithms, enhancing privacy and security measures, promoting ethical AI practices, addressing performance measures, and fostering stakeholder collaboration. By addressing these challenges, the full potential of AI-enabled metaverse can be harnessed to enhance sustainability, adaptability, and livability in smart cities.",
        "author_keywords": [
            "adaptive urban systems",
            "artificial intelligence",
            "digital twins",
            "generative AI",
            "large language models",
            "metaverse",
            "smart cities",
            "sustainable cities",
            "urban planning",
            "urban transformation"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "SolarGAN for Meso-Level Solar Radiation Prediction at the Urban Scale: A Case Study in Boston",
        "authors": "Lu Y.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs16234524",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85212189872",
        "scopus_id": "85212189872",
        "abstract": "Evaluating solar radiation distribution at the urban scale is crucial for optimizing the placement and size of solar installations and managing urban heat. This study introduces a method for predicting urban solar radiation using 2D mapping data, applying a Generative Adversarial Network (GAN) model to the city of Boston. Traditional solar radiation simulation methods, such as 3D modeling and satellite imagery, require complex and resource-intensive data inputs. In contrast, this research allows open-source 2D urban geographic information—such as building footprints, heights, and terrain—to predict solar radiation at various spatial scales (150 m, 300 m, and 500 m). The GAN model, using detailed 3D urban modeling and simulation results, trained paired datasets of geographic information and solar radiation heatmaps. It achieved high accuracy and resolution, with the 300 m scale model demonstrating the best performance (R2 = 0.864). The model’s capability to generate high-resolution (2 m) solar radiation maps from simplified inputs demonstrates the potential of GANs for urban climate data prediction, offering a rapid and efficient alternative to traditional methods. This approach holds significant potential for urban planning, particularly in optimizing photovoltaic (PV) system layouts and managing the UHI effect.",
        "author_keywords": [
            "Generative Adversarial Network (GAN)",
            "remote sensing data",
            "solar radiation mapping",
            "urban morphology"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "GAN-Based Map Generation Technique of Aerial Image Using Residual Blocks and Canny Edge Detector",
        "authors": "Si J.",
        "journal": "Applied Sciences (Switzerland)",
        "doi": "10.3390/app142310963",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211943280",
        "scopus_id": "85211943280",
        "abstract": "As the significance of meticulous and precise map creation grows in modern Geographic Information Systems (GISs), urban planning, disaster response, and other domains, the necessity for sophisticated map generation technology has become increasingly evident. In response to this demand, this paper puts forward a technique based on Generative Adversarial Networks (GANs) for converting aerial imagery into high-quality maps. The proposed method, comprising a generator and a discriminator, introduces novel strategies to overcome existing challenges; namely, the use of a Canny edge detector and Residual Blocks. The proposed loss function enhances the generator’s performance by assigning greater weight to edge regions using the Canny edge map and eliminating superfluous information. This approach enhances the visual quality of the generated maps and ensures the accurate capture of fine details. The experimental results demonstrate that this method generates maps of superior visual quality, achieving outstanding performance compared to existing methodologies. The results show that the proposed technology has significant potential for practical applications in a range of real-world scenarios.",
        "author_keywords": [
            "aerial image",
            "edge detection",
            "GAN",
            "image-to-image translation",
            "map generation"
        ],
        "subject_areas": [
            "Materials Science (all)",
            "Instrumentation",
            "Engineering (all)",
            "Process Chemistry and Technology",
            "Computer Science Applications",
            "Fluid Flow and Transfer Processes"
        ]
    },
    {
        "title": "Exploring hybrid models for identifying locations for active mobility pathways using real-time spatial Delphi and GANs",
        "authors": "Calleo Y.",
        "journal": "European Transport Research Review",
        "doi": "10.1186/s12544-024-00685-7",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85208942208",
        "scopus_id": "85208942208",
        "abstract": "The spatial planning process is considered an extremely complex system, as it comprises different variables that interrelate and interact with each other. Effectively addressing this spatial complexity necessitates a multidisciplinary approach, as unified methodologies may prove insufficient. Specifically, in urban planning, it is increasingly crucial to prioritize bike lanes, bike stations, and pedestrian zones, for functional transportation infrastructures. This approach can enhance cities by improving air quality, reducing emissions, and boosting public health and safety through physical activity and accident prevention. However, implementing these changes requires careful planning, community engagement, and stakeholder collaboration. This paper proposes a hybrid model for identifying optimal locations for bike lanes, bike stations, and pedestrian zones adopting Real-Time Spatial Delphi and Generative Adversarial Networks (GANs). The Real-Time Spatial Delphi is a modified version of the traditional Delphi method that incorporates real-time feedback and visualization of group response in real-time, aiming to achieve a convergence of opinions among experts on the territory. Nevertheless, these judgments are a spatial representation not visible in reality, and with the spread of artificial intelligence models, different implementations can support the planning process, such as the use of GANs. In this case, GANs can be exploited by adopting pre-existing location images resulting from experts’ judgments to illustrate the proposed intervention’s visual impact. To demonstrate the effectiveness of our hybrid model, we apply it to the city of Dublin. The results showcased how the method helps stakeholders, policymakers, and citizens in visualizing the proposed changes and gauging their potential impact with greater precision.",
        "author_keywords": [
            "Artificial intelligence",
            "Generative adversarial networks",
            "Real-time spatial Delphi",
            "Spatial planning"
        ],
        "subject_areas": [
            "Automotive Engineering",
            "Transportation",
            "Mechanical Engineering"
        ]
    },
    {
        "title": "Integrative Remote Sensing Approaches Using Generative Adversarial Networks for Urban Heat Island Analysis and Mitigation",
        "authors": "Sundar G.",
        "journal": "Remote Sensing in Earth Systems Sciences",
        "doi": "10.1007/s41976-024-00156-6",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85207754175",
        "scopus_id": "85207754175",
        "abstract": "The phenomenon of urban heat islands (UHI) presents a critical challenge for urban sustainability, exacerbating local temperatures, increasing energy demands, and impairing public health. Traditional methods for addressing UHI are often resource-intensive and slow. This study introduces a novel approach, utilizing a Hybrid CycleGAN-SVM (HCGS) model that leverages the synergy of Generative Adversarial Networks (GANs) and Support Vector Machines (SVMs) to efficiently analyze and mitigate UHI effects through high-resolution satellite imagery and temperature data. The model incorporates Enhanced Vision Transformers (EViTs) for superior feature extraction, adept at capturing intricate spatial and spectral urban patterns. The CycleGAN component of the model generates high-quality synthetic imagery, enhancing the dataset and addressing class imbalances, thereby bolstering the SVM classifier’s ability to precisely pinpoint heat-prone urban areas. Implemented in Google Colab, the HCGS model demonstrated exceptional performance, achieving a classification accuracy of 0.98. This indicates its potential as an effective tool for urban heat mitigation, offering actionable insights for urban planning and policy-making. By integrating advanced machine learning techniques with remote sensing data, the HCGS model paves the way for innovative climate adaptation strategies, fostering more sustainable and resilient urban environments.",
        "author_keywords": [
            "Enhanced Vision Transformers",
            "EViTs",
            "GANs",
            "Generative Adversarial Networks",
            "HCGS model",
            "Hybrid CycleGAN-SVM",
            "Satellite imagery",
            "Support Vector Machines",
            "SVM",
            "UHI effect",
            "Urban heat island"
        ],
        "subject_areas": [
            "Oceanography",
            "Geography, Planning and Development",
            "Computers in Earth Sciences",
            "Atmospheric Science",
            "Space and Planetary Science",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Deep-learning-based point cloud completion methods: A review",
        "authors": "Zhang K.",
        "journal": "Graphical Models",
        "doi": "10.1016/j.gmod.2024.101233",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205418465",
        "scopus_id": "85205418465",
        "abstract": "Point cloud completion aims to utilize algorithms to repair missing parts in 3D data for high-quality point clouds. This technology is crucial for applications such as autonomous driving and urban planning. With deep learning's progress, the robustness and accuracy of point cloud completion have improved significantly. However, the quality of completed point clouds requires further enhancement to satisfy practical requirements. In this study, we conducted an extensive survey of point cloud completion methods, with the following main objectives: (i) We classified point cloud completion methods into categories based on their principles, such as point-based, convolution-based, GAN-based, and geometry-based methods, and thoroughly investigated the advantages and limitations of each category. (ii) We collected publicly available datasets for point cloud completion algorithms and conducted experimental comparisons using various typical deep-learning networks to draw conclusions. (iii) With our research in this paper, we discuss future research trends in this rapidly evolving field.",
        "author_keywords": [
            "3D object geometry",
            "3D vision",
            "Deep learning",
            "Point cloud completion"
        ],
        "subject_areas": [
            "Software",
            "Modeling and Simulation",
            "Geometry and Topology",
            "Computer Graphics and Computer-Aided Design"
        ]
    },
    {
        "title": "Transforming satellite imagery into vector maps using modified GANs",
        "authors": "Taparia A.",
        "journal": "Alexandria Engineering Journal",
        "doi": "10.1016/j.aej.2024.09.074",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205235513",
        "scopus_id": "85205235513",
        "abstract": "Vector maps find widespread utility across diverse domains due to their capacity to not only store but also represent discrete data boundaries such as building footprints, disaster impact analysis, digitization, urban planning, location points, transport links, and more. Although extensive research exists on identifying building footprints and road types from satellite imagery, the generation of vector maps from such imagery remains an area with limited exploration. Furthermore, conventional map generation techniques rely on labor-intensive manual feature extraction or rule-based approaches, which impose inherent limitations. To surmount these limitations, we propose a novel method called HPix, which utilizes modified Generative Adversarial Networks (GANs) to generate vector tile map from satellite images. HPix incorporates two hierarchical frameworks: one operating at the global level and the other at the local level, resulting in a comprehensive model. Through empirical evaluations, our proposed approach showcases its effectiveness in producing highly accurate and visually captivating vector tile maps derived from satellite images. We achieved a pixel-level accuracy of 61.04% and an SSIM score of 0.75, outperforming all other existing methods. We further extend our study's application to include mapping of road intersections and building footprints cluster based on their area. We also show usability of our proposed architecture as a general-purpose solutions in other tasks like edges-to-photo, BW-to-color, or labels-to-street scene. GitHub: https://github.com/aditya-taparia/Satellite-Image-to-Vector-Map.",
        "author_keywords": [
            "Building footprint clustering",
            "Generative adversarial networks",
            "Hierarchical feature learning",
            "Image-to-image translation",
            "Road intersections mapping"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Integrating IoT and visual question answering in smart cities: Enhancing educational outcomes",
        "authors": "Gao T.",
        "journal": "Alexandria Engineering Journal",
        "doi": "10.1016/j.aej.2024.09.059",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85204777919",
        "scopus_id": "85204777919",
        "abstract": "Emerging as a paradigmatic shift in urban development, smart cities harness the potential of advanced information and communication technologies to seamlessly integrate urban functions, optimize resource allocation, and improve the effectiveness of city management. Within the domain of smart education, the imperative application of Visual Question Answering (VQA) technology encounters significant limitations at the prevailing stage, particularly the absence of a robust Internet of Things (IoT) framework and the inadequate incorporation of large pre-trained language models (LLMs) within contemporary smart education paradigms, especially in addressing zero-shot VQA scenarios, which pose considerable challenges. In response to these constraints, this paper introduces an IoT-based smart city framework that is designed to refine the functionality and efficacy of educational systems. This framework is delineated into four cardinal layers: the data collection layer, data transmission layer, data management layer, and application layer. Furthermore, we introduce the innovative TeachVQA methodology at the application layer, synergizing VQA technology with extensive pre-trained language models, thereby considerably enhancing the dissemination and assimilation of educational content. Evaluative metrics in the VQAv2 and OKVQA datasets substantiate that the TeachVQA methodology not only outperforms existing VQA approaches, but also underscores its profound potential and practical relevance in the educational sector.",
        "author_keywords": [
            "IoT framework",
            "Large language models",
            "Smart cities",
            "Smart education technology",
            "Visual question answering"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "CERN for AI: a theoretical framework for autonomous simulation-based artificial intelligence testing and alignment",
        "authors": "Bojić L.",
        "journal": "European Journal of Futures Research",
        "doi": "10.1186/s40309-024-00238-0",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201949790",
        "scopus_id": "85201949790",
        "abstract": "This paper explores the potential of a multidisciplinary approach to testing and aligning artificial intelligence (AI), specifically focusing on large language models (LLMs). Due to the rapid development and wide application of LLMs, challenges such as ethical alignment, controllability, and predictability of these models emerged as global risks. This study investigates an innovative simulation-based multi-agent system within a virtual reality framework that replicates the real-world environment. The framework is populated by automated 'digital citizens,' simulating complex social structures and interactions to examine and optimize AI. Application of various theories from the fields of sociology, social psychology, computer science, physics, biology, and economics demonstrates the possibility of a more human-aligned and socially responsible AI. The purpose of such a digital environment is to provide a dynamic platform where advanced AI agents can interact and make independent decisions, thereby mimicking realistic scenarios. The actors in this digital city, operated by the LLMs, serve as the primary agents, exhibiting high degrees of autonomy. While this approach shows immense potential, there are notable challenges and limitations, most significantly the unpredictable nature of real-world social dynamics. This research endeavors to contribute to the development and refinement of AI, emphasizing the integration of social, ethical, and theoretical dimensions for future research.",
        "author_keywords": [
            "AI Alignment",
            "Autonomy in AI",
            "Digital City Simulation",
            "Social Science in Artificial Intelligence",
            "Theoretical Framework"
        ],
        "subject_areas": [
            "Sociology and Political Science",
            "Social Sciences (miscellaneous)",
            "Economics, Econometrics and Finance (miscellaneous)",
            "Tourism, Leisure and Hospitality Management",
            "Management of Technology and Innovation"
        ]
    },
    {
        "title": "A method to promote safe cycling powered by large language models and AI agents",
        "authors": "Costa D.G.",
        "journal": "MethodsX",
        "doi": "10.1016/j.mex.2024.102880",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200231800",
        "scopus_id": "85200231800",
        "abstract": "This paper presents a novel information generation methodology to support safer cycling patterns in urban environments, leveraging for that Large Language Models (LLMs), AI-based agents, and open geospatial data. By processing multiple files containing previously computed urban risk levels and existing mobility infrastructure, which are generated by exploiting open data sources, our method exploits multi-layer data preprocessing procedures and prompt engineering to create easy-to-use, user-friendly assistive systems that are able to provide useful information concerning cycling safety. Through a well-defined processing pipeline based on Data Ingestion and Preparation, Agents Orchestration, and Decision Execution methodological steps, our method shows how to integrate open-source tools and datasets, ensuring reproducibility and accessibility for urban planners and cyclists. Moreover, an AI agent is also provided, which fully implements our method and acts as a proof-of-concept implementation. This paper demonstrates the effectiveness of our method in enhancing cycling safety and urban mobility planning. • A novel method that combines LLMs and AI agents is defined to enhance the processing of multi-domain open geospatial data, potentially promoting cycling safety. • It integrates urban risk data and cycling infrastructure for a more comprehensive understanding of cycling resources, which become accessible by textual or audio prompts.",
        "author_keywords": [
            "Artificial Intelligence",
            "Open data",
            "Smart cities",
            "Urban mobility"
        ],
        "subject_areas": [
            "Clinical Biochemistry",
            "Medical Laboratory Technology"
        ]
    },
    {
        "title": "Enhanced botnet detection in IoT networks using zebra optimization and dual-channel GAN classification",
        "authors": "Shareef S.K.",
        "journal": "Scientific Reports",
        "doi": "10.1038/s41598-024-67865-2",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85199805500",
        "scopus_id": "85199805500",
        "abstract": "The Internet of Things (IoT) permeates various sectors, including healthcare, smart cities, and agriculture, alongside critical infrastructure management. However, its susceptibility to malware due to limited processing power and security protocols poses significant challenges. Traditional antimalware solutions fall short in combating evolving threats. To address this, the research work developed a feature selection-based classification model. At first stage, a preprocessing stage enhances dataset quality through data smoothing and consistency improvement. Feature selection via the Zebra Optimization Algorithm (ZOA) reduces dimensionality, while a classification phase integrates the Graph Attention Network (GAN), specifically the Dual-channel GAN (DGAN). DGAN incorporates Node Attention Networks and Semantic Attention Networks to capture intricate IoT device interactions and detect anomalous behaviors like botnet activity. The model's accuracy is further boosted by leveraging both structural and semantic data with the Sooty Tern Optimization Algorithm (STOA) for hyperparameter tuning. The proposed STOA-DGAN model achieves an impressive 99.87% accuracy in botnet activity classification, showcasing robustness and reliability compared to existing approaches.",
        "author_keywords": [
            "Graph attention network",
            "Internet of things",
            "Node attention networks",
            "Sooty Tern optimization algorithm",
            "Zebra optimization algorithm"
        ],
        "subject_areas": [
            "Multidisciplinary"
        ]
    },
    {
        "title": "Land Value, and Urban Transport and Amenities: Evidence From Antananarivo, Madagascar",
        "authors": "Iimi A.",
        "journal": "Developing Economies",
        "doi": "10.1111/deve.12415",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85199112668",
        "scopus_id": "85199112668",
        "abstract": "Although urbanization is an engine of growth, many African cities are overly crowded with massive traffic congestion and high housing prices, pushing the poor away to unfavorable settlements or remote suburban areas and making them commute long. The paper sheds light on the relationship between land value and urban attributes in a rapidly growing African city, Antananarivo, Madagascar. It shows that the land value gradient is steep with an elasticity of −0.78 with respect to trip time to the city center. Thus, housing prices are overshooting. Better urban planning is needed through improving transport accessibility by minibus. Other urban infrastructure services, such as piped water and garbage collection, and urban amenities are also important to add to land values. Spatial heterogeneity is found across different locations in the city. While some areas require clean water and climate resilience, others need more city amenities, such as parks.",
        "author_keywords": [
            "Land price gradient",
            "Madagascar",
            "Spatial autoregressive model"
        ],
        "subject_areas": [
            "Development",
            "Economics and Econometrics"
        ]
    },
    {
        "title": "A deep learning approach for prediction of air quality index in smart city",
        "authors": "Binbusayyis A.",
        "journal": "Discover Sustainability",
        "doi": "10.1007/s43621-024-00272-9",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85193055112",
        "scopus_id": "85193055112",
        "abstract": "Industrial developments and consumption of massive amount of fossil fuels, vehicle pollution, and other calamities upsurges the AQI (Air Quality Index) of major cities in a drastic manner. Owing to these factors, it is important to take proactive measures for reducing the air pollution in order to avoid life- threatening consequence. Therefore, prediction of air quality is significant for improving the health of living beings as highly polluted regions have a higher concentration of pollutants mixed in the air, affecting the respiratory system and reducing the lifetime. To control pollution, AQI is used as a measure for estimating the pollutant content in the air. Even though many existing techniques have predicted AQI, enhancement is required in prediction algorithms with minimized loss. To address the challenges in traditional algorithms, the proposed smart cities-based AQI prediction intends to utilize the proposed regression algorithm in the dataset, namely Air- Quality-Data, which collected harmful pollutants on an hourly and daily basis from multiple cities in India between 2015 to 2020. To achieve prediction efficiency with reduced loss, pre-processing of input data is being performed using Deep GAN (Generative Adversarial Network). It performs the imputation of data in place of missing values to improve accurate prediction. Additionally, feature scaling normalizes independent real-data features to a fixed scale. With the processed data, regression is done through modified Stacked Attention GRU with KL divergence, which predicts Ernakulam, Chennai and Ahmedabad cities with higher, medium, and low levels of AQI in India. The performance of the proposed regression algorithm is measured using metrics such as MAE (Mean Absolute Error), MSE (Mean Square Error), R2 (Coefficient of determination), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Square Error) and better MAE, MSE, R2, MAPE and RMSE obtained by the model is 0.1013, 0.0134, 0.9479, 0.1152 and 0.1156. Internal assessment and comparative analysis performed with existing regression algorithms exhibit lower loss values obtained from the present research, which determines the efficacy of the proposed model.",
        "author_keywords": [
            "Ahmedabad",
            "Air quality index",
            "Chennai",
            "Deep generative adversarial network",
            "Ernakulam",
            "Modified stacked attention GRU",
            "Pollutants",
            "Regression"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Environmental Science (miscellaneous)",
            "Energy (miscellaneous)"
        ]
    },
    {
        "title": "Digitizing cities for urban weather: representing realistic cities for weather and climate simulations using computer graphics and artificial intelligence",
        "authors": "Aliaga D.",
        "journal": "Computational Urban Science",
        "doi": "10.1007/s43762-023-00111-z",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85187896705",
        "scopus_id": "85187896705",
        "abstract": "Due to their importance in weather and climate assessments, there is significant interest to represent cities in numerical prediction models. However, getting high resolution multi-faceted data about a city has been a challenge. Further, even when the data were available the integration into a model is even more of a challenge due to the parametric needs, and the data volumes. Further, even if this is achieved, the cities themselves continually evolve rendering the data obsolete, thus necessitating a fast and repeatable data capture mechanism. We have shown that by using AI/graphics community advances we can create a seamless opportunity for high resolution models. Instead of assuming every physical and behavioral detail is sensed, a generative and procedural approach seeks to computationally infer a fully detailed 3D fit-for-purpose model of an urban space. We present a perspective building on recent success results of this generative approach applied to urban design and planning at different scales, for different components of the urban landscape, and related applications. The opportunities now possible with such a generative model for urban modeling open a wide range of opportunities as this becomes mainstream.",
        "author_keywords": [
            "Artificial intelligence",
            "Generative AI",
            "Urban computational science",
            "Urban modeling"
        ],
        "subject_areas": [
            "Urban Studies",
            "Environmental Science (miscellaneous)",
            "Artificial Intelligence",
            "Computer Science Applications"
        ]
    },
    {
        "title": "Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models",
        "authors": "Han B.",
        "journal": "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
        "doi": "10.1145/3678717.3691296",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215132750",
        "scopus_id": "85215132750",
        "abstract": "Equitable urban transportation applications require high-fidelity digital representations of the built environment (streets, crossings, curb ramps and more). Direct inspections and manual annotations are costly at scale, while conventional machine learning methods require substantial annotated training data for adequate performance. This study explores vision language models as a tool for annotating diverse urban features from satellite images, reducing the dependence on human annotation. Although these models excel at describing common objects in human-centric images, their training sets may lack signals for esoteric built environment features, making their performance uncertain. We demonstrate a proof-of-concept using a vision language model and a visual prompting strategy that considers segmented image elements. Experiments on two urban features - stop lines and raised tables - show that while zero-shot prompting rarely works, the segmentation and visual prompting strategies achieve nearly 40% intersection-over-union accuracy. We describe how these results motivate further research in automatic annotation of the built environment to improve equity, accessibility, and safety at scale and in diverse environments.",
        "author_keywords": [
            "Image Segmentation",
            "Large Language Model",
            "Urban Computing",
            "Urban Data Annotation",
            "Vision Language Model"
        ],
        "subject_areas": [
            "Information Systems",
            "Earth-Surface Processes",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Computer Science Applications"
        ]
    },
    {
        "title": "Harnessing LLMs for Cross-City OD Flow Prediction",
        "authors": "Yu C.",
        "journal": "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
        "doi": "10.1145/3678717.3691308",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215081956",
        "scopus_id": "85215081956",
        "abstract": "Understanding and predicting Origin-Destination (OD) flows is crucial for urban planning and transportation management. Traditional OD prediction models, while effective within single cities, often face limitations when applied across different cities due to varied traffic conditions, urban layouts, and socio-economic factors. In this paper, by employing Large Language Models (LLMs), we introduce a new method for cross-city OD flow prediction. Our approach leverages the advanced semantic understanding and contextual learning capabilities of LLMs to bridge the gap between cities with different characteristics, providing a robust and adaptable solution for accurate OD flow prediction that can be transferred from one city to another. Our novel framework involves four major components: collecting OD training datasets from a source city, instruction-tuning the LLMs, predicting destination POIs in a target city, and identifying the locations that best match the predicted destination POIs. We introduce a new loss function that integrates POI semantics and trip distance during training. By extracting high-quality semantic features from human mobility and POI data, the model understands spatial and functional relationships within urban spaces and captures interactions between individuals and various POIs. Extensive experimental results demonstrate the superiority of our approach over the state-of-the-art learning-based methods in cross-city OD flow prediction.",
        "author_keywords": [
            "Cross-City Transferability",
            "Large Language Models(LLMs)",
            "origin-destination",
            "Urban Computing"
        ],
        "subject_areas": [
            "Information Systems",
            "Earth-Surface Processes",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Computer Science Applications"
        ]
    },
    {
        "title": "MobGLM: A Large Language Model for Synthetic Human Mobility Generation",
        "authors": "Zhang K.",
        "journal": "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
        "doi": "10.1145/3678717.3691311",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215078760",
        "scopus_id": "85215078760",
        "abstract": "Human mobility generation plays a critical role in urban transportation planning. Existing human mobility generation models often fall short of understanding travelers’ demographics and integrating multimodal information, including activity purposes, destination choices and transport mode preferences. Recently, mobility generation models leveraging Large Language Models (LLMs) have gained significant attention, while they are limited in directly reproducing spatial information in human mobility profiles. To address these challenges, this paper proposes the Mobility Generative Language Model (MobGLM), a novel approach for generating synthetic human mobility data to support urban planning, transport management, energy consumption and epidemic control. MobGLM addresses these limitations by capturing the complex relationships between agents’ mobility patterns and individual demographics. By incorporating personal information, activity types, locations and traffic modes as encoders, MobGLM uniquely identifies and replicates features of human mobility. Our framework is evaluated using a large, real-world mobility dataset and benchmarked against state-of-the-art personal mobility generation techniques. The results demonstrate the effectiveness of MobGLM in producing accurate and reliable synthetic mobility data, highlighting its potential applications in various urban mobility contexts.",
        "author_keywords": [
            "Human Mobility",
            "Logit Adjustment",
            "NLP",
            "Non-Daily Activity",
            "Sequence Generation",
            "Transformer"
        ],
        "subject_areas": [
            "Information Systems",
            "Earth-Surface Processes",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Computer Science Applications"
        ]
    },
    {
        "title": "Automating Geospatial Analysis Workflows Using ChatGPT-4",
        "authors": "Zhang Q.",
        "journal": "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
        "doi": "10.1145/3678717.3695760",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215072983",
        "scopus_id": "85215072983",
        "abstract": "The field of Geospatial Artificial Intelligence (GeoAI) has significantly impacted domain applications such as urban analytics, environmental monitoring, and disaster management. While powerful geoprocessing tools in geographic information systems (GIS) like ArcGIS Pro are available, automating these workflows with Python scripting using AI chatbots remains a challenge, especially for non-expert users. This study investigates whether ChatGPT-4 can automate GIS workflows by generating ArcPy functions based on structured instructions. We tested prompt engineering’s ability on helping large language models (LLMs) understand spatial data and GIS workflows. The overall task success rate reaches 80.5%. It is a valid and easy to implement approach for domain scientists who want to use ArcPy to automate their workflows.",
        "author_keywords": [
            "automate workflow",
            "GeoAI",
            "GIS",
            "LLM",
            "Prompt engineering"
        ],
        "subject_areas": [
            "Information Systems",
            "Earth-Surface Processes",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Computer Science Applications"
        ]
    },
    {
        "title": "From Geolocated Images to Urban Region Identification and Description: a Large Language Model Approach",
        "authors": "Rocchietti G.",
        "journal": "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
        "doi": "10.1145/3678717.3691317",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215067432",
        "scopus_id": "85215067432",
        "abstract": "Urban research faces challenges in understanding and describing city regions, which are essential for urban planning and tourism management. Traditional methods rely on predefined areas and non-human-readable representations. This paper presents a new unsupervised approach that overcomes these limitations using a data-driven method with Instruction-tuned Large Language Models (ILLMs). Our technique dynamically identifies urban regions with similar features and generates human-readable descriptions. We validate this method using Flickr images from Pisa, Italy, and our results show that it effectively captures the semantic features of urban regions and generates comprehensible textual descriptions.",
        "author_keywords": [
            "Image Captioning",
            "Large Language Models",
            "Sum-marization",
            "Urban Regions"
        ],
        "subject_areas": [
            "Information Systems",
            "Earth-Surface Processes",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Computer Science Applications"
        ]
    },
    {
        "title": "TrajGPT: Controlled Synthetic Trajectory Generation Using a Multitask Transformer-Based Spatiotemporal Model",
        "authors": "Hsu S.L.",
        "journal": "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
        "doi": "10.1145/3678717.3691303",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85212339706",
        "scopus_id": "85212339706",
        "abstract": "Human mobility modeling from GPS-trajectories and synthetic trajectory generation are crucial for various applications, such as urban planning, disaster management and epidemiology. Both of these tasks often require filling gaps in a partially specified sequence of visits, - a new problem that we call “controlled” synthetic trajectory generation. Existing methods for next-location prediction or synthetic trajectory generation cannot solve this problem as they lack the mechanisms needed to constrain the generated sequences of visits. Moreover, existing approaches (1) frequently treat space and time as independent factors, an assumption that fails to hold true in real-world scenarios, and (2) suffer from challenges in accuracy of temporal prediction as they fail to deal with mixed distributions and the inter-relationships of different modes with latent variables (e.g., day-of-the-week). These limitations become even more pronounced when the task involves filling gaps within sequences instead of solely predicting the next visit. We introduce TrajGPT, a transformer-based, multi-task, joint spatiotemporal generative model to address these issues. Taking inspiration from large language models, TrajGPT poses the problem of controlled trajectory generation as that of text infilling in natural language. TrajGPT integrates the spatial and temporal models in a transformer architecture through a Bayesian probability model that ensures that the gaps in a visit sequence are filled in a spatiotemporally consistent manner. Our experiments on public and private datasets demonstrate that TrajGPT not only excels in controlled synthetic visit generation but also outperforms competing models in next-location prediction tasks-Relatively, TrajGPT achieves a 26-fold improvement in temporal accuracy while retaining more than 98% of spatial accuracy on average.",
        "author_keywords": [
            "human mobility modeling",
            "Spatiotemporal modeling",
            "Synthetic Trajectory generation",
            "Transformers"
        ],
        "subject_areas": [
            "Information Systems",
            "Earth-Surface Processes",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Computer Science Applications"
        ]
    },
    {
        "title": "User generated content intelligent analysis for urban natural gas with transformer-based cyber-physical social systems",
        "authors": "Wang S.",
        "journal": "Applied Energy",
        "doi": "10.1016/j.apenergy.2024.123947",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200343281",
        "scopus_id": "85200343281",
        "abstract": "Intelligent analysis of user generated content (UGC) plays an important role in ensuring urban natural gas safety and controlling process risks. However, most existing analysis methods are single-task driven and ignore the spatio-temporal information of gas sensing data. To address these problems, we propose a Transformer-based cyber-physical social security system (CPSS) for UGC analysis. Specifically, this unified system integrates multiple tasks, i.e. quality assessment and control of gas data, security factors of user consumption, and spatio-temporal abnormal gas signal detection. In the developed Transformer-based model, a time-space cross-attention module is embedded for combining the long-range spatio-temporal dependences of gas data. Moreover, a feature memory block module is introduced for abnormal feature enhancement and high-level representation of gas quality. Experimental results on related gas datasets demonstrate that this Transformer-based method achieves state-of-the-art performance, and the security system significantly improves the safety factor of natural gas use in smart cities, providing a robust framework for risk management and safety enhancement.",
        "author_keywords": [
            "CPSS",
            "Security system",
            "Transformer",
            "Urban natural gas",
            "User generated content"
        ],
        "subject_areas": [
            "Building and Construction",
            "Renewable Energy, Sustainability and the Environment",
            "Mechanical Engineering",
            "Energy (all)",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Improving change detection performance with generative-adversarial augmentation of dataset",
        "authors": "Knyaz V.A.",
        "journal": "International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",
        "doi": "10.5194/isprs-archives-XLVIII-3-2024-265-2024",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213318752",
        "scopus_id": "85213318752",
        "abstract": "The relevance of maps is a prerequisite for most geospatial applications such as navigation, urban planning, cadastre updating, etc. The main source of information used for maps updating is remote sensing, and the progress in sensors and methods of data analysis allows automatically retrieving the changes in observed scene from multi-time image series. Nowadays unmanned aerial vehicles (UAV) became a readily available and power mean for acquiring aerial images of a given territory. But solving change detection task using UAV-acquired images has some additional specificity, caused by additional disturbing specifics. This study addresses the problem of improving change detection performance in UAV-acquired imagery. The proposed approach firstly provide accurate image registration based on orthophoto generation, and then uses special technique for augmentation of data, that allows to improve the performance of the network model for change detection. The evaluation of the developed framework on the collected UAV-acquired multi-temporary image dataset has demonstrated change detection improving.",
        "author_keywords": [
            "Change detection",
            "generative adversarial learning",
            "maps updating",
            "neural networks",
            "unmanned aerial vehicle"
        ],
        "subject_areas": [
            "Information Systems",
            "Geography, Planning and Development"
        ]
    },
    {
        "title": "Relationship Between Space Environment Factors and Land Surface Temperature in the Main Urban Area of Fuzhou Under the National Land and Spatial Planning System",
        "authors": "Liu Z.",
        "journal": "Journal of Geo-Information Science",
        "doi": "10.12082/dqxxkx.2024.240354",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210307782",
        "scopus_id": "85210307782",
        "abstract": "Urban construction land is categorized into different types in the overall planning of territorial space. Research on the relationship between spatial environment elements and Land Surface Temperature (LST) across various land types can provide a planning and management basis for ecological city construction. This paper focuses on the main urban area of Fuzhou and references the land classification system for territorial spatial planning published by the Ministry of Natural Resources in November 2023. Based on the urban road network and high-resolution remote sensing images, different types of construction land in Fuzhou, including residential land, public management and public service land, commercial service land, mixed commercial and residential land, industrial land, and green land and open space land, were identified. Landsat-8 remote sensing data and building vector data were used to calculate LST during summer and winter, as well as to gather spatial environment factor information (NDVI, NDISI, BCR, BH, BSD, SVF) for different land types. Finally, after analyzing the seasonal LST characteristics and spatial environment factors of various land types, spatial autocorrelation analysis and spatial autoregression model were used to explore the spatial relationship between these factors and seasonal LST. The results show that: (1) In summer, the average LST values for various land types are ranked as follows: Industrial land (40.38 ℃) > Public administration and public service land (38.28 ℃) > Commercial service land (38.25 ℃) > mixed commercial and residential land (37.87 ℃) > residential land (37.52 ℃) > green land and open space land (35.71 ℃). In winter, the ranking is: industrial land (18.32 ℃) > public administration and public service land (17.99 ℃) > commercial service land (17.93 ℃) > residential land (16.92 ℃) > mixed commercial and residential land (16.15 ℃) > green and open space land (15.79 ℃). (2) The correlation and influence of spatial environment elements on seasonal LST vary across different urban construction land types. In both summer and winter, BH and BSD are negatively correlated with urban land use LST, while NDISI, BCR, and SVF show positive correlations with LST. However, NDVI is negatively correlated with the LST of residential land and public administration and public service land during summer, with spatial error coefficients of -3.653 and -2.496, respectively, but shows a positive correlation in winter, with spatial error coefficients of 3.767 and 2.507, respectively.",
        "author_keywords": [
            "Land Surface Temperature (LST)",
            "national land and spatial planning",
            "seasonal differences",
            "spatial autocorrelation",
            "spatial autoregressive model",
            "spatial environment elements",
            "the main urban area of Fuzhou",
            "urban land use"
        ],
        "subject_areas": [
            "Information Systems",
            "Computer Science Applications",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Leveraging Multi-Source Data for the Trustworthy Evaluation of the Vibrancy of Child-Friendly Cities: A Case Study of Tianjin, China",
        "authors": "Zhang D.",
        "journal": "Electronics (Switzerland)",
        "doi": "10.3390/electronics13224564",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210296341",
        "scopus_id": "85210296341",
        "abstract": "The vitality of a city is shaped by its social structure, environmental quality, and spatial form, with child-friendliness being an essential component of urban vitality. While there are numerous qualitative studies on the relationship between child-friendliness and various indicators of urban vitality, quantitative research remains relatively scarce, leading to a lack of sufficient objective and trustworthy data to guide urban planning and the development of child-friendly cities. This paper presents an analytical framework, using Heping District in Tianjin, China, as a case study. It defines four main indicators—social vitality, environmental vitality, spatial vitality, and urban scene perception—for a trustworthy and transparent quantitative evaluation. The study integrates multi-source data, including primary education (POI) data, street view image (SVI) data, spatiotemporal big data, normalized difference vegetation index (NDVI), and large visual language models (LVLMs) for the trustworthy analysis. These data are visualized using corresponding big data and weighted analysis methods, ensuring transparent and accurate assessments of the child-friendliness of urban blocks. This research introduces an innovative and trustworthy method for evaluating the child-friendliness of urban blocks, addressing gaps in the quantitative theory of child-friendliness in urban planning. It also provides a practical and reliable tool for urban planners, offering a solid theoretical foundation to create environments that better meet the needs of children in a trustworthy manner.",
        "author_keywords": [
            "child-friendly",
            "multi-source data",
            "urban analysis",
            "urban vitality",
            "vision large language models"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "AI-Enhanced Strategies to Ensure New Sustainable Destination Tourism Trends Among the 27 European Union Member States",
        "authors": "Pinho M.",
        "journal": "Sustainability (Switzerland)",
        "doi": "10.3390/su16229844",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210267093",
        "scopus_id": "85210267093",
        "abstract": "The United Nations 2030 Agenda defines the priorities and aspirations for global development based on seventeen ambitious sustainable development goals encompassing economic, environmental, and social dimensions. Tourism plays a vital role in the list of actions for the people and the planet. While the tourism industry drives economic growth, its environmental and social impact is equally high. Sustainable tourism aims to reduce the damage caused by the tourism industry, protect communities, and guarantee the industry’s long-term future. These changes require tourists’ collective and concerted effort. The question arises whether tourists are willing to be more demanding about sustainability when looking for a destination. This study uses artificial intelligence to classify a new trend in European citizens’ search for sustainable destinations and to generate intelligent recommendations. Using data from the Flash Eurobarometer 499, we use a tree-based algorithm, random forest, to obtain intelligent citizens classification systems supported by machine learning. The classification system explores the predisposition of citizens to contribute to the three pillars of sustainability when choosing a destination to visit based on gender, age, and the region of living. We found that European citizens place little emphasis on the social sustainability pillar. While they care about preserving the environment, this competes with the cultural offerings and availability of activities at the destination. Additionally, we found that the willingness to contribute to the three pillars of sustainability varies by gender, age, and European region.",
        "author_keywords": [
            "economic sustainability",
            "environmental sustainability",
            "generative artificial intelligence",
            "machine learning",
            "social sustainability",
            "sustainable destinations",
            "sustainable development",
            "tourism sustainability"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Environmental Science (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Spatial–Temporal Similarity Fusion Graph Adversarial Convolutional Networks for traffic flow forecasting",
        "authors": "Wang B.",
        "journal": "Journal of the Franklin Institute",
        "doi": "10.1016/j.jfranklin.2024.107299",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205570650",
        "scopus_id": "85205570650",
        "abstract": "Traffic flow forecasting is integral to the advancement of intelligent transportation systems and the development of smart cities. This paper introduces a novel model, the Spatial–Temporal Similarity Fusion Graphs Adversarial Convolutional Networks (STSF-GACN), which leverages advanced data preprocessing techniques to enhance the predictive accuracy and efficiency of traffic flow forecasting. The innovation of our approach lies in the meticulous construction of the spatial–temporal similarity matrix through the precise calculation of temporal and spatial similarities. This matrix forms the backbone of our model, serving as the generator in the integrated Generative Adversarial Network (GAN) architecture. The Spatial–Temporal Similarity Fusion Adaptive Graph Convolutional Network, developed as part of our GAN's generator, utilizes cutting-edge techniques such as the Wasserstein distance and Dynamic Time Warping to optimize the adaptive adjacency matrix, enabling the model to capture latent spatial–temporal correlations with unprecedented depth and precision. The discriminator of the GAN further refines the model by evaluating the accuracy of the traffic predictions, ensuring that the generative model produces results that are not only accurate but also robust against varying traffic conditions. This cohesive integration of GAN into the model architecture allows for a significant improvement in prediction accuracy and convergence speed, moving beyond traditional forecasting methods.",
        "author_keywords": [
            "Graph Convolutional Neural Network",
            "Similarity measure",
            "Traffic flow forecasting"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications",
            "Applied Mathematics"
        ]
    },
    {
        "title": "Climate-responsive urban planning through generative models: Sensitivity analysis of urban planning and design parameters for urban heat island in Singapore's residential settlements",
        "authors": "Aydin E.E.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2024.105779",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203014626",
        "scopus_id": "85203014626",
        "abstract": "The Urban Heat Island (UHI) effect exacerbates the sustainability and well-being challenges of extreme heat events. While city planning and design measures have been shown to mitigate UHI severity, the complex interaction among these measures has limited the ability of previous research to assess their impact holistically and across urban scales. To investigate the cross-scalar effectiveness of multiple UHI mitigation measures, this study applies sensitivity analysis (SA) to nine parameters in an urban generative model. Previously unstudied planning parameters, land parcel area and road network density, are included in the analysis. From the SA of 21,000 model solutions for a 100 ha case study site in Singapore, building density, podium density, and land parcel area are found to have greatest impacts on UHI. This finding supports a hypothesis that urban planning parameters have a high potential for UHI mitigation. Key findings include that a high green plot ratio (>50 %) combined with a low site coverage ratio ( 4) to maintain annual UHI below 0.89 °C. The conclusion discusses the implications of the findings for heat-resilient city planning and demonstrates that performance-based evaluation of generative urban models can improve upon prescriptive planning approaches.",
        "author_keywords": [
            "Correlation analysis",
            "Performance simulation",
            "Planning",
            "Sensitivity analysis",
            "Urban design",
            "Urban heat island"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "AI-enhanced multi-stage learning-to-learning approach for secure smart cities load management in IoT networks",
        "authors": "Wang B.",
        "journal": "Ad Hoc Networks",
        "doi": "10.1016/j.adhoc.2024.103628",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201517922",
        "scopus_id": "85201517922",
        "abstract": "In the context of rapidly urbanizing smart cities reliant on IoT networks, efficient load management is critical for sustainable energy use. This paper proposes an AI-enhanced Multi-Stage Learning-to-Learning (MSLL) approach tailored for secure load management in IoT networks. The proposed approach leverages MMStransformer, a transformer-based model designed to handle multivariate, correlated data, and to capture long-range dependencies inherent in load forecasting. MMStransformer employs a multi-mask learning-to-learning strategy, optimizing computational efficiency without compromising prediction accuracy. The study addresses the dynamic and complex nature of smart city data by integrating diverse environmental and operational variables. Security and privacy concerns inherent in IoT networks are also addressed, ensuring secure data handling and communication. Experimental results demonstrate the efficacy of the proposed approach, achieving competitive performance compared to traditional methods and baseline models. The findings highlight the potential of AI-driven solutions in enhancing load forecasting accuracy while ensuring robust security measures in smart city infrastructures. This research contributes to advancing the state-of-the-art in AI applications for sustainable urban development and energy management.",
        "author_keywords": [
            "AI-enhanced",
            "IoT networks",
            "Load management",
            "MMStransformer",
            "Smart cities"
        ],
        "subject_areas": [
            "Software",
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Intrusion Detection for Blockchain-Based Internet of Things Using Gaussian Mixture–Fully Convolutional Variational Autoencoder Model",
        "authors": "Om Kumar C.U.",
        "journal": "International Journal of Network Management",
        "doi": "10.1002/nem.2295",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201365499",
        "scopus_id": "85201365499",
        "abstract": "The Internet of Things (IoT) is an evolving paradigm that has dramatically transformed the traditional style of living into a smart lifestyle. IoT devices have recently attained great attention due to their wide range of applications in various sectors, such as healthcare, smart home devices, smart industries, smart cities, and so forth. However, security is still a challenging issue in the IoT environment. Because of the disparate nature of IoT devices, it is hard to detect the different kinds of attacks available in IoT. Various existing works aim to provide a reliable intrusion detection system (IDS) technique. But they failed to work because of several security issues. Thus, the proposed study presents a blockchain-based deep learning model for IDS. Initially, the input data are preprocessed using min-max normalization, converting the raw input data into improved quality. In order to detect the presented attacks in the provided dataset, the proposed work introduced Gaussian mixture–fully convolutional variational autoencoder (GM-FCVAE) model. The implementation is performed in Python, and the performance of the proposed GM-FCVAE model is analyzed by evaluating several metrics. The proposed GM-FCVAE model is tested on three datasets and attained superior accuracy of 99.18%, 98.81%, and 98.4% with UNSW-NB15, CICIDS 2019, and N_BaIoT datasets, respectively. The comparison reveals that the proposed GM-FCVAE model obtained higher results than the other deep learning techniques. The outperformance shows the efficacy of the proposed study in identifying security attacks.",
        "author_keywords": [
            "blockchain",
            "improved proof of work (I-PoW)",
            "Internet of Things (IoT)",
            "intrusion detection system (IDS)",
            "preprocessing",
            "variational autoencoder (VAE)"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Dataset Generation for Korean Urban Parks Analysis with Large Language Models",
        "authors": "Kim H.",
        "journal": "International Conference on Information and Knowledge Management, Proceedings",
        "doi": "10.1145/3627673.3679109",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210013106",
        "scopus_id": "85210013106",
        "abstract": "Understanding how urban parks are utilized and perceived by the public is crucial for effective urban planning and management. This study introduces a novel dataset derived from Instagram, using 42,187 images tagged with #Seoul and #Park hashtags from 2017 to 2023. These images were filtered using InternLM-XComposer2, a Multimodal Large Language Model (MLLM), to confirm they depicted park scenes. GPT-4 then annotated the filtered images, resulting in 29,866 valid image annotations of physical elements, human activities, animals, and emotions. The dataset is publicly available at https://huggingface.co/datasets/RedBall/seoul-urban-park-analysis-by-llm.",
        "author_keywords": [
            "datasets",
            "image annotation",
            "large language models",
            "urban park"
        ],
        "subject_areas": [
            "Business, Management and Accounting (all)",
            "Decision Sciences (all)"
        ]
    },
    {
        "title": "Application of mask R-CNN for building detection in UAV remote sensing images",
        "authors": "Hou T.",
        "journal": "Heliyon",
        "doi": "10.1016/j.heliyon.2024.e38141",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85204876529",
        "scopus_id": "85204876529",
        "abstract": "This study aims to tackle the challenges of low accuracy in building feature extraction and insufficient details in three-dimensional (3D) modeling faced by traditional methods, particularly in complex backgrounds. To address these issues, a method for building feature extraction based on Mask Region-Convolutional Neural Network (Mask R-CNN) is proposed. This approach combines deep learning techniques with aerial images to ensure precise and efficient automatic detection and feature extraction. Urban building images are captured through aerial photography, and building outlines are annotated to create a comprehensive dataset of building features. The Mask R-CNN-based method efficiently processes and classifies the features of the dataset, generating candidate regions for further analysis. Additionally, this method demonstrates significant advantages in building feature extraction by employing the Mask R-CNN model to generate adaptive features. Comparative analysis with models such as Convolutional Neural Network (CNN), Region-based Convolutional Neural Network (R-CNN), Fast Region-based Convolutional Neural Network (Fast R-CNN), Faster Region-based Convolutional Neural Network (Faster R-CNN), and Generative Adversarial Network (GAN) indicates that Mask R-CNN exhibits superior performance in building feature extraction. The Mask R-CNN-based approach achieved approximately 95 % classification accuracy, while also showcasing strong stability and generalization capabilities. This study provides new methodologies and insights for enhancing feature extraction in aerial building imagery, offering significant reference value for the fields of architectural design and urban planning.",
        "author_keywords": [
            "Deep learning",
            "Instance segmentation",
            "UAV remote sensing"
        ],
        "subject_areas": [
            "Multidisciplinary"
        ]
    },
    {
        "title": "Richard Sennett on the user-friendly city and technology",
        "authors": "Fraser B.",
        "journal": "Journal of Urban Cultural Studies",
        "doi": "10.1386/jucs_00085_2",
        "publication_date": "2024",
        "document_type": "Editorial",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216477834",
        "scopus_id": "85216477834",
        "abstract": "This editorial for issue 11.2 of the Journal of Urban Cultural Studies follows from a reading of Richard Sennett’s book Building and Dwelling (2018), in which the urban thinker discusses the user-friendly city, among other topics. Following first The Craftsman (2008) and second Together (2012), Building and Dwelling is the third volume in his Homo Faber series, a reflection on the relationship between head and hand. Here Sennett’s remarks on user-friendliness and technology serve as a launching point for assessing what is at stake in the rise of generative artificial intelligence for long-form writing.",
        "author_keywords": [
            "artificial intelligence",
            "editing",
            "libraries",
            "smart city",
            "urban planning",
            "writing"
        ],
        "subject_areas": [
            "Cultural Studies",
            "Arts and Humanities (miscellaneous)",
            "Urban Studies"
        ]
    },
    {
        "title": "Forecasting Population Migration in Small Settlements Using Generative Models under Conditions of Data Scarcity",
        "authors": "Zakharov K.",
        "journal": "Smart Cities",
        "doi": "10.3390/smartcities7050097",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85207311500",
        "scopus_id": "85207311500",
        "abstract": "Highlights: What are the main findings? We have proposed a method for creating synthetic data in the context of the task of predicting migration balances. We investigated the impact of social and economic variables on migration patterns, which vary significantly between small villages and large cities and urban areas, and developed machine learning models to forecast migration balances based on these variables. What are the implications of the main findings? Our findings can be utilized in the optimal design of project compositions for the transformation of a territory, including determining the placement of infrastructure, altering migration dynamics, and finetuning the functional purpose of specific areas in order to attain desired, sustainable increases in the levels of certain social and economic development indicators. Our findings also include a value-based approach, applied within the context of predicting social risks arising from conflicts between the goals and needs of a population and plans for the arrangement of their environment. Today, the problem of predicting population migration is essential in the concept of smart cities for the proper development planning of certain regions of the country, as well as their financing and landscaping. In dealing with population migration in small settlements whose population is below 100,000, data collection is challenging. In countries where data collection is not well developed, most of the available data in open access are presented as part of textual reports issued by authorities in municipal districts. Therefore, the creation of a more or less adequate dataset requires significant efforts, and despite these efforts, the outcome is far from ideal. However, for large cities, there are typically aggregated databases maintained by authorities. We used them to find out what factors had an impact on the number of people who arrived or departed the city. Then, we reviewed several dozens of documents to mine the data of small settlements. These data were not sufficient to solve machine learning tasks, but they were used as the basis for creating a synthetic sample for model fitting. We found that a combination of two models, each trained on synthetic data, performed better. A binary classifier predicted the migration direction and a regressor estimateed the number of migrants. Lastly, the model fitted with synthetics was applied to the other set of real data, and we obtained good results, which are presented in this paper.",
        "author_keywords": [
            "collecting data",
            "machine learning for migration",
            "migration forecasting",
            "small settlements",
            "synthetic data"
        ],
        "subject_areas": [
            "Urban Studies",
            "Artificial Intelligence",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "MapGen-Diff: An End-to-End Remote Sensing Image to Map Generator via Denoising Diffusion Bridge Model",
        "authors": "Tian J.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs16193716",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206458118",
        "scopus_id": "85206458118",
        "abstract": "Online maps are of great importance in modern life, especially in commuting, traveling and urban planning. The accessibility of remote sensing (RS) images has contributed to the widespread practice of generating online maps based on RS images. The previous works leverage an idea of domain mapping to achieve end-to-end remote sensing image-to-map translation (RSMT). Although existing methods are effective and efficient for online map generation, generated online maps still suffer from ground features distortion and boundary inaccuracy to a certain extent. Recently, the emergence of diffusion models has signaled a significant advance in high-fidelity image synthesis. Based on rigorous mathematical theories, denoising diffusion models can offer controllable generation in sampling process, which are very suitable for end-to-end RSMT. Therefore, we design a novel end-to-end diffusion model to generate online maps directly from remote sensing images, called MapGen-Diff. We leverage a strategy inspired by Brownian motion to make a trade-off between the diversity and the accuracy of generation process. Meanwhile, an image compression module is proposed to map the raw images into the latent space for capturing more perception features. In order to enhance the geometric accuracy of ground features, a consistency regularization is designed, which allows the model to generate maps with clearer boundaries and colorization. Compared to several state-of-the-art methods, the proposed MapGen-Diff achieves outstanding performance, especially a (Formula presented.) RMSE and (Formula presented.) SSIM improvement on Los Angeles and Toronto datasets. The visualization results also demonstrate more accurate local details and higher quality.",
        "author_keywords": [
            "denoising diffusion bridge model",
            "domain mapping",
            "online map translation",
            "remote sensing image"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "A Super-Resolution Enhancement Algorithm for Remote Sensing Images Using Conditional Controlled Diffusion Models",
        "authors": "Fu Y.",
        "journal": "Journal of Geo-Information Science",
        "doi": "10.12082/dqxxkx.2024.240315",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206299604",
        "scopus_id": "85206299604",
        "abstract": "Image super-resolution technology enhances image clarity and enriches image detail by improving image spatial resolution, enabling quality enhancement without changing hardware conditions. Given the large size, complex target features, and abundant details of remote sensing images, along with the need for efficient information acquisition, we propose a Diffusion Super-Resolution (DSR) algorithm based on a conditional diffusion model. This approach uses low-resolution remote sensing images from the same region as conditioning inputs to the diffusion model, while high-resolution images with added noise are concatenated as inputs. A deep noise training network was constructed with U-Net as the backbone, incorporating residual connections and self-attention mechanisms. The loss function was also improved for better super-resolution results. The DSR method was tested using high-resolution remote sensing images from multiple periods of the domestic Gaofen and SuperView satellite series. The super-resolution results demonstrated pixel dimension expansion from 32 to 128. Comparative experiments with Bicubic, SRGAN, Real-ESRGAN, and SwinIR super-resolution algorithms showed that the DSR method outperforms these algorithms in both PSNR and SSIM metrics. Additionally, the DSR method significantly improves the quality of multispectral remote sensing images. By leveraging the conditional diffusion model, it successfully preserves rich detail and enhances spatial resolution without compromising image clarity. This method offers an efficient solution for super-resolution reconstruction, ensuring effective information acquisition in remote sensing applications and fulfilling the requirements of various domains such as land use classification, environmental monitoring, and urban planning. Moreover, the DSR method also opens new avenues for future research by demonstrating the potential of diffusion models in remote sensing image processing. It overcomes the limitations of simple convolutional networks, which extract only shallow features, and avoids the convergence issues commonly seen in adversarial neural networks during training, ultimately improving the restoration of rich details in remote sensing images.",
        "author_keywords": [
            "deep learning",
            "Diffusion Model",
            "high-resolution remote sensing",
            "remote sensing image reconstruction",
            "remote sensing images",
            "residual network",
            "super-resolution"
        ],
        "subject_areas": [
            "Information Systems",
            "Computer Science Applications",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "‘Where #freedom and #patriotism live:’ Linking digital media to far-right geographies",
        "authors": "Luger J.",
        "journal": "Political Geography",
        "doi": "10.1016/j.polgeo.2024.103195",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203009735",
        "scopus_id": "85203009735",
        "abstract": "This paper explores some ways that far-right worldviews are digitally encoded and strategically-assembled in and through built environments. The paper argues that an understanding of far-right spatiality will be limited without a more inter-scalar, relational and material framing of the various components of far-right world-building. Assemblage ontologies, seen through comparative cases, therefore hold value in making sense of the far-right today. Explorations of how digital media and the far-right are entangled with and co-producing built environments, are thus vital. As ideologies and philosophies (e.g., nationalism or conspiracism) travel across networked medias, complex hybridizations become infrastructurally-fixed-in-place. These affixations produce, and are produced by, geographical communities (e.g., urban developments). Far-right material infrastructures thereby extend from, and into, the digital, mediated by both human and nonhuman processes (such as generative AI), thus becoming co-constitutive elements of place, via land ownership, buildings, aesthetics, social encounters and practices, urban planning processes, and electoral politics; e.g., the assembled spatialities of everyday life. The paper juxtaposes two international cases, drawn from ethnography and critical discourse/visual analyses. The first is the territorialisation of circulating notions of American hyper-patriotic nationalism in the suburban South via urban developments and recreational spaces. The second case explores how far-right representations of conspiracism and debates around urban traditionalism versus modernity, are contested online and offline in Dresden, Saxony. Both cases point to the powerful entanglements of far-right ideology, digital media, and place. Conceptually, the paper juxtaposes phenomenological notions of far-right space/place with ideas of ‘strategic assemblage’ and online/offline ‘code space’, as ontological lenses to interrogate the relationships between far-right online worlds and the material configurations of physical infrastructures and materials which have troubling implications for everyday environments and democratic life.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "A new clustering-based semi-supervised method to restrict the users from anomalous electricity consumption: supporting urbanization",
        "authors": "Aslam Z.",
        "journal": "Electrical Engineering",
        "doi": "10.1007/s00202-024-02362-3",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190418189",
        "scopus_id": "85190418189",
        "abstract": "One of the crucial issues for power grids in strengthening the urbanization around the world is imbalance between supply and demand, which leads the users to consume electricity in an anomalous manner without paying for it. Electricity theft plays a pivotal role in cutting down on the electricity bills. The existing data-oriented approaches for electricity theft detection (ETD) in the smart cities have limited ability to handle noisy high-dimensional data and features’ associations. These limitations raise the misclassification rate, which makes some of the approaches unacceptable for electric utilities. A new twofold end-to-end methodology is proposed for ETD. In the first fold, it groups the similar electricity consumption (EC) cases through grey wolf optimization (GWO)-based clustering mechanism; clustering by fast search and find of density peaks (CFSFDP), we named it GC. In the second fold, a new relational stacked denoising autoencoder (RSDAE)-based semi-supervised generative adversarial network (GAN), termed as RGAN, is used for ETD. The combined methodology is named as GC-RGAN. In the methodology, RSDAE acts as both feature extraction technique and generator sub-model of the proposed RGAN. The proposed methodology utilizes the advantages of clustering, adversarial learning and semi-supervised EC data. Besides, to validate the effectiveness of the proposed solution, extensive simulations are performed using smart meter data. Simulation results validate the excellent ETD performance of the proposed GC-RGAN against existing ETD schemes, such as random forest and semi-supervised support vector machine. In comparison, GC-RGAN covers the ETD score of 98% that shows its suitability for real-world scenarios. The proposed solution has extraordinary performance for ETD as compared to traditional solutions, which shows its superiority and usefulness for real-world applications.",
        "author_keywords": [
            "Anomalous electricity consumption",
            "Electricity theft detection",
            "Grey wolf optimization",
            "Relational stacked denoising autoencoder",
            "Semi-supervised GAN",
            "Smart cities",
            "Urban planning"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering",
            "Applied Mathematics"
        ]
    },
    {
        "title": "Evolvable case-based design: An artificial intelligence system for urban form generation with specific indicators",
        "authors": "Liu Y.",
        "journal": "Environment and Planning B: Urban Analytics and City Science",
        "doi": "10.1177/23998083231219364",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85179355054",
        "scopus_id": "85179355054",
        "abstract": "This research proposes a design system that combines a case-based learning algorithm with a rule-based optimization algorithm to automatically generate and revise urban form prototypes based on historical cases and user requirements. The system aims to address the challenges of existing generative methods for urban forms, such as the lack of flexibility and organicity of rule-based methods and the insufficient manipulability and interpretability of the newest GAN-integrated case-based methods. It can help designers generate multiple solutions with specific indicators in the conceptual stage and has the potential to facilitate citizen participation in urban planning and design. This research demonstrates the feasibility and effectiveness of the system through a case study in Shenzhen. The research further extends the discussion about the application of the proposed system and the alternative evolution approach for the next generation of automatic design methods.",
        "author_keywords": [
            "artificial intelligence",
            "case-based design",
            "generative adversarial networks",
            "reinforcement learning",
            "urban form generation"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Architecture",
            "Urban Studies",
            "Nature and Landscape Conservation",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Geovisualization of Buildings: AI vs. Procedural Modeling",
        "authors": "Nikçi R.",
        "journal": "Applied Sciences (Switzerland)",
        "doi": "10.3390/app14188345",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205300875",
        "scopus_id": "85205300875",
        "abstract": "Procedural modeling offers significant advantages over traditional methods of geovisualizing 3D building models, particularly in its use of scripts or machine language for model description. This approach is highly suitable for computer processing and allows for the rapid rendering of entire building models and cities, especially when the buildings are not highly diverse, thus fully leveraging the strengths of procedural modeling. The first hypothesis is that buildings in the real world are mostly different and they should still be able to be displayed through procedural modeling procedures, and the second hypothesis is that this can be achieved in several ways. The first hypothesis suggests that real-world buildings, despite their diversity, can still be effectively represented through procedural modeling. The second hypothesis explores various methods to achieve this representation. The first approach involves recognizing the basic characteristics of a building from photographs and creating a model using machine learning. The second approach utilizes artificial intelligence (AI) to generate detailed building models based on comprehensive input data. A script is generated for each building, making reverse procedural modeling in combination with AI an intriguing field of study, which is explored in this research. To validate this method, we compare AI-generated building models with manually derived models created through traditional procedural modeling techniques. The research demonstrates that integrating AI and machine learning techniques with procedural modeling significantly improves the efficiency and accuracy of generating 3D building models. Specifically, the use of convolutional neural networks (CNNs) for image-to-geometry translation, and Generative Adversarial Networks (GANs) for texture generation, showed promising results in creating detailed and realistic 3D structures. This research is significant as it introduces a novel methodology that bridges the gap between traditional procedural modeling and modern AI-driven techniques. It offers a robust solution for automated 3D building modeling, potentially revolutionizing the fields of urban planning and architectural design by enabling more efficient and accurate digital representations of complex building geometries.",
        "author_keywords": [
            "building",
            "geovisualization",
            "procedural modeling"
        ],
        "subject_areas": [
            "Materials Science (all)",
            "Instrumentation",
            "Engineering (all)",
            "Process Chemistry and Technology",
            "Computer Science Applications",
            "Fluid Flow and Transfer Processes"
        ]
    },
    {
        "title": "An AI-Based Evaluation Framework for Smart Building Integration into Smart City",
        "authors": "Shahrabani M.M.N.",
        "journal": "Sustainability (Switzerland)",
        "doi": "10.3390/su16188032",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205257175",
        "scopus_id": "85205257175",
        "abstract": "The integration of smart buildings (SBs) into smart cities (SCs) is critical to urban development, with the potential to improve SCs’ performance. Artificial intelligence (AI) applications have emerged as a promising tool to enhance SB and SC development. The authors apply an AI-based methodology, particularly Large Language Models of OpenAI ChatGPT-3 and Google Bard as AI experts, to uniquely evaluate 26 criteria that represent SB services across five SC infrastructure domains (energy, mobility, water, waste management, and security), emphasizing their contributions to the integration of SB into SC and quantifying their impact on the efficiency, resilience, and environmental sustainability of SC. The framework was then validated through two rounds of the Delphi method, leveraging human expert knowledge and an iterative consensus-building process. The framework’s efficiency in analyzing complicated information and generating important insights is demonstrated via five case studies. These findings contribute to a deeper understanding of the effects of SB services on SC infrastructure domains, highlighting the intricate nature of SC, as well as revealing areas that require further integration to realize the SC performance objectives.",
        "author_keywords": [
            "artificial intelligence",
            "evaluation framework",
            "Google Bard",
            "OpenAI ChatGPT-3",
            "smart building",
            "smart city"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Environmental Science (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Computational Optimisation of Urban Design Models: A Systematic Literature Review",
        "authors": "Tay J.Z.",
        "journal": "Urban Science",
        "doi": "10.3390/urbansci8030093",
        "publication_date": "2024",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205128847",
        "scopus_id": "85205128847",
        "abstract": "The densification of urban spaces globally has contributed to a need for design tools supporting the planning of more sustainable, efficient, and liveable cities. Urban Design Optimisation (UDO) responds to this challenge by providing a means to explore many design solutions for a district, evaluate multiple objectives, and make informed selections from many Pareto-efficient solutions. UDO distinguishes itself from other forms of design optimisation by addressing the challenges of incorporating a wide range of planning goals, managing the complex interactions among various urban datasets, and considering the social–technical aspects of urban planning involving multiple stakeholders. Previous reviews focusing on specific topics within UDO do not sufficiently address these challenges. This PRISMA systematic literature review provides an overview of research on topics related to UDO from 2012 to 2022, with articles analysed across seven descriptive categories. This paper presents a discussion on the state-of-the-art and identified gaps present in each of the seven categories. Finally, this paper argues that additional research to improve the socio-technical understanding and usability of UDO would require: (i) methods of optimisation across multiple models, (ii) interfaces that address a multiplicity of stakeholders, (iii) exploration of frameworks for scenario building and backcasting, and (iv) advancing AI applications for UDO, including generalizable surrogates and user preference learning.",
        "author_keywords": [
            "generative modelling",
            "optimisation frameworks",
            "solution space exploration",
            "surrogate models",
            "urban design optimisation"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Environmental Science (miscellaneous)",
            "Waste Management and Disposal",
            "Urban Studies",
            "Pollution"
        ]
    },
    {
        "title": "SpecRep: Adversary Emulation Based on Attack Objective Specification in Heterogeneous Infrastructures",
        "authors": "Portase R.M.",
        "journal": "Sensors",
        "doi": "10.3390/s24175601",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203868395",
        "scopus_id": "85203868395",
        "abstract": "Cybercriminals have become an imperative threat because they target the most valuable resource on earth, data. Organizations prepare against cyber attacks by creating Cyber Security Incident Response Teams (CSIRTs) that use various technologies to monitor and detect threats and to help perform forensics on machines and networks. Testing the limits of defense technologies and the skill of a CSIRT can be performed through adversary emulation performed by so-called “red teams”. The red team’s work is primarily manual and requires high skill. We propose SpecRep, a system to ease the testing of the detection capabilities of defenses in complex, heterogeneous infrastructures. SpecRep uses previously known attack specifications to construct attack scenarios based on attacker objectives instead of the traditional attack graphs or a list of actions. We create a metalanguage to describe objectives to be achieved in an attack together with a compiler that can build multiple attack scenarios that achieve the objectives. We use text processing tools aided by large language models to extract information from freely available white papers and convert them to plausible attack specifications that can then be emulated by SpecRep. We show how our system can emulate attacks against a smart home, a large enterprise, and an industrial control system.",
        "author_keywords": [
            "adversary emulation",
            "attacks against complex infrastructures",
            "cyber security for the smart city",
            "formal languages",
            "large language models used for knowledge extraction"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Information Systems",
            "Atomic and Molecular Physics, and Optics",
            "Biochemistry",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "A conditional diffusion model for probabilistic estimation of traffic states at sensor-free locations",
        "authors": "Lei D.",
        "journal": "Transportation Research Part C: Emerging Technologies",
        "doi": "10.1016/j.trc.2024.104798",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200213140",
        "scopus_id": "85200213140",
        "abstract": "Transportation administrators and urban planners rely on accurate network-wide traffic state estimation to make well-informed decisions. However, due to insufficient sensor coverage, traffic state estimation at sensor-free locations (TSES) poses significant challenges for downstream network-wide traffic analysis. This is because direct observations are not available at these sensor-free locations. Most existing traffic state estimation (TSE) research focuses on inferring several unknown time points based on observed historical data using deterministic models. In contrast, TSES is to infer the entire unknown traffic time series of a given sensor-free node, thereby presenting high predictive difficulty, as we could not learn any historical traffic patterns locally. In this study, we introduce a novel probabilistic model — the conditional diffusion framework with spatio-temporal estimator (CDSTE) — to tackle the TSES problem. When dealing with TSES, deterministic models can only produce point value estimates, which may substantially deviate from the actual traffic states of sensor-free locations. To mitigate this, the proposed CDSTE integrates the conditional diffusion framework with cutting-edge spatio-temporal networks to extract the underlying dependencies in traffic states between sensor-free and sensor-equipped nodes. This integration enables reliable probabilistic traffic state estimations for sensor-free locations, which can be used to quantify the variability of estimations in TSES to support flexible and robust decision-making processes for traffic management and control. Extensive numerical experiments on real-world datasets demonstrate the superior performance of CDSTE for TSES over five widely-used baseline models.",
        "author_keywords": [
            "Conditional diffusion model",
            "Insufficient sensor coverage",
            "Network-wide estimation",
            "Probabilistic estimation",
            "Spatio-temporal estimator"
        ],
        "subject_areas": [
            "Civil and Structural Engineering",
            "Automotive Engineering",
            "Transportation",
            "Management Science and Operations Research"
        ]
    },
    {
        "title": "UrbanEvolver: Function-Aware Urban Layout Regeneration",
        "authors": "Qin Y.",
        "journal": "International Journal of Computer Vision",
        "doi": "10.1007/s11263-024-02030-w",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85188142987",
        "scopus_id": "85188142987",
        "abstract": "Urban regeneration is an important strategy for land redevelopment, to address the urban decay in cities. Among many tasks, urban layout is the foundation for urban regeneration. In this paper, we target a new task called function-aware urban layout regeneration, and propose UrbanEvolver, a function-aware deep generative model for the task. Given a target region to be regenerated, our model outputs a regenerated urban layout (i.e., roads and buildings) for the target region by considering the function (i.e., land use type) of the target region and its surrounding context (i.e., the functions and urban layouts of the surrounding regions). UrbanEvolver first extracts implicit regeneration rules from the target function and the surrounding context by encoding them separately in different scales through the function-layout adaptive (FA) blocks, and then constrains the regenerated urban layout based on the learned regeneration rules. To enforce the regenerated layout to be valid and to follow the road structure, we design a set of losses covering both pixel-level and geometry-level constraints. To train our model, we collect a large-scale urban layout dataset covering more than 147 K regions under 1300 km2 with rich annotations, including functions, region shapes, urban road layouts, and urban building layouts. We conduct extensive experiments to show that our model outperforms the baseline methods in generating practical and function-aware urban layouts based on the given target function and surrounding context.",
        "author_keywords": [
            "Function-aware generative model",
            "Urban layout regeneration",
            "Urban regeneration"
        ],
        "subject_areas": [
            "Software",
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "A convolutional neural network approach to classifying urban spaces using generative tools for data augmentation",
        "authors": "Medel-Vera C.",
        "journal": "International Journal of Architectural Computing",
        "doi": "10.1177/14780771231225697",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85181258654",
        "scopus_id": "85181258654",
        "abstract": "This article discusses an application for classifying urban spaces using convolutional neural networks (CNNs). A seed dataset was initially generated composed of 630 photographs of urban spaces from the Adobe Stock repository. This dataset was topped up with images produced by two generative artificial intelligence (AI) engines, namely, Deep Dream Generator and Midjourney, making two additional augmented datasets, each composed of 2200 images. The training process was carried out using four well-known CNNs, namely, GoogLeNet, ResNet-18, ShuffleNet, and MobileNet-v2. The results show an increase of roughly 30% in the predicting capabilities in both augmented datasets when compared to the seed dataset. Furthermore, performance metrics are generally higher when using ResNet-18 which may suggest that this CNN architecture is more applicable to urban classification projects. Finally, although both generative AI engines have similar performance, Midjourney seems to slightly outperform Deep Dream Generator as a data augmentation engine for urban spaces.",
        "author_keywords": [
            "classification",
            "deep learning",
            "diffusion models",
            "machine learning",
            "neural architecture",
            "Urban categories"
        ],
        "subject_areas": [
            "Building and Construction",
            "Computer Science Applications",
            "Computer Graphics and Computer-Aided Design"
        ]
    },
    {
        "title": "FedKDD: International Joint Workshop on Federated Learning for Data Mining and Graph Analytics",
        "authors": "Hong J.",
        "journal": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "doi": "10.1145/3637528.3671490",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203719456",
        "scopus_id": "85203719456",
        "abstract": "Deep Learning has facilitated various high-stakes applications such as crime detection, urban planning, drug discovery, and healthcare. Its continuous success hinges on learning from massive data in miscellaneous sources, ranging from data with independent distributions to graph-structured data capturing intricate inter-sample relationships. Scaling up the data access requires global collaboration from distributed data owners. Yet, centralizing all data sources to an untrustworthy centralized server will put users' data at risk of privacy leakage or regulation violation. Federated Learning (FL) is a de facto decentralized learning framework that enables knowledge aggregation from distributed users without exposing private data. Though promising advances are witnessed for FL, new challenges are emerging when integrating FL with the rising needs and opportunities in data mining, graph analytics, foundation models, generative AI, and new interdisciplinary applications in science. By hosting this workshop, we aim to attract a broad range of audiences, including researchers and practitioners from academia and industry interested in the emergent challenges in FL. As an effort to advance the fundamental development of FL, this workshop will encourage ideas exchange on the trustworthiness, scalability, and robustness of distributed data mining and graph analytics and their emergent challenges.",
        "author_keywords": [
            "applications",
            "distributed data mining",
            "federated learning",
            "graph analytics",
            "trustworthiness"
        ],
        "subject_areas": [
            "Software",
            "Information Systems"
        ]
    },
    {
        "title": "ControlTraj: Controllable Trajectory Generation with Topology-Constrained Diffusion Model",
        "authors": "Zhu Y.",
        "journal": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "doi": "10.1145/3637528.3671866",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203713682",
        "scopus_id": "85203713682",
        "abstract": "Generating trajectory data is among promising solutions to addressing privacy concerns, collection costs, and proprietary restrictions usually associated with human mobility analyses. However, existing trajectory generation methods are still in their infancy due to the inherent diversity and unpredictability of human activities, grappling with issues such as fidelity, flexibility, and generalizability. To overcome these obstacles, we propose ControlTraj, a Controllable Trajectory generation framework with the topology-constrained diffusion model. Distinct from prior approaches, ControlTraj utilizes a diffusion model to generate high-fidelity trajectories while integrating the structural constraints of road network topology to guide the geographical outcomes. Specifically, we develop a novel road segment autoencoder to extract fine-grained road segment embedding. The encoded features, along with trip attributes, are subsequently merged into the proposed geographic denoising UNet architecture, named GeoUNet, to synthesize geographic trajectories from white noise. Through experimentation across three real-world data settings, ControlTraj demonstrates its ability to produce human-directed, high-fidelity trajectory generation with adaptability to unexplored geographical contexts.",
        "author_keywords": [
            "diffusion model",
            "gps trajectory",
            "urban computing"
        ],
        "subject_areas": [
            "Software",
            "Information Systems"
        ]
    },
    {
        "title": "UrbanGPT: Spatio-Temporal Large Language Models",
        "authors": "Li Z.",
        "journal": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "doi": "10.1145/3637528.3671578",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203709974",
        "scopus_id": "85203709974",
        "abstract": "Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. In certain cases, it becomes challenging to collect any labeled data from downstream scenarios, intensifying the problem further. Consequently, it becomes necessary to build a spatio-temporal model that can exhibit strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce. The code and data are available at: https://github.com/HKUDS/UrbanGPT.",
        "author_keywords": [
            "generative ai",
            "large language models",
            "smart cities",
            "spatial-temporal data mining",
            "urban computing"
        ],
        "subject_areas": [
            "Software",
            "Information Systems"
        ]
    },
    {
        "title": "DiffCrime: A Multimodal Conditional Diffusion Model for Crime Risk Map Inference",
        "authors": "Wang S.",
        "journal": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "doi": "10.1145/3637528.3671843",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203709413",
        "scopus_id": "85203709413",
        "abstract": "Crime risk map plays a crucial role in urban planning and public security management. Traditionally, it is obtained solely from historical crime incidents or inferred from limited environmental factors, which are not sufficient to accurately model the occurrences of crimes over the geographical space well. Motivated by the impressive and realistic conditional generating power of diffusion models, in this paper, we propose a multimodal conditional diffusion method, namely, DiffCrime, to infer the crime risk map based on datasets in various domains, i.e., historical crime incidents, satellite imagery, and map imagery. It is equipped with a history-gated multimodal denoising network, i.e., HamNet, dedicated to the crime risk map inference. HamNet emphasizes the importance of historical crime data via a Gated-based History Fusion (GHF) module and adaptively controls multimodal conditions to be fused across different diffusion time steps via a Time step-Aware Modality Fusion (TAMF) module. Extensive experiments on two real-world datasets demonstrate the effectiveness of DiffCrime, which outperforms baselines by at least 43% and 31% in terms of RMSE, respectively.",
        "author_keywords": [
            "conditional diffusion model",
            "crime risk map inference",
            "multimodal learning"
        ],
        "subject_areas": [
            "Software",
            "Information Systems"
        ]
    },
    {
        "title": "Graph Intelligence with Large Language Models and Prompt Learning",
        "authors": "Li J.",
        "journal": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "doi": "10.1145/3637528.3671456",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203684562",
        "scopus_id": "85203684562",
        "abstract": "Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Graph intelligence is rapidly becoming a crucial aspect of understanding and exploiting the intricate interconnections within graph data. Recently, large language models (LLMs) and prompt learning techniques have pushed graph intelligence forward, outperforming traditional Graph Neural Network (GNN) pre-training methods and setting new benchmarks for performance. In this tutorial, we begin by offering a comprehensive review and analysis of existing methods that integrate LLMs with graphs. We introduce existing works based on a novel taxonomy that classifies them into three distinct categories according to the roles of LLMs in graph tasks: as enhancers, predictors, or alignment components. Secondly, we introduce a new learning method that utilizes prompting on graphs, offering substantial potential to enhance graph transfer capabilities across diverse tasks and domains. We discuss existing works on graph prompting within a unified framework and introduce our developed tool for executing a variety of graph prompting tasks. Additionally, we discuss the applications of combining Graphs, LLMs, and prompt learning across various tasks, such as urban computing, recommendation systems, and anomaly detection. This lecture-style tutorial is an extension of our original work published in IJCAI 2024[44] and arXiv[77] with the invitation of KDD24.",
        "author_keywords": [
            "graph learning",
            "graph prompting",
            "large language model"
        ],
        "subject_areas": [
            "Software",
            "Information Systems"
        ]
    },
    {
        "title": "Feature matching of remote-sensing images: using optimal regularized nonlinear diffusion model",
        "authors": "Liu H.",
        "journal": "Optical Engineering",
        "doi": "10.1117/1.OE.63.8.088104",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85203283740",
        "scopus_id": "85203283740",
        "abstract": "Unmanned aerial vehicle remote sensing image matching techniques are crucial for urban planning and environmental monitoring. However, existing feature matching methods have limitations due to the lack of effective extraction of key diverse features, which hinders the improvement of matching accuracy for diverse ground scenes. To address the above limitations, we propose a remote sensing image feature-matching method using optimally regularized nonlinear diffusion model. Specifically, we first use the accelerated-KAZE (AKAZE) algorithm framework to detect and characterize features within a nonlinear scale space. To improve the adaptation of diffusion to the local image structure, we propose the introduction of a novel Charbonnier regularized nonlinear diffusion model for constructing the diffusion coefficients. We then propose to combine Brute force with the K -nearest neighbor algorithm to eliminate invalid matches. Lastly, we modified the sampling approach of the random sample consensus (RANSAC) algorithm. Instead, we achieve iterative dataset purification using the progressive sample consensus algorithm, complemented by the implementation of a termination criterion for the sampling process. Experimental results show that our method achieves an average matching precision of 82.8%, 80.2%, 82.9%, and 91.2% when the test set undergoes scale, rotation angle, noise blurring, and luminance variations, respectively, outperforming the existing feature matching methods.",
        "author_keywords": [
            "accelerated-KAZE algorithm",
            "feature matching",
            "K-nearest neighbor algorithm",
            "Person-Malik and Charbonnier regularized nonlinear diffusion model",
            "progressive sample consensus algorithm"
        ],
        "subject_areas": [
            "Atomic and Molecular Physics, and Optics",
            "Engineering (all)"
        ]
    },
    {
        "title": "TrafficPro：a framework to predict link speeds on signalized urban traffic network",
        "authors": "Wen X.Y.",
        "journal": "Jilin Daxue Xuebao (Gongxueban)/Journal of Jilin University (Engineering and Technology Edition)",
        "doi": "10.13229/j.cnki.jdxbgxb.20221386",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202776897",
        "scopus_id": "85202776897",
        "abstract": "When the traditional deep learning-based models predict link speeds for the entire urban traffic network，they do not consider the proactive feature （signal control information） of traffic flow，and therefore achieve low prediction accuracy. In order to tackle this issue，this paper proposed a link speed prediction framework，based on generative adversarial network and graph neural network. By adopting a proactive and a reactive prediction module，the generator of this framework is able to encode traffic flow and signal control information at the entire network level. The discriminator is then used to increase the generalizability of the prediction outcome. By comparing its performance with traditional time-series and deep learning-based models in real-world traffic circumstances，it is found that the proposed framework achieved less prediction error（3%-5% RMSE drop）than the SOTA model（ASTGCN）.",
        "author_keywords": [
            "generative adversarial network",
            "signalized urban traffic network",
            "traffic speed prediction",
            "transportation planning and management"
        ],
        "subject_areas": [
            "Multidisciplinary"
        ]
    },
    {
        "title": "What Factors Revitalize the Street Vitality of Old Cities? A Case Study in Nanjing, China",
        "authors": "Zheng Y.",
        "journal": "ISPRS International Journal of Geo-Information",
        "doi": "10.3390/ijgi13080282",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202640164",
        "scopus_id": "85202640164",
        "abstract": "Urban street vitality has been a perennial focus within the domain of urban planning. This study examined spatial patterns of street vitality in the old city of Nanjing during working days and weekends using real-time user datasets (RTUDs). A spatial autoregressive model (SAM) and a multiscale geographically weighted regression (MGWR) model were employed to quantitatively assess the impact of various factors on street vitality and their spatial heterogeneity. This study revealed the following: (1) the distribution of street vitality in the old city of Nanjing exhibited a structure centered around Xinjiekou, with greater regularity and predictability in street vitality on working days than on weekends; (2) eight variables, such as traffic location, road density, and functional density, are positively associated with street vitality, whereas the green view index is negatively associated with street vitality, and commercial location benefits street vitality at weekends but detracts from street vitality on working days; and (3) the influence of variables such as traffic location and functional density on street vitality is contingent on their spatial position. Based on these results, this study provides new strategies to enhance the street vitality of old cities.",
        "author_keywords": [
            "multiscale geographically weighted regression",
            "multisource data",
            "residents’ perceptions",
            "street vitality",
            "the old city of Nanjing"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Fusion of Hierarchical Optimization Models for Accurate Power Load Prediction",
        "authors": "Wan S.",
        "journal": "Sustainability (Switzerland)",
        "doi": "10.3390/su16166903",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202627357",
        "scopus_id": "85202627357",
        "abstract": "Accurate power load forecasting is critical to achieving the sustainability of energy management systems. However, conventional prediction methods suffer from low precision and stability because of crude modules for predicting short-term and medium-term loads. To solve such a problem, a Combined Modeling Power Load-Forecasting (CMPLF) method is proposed in this work. The CMPLF comprises two modules to deal with short-term and medium-term load forecasting, respectively. Each module consists of four essential parts including initial forecasting, decomposition and denoising, nonlinear optimization, and evaluation. Especially, to break through bottlenecks in hierarchical model optimization, we effectively fuse the Nonlinear Autoregressive model with Exogenous Inputs (NARX) and Long-Short Term Memory (LSTM) networks into the Autoregressive Integrated Moving Average (ARIMA) model. The experiment results based on real-world datasets from Queensland and China mainland show that our CMPLF has significant performance superiority compared with the state-of-the-art (SOTA) methods. CMPLF achieves a goodness-of-fit value of 97.174% in short-term load prediction and 97.162% in medium-term prediction. Our approach will be of great significance in promoting the sustainable development of smart cities.",
        "author_keywords": [
            "ARIMA",
            "deep learning",
            "hierarchical optimization models",
            "LSTM",
            "NARX",
            "power load forecasting"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Environmental Science (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "An Improved 3D Reconstruction Method for Satellite Images Based on Generative Adversarial Network Image Enhancement",
        "authors": "Li H.",
        "journal": "Applied Sciences (Switzerland)",
        "doi": "10.3390/app14167177",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202434572",
        "scopus_id": "85202434572",
        "abstract": "Three-dimensional reconstruction based on optical satellite images has always been a research hotspot in the field of photogrammetry. In particular, the 3D reconstruction of building areas has provided great help for urban planning, change detection and emergency response. The results of 3D reconstruction of satellite images are greatly affected by the input images, and this paper proposes an improvement method for 3D reconstruction of satellite images based on the generative adversarial network (GAN) image enhancement. In this method, the perceptual loss function is used to optimize the network, so that it can output high-definition satellite images for 3D reconstruction, so as to improve the completeness and accuracy of the reconstructed 3D model. We use the public benchmark dataset of satellite images to test the feasibility and effectiveness of the proposed method. The experiments show that compared with the satellite stereo pipeline (S2P) method and the bundle adjustment (BA) method, the proposed method can automatically reconstruct high-quality 3D point clouds.",
        "author_keywords": [
            "3D reconstruction",
            "deep learning",
            "generative adversarial network (GAN)",
            "optical satellite imagery",
            "RPC model"
        ],
        "subject_areas": [
            "Materials Science (all)",
            "Instrumentation",
            "Engineering (all)",
            "Process Chemistry and Technology",
            "Computer Science Applications",
            "Fluid Flow and Transfer Processes"
        ]
    },
    {
        "title": "Metro Stations as Catalysts for Land Use Patterns: Evidence from Wuhan Line 11",
        "authors": "Yang Y.",
        "journal": "Sustainability (Switzerland)",
        "doi": "10.3390/su16156320",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200721701",
        "scopus_id": "85200721701",
        "abstract": "Urban rail transit systems significantly influence land use patterns in newly developed areas, yet their impact on spatial organization and functional characteristics remains understudied. This research examines Wuhan Metro Line 11, analyzing land use within an 800 m radius of stations using Point of Interest data, ArcGIS spatial analysis, and locational entropy methods. The study reveals three station types, i.e., single-function, mixed-function, and underdeveloped, each exhibiting distinct spatial differentiation patterns. On this basis, a novel “core-diffusion” model emerges, with the highest density of functional elements observed at approximately 600 m from station centers, challenging conventional proximity assumptions. Three spatial organization modes are identified: single-core independent in two-level axis, single-core continuous in single-level axis, and double-core continuous in two-level axis. These findings contribute to the Transit-Oriented Development literature, offering sustainable insights into optimizing land use around metro stations in rapidly urbanizing contexts. This study also provides a methodological framework applicable to similar urban environments, enhancing the understanding of the complex relationships between metro development and surrounding land use patterns. These results have significant implications for urban planning and policy-making, particularly in emerging economies seeking to balance transit efficiency with sustainable urban growth.",
        "author_keywords": [
            "GIS",
            "land use",
            "new urban areas",
            "rail transit"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Environmental Science (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "A task-oriented framework for generative AI in design",
        "authors": "Furtado L.S.",
        "journal": "Journal of Creativity",
        "doi": "10.1016/j.yjoc.2024.100086",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85189778018",
        "scopus_id": "85189778018",
        "abstract": "The intersection of Artificial Intelligence and Design disciplines such as Architecture, Urban Planning, Engineering and Product Design has been a longstanding pursuit, with Generative AI (GAI) ushering in a new era of possibilities. The research presented here explores how GAI can enhance creativity and assist Design practitioners with tasks to create products such as, but not limited to, renderings, concepts, construction techniques, materials, data analytics or maps. We apply a framework of combinational, exploratory and transformational creativity to organize how recent advancements in GAI can support each creative category. We propose a conceptual framework of GAI towards transformational creativity, and identify real-world examples to demonstrate GAI's impact, such as transforming sketches into detailed renders, facilitating real-time 3D model generation, predicting trends through analytics and creating images or reports via text prompts. Our work envisions a future where GAI becomes a real-time collaborator to complete certain automated tasks while liberating Designers to focus on transformational innovation.",
        "author_keywords": [
            "Creative computing",
            "Generative artificial intelligence",
            "Product",
            "Transformational Creativity"
        ],
        "subject_areas": [
            "Experimental and Cognitive Psychology"
        ]
    },
    {
        "title": "Evaluating Cyber Security Dashboards for Smart Cities and Buildings: Enhancing User Modeling with LLMs",
        "authors": "Zhao H.",
        "journal": "ACM International Conference Proceeding Series",
        "doi": "10.1145/3664476.3670943",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200371526",
        "scopus_id": "85200371526",
        "abstract": "Designing effective cybersecurity visualization has become a crucial component of cyber defense strategies in many domains and industrial environments. Human behaviour, modeling and input are major aspects of designing visualization systems. Yet, the task of evaluating these developed visualization systems is both time-consuming and challenging, and it is often prone to cases where user evaluation is limited owing to a lack of different stakeholders and end users during the design process. Recognizing the potential of advanced Generative Artificial Intelligence and Large Language Models (LLMs), our study aims to explore their capabilities in evaluating web-based security visualization tools and dashboards, particularly in the context of smart cities and buildings. We study and compare the feasibility of using various LLMs available today, for conducting usability testing, serving as an additional resource given the limited availability of human participants. In particular, we focus on three different LLMs: Bing Chat, ChatGPT-4 and ChatGPT-4o. While each had its strengths and drawbacks, our findings revealed that the results obtained had a strong correlation with human test subjects. LLMs can be a valuable aid during evaluation, by offering in-depth insights and evaluations, tailored to the specific requirements of smart buildings, cities and automation cybersecurity. Moreover, our research and findings also reveal that LLMs can similarly be used for the evaluation of a wide range of other visual systems for industrial environments.",
        "author_keywords": [
            "LLM",
            "Security Visualization",
            "Smart City",
            "Usability Testing"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Networks and Communications",
            "Computer Vision and Pattern Recognition",
            "Software"
        ]
    },
    {
        "title": "Energy efficiency security in urban areas: Challenges and implementation",
        "authors": "Huang J.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2024.105380",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191654290",
        "scopus_id": "85191654290",
        "abstract": "In this paper, we explore the transformative potential of data-driven methodologies in the intricate landscape of urban energy transactions, with a keen focus on enhancing decision-making intelligence, amplifying the integration of renewable energy sources, and fostering active community engagement. A pivotal contribution to this research lies in the introduction of an innovative Intrusion Detection System (IDS) fortified by the robust capabilities of deep evolving convolutional Generative Adversarial Networks (GANs). This novel security measure is designed to fortify urban energy transactions against potential cyber threats, ensuring the integrity and reliability of the energy infrastructure. Furthermore, our study introduces a groundbreaking hybridization of the Bat Algorithm (BA) and Teaching-Learning-Based Optimization (TLBO) for the optimization of GAN model training. This fusion of optimization techniques enhances the efficiency and accuracy of the training process, elevating the reliability of the generated models within the context of urban energy management. To validate and demonstrate the practical applicability of these innovations, we deploy them on the real-time dataset of a smart city's digital twin. This implementation serves as a tangible proof of concept, offering valuable insights into the performance and adaptability of the proposed approaches within real-world urban energy scenarios. As the findings unfold, it becomes evident that our research significantly contributes to the evolution of urban energy management, providing a robust foundation for the development of secure, resilient, and community-centric smart city energy systems. Through these advancements, we pave the way for a sustainable urban future where energy transactions are not only efficient but also secure and inclusive, aligning with the broader goals of smart city development.",
        "author_keywords": [
            "Convolutional GAN",
            "Data-driven approaches",
            "Intrusion detection system",
            "Renewable energy integration",
            "Smart decision making",
            "Urban energy transactions"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Smart infrastructure design: Machine learning solutions for securing modern cities",
        "authors": "Shuhan W.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2024.105439",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190889519",
        "scopus_id": "85190889519",
        "abstract": "In the realm of securing smart cities against emerging cyber threats, this research encompasses three distinct yet interconnected initiatives. First, a pioneering data architecture design leveraging CycleGAN is proposed to counteract False Data Injection Attacks (FDIA). By cyclically transforming data distributions, CycleGAN ensures the integrity and reliability of smart city information, fortifying against malicious manipulations. Second, an innovative Internet of Things (IoT) concept is introduced, aiming to enhance real-time monitoring and context-aware threat detection within Intrusion Detection Systems (IDS). Harnessing the wealth of data generated by IoT devices, this concept provides a comprehensive understanding of network activities, fostering adaptive responses to emerging threats. Lastly, the research delves into the development of a novel IDS hyperparameter adjusting system. This system integrates the strengths of Biogeography-Based Optimization (BBO) and Whale Optimization Algorithm (WOA) to fine-tune IDS configuration parameters. Drawing inspiration from biogeographical principles and collaborative whale behavior, the hybrid optimization system balances exploration and exploitation, adapting the IDS to diverse network environments. Together, these initiatives represent a holistic approach to fortifying smart cities through cutting-edge data architecture, IoT-driven threat detection, and optimized IDS configurations, contributing to the resilience and cybersecurity of modern urban landscapes.",
        "author_keywords": [
            "CycleGAN",
            "False data injection attacks (FDIA)",
            "Internet of things (IOT)",
            "Intrusion Detection Systems (IDS)",
            "Smart city cybersecurity"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Improving Conversational User Interfaces for Citizen Complaint Management through enhanced Contextual Feedback",
        "authors": "Karren K.",
        "journal": "Proceedings of the 6th Conference on ACM Conversational User Interfaces, CUI 2024",
        "doi": "10.1145/3640794.3665562",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85199501047",
        "scopus_id": "85199501047",
        "abstract": "As cities transform, disrupting citizens' lives, their participation in urban development is often undervalued despite its importance. Citizen complaint systems exist but are often limited in fostering meaningful dialogue with municipalities. Meanwhile, smart cities aim to improve living standards, efficiency, and sustainability by integrating digital twins with physical infrastructures, potentially enhancing transparency and enriching communication between cities and their inhabitants with real-time data. Complementing these developments, technologies realizing Conversational User Interfaces (CUIs) are becoming more capable in providing a conversational and feedback-oriented approach such as complaint management processes. The improvement of CUIs for citizen complaint management through enhanced contextual feedback is explored in this work. The term contextual feedback has been developed and defined as all information (for example, background, conditions, explanations, timelines, and the existence of similar complaints) related to a complaint and or the underlying problem that could potentially be relevant for the user. The solution proposed in this paper gathers data from users about their issues via a CUI, which subsequently queries various data sources to obtain relevant contextual information. Following this, a Large Language Model processes the collected data to produce the corresponding feedback. In the study, a static CUI without contextual data as the baseline has been compared to a CUI that includes contextual data, analyzing their impact on pragmatic and hedonic quality, reuse intention, and potential influence on the citizens' trust in their municipality. The study has been conducted in cooperation with the German municipality of Wadgassen. The good performance of the baseline system shows the general potential of LLMs in the citizen complaint domain even without data sources. The results show that contextual feedback performed better overall, with significant improvements in the pragmatic and hedonic quality, attractiveness, reuse intention, feeling that the complaint is taken seriously, and the citizens' trust in their municipality.",
        "author_keywords": [
            "Citizen Engagement",
            "Context Information",
            "Conversational UI",
            "Smart City"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Software"
        ]
    },
    {
        "title": "Traffic trajectory generation via conditional Generative Adversarial Networks for transportation Metaverse",
        "authors": "Kong X.",
        "journal": "Applied Soft Computing",
        "doi": "10.1016/j.asoc.2024.111690",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85192244196",
        "scopus_id": "85192244196",
        "abstract": "The transportation Metaverse, by integrating real and virtual vehicular networks, brings significant benefits to the development of smart cities. However, the difficulty and high cost of conducting large-scale traffic and driving simulations in the transportation Metaverse via realistic data collection and fusion from the physical world directly result in the lack of spatial–temporal traffic data and privacy concerns, which significantly hinder the development of the transportation Metaverse. Hence, in these situations, it becomes essential to produce high-quality, large-scale trajectory data to support relevant applications. However, the deficiency of data-driven method is the heavy dependence on high-quality historical data. Prior knowledge can help reduce learning difficulties and overfitting problems with small amounts of data. In our study, we use a hybrid framework, the Travel Demand Conditioning Generative Adversarial Network (TD-GAN), which combines data-driven and knowledge-driven approaches to address the issue of traffic trajectory generation. First, we employ a conditional mechanism to incorporate prior knowledge of travel demand to reduce learning difficulties. Second, non-standard convolutional module and multi-headed self-attention module are developed to capture spatial–temporal correlations. The experimental results show that our model outperforms the baseline models.",
        "author_keywords": [
            "Conditional adversarial generative networks",
            "Prior knowledge",
            "Spatial–temporal data",
            "Traffic trajectory generation",
            "Transportation metaverse"
        ],
        "subject_areas": [
            "Software"
        ]
    },
    {
        "title": "SaReGAN: a salient regional generative adversarial network for visible and infrared image fusion",
        "authors": "Gao M.",
        "journal": "Multimedia Tools and Applications",
        "doi": "10.1007/s11042-023-14393-2",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85146862705",
        "scopus_id": "85146862705",
        "abstract": "Multispectral image fusion plays a crucial role in smart city environment safety. In the domain of visible and infrared image fusion, object vanishment after fusion is a key problem which restricts the fusion performance. To address this problem, a novel Salient Regional Generative Adversarial Network GAN (SaReGAN) is presented for infrared and VIS image fusion. The SaReGAN consists of three parts. In the first part, the salient regions of infrared image are extracted by visual saliency map and the information of these regions is preserved. In the second part, the VIS image, infrared image and salient information are merged thoroughly in the generator to gain a pre-fused image. In the third part, the discriminator attempts to differentiate the pre-fused image and VIS image, in order to learn details from VIS image based on the adversarial mechanism. Experimental results verify that the SaReGAN outperforms other state-of-the-art methods in quantitative and qualitative evaluations.",
        "author_keywords": [
            "Generative adversarial network",
            "Image fusion",
            "Salient region",
            "Smart city",
            "Visible and infrared image"
        ],
        "subject_areas": [
            "Software",
            "Media Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Towards a Deep Automatic Generation of Figure-ground Maps",
        "authors": "Arzoumanidis L.",
        "journal": "ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",
        "doi": "10.5194/isprs-annals-X-4-W5-2024-33-2024",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85198620463",
        "scopus_id": "85198620463",
        "abstract": "Figure-ground maps play a key role in many disciplines where urban planning or analysis is involved. In this context, the automatic generation of such maps with respect to certain requirements and constraints is an important task. This paper presents a first step towards a deep automatic generation of figure-ground maps where the built density of the generated scenes is controlled and taken into account. This is preformed building upon a Geographic Data Translation model which has been applied to generate less available geospatial features, e.g. building footprints, from more widely available geospatial data, e.g. street network data, using conditional Generative Adversarial Networks. A novel processing approach is introduced to incorporate the population density and the built density accordingly. Furthermore, the impact of both the level of detail of the street network, i.e. its sparsity or density, and the spatial resolution of the training data on the generated figure-ground maps has been investigated. The generated maps and the qualitative results reveal an obvious impact of these parameters on the layout of built and unbuilt areas. Our approach paves the way for the expansion of existing districts by figure-ground maps of future neighbourhoods considering factors such as density and further parameters which will be subject of future work.",
        "author_keywords": [
            "Built Density",
            "Figure-ground Maps",
            "Generative Adversarial Networks",
            "Geographical Data Translation",
            "Urban Morphology",
            "Volunteered Geographic Information"
        ],
        "subject_areas": [
            "Instrumentation",
            "Environmental Science (miscellaneous)",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Development of the AI Implementation Framework in Taipei City",
        "authors": "Lee D.",
        "journal": "ACM International Conference Proceeding Series",
        "doi": "10.1145/3657054.3657065",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195321103",
        "scopus_id": "85195321103",
        "abstract": "Taipei City has been experimenting with the use of Artificial Intelligence (AI) tools to enhance its smart capabilities, aiming to increase citizen satisfaction. This initiative is part of the city’s Smart City Proof of Concept (PoC) projects, which have been progressively rolled out since 2015. Most of these projects incorporate AI tools or algorithms, such as the combination of the Internet of Things (IoT) with AI to form AIoT, or the application of Large Language Models (LLMs). The objective is to leverage the latest technological developments to achieve a smarter Taipei. This study analyzes the execution of 302 PoC projects, categorizing them into 22 technological segments that together form an AI framework for smart city construction applications. This framework corresponds to 15 major issues of concern to Taipei’s residents, with the potential to address or mitigate 13 of them. According to the IMD Smart City Index Report 2023, Taipei’s smart city rating improved from a B in 2021 to an A in 2023, indicating progress. The results demonstrate that the AI framework derived from dissecting multiple PoC projects can effectively enhance the city’s smart construction ratings. This framework, aligned with major municipal concerns, proposes solutions driven by AI, guiding Taipei’s digital transformation into a smarter city and enabling its citizens to enjoy an improved quality of life.",
        "author_keywords": [
            "AI",
            "AIoT",
            "Implementation framework",
            "IoT",
            "LLM",
            "PoC"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Networks and Communications",
            "Computer Vision and Pattern Recognition",
            "Software"
        ]
    },
    {
        "title": "AI Impact on Health Equity for Marginalized, Racial, and Ethnic Minorities",
        "authors": "Iloanusi N.J.",
        "journal": "ACM International Conference Proceeding Series",
        "doi": "10.1145/3657054.3657152",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195299835",
        "scopus_id": "85195299835",
        "abstract": "Predictive analytics technologies like machine learning, AI and Generative AI models like Large Language Models (LLMs), have garnered enthusiasm for their potential to improve healthcare services in smart cities. However, these rapidly developing intelligent agents that guides the healthcare decisions may also risk exacerbating health inequities along racial, ethnic, gender, and socioeconomic lines, reflecting systemic discrimination ingrained within healthcare practices. Flawed or injudiciously applied AI systems could improperly restrict opportunities and provide substandard care for minority groups by propagating historical patterns of prejudice encoded within limited training datasets. These advanced intelligent technologies can hinder the sustainable health solutions for smart cities. This study examines intelligent AI models and applications in healthcare settings, with a focus on assessing impacts on marginalized and disadvantaged populations. Comprehensive scholarly database searches identified 45 relevant studies investigating issues on algorithmic bias, lack of diverse training data, and discrimination risks linked to healthcare AI systems. The review finds most applications still lack adequate safeguards to prevent discrimination against vulnerable populations. Through the review of these systems, we propose an integrated inclusive smart health model that considers both technical interventions as well as broader participatory and ethical approaches. Realizing AI’s fullest potential to meaningfully advance health justice requires not only algorithmic adjustments to mitigate bias, and efforts to improve diversity of training data, transparent analysis frameworks, and best practices for ensuring just AI systems in healthcare, but also a human-centered commitment to thoughtful, inclusive development approaches that center the needs and priorities of communities impacted by health disparities from the outset.",
        "author_keywords": [
            "AI and healthcare",
            "Algorithmic Bias",
            "Health Equity",
            "Machine Learning in health decision support",
            "Trustworthy AI"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Networks and Communications",
            "Computer Vision and Pattern Recognition",
            "Software"
        ]
    },
    {
        "title": "Generating Urban Road Networks with Conditional Diffusion Models",
        "authors": "Gu X.",
        "journal": "ISPRS International Journal of Geo-Information",
        "doi": "10.3390/ijgi13060203",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85197952100",
        "scopus_id": "85197952100",
        "abstract": "The auto-generation of urban roads can greatly improve efficiency and productivity in urban planning and designing. However, it has also raised concerns amongst researchers over the past decade. In this paper, we present an image-based urban road network generation framework using conditional diffusion models. We first trained a diffusion model capable of generating road images with similar characteristics to the ground truth using four context factors. Then, we used the trained model as the generator to synthesize road images conditioned in a geospatial context. Finally, we converted the generated road images into road networks with several post-processes. The experiments conducted in five cities of the United States showed that our model can generate reasonable road networks, maintaining the layouts and styles of real examples. Moreover, our model has the ability to show the obstructive effect of geographic barriers on urban roads. By comparing models with different context factors as input, we find that the model that considers all four factors generally performs the best. The most important factor in guiding the shape of road networks is intersections, implying that the development of urban roads is not only restricted by the natural environment but is more strongly influenced by human design.",
        "author_keywords": [
            "diffusion models",
            "generative models",
            "geospatial context",
            "road network generation"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Evaluating Urban Green Space Inequity to Promote Distributional Justice in Portland, Oregon",
        "authors": "Elderbrock E.",
        "journal": "Land",
        "doi": "10.3390/land13060720",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85197306363",
        "scopus_id": "85197306363",
        "abstract": "Access and exposure to urban green space—the combination of parks and vegetative cover in cities—are associated with various health benefits. As urban green space is often unequally distributed throughout cities, understanding how it is allocated across socio-demographic populations can help city planners and policy makers identify and address urban environmental justice and health equity issues. To our knowledge, no studies have yet combined assessments of park quality, park availability, and green cover to inform equitable urban green space planning. To this end, we developed a comprehensive methodology to identify urban green space inequities at the city scale and applied it in Portland, OR, USA. After auditing all public parks in Portland and gathering green cover data from publicly accessible repositories, we used a suite of statistical tests to evaluate distribution of parks and green cover across Census block groups, comprising race, ethnicity, income, and educational attainment characteristics. Right-of-way tree canopy cover was the most significant urban green space inequity identified in bivariate analysis (rs = −0.73). Spatial autoregressive models identified that right-of-way, private, and overall tree canopy cover (Nagelkerke pseudo-R2 = 0.66, 0.77, and 0.67, respectively) significantly decreased with the proportion of minoritized racial population and increased with median income. The results were then used to identify priority locations for specific urban green space investments. This research establishes a process to assess intra-urban green space inequities, as well as identify data-informed and spatially explicit planning priorities to promote health equity and environmental justice.",
        "author_keywords": [
            "built environment",
            "environmental justice",
            "health equity",
            "neighborhood characteristics",
            "parks",
            "public health",
            "recreation",
            "spatial modeling",
            "urban forestry",
            "urban planning"
        ],
        "subject_areas": [
            "Global and Planetary Change",
            "Ecology",
            "Nature and Landscape Conservation"
        ]
    },
    {
        "title": "Multivariate Hydrological Modeling Based on Long Short-Term Memory Networks for Water Level Forecasting †",
        "authors": "Renteria-Mena J.B.",
        "journal": "Information (Switzerland)",
        "doi": "10.3390/info15060358",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196879982",
        "scopus_id": "85196879982",
        "abstract": "In the Department of Chocó, flooding poses a recurrent and significant challenge due to heavy rainfall and the dense network of rivers characterizing the region. However, the lack of adequate infrastructure to prevent and predict floods exacerbates this situation. The absence of early warning systems, the scarcity of meteorological and hydrological monitoring stations, and deficiencies in urban planning contribute to the vulnerability of communities to these phenomena. It is imperative to invest in flood prediction and prevention infrastructure, including advanced monitoring systems, the development of hydrological prediction models, and the construction of hydraulic infrastructure, to reduce risk and protect vulnerable communities in Chocó. Additionally, raising public awareness of the associated risks and encouraging the adoption of mitigation and preparedness measures throughout the population are essential. This study introduces a novel approach for the multivariate prediction of hydrological variables, specifically focusing on water level forecasts for two hydrological stations along the Atrato River in Colombia. The model, utilizing a specialized type of recurrent neural network (RNN) called the long short-term memory (LSTM) network, integrates data from hydrological variables, such as the flow, precipitation, and level. With a model architecture featuring four inputs and two outputs, where flow and precipitation serve as inputs and the level serves as the output for each station, the LSTM model is adept at capturing the complex dynamics and cross-correlations among these variables. Validation involves comparing the LSTM model’s performance with linear and nonlinear Autoregressive with Exogenous Input (NARX) models, considering factors such as the estimation error and computational time. Furthermore, this study explores different scenarios for water level prediction, aiming to utilize the proposed approach as an effective flood early warning system.",
        "author_keywords": [
            "data analysis",
            "flood risk assessment",
            "nonlinear autoregressive model",
            "prediction",
            "recurrent neural network",
            "time-series analysis"
        ],
        "subject_areas": [
            "Information Systems"
        ]
    },
    {
        "title": "Chat3D: Interactive understanding 3D scene-level point clouds by chatting with foundation model for urban ecological construction",
        "authors": "Chen Y.",
        "journal": "ISPRS Journal of Photogrammetry and Remote Sensing",
        "doi": "10.1016/j.isprsjprs.2024.04.024",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85192327316",
        "scopus_id": "85192327316",
        "abstract": "With the artificial intelligence technology development boom, large language models are demonstrating their potential in comprehension and creativity. Large language models such as GPT-4 and Gemini have been able to powerfully study for various professional-level exams. However, as a language model itself, its powerful comprehension can only be reflected in text sequences. Currently, although videos can be generated through the connection between 3D point clouds and large language models, there is currently no prompt project that directly interacts with one-dimensional through attribute calculation results. The point cloud data is also rich in information that can support various tasks of urban construction. For scene-level point cloud data, there has been a lot of research done on semantic segmentation, target detection, and other tasks. However, it is usually difficult to provide direct help to scene construction from the perception results. This paper presents a method for applying large language models to urban ecological construction by combining the results of 3D point cloud semantic segmentation. The objective is to integrate the prior knowledge and creative capabilities of Large Language Models (LLMs) within urban development with the outcomes derived from point cloud semantic segmentation results. This integration aims to establish an interactive point cloud intelligent analysis system, tailored for aiding decision-making processes in urban ecological civilization construction, thus presenting innovative perspectives for the advancement of smart city development.",
        "author_keywords": [
            "Large language model interact",
            "Point cloud understanding",
            "Prompt engineering",
            "Thought chain",
            "Urban ecological construction"
        ],
        "subject_areas": [
            "Atomic and Molecular Physics, and Optics",
            "Engineering (miscellaneous)",
            "Computer Science Applications",
            "Computers in Earth Sciences"
        ]
    },
    {
        "title": "Enhancing human–robot communication with a comprehensive language-conditioned imitation policy for embodied robots in smart cities",
        "authors": "Ju Z.",
        "journal": "Computer Communications",
        "doi": "10.1016/j.comcom.2024.04.029",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85192231859",
        "scopus_id": "85192231859",
        "abstract": "Integrating Embodied Robots into a smart city's networked system can significantly enhance the city's operational efficiency. These robots can be connected to the city's network, receiving and transmitting data in real time for enhancing human–robot communications. Language-conditioned robot behavior plays a vital role in executing complex tasks by associating human commands or instructions with perception and actions. However, most language-conditioned policy-related research is limited to specific datasets and cannot generalize across different environments. In this study, we propose a novel imitation learning framework tailored for language-conditioned robotic tasks. Our framework includes specialized encoders designed for various benchmarks and utilizes two distinct models: the Transformer and Diffusion models. We rigorously evaluate this framework in three different robotic environments. Our findings indicate that the framework consistently delivers superior performance across multiple domains. Notably, we observe that the Transformer model is particularly effective in managing tasks with long trajectories, whereas the Diffusion model demonstrates enhanced proficiency in generating trajectories from limited training datasets. Our approach showcases remarkable generalization capabilities across a range of tasks and achieves significantly higher success rates in task completion.",
        "author_keywords": [
            "Embodied robot",
            "Human–robot communication",
            "Imitation learning",
            "Neural network",
            "Smart city"
        ],
        "subject_areas": [
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "How can generative AI help in different parts of research? An experiment study on smart cities’ definitions and characteristics",
        "authors": "Dashkevych O.",
        "journal": "Technology in Society",
        "doi": "10.1016/j.techsoc.2024.102555",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191017400",
        "scopus_id": "85191017400",
        "abstract": "Artificial intelligence (AI) engines, such as ChatGPT, InferKit, and DeepAI, are very popular today and new AI engines, such as Google Bard, Chinchilla AI DeepMind, and GPT-4, constantly emerge. However, question remains how these new data management tools can assist scholars in improving the research design and implementation. In an attempt to answer this question, we focus on one particular research field – definition and identification of smart cities (SCs), – and compare the answers provided by different AI engines with the answers given in a sequence of research papers, prepared without the use of AI and recently published by these authors. In particular, the following aspects of the original studies were re-analysed here using the AI input: a) problem definition; b) summary of current knowledge; c) identification of unknowns; d) research strategy, and e) recommendations for research and practice. As the study reveals, the recommendations of AI engines are, at times, inconsistent and data sources cited are often inaccurate. However, as such engines scan multiple open sources and retrieve relevant information, they can help to bridge gaps in the summary of background studies and streamline the research design, by supplementing missing or overlooked information.",
        "author_keywords": [
            "Artificial intelligence (AI)",
            "Research design",
            "Smart cities (SCs)"
        ],
        "subject_areas": [
            "Human Factors and Ergonomics",
            "Business and International Management",
            "Education",
            "Sociology and Political Science"
        ]
    },
    {
        "title": "Data augmentation strategies to improve text classification: a use case in smart cities",
        "authors": "Bencke L.",
        "journal": "Language Resources and Evaluation",
        "doi": "10.1007/s10579-023-09685-w",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85168569041",
        "scopus_id": "85168569041",
        "abstract": "Text classification is a very common and important task in Natural Language Processing. In many domains and real-world settings, a few labeled instances are the only resource available to train classifiers. Models trained on small datasets tend to overfit and produce inaccurate results – Data augmentation (DA) techniques come as an alternative to minimize this problem. DA generates synthetic instances that can be fed to the classification algorithm during training. In this article, we explore a variety of DA methods, including back translation, paraphrasing, and text generation. We assess the impact of the DA methods over simulated low-data scenarios using well-known public datasets in English with classifiers built fine-tuning BERT models. We describe the means to adapt these DA methods to augment a small Portuguese dataset containing tweets labeled with smart city dimensions (e.g., transportation, energy, water, etc.). Our experiments showed that some classes were noticeably improved by DA – with an improvement of 43% in terms of F1 compared to the baseline with no augmentation. In a qualitative analysis, we observed that the DA methods were able to preserve the label but failed to preserve the semantics in some cases and that generative models were able to produce high-quality synthetic instances.",
        "author_keywords": [
            "Data augmentation",
            "Low-resources",
            "Smart cities",
            "Text classification"
        ],
        "subject_areas": [
            "Language and Linguistics",
            "Education",
            "Linguistics and Language",
            "Library and Information Sciences"
        ]
    },
    {
        "title": "POI GPT: Extracting POI Information from Social Media Text Data",
        "authors": "Kim H.",
        "journal": "International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",
        "doi": "10.5194/isprs-archives-XLVIII-4-W10-2024-113-2024",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196748819",
        "scopus_id": "85196748819",
        "abstract": "Point of Interest (POI) is an important intermediary connecting geo data and text data in smart cities, widely used to extract and identify urban functional areas. While computer uses numerical coordinates, human uses places names or addresses to find location, leading to spatial-semantic ambiguities. However, traditional methods of extracting POIs are time-consuming and costly, and has the limitation of the lack of integration of functionalities such as information extraction(IE), information searching. Also, previous models have low accessibility and high barriers for users. With the advent of Large Language Models(LLMs) we propose a method that connects LLM models and POI information based on social media text data. By employing two steps, named entities recognition(NER) and POI information searching, we introduce POI GPT, the specialized model for providing precise location of POIs in social media text data. We compared its results with those obtained by human experts, NER model and zero-shot prompts. The findings show that our model effectively found the POI and precise location from social media text data. In result, POI GPT is a effective model that solves the existing POI extraction problems. We provide new extraction technique of POI GPT which is a new paradigm in traditional urban research methodologies and be actively utilized in urban studies in the future.",
        "author_keywords": [
            "ChatGPT",
            "Large Language Model(LLM)",
            "Named Entity Recognition(NER)",
            "Point of Interest(POI)",
            "Social Media"
        ],
        "subject_areas": [
            "Information Systems",
            "Geography, Planning and Development"
        ]
    },
    {
        "title": "Role of ChatGPT in smart cities",
        "authors": "Freeda A.R.",
        "journal": "Applications, Challenges, and the Future of ChatGPT",
        "doi": "10.4018/979-8-3693-6824-4.ch010",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196885829",
        "scopus_id": "85196885829",
        "abstract": "In smart cities, generative artificial intelligence (AI) models such as ChatGPT have become revolutionary tools in many respects, chiefly due to their ability to process and communicate natural language. These artificial intelligence (AI) systems have greatly enhanced communication and problem-solving skills, leading to increased productivity and efficiency in a variety of fields, including healthcare, education, environmental monitoring, public health, smart grid management, traffic management, citizen engagement, environmental monitoring, and environmental monitoring. This study looks at ChatGPT's and similar Generative AI's changing role in smartcity contexts. It highlights the need for ethical frameworks and regulatory rules by examining the difficulties in putting them into practice. Concurrently, it highlights the enormous potential these technologies provide, from promoting inclusivity to igniting innovation, forming a future in which artificial intelligence augments human capabilities and fosters peaceful coexistence between sentient machines and people.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Score-based Graph Learning for Urban Flow Prediction",
        "authors": "Wang P.",
        "journal": "ACM Transactions on Intelligent Systems and Technology",
        "doi": "10.1145/3655629",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191366772",
        "scopus_id": "85191366772",
        "abstract": "Accurate urban flow prediction (UFP) is crucial for a range of smart city applications such as traffic management, urban planning, and risk assessment. To capture the intrinsic characteristics of urban flow, recent efforts have utilized spatial and temporal graph neural networks to deal with the complex dependence between the traffic in adjacent areas. However, existing graph neural network based approaches suffer from several critical drawbacks, including improper graph representation of urban traffic data, lack of semantic correlation modeling among graph nodes, and coarse-grained exploitation of external factors. To address these issues, we propose DiffUFP, a novel probabilistic graph-based framework for UFP. DiffUFP consists of two key designs: (1) a semantic region dynamic extraction method that effectively captures the underlying traffic network topology, and (2) a conditional denoising score-based adjacency matrix generator that takes spatial, temporal, and external factors into account when constructing the adjacency matrix rather than simply concatenation in existing studies. Extensive experiments conducted on real-world datasets demonstrate the superiority of DiffUFP over the state-of-the-art UFP models and the effect of the two specific modules.",
        "author_keywords": [
            "Flow prediction",
            "graph neural networks",
            "score-based model",
            "spatio-temporal learning",
            "urban computing"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Enhanced Security in Smart City GAN-Based Intrusion Detection Systems in WSNs",
        "authors": "Sirigineedi M.",
        "journal": "Enhancing Security in Public Spaces Through Generative Adversarial Networks (GANs)",
        "doi": "10.4018/9798369335970.ch012",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195754783",
        "scopus_id": "85195754783",
        "abstract": "As intelligent urban centers continue to evolve, the reliance on wireless type sensory networks (WSNs) for data samples collections and message interaction will become paramount. However, the increasingly complexity of the networks may demand robust security measures to safeguarding against potential intrusions. In response, this chapter introduces IntelligentGuard, a novelistic intrusion identification system leverages generative based adversarial networks (GANs) for enhancement in security in WSNs within intelligent urban centers. IntelligentGuard will employs machine learning-driven techniques, including supervises learning algorithms such as support vector supportive machines (SVMs) and decision-based trees, to discern normal network behavior from anomalous patterns, thus fortifying the WSN against various intrusion scenarios. The proposed system's GAN-based architecture not only enhances identification accuracy but also adapts dynamically to evolving threat landscapes.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Enhancing security in public spaces through Generative Adversarial Networks (GANs)",
        "authors": "Ponnusamy S.",
        "journal": "Enhancing Security in Public Spaces Through Generative Adversarial Networks (GANs)",
        "doi": "10.4018/9798369335970",
        "publication_date": "2024",
        "document_type": "Book",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195732124",
        "scopus_id": "85195732124",
        "abstract": "As the demand for data security intensifies, the vulnerabilities become glaring, exposing sensitive information to potential threats. In this tumultuous landscape, Generative Adversarial Networks (GANs) emerge as a groundbreaking solution, transcending their initial role as image generators to become indispensable guardians of data security. Within the pages of Enhancing Security in Public Spaces Through Generative Adversarial Networks (GANs), readers are guided through the intricate world of GANs, unraveling their unique design and dynamic adversarial training. The book presents GANs not merely as a technical marvel but as a strategic asset for organizations, offering a comprehensive solution to fortify cybersecurity, protect data privacy, and mitigate the risks associated with evolving cyber threats. It navigates the ethical considerations surrounding GANs, emphasizing the delicate balance between technological advancement and responsible use. Tailored for a diverse audience, the book speaks directly to organizations, researchers, government agencies, cybersecurity professionals, data privacy advocates, AI specialists, educational institutions, regulatory bodies, cybersecurity solution providers, and the general public. It provides actionable insights on integrating GANs into various sectors, offering a roadmap for leveraging their capabilities in healthcare, finance, smart cities, and beyond. Dive into the future of data security, armed with the knowledge and practical applications presented in this transformative book, as it unfolds the potential of GANs to safeguard our digital infrastructure in an era of unprecedented challenges.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Federated Learning in Large Model Era: Vision-Language Model for Smart City Safety Operation Management",
        "authors": "Li Z.",
        "journal": "WWW 2024 Companion - Companion Proceedings of the ACM Web Conference",
        "doi": "10.1145/3589335.3651939",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85194459323",
        "scopus_id": "85194459323",
        "abstract": "With the tremendous success of large language models such as ChatGPT, artificial intelligence has entered a new era of large models. Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains. In this paper, we tackle the problem of building large vision-language intelligent models for specific industrial domains by leveraging the general large models and federated learning. We compare the challenges faced by federated learning in the era of small models and large models from different dimensions, and propose a technical framework for federated learning in the era of large models.Specifically, our framework mainly considers three aspects: heterogeneous model fusion, flexible aggregation methods, and data quality improvement. Based on this framework, we conduct a case study of leading enterprises contributing vision-language data and expert knowledge to city safety operation management. The preliminary experiments show that enterprises can enhance and accumulate their intelligence capabilities through federated learning, and jointly create an intelligent city model that provides high-quality intelligent services covering energy infrastructure security, residential community security and urban operation management.",
        "author_keywords": [
            "Federated learning",
            "Large model",
            "Multimodal model"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Software"
        ]
    },
    {
        "title": "UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web",
        "authors": "Yan Y.",
        "journal": "WWW 2024 - Proceedings of the ACM Web Conference",
        "doi": "10.1145/3589334.3645378",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85194104842",
        "scopus_id": "85194104842",
        "abstract": "Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.",
        "author_keywords": [
            "language-image pretraining",
            "spatio-temporal data",
            "urban computing"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Software"
        ]
    },
    {
        "title": "Role of net-zero renewable-based transportation systems in smart cities toward enhancing cultural diversity: Realistic model in digital twin",
        "authors": "Li B.",
        "journal": "Sustainable Energy Technologies and Assessments",
        "doi": "10.1016/j.seta.2024.103715",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85189756385",
        "scopus_id": "85189756385",
        "abstract": "This paper introduces an advanced framework for energy and data transactions, aiming to optimize the sustainable management in smart cities. The prominence of smart cities in power systems has grown recently, offering comprehensive monitoring and accessibility. However, this advancement also brings about increased susceptibility to cyber-attacks. To address this concern, we present an integrated smart city encompassing the smart grid (SG), transportation comprising subway and vehicles, microgrid (MG), and energy hub (EH). Within this proposed model, we employ an enhanced intrusion detection system (IDS) utilizing Generative Adversarial Networks (GAN) through deep learning to fortify the safety of information transactions inside the smart city. This involves incorporating a security layer into the smart city design, effectively thwarting cyber hackers' attempts to access system information. This paper develops an efficient energy management schedule. To achieve this, we introduce a novel optimization method deploying the honey bee mating optimization technique for the optimum allocation of charging stations. The grid randomness is addressed using the point estimate method (PEM) with a 2 m-scheme. The validity and effectiveness of the proposed framework are proved, showcasing its ability to enhance the security and efficiency of smart city operations. This research advocates for the application of a Cyber-Physical Digital Twin to explore optimal energy management within a Smart City while ensuring a safe and secure framework. The proposed methodology involves the creation of a comprehensive digital replica incorporating real-time data, cybersecurity measures, optimization algorithms, and machine learning. This digital twin serves as a dynamic simulation environment, enabling stakeholders to analyze, simulate, and refine energy management strategies in a risk-free setting. The study emphasizes the importance of continuous improvement, iterative testing, and adaptability to real-world data for ensuring the relevance and effectiveness of the digital twin in guiding Smart Cities toward efficient, secure, and resilient energy management.",
        "author_keywords": [
            "Cybersecurity",
            "Digital Twin",
            "Energy Management",
            "Intrusion Detection System",
            "Smart cities"
        ],
        "subject_areas": [
            "Renewable Energy, Sustainability and the Environment",
            "Energy Engineering and Power Technology"
        ]
    },
    {
        "title": "A Generative Artificial Intelligence Using Multilingual Large Language Models for ChatGPT Applications",
        "authors": "Tuan N.T.",
        "journal": "Applied Sciences (Switzerland)",
        "doi": "10.3390/app14073036",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85192535828",
        "scopus_id": "85192535828",
        "abstract": "ChatGPT plays significant roles in the third decade of the 21st Century. Smart cities applications can be integrated with ChatGPT in various fields. This research proposes an approach for developing large language models using generative artificial intelligence models suitable for small- and medium-sized enterprises with limited hardware resources. There are many generative AI systems in operation and in development. However, the technological, human, and financial resources required to develop generative AI systems are impractical for small- and medium-sized enterprises. In this study, we present a proposed approach to reduce training time and computational cost that is designed to automate question–response interactions for specific domains in smart cities. The proposed model utilises the BLOOM approach as its backbone for using generative AI to maximum the effectiveness of small- and medium-sized enterprises. We have conducted a set of experiments on several datasets associated with specific domains to validate the effectiveness of the proposed model. Experiments using datasets for the English and Vietnamese languages have been combined with model training using low-rank adaptation to reduce training time and computational cost. In comparative experimental testing, the proposed model outperformed the ‘Phoenix’ multilingual chatbot model by achieving a 92% performance compared to ‘ChatGPT’ for the English benchmark.",
        "author_keywords": [
            "chatbot",
            "ChatGPT",
            "generative AI",
            "language comprehension",
            "large language models",
            "multilingual language models",
            "support systems",
            "technological determinism"
        ],
        "subject_areas": [
            "Materials Science (all)",
            "Instrumentation",
            "Engineering (all)",
            "Process Chemistry and Technology",
            "Computer Science Applications",
            "Fluid Flow and Transfer Processes"
        ]
    },
    {
        "title": "Generative AI-enabled iot applications for smart cities: Unleashing innovation and paving the way for the future",
        "authors": "Ghai A.S.",
        "journal": "Secure and Intelligent IoT-Enabled Smart Cities",
        "doi": "10.4018/979-8-3693-2373-1.ch011",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85192492682",
        "scopus_id": "85192492682",
        "abstract": "In the dynamic evolution of smart cities, the collaboration between generative artificial intelligence (AI) and internet of things (IoT) technologies is reshaping urban experiences and fostering sustainable urban development. This collaborative explores the intricate balance of dynamic resource allocation and optimization facilitated by generative AI algorithms within intelligent city IoT networks. It unfolds the transformative potential of generative design for smart city infrastructure, offering insights into energy efficiency and advanced AI processes. The chapter underscores the pivotal role of predictive analytics, behavior prediction, and cybersecurity measures in steering decision-making for optimal urban func¬tioning. Real-world case studies illuminate successful generative AI-IoT integrations, providing tangible lessons for stakeholders, and conclude by urging ongoing collaborative research to address evolving challenges and chart future directions for a more interconnected and resilient urban future. This chapter serves as a valuable contribution, providing a comprehensive exploration of the transformative potential of this collaborative paradigm.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Detection of Forest Fire Using Modified LSTM Based Feature Extraction with Waterwheel Plant Optimisation Algorithm Based VAE-GAN Model",
        "authors": "Aluri Y.K.",
        "journal": "International Journal of Safety and Security Engineering",
        "doi": "10.18280/ijsse.140202",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191979067",
        "scopus_id": "85191979067",
        "abstract": "A crucial natural resource that directly affects the ecology is forests. Forest fires have become a noteworthy problem recently as a result of both natural and man-made climatic changes. A smart city application that uses a forest fire discovery technology based on artificial intelligence is provided in order to prevent significant catastrophes. A major danger to the environment, animals, and human lives is posed by forest fires. The early detection and suppression of these fires is crucial. This work offers a thorough method for detecting forest fires using advanced deep learning (DL) algorithms. Preprocessing the forest fire dataset is the initial step in order to improve its relevance and quality. Then, to enable the model to capture the dynamic character of forest fire data, long short-term memory (LSTM) networks are used to extract useful feature from the dataset. In this work, weight optimisation in LSTM is performed using a Modified Firefly Algorithm (MFFA), which enhances the model's performance and convergence. The Variational Autoencoder Generative Adversarial Networks (VAEGAN) model is used to classify the retrieved features. Furthermore, every DL model's success depends heavily on hyperparameter optimisation. The hyperparameters of an VAEGAN model are tuned in this research using the Waterwheel Plant Optimisation Algorithm (WWPA), an optimisation technique inspired by nature. WPPA uses the idea of plant growth to properly tune the VAEGAN's parameters, assuring the network's peak fire detection performance. The outstanding accuracy (ACC) of 97.8%, precision (PR) of 97.7%, recall (RC) of 96.26%, F1-score (F1) of 97.3%, and specificity (SPEC) of 97.5% of the suggested model beats all other existing models, which is probably owing to its improved architecture and training techniques.",
        "author_keywords": [
            "forest fire",
            "long short term memory",
            "modified firefly algorithm",
            "variational autoencoder",
            "waterwheel plant optimization"
        ],
        "subject_areas": [
            "Safety, Risk, Reliability and Quality",
            "Environmental Science (all)"
        ]
    },
    {
        "title": "Multispectral Band-Aware Generation of Satellite Images across Domains Using Generative Adversarial Networks and Contrastive Learning",
        "authors": "Mahara A.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs16071154",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190270828",
        "scopus_id": "85190270828",
        "abstract": "Generative models have recently gained popularity in remote sensing, offering substantial benefits for interpreting and utilizing satellite imagery across diverse applications such as climate monitoring, urban planning, and wildfire detection. These models are particularly adept at addressing the challenges posed by satellite images, which often exhibit domain variability due to seasonal changes, sensor characteristics, and, especially, variations in spectral bands. Such variability can significantly impact model performance across various tasks. In response to these challenges, our work introduces an adaptive approach that harnesses the capabilities of generative adversarial networks (GANs), augmented with contrastive learning, to generate target domain images that account for multispectral band variations effectively. By maximizing mutual information between corresponding patches and leveraging the power of GANs, our model aims to generate realistic-looking images across different multispectral domains. We present a comparative analysis of our model against other well-established generative models, demonstrating its efficacy in generating high-quality satellite images while effectively managing domain variations inherent to multispectral diversity.",
        "author_keywords": [
            "contrastive learning",
            "domain variation",
            "generation",
            "generative adversarial networks (GANs)",
            "multispectral bands",
            "remote sensing",
            "satellite image"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Road Extraction from Remote Sensing Imagery with Spatial Attention Based on Swin Transformer",
        "authors": "Zhu X.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs16071183",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190064755",
        "scopus_id": "85190064755",
        "abstract": "Road extraction is a crucial aspect of remote sensing imagery processing that plays a significant role in various remote sensing applications, including automatic driving, urban planning, and path navigation. However, accurate road extraction is a challenging task due to factors such as high road density, building occlusion, and complex traffic environments. In this study, a Spatial Attention Swin Transformer (SASwin Transformer) architecture is proposed to create a robust encoder capable of extracting roads from remote sensing imagery. In this architecture, we have developed a spatial self-attention (SSA) module that captures efficient and rich spatial information through spatial self-attention to reconstruct the feature map. Following this, the module performs residual connections with the input, which helps reduce interference from unrelated regions. Additionally, we designed a Spatial MLP (SMLP) module to aggregate spatial feature information from multiple branches while simultaneously reducing computational complexity. Two public road datasets, the Massachusetts dataset and the DeepGlobe dataset, were used for extensive experiments. The results show that our proposed model has an improved overall performance compared to several state-of-the-art algorithms. In particular, on the two datasets, our model outperforms D-LinkNet with an increase in Intersection over Union (IoU) metrics of 1.88% and 1.84%, respectively.",
        "author_keywords": [
            "remote sensing applications",
            "road extraction",
            "Spatial MLP",
            "spatial self-attention"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Privacy-preserved learning from non-i.i.d data in fog-assisted IoT: A federated learning approach",
        "authors": "Abdel-Basset M.",
        "journal": "Digital Communications and Networks",
        "doi": "10.1016/j.dcan.2022.12.013",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85189240053",
        "scopus_id": "85189240053",
        "abstract": "With the prevalence of the Internet of Things (IoT) systems, smart cities comprise complex networks, including sensors, actuators, appliances, and cyber services. The complexity and heterogeneity of smart cities have become vulnerable to sophisticated cyber-attacks, especially privacy-related attacks such as inference and data poisoning ones. Federated Learning (FL) has been regarded as a hopeful method to enable distributed learning with privacy-preserved intelligence in IoT applications. Even though the significance of developing privacy-preserving FL has drawn as a great research interest, the current research only concentrates on FL with independent identically distributed (i.i.d) data and few studies have addressed the non-i. i.d setting. FL is known to be vulnerable to Generative Adversarial Network (GAN) attacks, where an adversary can presume to act as a contributor participating in the training process to acquire the private data of other contributors. This paper proposes an innovative Privacy Protection-based Federated Deep Learning (PP-FDL) framework, which accomplishes data protection against privacy-related GAN attacks, along with high classification rates from non-i. i.d data. PP-FDL is designed to enable fog nodes to cooperate to train the FDL model in a way that ensures contributors have no access to the data of each other, where class probabilities are protected utilizing a private identifier generated for each class. The PP-FDL framework is evaluated for image classification using simple convolutional networks which are trained using MNIST and CIFAR-10 datasets. The empirical results have revealed that PF-DFL can achieve data protection and the framework outperforms the other three state-of-the-art models with 3%–8% as accuracy improvements.",
        "author_keywords": [
            "Deep learning",
            "Federated learning",
            "Fog computing",
            "Privacy preservation",
            "Smart cities"
        ],
        "subject_areas": [
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Enhanced Dwarf Mongoose optimization algorithm with deep learning-based attack detection for drones",
        "authors": "Alsariera Y.A.",
        "journal": "Alexandria Engineering Journal",
        "doi": "10.1016/j.aej.2024.02.048",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85187777278",
        "scopus_id": "85187777278",
        "abstract": "Security in smart cities is a challenging issue in urban environments as they depend upon interconnected technologies and data for effective services. To address security challenges, smart cities implement robust cybersecurity measures, including network monitoring, encryption, and intrusion detection systems. Detecting and mitigating possible security risks in drone network B5G is a crucial aspect of ensuring reliable and safe drone operation. It is necessary to establish sophisticated and robust attack detection techniques to defend against security threats as the use of drones becomes increasingly widespread and their applications diversify. This is due to the lack of privacy and security consideration in the drone's system, including an inadequate computation capability and unsecured wireless channels to perform advanced cryptographic algorithms. Intrusion detection systems (IDS) and anomaly detection systems can identify suspicious activities and monitor network traffic, such as anomalous communication patterns or unauthorized access attempts. Therefore, the study presents an enhanced dwarf mongoose optimization algorithm with deep learning-based attack detection (EDMOA-DLAD) in Networks B5G for the purpose of Drones technique. The presented EDMOA-DLAD technique aims to recognize the attacks and classifies them on the drone network B5G. Primarily, the EDMOA-DLAD technique designs a feature selection (FS) approach using EDMOA. To detect attacks, the EDMOA-DLAD technique uses a deep variational autoencoder (DVAE) classifier. Finally, the EDMOA-DLAD technique applies the beetle antenna search (BAS) technique for the optimum hyperparameter part of DVAE model. The outcome of EDMOA-DLAD approach can be verified on benchmark datasets. A wide range of simulations inferred that the EDMOA-DLAD method obtains enhanced performance of 99.79% over other classification techniques.",
        "author_keywords": [
            "Deep learning",
            "Dwarf mongoose optimization algorithm",
            "Security",
            "Smart cities attacks"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Transformation and learning of the non-equidimensional hesitant fuzzy information based on an extended generative adversarial network",
        "authors": "Liu M.",
        "journal": "Information Sciences",
        "doi": "10.1016/j.ins.2024.120307",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185882240",
        "scopus_id": "85185882240",
        "abstract": "In the subjective evaluation process, the hesitant fuzzy set (HFS), as a convenient and robust presentation tool, cannot only suitably address the decision makers’ (DMs’) or experts’ hesitant and uncertain issues but also can arise the dimension curse puzzle. Furthermore, the decision-making result is just derived according to the given objective and subjective information, without considering the DM's subjective evaluation and the environment's dynamic influence. Unlike the previous studies, this paper tries to address them from the deep learning viewpoint. To this end, we first define the non-equidimensional HFS (NHFS) and then introduce the equidimensional and classification characters into the NHFS to further develop the equidimensional HFS (EHFS) and the EHFS with the optimal classification result. Then, the equidimensional hesitant fuzzy-generative adversarial network (EHF-GAN) model is proposed to transform the hesitant fuzzy information from the non-equidimensional to the equidimensional form. The generalization and the convergence of the new model are proven to show the models’ reasonability. In addition, the double-learning algorithm of the EHF-GAN model is designed, which can fuse the DMs’ dynamic judgments and derive the optimal decision-making results. Lastly, this paper applies the proposed model and algorithm to an illustrative example of the new smart city enterprises and then shows their feasibility and effectiveness.",
        "author_keywords": [
            "Classification label",
            "Double-learning algorithm",
            "Generative adversarial network",
            "Hesitant fuzzy set",
            "New smart city",
            "Non-equidimensional information"
        ],
        "subject_areas": [
            "Software",
            "Control and Systems Engineering",
            "Theoretical Computer Science",
            "Computer Science Applications",
            "Information Systems and Management",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Social Physics Informed Diffusion Model for Crowd Simulation",
        "authors": "Chen H.",
        "journal": "Proceedings of the AAAI Conference on Artificial Intelligence",
        "doi": "10.1609/aaai.v38i1.27802",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85186660934",
        "scopus_id": "85186660934",
        "abstract": "Crowd simulation holds crucial applications in various domains, such as urban planning, architectural design, and traffic arrangement. In recent years, physics-informed machine learning methods have achieved state-of-the-art performance in crowd simulation but fail to model the heterogeneity and multi-modality of human movement comprehensively. In this paper, we propose a social physics-informed diffusion model named SPDiff to mitigate the above gap. SPDiff takes both the interactive and historical information of crowds in the current timeframe to reverse the diffusion process, thereby generating the distribution of pedestrian movement in the subsequent timeframe. Inspired by the well-known social physics model, i.e., Social Force, regarding crowd dynamics, we design a crowd interaction module to guide the denoising process and further enhance this module with the equivariant properties of crowd interactions. To mitigate error accumulation in long-term simulations, we propose a multi-frame rollout training algorithm for diffusion modeling. Experiments conducted on two real-world datasets demonstrate the superior performance of SPDiff in terms of macroscopic and microscopic evaluation metrics. Code and appendix are available at https://github.com/tsinghua-fib-lab/SPDiff.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "HDA-IDS: A Hybrid DoS Attacks Intrusion Detection System for IoT by using semi-supervised CL-GAN",
        "authors": "Li S.",
        "journal": "Expert Systems with Applications",
        "doi": "10.1016/j.eswa.2023.122198",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85175232486",
        "scopus_id": "85175232486",
        "abstract": "In recent years, the application of the internet of things (IoT) in areas such as intelligent transportation, smart cities, and the industrial internet has become increasingly widespread. As a crucial supporting infrastructure, IoT devices are utilized in various fields to construct IoT networks. However, due to the inherent limitations of IoT devices, such as limited computing resources and low memory capacity, security concerns have become increasingly prominent. Among these concerns are Denial-of-Service (DoS) and botnet attacks, which are difficult to prevent due to their large-scale and covert nature. To address these challenges, this paper proposes a Hybrid DoS Attack Intrusion Detection System (HDA-IDS) that combines signature-based detection with anomaly-based detection to effectively identify both known and unknown DoS/botnet attacks. Additionally, this paper introduces a novel anomaly-based detection model called CL-GAN. It integrates CNN-LSTM with GAN to establish a baseline for normal behavior and detect malicious traffic. In contrast to other semi-supervised models, the CL-GAN exhibits superior accuracy, as well as shorter training and testing times, in detecting DoS and botnet attacks. In addition, experimental results demonstrate that the HDA-IDS outperforms other IDSs in detecting DoS and botnet attacks. When tested on datasets such as NSL-KDD, CICIDS2018, and Bot-IoT, the HDA-IDS achieved an average of 5% overall improvement superior performance in terms of accuracy, precision, recall, and F1-Score compared to other works. These results highlight the effectiveness of the proposed system in addressing security issues in IoT networks, and presents a general framework that addresses the challenge of large-scale attacks constructed through the dissemination of false information.",
        "author_keywords": [
            "Generative adversarial network",
            "Internet of Things",
            "Intrusion Detection System",
            "Machine learning"
        ],
        "subject_areas": [
            "Engineering (all)",
            "Computer Science Applications",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Towards a Framework to Evaluate Generative Time Series Models for Mobility Data Features",
        "authors": "Ribeiro I.F.",
        "journal": "Journal of Internet Services and Applications",
        "doi": "10.5753/jisa.2024.3887",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202147397",
        "scopus_id": "85202147397",
        "abstract": "Understanding human mobility has implications for several areas, such as immigration, disease control, mobile networks performance, and urban planning. However, gathering and disseminating mobility data face challenges such as data collection, handling of missing information, and privacy protection. An alternative to tackle these problems consists of modeling raw data to generate synthetic data, preserving its characteristics while maintaining its privacy. Thus, we propose MobDeep, a unified framework to compare and evaluate generative models of time series based on mobility data features, which considers statistical and deep learning-based modeling. To achieve its goal, MobDeep receives as input statistical or Generative Adversarial Network-based models (GANs) and the raw mobility data, and outputs synthetic data and the metrics comparing the synthetic with the original data. In such way, MobDeep allows evaluating synthetic datasets through qualitative and quantitative metrics. As a proof-of-concept, MobDeep implements one classical statistical model (ARIMA) and three GANs models. To demonstrate MobDeep on distinct mobility scenarios, we considered an open dataset containing information about bicycle rentals in US cities and a private dataset containing information about a Brazilian metropolis’s urban traffic. MobDeep allows observing how each model performs in specific scenarios, depending on the characteristics of the mobility data. Therefore, by using MobDeep researchers can evaluate their resulting models, improving the fidelity of the synthetic data regarding the original dataset.",
        "author_keywords": [
            "Generative adversarial networks",
            "Mobility",
            "time series"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Creativity and Innovation in Civic Spaces Supported by Cognitive Flexibility When Learning with AI Chatbots in Smart Cities",
        "authors": "Chauncey S.A.",
        "journal": "Urban Science",
        "doi": "10.3390/urbansci8010016",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85188959477",
        "scopus_id": "85188959477",
        "abstract": "The purpose of this study is to advance conceptual understandings of the cognitive flexibility construct, in support of creativity and innovation in smart city civic spaces, employing the use of large language model artificial intelligence chatbots such as ChatGPT. Based on a review of the research and practice literature, this study formulates a conceptual framework for cognitive flexibility in support of creativity and innovation in AI environments, adaptable to smart cities. A research design is used that employs AI as a design material, in combination with a topical inquiry involving boundary setting and perspective taking, to co-pilot an exploration with ChatGPT-3.5/4. This study operationalizes the framework for applications to learning approaches, addressing flexibility and inclusivity in smart city spaces and regions. With the rapid evolving of chatbot technologies, ChatGPT-4 is used in the exploration of a speculative real-world urban example. This work is significant in that AI chatbots are explored for application in urban spaces involving creative ideation, iteration, engagement, and cognitive flexibility; future directions for exploration are identified pertaining to ethical and civil discourse in smart cities and learning cities, as well as the notion that AI chatbots and GPTs (generative pre-trained transformers) may become a zeitgeist for understanding and learning in smart cities.",
        "author_keywords": [
            "AI chatbots",
            "creative AI",
            "creativity",
            "innovation",
            "large language models",
            "learning cities",
            "new educational habits",
            "new technologies and developments",
            "smart cities",
            "urban agenda"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Environmental Science (miscellaneous)",
            "Waste Management and Disposal",
            "Urban Studies",
            "Pollution"
        ]
    },
    {
        "title": "Exploring the new frontier of information extraction through large language models in urban analytics",
        "authors": "Crooks A.",
        "journal": "Environment and Planning B: Urban Analytics and City Science",
        "doi": "10.1177/23998083241235495",
        "publication_date": "2024",
        "document_type": "Editorial",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185691163",
        "scopus_id": "85185691163",
        "abstract": NaN,
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "High-Definition Image Formation Using Multi-stage Cycle Generative Adversarial Network with Applications in Image Forensic",
        "authors": "Arif D.",
        "journal": "Arabian Journal for Science and Engineering",
        "doi": "10.1007/s13369-023-08193-x",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85168340915",
        "scopus_id": "85168340915",
        "abstract": "In the modern world, human safety and crime control are daunting tasks. Each year the number of street crime cases has been increasing. In many cases, the culprit is unknown, in which the challenging task is to identify the right culprit possibly among hundreds of options in contexts of densely populated public spaces like target killing, vehicle snatching, etc. Often, in these situations, a sketch artist, working for the police forensic department, produces a drawing of the culprit’s face based on guidelines from the victims or witnesses to the crime. However, hand-drawn sketches can be an inefficient means for matching facial photographs of the culprit, particularly in cases where the software is designed around using images of real faces. In this research work, a novel technique is proposed to generate hyperreal high-definition (H-HD) face images of the culprit from a single hand-drawn face sketch. ’Hyperreal’ is used here in the way it is used in the Arts, as in making the image, albeit based on a person’s thoughts, truer to reality through a deep understanding of how the real subject would appear. To produce this image translation from sketch to H-HD face, two techniques are presented in this article, namely cycle generative adversarial network (CGAN) and multistage cycle generative adversarial network (MS-CGAN). MS-CGAN has multiple layers as stages and produces minimum cycle consistency and generative adversarial losses. CGAN uses paired data for training whereas MS-CGAN uses unpaired data. The training results show that the MSE loss of the proposed technique is found to be less than CGANs. GANs can be evaluated in three ways, namely qualitative, quantitative, and observational. In this paper, a quantitative comparison is made by the evaluation of CGAN and MS-CGAN based on the pixel-to-pixel comparison. An observational analysis is performed on the feedback from the observers. According to the evaluations, 54% of participants voted for the MS-CGAN whereas 46% rated CGAN to be the better performer. Two types of pixel-to-pixel comparisons are performed: color-to-color comparison and sketch-to-sketch comparison in terms of mean square error (MSE) and root mean square error (RMSE). For color-to-color image comparison, CGAN achieved an MSE of 2.312 and RMSE of 1.521 whereas MS-CGAN achieved an MSE of 2.232 and RMSE of 1.494. For sketch-to-sketch pixel comparison, CGAN achieved an MSE of 1.901 and RMSE of 1.379 whereas MS-CGAN achieved an MSE of 1.81 and 1.345 RMSE. The development of MS-CGAN and the research of this article are aimed at the police forensic department to generate a true-to-life H-HD face of a culprit and thereby contribute toward the overarching goal of maintaining a peaceful society.",
        "author_keywords": [
            "Face sketch",
            "Generative adversarial network",
            "Image forensic",
            "Image translation",
            "Multistage cycle generative adversarial network",
            "Smart cities"
        ],
        "subject_areas": [
            "Multidisciplinary"
        ]
    },
    {
        "title": "Enhancing Urban Landscape Design: A GAN-Based Approach for Rapid Color Rendering of Park Sketches",
        "authors": "Chen R.",
        "journal": "Land",
        "doi": "10.3390/land13020254",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185886583",
        "scopus_id": "85185886583",
        "abstract": "In urban ecological development, the effective planning and design of living spaces are crucial. Traditional color plan rendering methods, mainly using generative adversarial networks (GANs), rely heavily on edge extraction. This often leads to the loss of important details from hand-drawn drafts, significantly affecting the portrayal of the designer’s key concepts. This issue is especially critical in complex park planning. To address this, our study introduces a system based on conditional GANs. This system rapidly converts black-and-white park sketches into comprehensive color designs. We also employ a data augmentation strategy to enhance the quality of the output. The research reveals: (1) Our model efficiently produces designs suitable for industrial applications. (2) The GAN-based data augmentation improves the data volume, leading to enhanced rendering effects. (3) Our unique approach of direct rendering from sketches offers a novel method in urban planning and design. This study aims to enhance the rendering aspect of an intelligent workflow for landscape design. More efficient rendering techniques will reduce the iteration time of early design solutions and promote the iterative speed of designers’ thinking, thus improving the speed and efficiency of the whole design process.",
        "author_keywords": [
            "data augmentation",
            "generative adversarial networks",
            "hand-drawn sketch",
            "image color rendering",
            "landscape design"
        ],
        "subject_areas": [
            "Global and Planetary Change",
            "Ecology",
            "Nature and Landscape Conservation"
        ]
    },
    {
        "title": "Enhancing Smart City Safety and Utilizing AI Expert Systems for Violence Detection",
        "authors": "Kumar P.",
        "journal": "Future Internet",
        "doi": "10.3390/fi16020050",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185565990",
        "scopus_id": "85185565990",
        "abstract": "Violent attacks have been one of the hot issues in recent years. In the presence of closed-circuit televisions (CCTVs) in smart cities, there is an emerging challenge in apprehending criminals, leading to a need for innovative solutions. In this paper, the propose a model aimed at enhancing real-time emergency response capabilities and swiftly identifying criminals. This initiative aims to foster a safer environment and better manage criminal activity within smart cities. The proposed architecture combines an image-to-image stable diffusion model with violence detection and pose estimation approaches. The diffusion model generates synthetic data while the object detection approach uses YOLO v7 to identify violent objects like baseball bats, knives, and pistols, complemented by MediaPipe for action detection. Further, a long short-term memory (LSTM) network classifies the action attacks involving violent objects. Subsequently, an ensemble consisting of an edge device and the entire proposed model is deployed onto the edge device for real-time data testing using a dash camera. Thus, this study can handle violent attacks and send alerts in emergencies. As a result, our proposed YOLO model achieves a mean average precision (MAP) of 89.5% for violent attack detection, and the LSTM classifier model achieves an accuracy of 88.33% for violent action classification. The results highlight the model’s enhanced capability to accurately detect violent objects, particularly in effectively identifying violence through the implemented artificial intelligence system.",
        "author_keywords": [
            "artificial intelligence",
            "edge computing",
            "expert system",
            "image-to-image stable diffusion",
            "LSTM",
            "MediaPipe",
            "real-time application",
            "smart city",
            "violence detection",
            "YOLO v7"
        ],
        "subject_areas": [
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Smart Grid Security: An Effective Hybrid CNN-Based Approach for Detecting Energy Theft Using Consumption Patterns",
        "authors": "Gunduz M.Z.",
        "journal": "Sensors",
        "doi": "10.3390/s24041148",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185540910",
        "scopus_id": "85185540910",
        "abstract": "In Internet of Things-based smart grids, smart meters record and report a massive number of power consumption data at certain intervals to the data center of the utility for load monitoring and energy management. Energy theft is a big problem for smart meters and causes non-technical losses. Energy theft attacks can be launched by malicious consumers by compromising the smart meters to report manipulated consumption data for less billing. It is a global issue causing technical and financial damage to governments and operators. Deep learning-based techniques can effectively identify consumers involved in energy theft through power consumption data. In this study, a hybrid convolutional neural network (CNN)-based energy-theft-detection system is proposed to detect data-tampering cyber-attack vectors. CNN is a commonly employed method that automates the extraction of features and the classification process. We employed CNN for feature extraction and traditional machine learning algorithms for classification. In this work, honest data were obtained from a real dataset. Six attack vectors causing data tampering were utilized. Tampered data were synthetically generated through these attack vectors. Six separate datasets were created for each attack vector to design a specialized detector tailored for that specific attack. Additionally, a dataset containing all attack vectors was also generated for the purpose of designing a general detector. Furthermore, the imbalanced dataset problem was addressed through the application of the generative adversarial network (GAN) method. GAN was chosen due to its ability to generate new data closely resembling real data, and its application in this field has not been extensively explored. The data generated with GAN ensured better training for the hybrid CNN-based detector on honest and malicious consumption patterns. Finally, the results indicate that the proposed general detector could classify both honest and malicious users with satisfactory accuracy.",
        "author_keywords": [
            "convolutional neural network",
            "cyber security",
            "deep learning",
            "energy theft",
            "generative adversarial network",
            "Internet of Things",
            "smart grid"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Information Systems",
            "Atomic and Molecular Physics, and Optics",
            "Biochemistry",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Autoencoding tree for city generation and applications",
        "authors": "Han W.",
        "journal": "ISPRS Journal of Photogrammetry and Remote Sensing",
        "doi": "10.1016/j.isprsjprs.2024.01.010",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85184751549",
        "scopus_id": "85184751549",
        "abstract": "City modeling and generation have attracted an increased interest in various applications, including gaming, urban planning, and autonomous driving. Unlike previous works focused on the generation of single objects or indoor scenes, the huge volumes of spatial data in cities pose a challenge to the generative models. Furthermore, few publicly available 3D real-world city datasets also hinder the development of methods for city generation. In this paper, we first collect over 3,000,000 geo-referenced objects for the cities of New York, Zurich, Tokyo, Berlin, Boston, and several other large cities. Based on this dataset, we propose AETree, a tree-structured auto-encoder neural network, for city generation. Specifically, we first propose a novel Spatial-Geometric Distance (SGD) metric to measure the similarity between building layouts and then construct a binary tree over the raw geometric data of the building based on the SGD metric. Next, we present a tree-structured network whose encoder learns to extract and merge spatial information from the bottom-up iteratively. The resulting global representation is reversely decoded for reconstruction or generation. To address the issue of long-dependency as the level of the tree increases, a Long Short-Term Memory (LSTM) Cell is employed as a basic network element of the proposed AETree. Moreover, we introduce a novel metric, Overlapping Area Ratio (OAR), to quantitatively evaluate the generation results. Experiments on the collected dataset demonstrate that the proposed model outperforms baseline models, such as LayoutTransformer and LayoutVAE, in terms of key metrics. Specifically, the proposed model achieves a Jensen–Shannon Divergence (JSD) of 0.0033, compared to 0.0041 and 0.0061 for LayoutTransformer and LayoutVAE, respectively. Similarly, for the Overall Accuracy Rate (OAR), the proposed model scores 1.66, significantly better than 28.24 and 19.01 for the baseline models Furthermore, the latent features learned by AETree can serve downstream urban planning applications. Project webpage is available at https://ai4ce.github.io/RealCity3D.",
        "author_keywords": [
            "City generation",
            "Real-world city datasets",
            "Tree-structured neural network",
            "Urban planning applications"
        ],
        "subject_areas": [
            "Atomic and Molecular Physics, and Optics",
            "Engineering (miscellaneous)",
            "Computer Science Applications",
            "Computers in Earth Sciences"
        ]
    },
    {
        "title": "Generative urban design: A systematic review on problem formulation, design generation, and decision-making",
        "authors": "Jiang F.",
        "journal": "Progress in Planning",
        "doi": "10.1016/j.progress.2023.100795",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85165684105",
        "scopus_id": "85165684105",
        "abstract": "Urban design is the process of designing and shaping the physical forms of cities, towns, and suburbs. It involves the arrangement and design of street systems, groups of buildings, public spaces, and landscapes, to make the urban environment performative and sustainable. The typical design process, reliant on manual work and expert experience has unavoidable low efficiency in generating high-performing design solutions due to the involvement of complex social, institutional, and economic contexts and the trade-off between conflicting preferences of different stakeholder groups. Taking advantage of artificial intelligence (AI) and computational capacity, generative urban design (GUD) has been developed as a trending technical direction to narrow the gaps and produce design solutions with high efficiency at early design stages. It uses computer-aided generative methods, such as evolutionary optimization and deep generative models, to efficiently explore complex solution spaces and automatically generate design options that satisfy conflicting objectives and various constraints. GUD experiments have attracted much attention from academia, practitioners, and public authorities in recent years. However, a systematic review of the current stage of GUD research is lacking. This study, therefore, reports on a systematic investigation of the existing literature according to the three key stages in the GUD process: (1) design problem formulation, (2) design option generation, and (3) decision-making. For each stage, current trends, findings, and limitations from GUD studies are examined. Future directions and potential challenges are discussed and presented. The review is highly interdisciplinary and involves articles from urban study, computer science, social science, management, and other fields. It reports what scholars have found in GUD experiments and organizes a diverse and complicated technical agenda into something accessible to all stakeholders. The results and discoveries will serve as a holistic reference for GUD developers and users in both academia and industry and form a baseline for the field of GUD development in the coming years.",
        "author_keywords": [
            "AI-generated content (AIGC)",
            "Generative AI",
            "Generative method",
            "Generative urban design",
            "Human-machine collaboration",
            "Urban form generation"
        ],
        "subject_areas": [
            "Geography, Planning and Development"
        ]
    },
    {
        "title": "Privacy preserving machine unlearning for smart cities",
        "authors": "Chen K.",
        "journal": "Annales des Telecommunications/Annals of Telecommunications",
        "doi": "10.1007/s12243-023-00960-z",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85153583972",
        "scopus_id": "85153583972",
        "abstract": "Due to emerging concerns about public and private privacy issues in smart cities, many countries and organizations are establishing laws and regulations (e.g., GPDR) to protect the data security. One of the most important items is the so-called The Right to be Forgotten, which means that these data should be forgotten by all inappropriate use. To truly forget these data, they should be deleted from all databases that cover them, and also be removed from all machine learning models that are trained on them. The second one is called machine unlearning. One naive method for machine unlearning is to retrain a new model after data removal. However, in the current big data era, this will take a very long time. In this paper, we borrow the idea of Generative Adversarial Network (GAN), and propose a fast machine unlearning method that unlearns data in an adversarial way. Experimental results show that our method produces significant improvement in terms of the forgotten performance, model accuracy, and time cost.",
        "author_keywords": [
            "Generative adversarial network",
            "Machine unlearning",
            "Membership inference attack",
            "Privacy protection"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Predicting humans future motion trajectories in video streams using generative adversarial network",
        "authors": "Hassan M.A.",
        "journal": "Multimedia Tools and Applications",
        "doi": "10.1007/s11042-021-11457-z",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85114819265",
        "scopus_id": "85114819265",
        "abstract": "Understanding the behavior of human motion in social environments is important for various domains of a smart city, e.g, smart transportation, automatic navigation of service robots, efficient navigation of autonomous cars and surveillance systems. Examining past trajectories or environmental factors alone are not enough to address this problem. We propose a novel methodology to predict future motion trajectories of humans based on past attitude of individuals, crowd attitude and environmental context. Many researchers have proposed different techniques based on different features extraction and features fusion to predict the future motion trajectory. They used traditional machine learning algorithms like SVM,social forces, probabilistic models and LSTM to analyze the heuristic motion trajectories but they didn’t consider the other environmental factors e.g relative positions of other humans present in environment and positions of objects present in environment which can affect the motion trajectories of humans. We intend to achieve this goal by employing Long Short Term Memory(LSTM) units to analyze motion histories, convolution neural networks to environmental facts e.g. human-human, human-object interaction and relative positioning of 80 different objects including pedestrians and generative adversarial networks(GANs) to predict possible future motion paths. Our proposed method achieved 70% lower Average Displacement Error(ADE) and 41% lower Final Displacement Error(FDE) in comparison to other state of the art techniques.",
        "author_keywords": [
            "Future motion trajectories",
            "GAN",
            "Human re-identification",
            "LSTM",
            "Object detection",
            "Path planning"
        ],
        "subject_areas": [
            "Software",
            "Media Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Generative Adversarial Model Equipped with Contrastive Learning in Map Synthesis",
        "authors": "Mahara A.",
        "journal": "ACM International Conference Proceeding Series",
        "doi": "10.1145/3645259.3645277",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85192838779",
        "scopus_id": "85192838779",
        "abstract": "In the dynamic field of urban planning and the context of unprecedented natural events, such as hurricanes, the fast generation of accurate maps from satellite imagery is paramount. While several studies have utilized Generative Adversarial Networks (GANs) for map generation from satellite images, the present work introduces a new approach by integrating contrastive learning into the GAN framework for enhanced map synthesis. Our methodology distinctively employs positive sampling by aligning similar features (e.g., roads) in both satellite images and their corresponding map outputs, and contrasts this with negative samples for disparate elements. This approach effectively replaces the conventional cyclic process in GANs with a more streamlined, unidirectional procedure, leading to improvements in both the quality of the synthesized maps and computational efficiency. We show the effectiveness of our proposed model, offering an advancement in map generation for remote sensing applications.",
        "author_keywords": [
            "Anchor",
            "Contrastive Learning",
            "CycleGAN",
            "Generation",
            "Generative Adversarial Networks (GANs)",
            "Map",
            "PatchNCE",
            "Satellite Imagery",
            "Synthesis"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Networks and Communications",
            "Computer Vision and Pattern Recognition",
            "Software"
        ]
    },
    {
        "title": "Second-Order Graph ODEs for Multi-Agent Trajectory Forecasting",
        "authors": "Wen S.",
        "journal": "Proceedings - 2024 IEEE Winter Conference on Applications of Computer Vision, WACV 2024",
        "doi": "10.1109/WACV57701.2024.00501",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191986654",
        "scopus_id": "85191986654",
        "abstract": "Trajectory forecasting of multiple agents is a fundamental task that has applications in various fields, such as autonomous driving, physical system modeling and smart cities. It is challenging because agent interactions and underlying continuous dynamics jointly affect its behavior. Existing approaches often rely on Graph Neural Networks (GNNs) or Transformers to extract agent interaction features. However, they tend to neglect how the distance and velocity information between agents impact their interactions dynamically. Moreover, previous methods use RNNs or first-order Ordinary Differential Equations (ODEs) to model temporal dynamics, which may lack interpretability with respect to how each agent is driven by interactions. To address these challenges, this paper proposes the Agent Graph ODE, a novel approach that models agent interactions and continuous second-order dynamics explicitly. Our method utilizes a variational autoencoder architecture, incorporating spatial-temporal Transformers with distance information and dynamic interaction graph construction in the encoder module. In the decoder module, we employ GNNs with distance information to model agent interactions, and use coupled second-order ODEs to capture the underlying continuous dynamics by modeling the relationship between acceleration and agent interactions. Experimental results show that our proposed Agent Graph ODE outperforms state-of-the-art methods in prediction accuracy. Moreover, our method performs well in sudden situations not seen in the training dataset.",
        "author_keywords": [
            "3D",
            "Algorithms",
            "Algorithms",
            "Algorithms",
            "and algorithms",
            "etc.",
            "formulations",
            "Generative models for image",
            "Machine learning architectures",
            "video",
            "Video recognition and understanding"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "title": "Leveraging Siamese Framework for Enhanced Contextual Feature Learning in Traffic Forecasting",
        "authors": "Yao Z.",
        "journal": "Proceedings - 2024 China Automation Congress, CAC 2024",
        "doi": "10.1109/CAC63892.2024.10865788",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000719011",
        "scopus_id": "86000719011",
        "abstract": "As smart city systems become increasingly complex and urban road networks become more interconnected, traditional predictive models are gradually losing their ability to handle the intricate information among contextual data, such as traffic flow and weather data, due to their inability to learn the holistic features of the entire dataset. These data not only require consideration of contextual relationships but also an understanding of the overall characteristics of the data, which traditional models typically fail to achieve. To address these challenges, this paper proposes a novel deep learning architecture: SimFormer. This architecture leverages the advantages of both the Siamese network and Transformer architectures, mapping complex time series into high-dimensional space to better capture their contextual features. Concurrently, the Transformer encoder’s focus on capturing global temporal dynamics ensures that global features are preserved and utilized in subsequent prediction tasks. We evaluate this innovative architecture on multiple real-world datasets using two different performance metrics, and it consistently outperforms traditional models.",
        "author_keywords": [
            "Contrastive Representation Learning",
            "Traffic Prediction",
            "Transformer"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Control and Systems Engineering",
            "Control and Optimization",
            "Modeling and Simulation",
            "Instrumentation"
        ]
    },
    {
        "title": "Align Along Time and Space: A Graph Latent Diffusion Model for Traffic Dynamics Prediction",
        "authors": "Liu Y.",
        "journal": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "doi": "10.1109/ICDM59182.2024.00034",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000266547",
        "scopus_id": "86000266547",
        "abstract": "The problem of traffic dynamics prediction, aiming to capture the complicated patterns of urban dynamics and forecast short-term future traffic status, is essential for managing transportation systems, reducing congestion, enhancing safety, improving commuter efficiency, and supporting urban planning and infrastructure development. Current approaches using ma-chine learning and deep neural networks have advanced traffic prediction but often focus on individual urban dynamic aspects and rely on auto-regressive methods for consecutive predictions, which can be inaccurate and computationally expensive. In this work, we propose the Spatial- Temporal Graph LAtent DIffusion ModeL (STGAIL) to address these limitations. STGAIL views geographical regions as graphs with various traffic features, capturing their interconnections. Operating in a pre-trained latent space, STGAIL uses latent diffusion processes and inno-vative spatial-temporal graph layers for accurate and efficient multi-step predictions. Fine-tuning with temporal binary masks further enhances its performance, avoiding error accumulation and reducing computational costs. Experiments on real-world datasets demonstrate STGAIL's superior accuracy and efficiency over state-of-the-art methods. We also make our code and dataset available, contributing to ongoing research in traffic dynamics prediction.",
        "author_keywords": [
            "latent diffusion models",
            "spatial-temporal data mining",
            "urban dynamics prediction"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Advancing IoT Security: A Review of Intrusion Detection Systems Challenges and Emerging Solutions",
        "authors": "Zhukabayeva T.",
        "journal": "2024 11th International Conference on Software Defined Systems, SDS 2024",
        "doi": "10.1109/SDS64317.2024.10883899",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/86000196408",
        "scopus_id": "86000196408",
        "abstract": "The rapid proliferation of the Internet of Things (IoT) has revolutionized industries through interconnected devices and smart decision-making. However, this expansion has also introduced significant security challenges, as IoT networks are characterized by heterogeneity, resource constraints, and evolving threats. Intrusion Detection Systems (IDS) have emerged as essential mechanisms to complement preventive measures, yet existing solutions fall short of addressing the full spectrum of IoT-specific vulnerabilities. This paper critically reviews state-of-the-art IDS techniques, including advanced methods such as machine learning, federated learning, blockchain, and hybrid detection. Additionally, emerging approaches like Generative Adversarial Networks (GANs), reinforcement learning, and bio-inspired algorithms are explored for their potential to enhance IDS adaptability and scalability. The role of complementary security techniques, such as penetration testing, is highlighted in validating and strengthening IDS implementations. Applications in critical areas such as smart cities are discussed, emphasizing the need for robust and efficient security mechanisms. Key challenges such as interoperability, real-time detection, and resource efficiency are analyzed, and future research directions are proposed to develop comprehensive IDS frameworks tailored to the dynamic and diverse IoT ecosystem.",
        "author_keywords": [
            "Intrusion detection systems (IDS)",
            "IoT security",
            "Smart Cities",
            "wireless sensor networks"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Information Systems",
            "Software",
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality"
        ]
    },
    {
        "title": "Recent Innovation of Deep Learning Approches in Satellite Imagery: A Comprehensive Review",
        "authors": "Sheeba Joice C.",
        "journal": "5th International Conference on Sustainable Communication Networks and Application, ICSCNA 2024 - Proceedings",
        "doi": "10.1109/ICSCNA63714.2024.10863905",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85219627747",
        "scopus_id": "85219627747",
        "abstract": "In a variety of industries, including agriculture, urban planning, disaster management, and environmental monitoring, deep learning has significantly improved accuracy and efficiency in satellite image processing. Traditional image processing methods often face challenges due to the complexity and sheer volume of satellite data. By contrast, key characteristics are automatically extracted from raw pictures using deep learning techniques like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs). Tasks including deforestation detection, picture categorization, and super-resolution have significantly improved as a result of deep learning's explosive growth. The segmentation of geographical characteristics and the identification of spatial and temporal patterns have been improved by sophisticated approaches such as transformer networks and U-Net topologies. Notwithstanding these developments, problems persist, including picture quality fluctuation and the requirement for sizable label datasets. This article investigates the use of deep learning techniques in the processing of satellite images, looking at approaches, important uses, current issues, and potential future developments. The text underscores the transformational potential of these technologies and emphasizes the significance of performance indicators such as F1 Score, accuracy, precision, Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Intersection over Union (IoU).",
        "author_keywords": [
            "applications",
            "approach analysis",
            "deep learning techniques",
            "performance evaluation",
            "Satellite images"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Modeling and Simulation",
            "Health Informatics",
            "Renewable Energy, Sustainability and the Environment",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Small Language Models and Their Role in Hybrid AI Architectures for Big Data Analytics",
        "authors": "Rosamma K.S.",
        "journal": "5th International Conference on Sustainable Communication Networks and Application, ICSCNA 2024 - Proceedings",
        "doi": "10.1109/ICSCNA63714.2024.10863995",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85219602935",
        "scopus_id": "85219602935",
        "abstract": "The growing demand for data-driven applications requires AI solutions that are both efficient and scalable to support big data analytics across diverse industries. Large Language Models (LLMs), such as GPT-4, offer advanced performance but incur high computational costs, latency, and energy demands, making them less suitable for real-time analytics or edge computing. Small Language Models (SLMs), like LLaMA 2 and Mistral 7B, have been developed to address these challenges by reducing cost and power consumption while retaining high task-specific performance. This paper explores how SLMs integrate within hybrid AI architectures, handling sub-tasks like pre-processing and localized inference, while LLMs perform complex analytics in cloud environments. Such hybrid architectures present scalable, efficient solutions for sectors including finance, healthcare, and smart cities. The challenges of SLM integration, such as reduced contextual understanding and accuracy tradeoffs, are also addressed. Further, we propose future directions to mitigate these issues, including AutoML frameworks, federated learning, and quantization techniques to enhance model efficiency. This paper discusses deployment strategies for SLMs within hybrid architectures to achieve balanced performance, scalability, and efficiency in big data applications.",
        "author_keywords": [
            "Big data analytics",
            "Edge computing",
            "Federated learning",
            "Hybrid AI architectures",
            "Small Language Models (SLMs)"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Modeling and Simulation",
            "Health Informatics",
            "Renewable Energy, Sustainability and the Environment",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Integration of Generative AI System to IoT Based Healthcare Systems 5.0",
        "authors": "Ramesh J.V.N.",
        "journal": "Studies in Systems, Decision and Control",
        "doi": "10.1007/978-3-031-75771-6_14",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85219006220",
        "scopus_id": "85219006220",
        "abstract": "The combination of Generative AI and IoT technologies has created opportunities to improve the capabilities and efficiency of Healthcare Systems. This integration has the capacity to transform several sectors, such as healthcare, manufacturing, transportation, and smart cities. Generative AI systems give machines with tangible existence and independent decision-making powers, while IoT enables effortless connection and data interchange between physical objects and digital systems. This research examines the difficulties and potential advantages of incorporating Generative artificial intelligence systems into internet of things-based Healthcare systems. The study first examines the structure and elements of Generative AI systems and IoT-based Healthcare Systems, emphasizing their individual functions and interconnections. Subsequently, it analyzes the advantages of integrating various technologies, including improved perception of the surrounding circumstances, immediate and informed decision-making, and flexible responses in ever-changing settings. Furthermore, the study discusses the difficulties linked to this integration, including interoperability, security, privacy, and ethical issues. In addition, the paper showcases several instances and uses where the combination of Generative AI systems with IoT-based Healthcare Systems has shown notable progress. These include self-governing robotic systems in advanced manufacturing, intelligent gadgets for healthcare monitoring, self-driving automobiles, and systems for managing smart infrastructure. In addition, the study explores forthcoming areas of research and upcoming developments in this domain, including edge computing, swarm robotics, human–robot cooperation, and decentralized AI. Furthermore, it underscores the need of multidisciplinary cooperation among specialists in AI, IoT, robotics, cybersecurity, and domain-specific businesses to tackle intricate obstacles and fully unlock the potential of integrated Generative AI systems in IoT-based Healthcare Systems. Ultimately, the incorporation of Generative AI systems into IoT-based Healthcare Systems shows great potential for developing highly intelligent, adaptable, and effective Healthcare systems in several fields. Nevertheless, it necessitates meticulous examination of technological, ethical, and sociological ramifications to guarantee responsible implementation and optimize the advantages for mankind.",
        "author_keywords": [
            "Cybersecurity",
            "Generative AI",
            "Healthcare systems",
            "Industrial 5.0",
            "IoT"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Control and Systems Engineering",
            "Automotive Engineering",
            "Social Sciences (miscellaneous)",
            "Economics, Econometrics and Finance (miscellaneous)",
            "Control and Optimization",
            "Decision Sciences (miscellaneous)"
        ]
    },
    {
        "title": "DyFormer: A CNN-Transformer Network Combining Local and Global Attention for Optical Remote Sensing Object Detection",
        "authors": "Huang Y.",
        "journal": "2024 4th International Conference on Artificial Intelligence, Virtual Reality and Visualization, AIVRV 2024",
        "doi": "10.1109/AIVRV63595.2024.10860094",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218493890",
        "scopus_id": "85218493890",
        "abstract": "Remote sensing image (RSI) object detection is crucial for natural disaster management, urban planning, and resource exploration. However, due to significant differences between RSIs and natural images (NIs), existing object detectors designed for NIs are not directly applicable to RSIs. CNN-based models typically require specialized attention modules to relate small targets to global contexts, while Transformer-based models often add modules to enhance detail extraction, increasing computational costs for edge deployment. To address these challenges, we propose DyFormer, a hybrid CNN-Transformer model that combines local and global attention mechanisms for effective feature fusion. Additionally, a feature residual pyramid network (FRPN) is introduced to enhance multi-scale feature integration. We conduct experiments on the open source NWPU VHR-10 dataset to evaluate the proposed DyFormer, achieving a mAP@0.5 of 61.7%, outperforms existing sort-of-the-art methods, demonstrating its effectiveness for RSI object detection tasks.",
        "author_keywords": [
            "feature fusion",
            "local and global attention",
            "Object detection",
            "vision transformer"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Media Technology",
            "Modeling and Simulation",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Safety, Risk, Reliability and Quality"
        ]
    },
    {
        "title": "Enhancing Energy Efficiency and Security in IoTDriven Smart Cities Using Hybrid GAN-ICA Framework",
        "authors": "Hafeezuddin M.",
        "journal": "2024 Global Conference on Communications and Information Technologies, GCCIT 2024",
        "doi": "10.1109/GCCIT63234.2024.10862065",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218428007",
        "scopus_id": "85218428007",
        "abstract": "The rapid emergence of IoT-powered smart cities has generated substantial apprehensions regarding energy efficiency and security. Current technologies frequently fail to adequately address these concerns in a comprehensive manner. This study presents a hybrid framework that combines GAN with ICA to improve energy efficiency and security in smart city infrastructures. The design of the model utilizes GANs to generate synthetic data and ICA to extract independent characteristics, resulting in improved accuracy and security of IoT systems. The accuracy of our model surpassed that of previous technologies, reaching 97.5%. Additionally, our model achieved a precision of 95.0% and an F1 score of 95.6%. As a result, our model has established a new benchmark in smart city research. The results showcase the model's capacity to enhance smart city operations, rendering it a worthwhile addition to the field.",
        "author_keywords": [
            "Data Preprocessing",
            "Energy Efficiency",
            "Feature Extraction",
            "Generative Adversarial Networks",
            "Hybrid GAN-ICA",
            "Independent Component Analysis",
            "Internet of Things (IoT) Security",
            "Model Training",
            "Performance Metrics",
            "Smart Cities"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Safety, Risk, Reliability and Quality",
            "Modeling and Simulation",
            "Health Informatics"
        ]
    },
    {
        "title": "Real-Time IoT Data Analytics Using Advanced Large Language Model Techniques",
        "authors": "Marripudugala M.",
        "journal": "2024 Global Conference on Communications and Information Technologies, GCCIT 2024",
        "doi": "10.1109/GCCIT63234.2024.10862622",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218409011",
        "scopus_id": "85218409011",
        "abstract": "The integration of Internet of Things (IoT) technologies with advanced analytics has become critical in extracting valuable insights from continuous data streams in real-time. This paper explores the application of Large Language Models (LLMs) as a transformative approach to enhancing IoT data analytics. We present a novel framework that leverages LLMs for the real-time interpretation and processing of vast, diverse IoT data sets. Our methodology involves the adaptation of transformer-based architectures to handle structured and unstructured data from IoT sources, enabling immediate decision-making and actionable insights. Through rigorous experimentation, we demonstrate how LLMs can significantly improve the accuracy and speed of data analytics in IoT environments compared to traditional methods. The results underscore the potential of LLMs to revolutionize real-time data processing tasks across various industries, from smart cities to healthcare. Our study not only reinforces the applicability of LLMs in real-time analytics but also outlines future research directions for integrating AI with IoT infrastructure to achieve scalable and efficient solutions.",
        "author_keywords": [
            "Data Engineering",
            "Data Science",
            "IoT Data Analytics",
            "Large language models (LLMs)",
            "Real-Time Processing"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Safety, Risk, Reliability and Quality",
            "Modeling and Simulation",
            "Health Informatics"
        ]
    },
    {
        "title": "Image Classification of House Interiors and Street Views Using Vision Transformer (ViT-B/16)",
        "authors": "Rani R.",
        "journal": "Proceedings of the 9th International Conference on Communication and Electronics Systems, ICCES 2024",
        "doi": "10.1109/ICCES63552.2024.10860237",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218408500",
        "scopus_id": "85218408500",
        "abstract": "The application of the Vision Transformer (ViT-B/I6) model for street and dwelling image classification is investigated in this work. With all photos reduced to 224 × 224 pixels, the dataset consists in house interiors (e.g., bathrooms, kitchens) and street views (e.g., apartments, churches, industrial buildings). Leveraging self-attention strategies, the ViT model was refined to identify complex visual patterns and long-range dependencies inside the images. Using criteria including accuracy, precision, recall, and F1-score, the model's performance was evaluated and classified accuracy of 96.75% emerged. With little misclassification, the confusion matrix and classification report showed that the model reasonably separated between house interiors and street views. Usually depending on local feature detection, the ViT-B/I6's global attention strategy helped it to surpass conventional convolutional neural networks (CNNs). This work emphasizes the possibilities of transformer-based models such as ViT for image classification tasks including various and challenging images. ViT models provide better accuracy and generalization in real-world uses including real estate analysis or urban planning by concentrating on worldwide image attributes. The results create paths for next investigation on computer vision transformer architectures.",
        "author_keywords": [
            "Climate Action and AI for Urban Management, etc.",
            "Innovation and Infrastructure",
            "Quality Education in AI",
            "Smart Urban Planning",
            "Sustainable Cities and Communities"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering",
            "Safety, Risk, Reliability and Quality",
            "Control and Optimization",
            "Instrumentation",
            "Computer Networks and Communications",
            "Information Systems and Management",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "A Smart Traffic Flow Optimization using Graph Convolutional Network with Graph Long Short-Term Memory",
        "authors": "Ratnam V.S.",
        "journal": "2nd IEEE International Conference on Integrated Intelligence and Communication Systems, ICIICS 2024",
        "doi": "10.1109/ICIICS63763.2024.10860256",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218193075",
        "scopus_id": "85218193075",
        "abstract": "In recent years, Smart Cities (SC), Traffic Flow (TF) refers to the optimized movement of vehicles, pedestrians, and other road users by progressive technologies. Predicting traffic flow is dynamic to ease congestion, enhance traffic management, and to improve emergency response. Previously, many methods were proposed to enhance the prediction of traffic flow, although the existing methods have overfitting, computational complexity, and generalizability problems. To overcome these problems, a Graph Convolutional Network based Graph Long Short-Term Memory (GCN-GLSTM) model is considered to predict traffic flow. Initially, Urban Traffic Density in Cities (UTDC) dataset is employed to optimize the flow of traffic. The preprocessing is performed with Data cleaning, to remove outliers and missing values, Data filtering to remove data points with low GPS accuracy, Z-Score normalization to normalize data, and Data transformation to Converted data into suitable formats. Feature extraction is performed by employing Graph Attention Network (GAN) to handle complexity. For classification, GCN-GLSTM is used to handle high-dimensionality, and to enhance generalizability. The proposed GCN-GLSTM method gained high performance metrics such as accuracy, MSE, MAE, and RMSE of 98.34%, 1.72, 1.14, and 1.35 compared to existing methods like Graph Neural Network (GNN).",
        "author_keywords": [
            "graph attention network",
            "graph convolutional network with graph long short-term memory",
            "smart cities",
            "traffic flow",
            "urban traffic density in cities"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Health Informatics",
            "Artificial Intelligence",
            "Information Systems",
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality",
            "Control and Optimization"
        ]
    },
    {
        "title": "A Novel Framework for Satellite Image Dehazing Using Advanced Computational Techniques",
        "authors": "Vishwakarma S.",
        "journal": "2024 4th Asian Conference on Innovation in Technology, ASIANCON 2024",
        "doi": "10.1109/ASIANCON62057.2024.10838055",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218109734",
        "scopus_id": "85218109734",
        "abstract": "Satellite imagery information is used in many different ways; some of the more common ones are environmental and urban planning and disaster response. That is why haze has a highly negative impact on the quality and visibility of such images and their further usage. The following paper proposes an innovative approach to satellite images dehazing to enhance its value to professionals and researchers in the field. The ideas for the proposed method involve incorporating the use of machine learning algorithms into image enhancement procedures to adequately dehaze the images, increase image resolution, and enhance the efficiency of getting information from satellite images. Our approach involves a three-step process: seen as consisting of preprocessing, a dehazing network, and postprocessing. The preliminary processing generally includes initial enhancement operations such as histogram equalization and color stretch. The foundation of our framework is a deep learning-based dehazing network that uses CNNs, residual blocks, attention mechanisms, and GANs to dehaze and restore the images' quality. Additional operations are performed in postprocessing; they include details enlargement, the removal of noise , and color correction so as to achieve natural and quality results. We evaluate our framework using two standard satellite image datasets: The users of the mentioned services are SateHaze1k and RICE. The effectiveness of the proposed method is evaluated by means of two quality measures, namely Peak Signal-to-Noise Ratio and Structural Similarity Index. Test results portray the efficiency of the proposed technique in dehazing with enhanced PSNR and SSIM values over other conventional and state-of-art works on machine learning-based dehazing methods. That is why our framework can provide the workable and scalable solution for the improvement of the satellite images' clarity that would be the beneficial for its usage in numerous applications.",
        "author_keywords": [
            "Advanced Computational Techniques",
            "Convolutional Neural Networks (CNNs)",
            "Generative Adversarial Networks (GANs)",
            "Image Quality Enhancement",
            "Satellite Image Dehazing"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Modeling and Simulation",
            "Health Informatics"
        ]
    },
    {
        "title": "Agentic Large Language Models for Generating Large-Scale Urban Daily Activity Patterns",
        "authors": "Zhang Y.",
        "journal": "Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024",
        "doi": "10.1109/BigData62323.2024.10825138",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218053813",
        "scopus_id": "85218053813",
        "abstract": "Urban daily activity patterns play an important role in fields such as urban planning and traffic management, while the powerful data generation and reasoning capabilities of LLMs (Large Language Models) have sparked a surge of interest in recent years, with applications in various domains. Inspired by their natural language processing and pattern recognition functionalities, we attempted to utilize LLMs to simulate the activity patterns of people of different ages and occupations in metropolitan areas (Tokyo). By leveraging pre-processed Person Trip data, we employed 3 methods to test the ability of LLMs to generate urban daily activity data. The results were evaluated based on metrics such as rationality, diversity, and error rates. Results indicate that the fine-tuned LLaMA-3 model is capable of accurately simulating the activity distribution patterns of metropolitan populations. Among the prompt-based strategies, the few-shot approach yielded the best performance. Although designing the instruction for prompts and post-processing the data required considerable time, the few-shot prompt strategy proved to be an effective option for this task.",
        "author_keywords": [
            "Human Mobility",
            "NLP",
            "Prompt strategy",
            "Sequence Generation"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Addressing data scarcity in local photovoltaic datasets: A GAN-based workflow",
        "authors": "Izzi F.",
        "journal": "Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024",
        "doi": "10.1109/BigData62323.2024.10825752",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218038245",
        "scopus_id": "85218038245",
        "abstract": "Digital twins are increasingly being implemented in smart cities, where they are designed to provide 3D digital representations for near-real time interactivity and status feedback of the twinned physical assets. The ability to provide accurate predictions in what-if scenarios plays a key role in driving the advances in resources optimization and risk mitigation. To this end, prediction models require large datasets to train, and such datasets are usually scarce at local level. In this paper, we propose a generative AI-based workflow to infer domestic photovoltaic energy production data, based on a process that uses Generative Adversarial Networks to generate an enriched meteorological dataset. The generated meteorological data captures essential statistical properties of real data that can be later used to infer realistic energy production data points. The resulting output dataset is validated against a real photovoltaic system, highlighting the ability to deliver high-fidelity time series out of scarce input datasets.",
        "author_keywords": [
            "data augmentation",
            "data scarcity",
            "digital twin",
            "Generative Adversarial Networks",
            "smart city"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "DiffCast: A Unified Framework via Residual Diffusion for Precipitation Nowcasting",
        "authors": "Yu D.",
        "journal": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
        "doi": "10.1109/CVPR52733.2024.02622",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85218026379",
        "scopus_id": "85218026379",
        "abstract": "Precipitation nowcasting is an important spatiotemporal prediction task to predict the radar echoes sequences based on current observations, which can serve both meteorological science and smart city applications. Due to the chaotic evolution nature of the precipitation systems, it is a very challenging problem. Previous studies address the problem either from the perspectives of deterministic modeling or probabilistic modeling. However, their predictions suffer from the blurry, high-value echoes fading away and position inaccurate issues. The root reason of these issues is that the chaotic evolutionary precipitation systems are not appropriately modeled. Inspired by the nature of the systems, we propose to decompose and model them from the perspective of global deterministic motion and local stochastic variations with residual mechanism. A unified and flexible framework that can equip any type of spatio-temporal models is proposed based on residual diffusion, which effectively tackles the shortcomings of previous methods. Extensive experimental results on four publicly available radar datasets demonstrate the effectiveness and superiority of the proposed framework, compared to state-of-the-art techniques.",
        "author_keywords": [
            "Diffusion Model",
            "Precipitation Nowcasting",
            "Spatio-Temporal Prediction"
        ],
        "subject_areas": [
            "Software",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "title": "Deep Attention Driven Reinforcement Learning (DAD-RL) for Autonomous Decision-Making in Dynamic Environment",
        "authors": "Chowdhury J.",
        "journal": "Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",
        "doi": "10.1109/SMC54092.2024.10832016",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85217857706",
        "scopus_id": "85217857706",
        "abstract": "Autonomous Vehicle (AV) decision-making in ur-ban environments is inherently challenging due to the dynamic interactions with surrounding vehicles. For safe planning, AV/ego must understand the weightage of various spatiotemporal interactions in a scene. Contemporary works use colos-sal transformer architectures to encode interactions mainly for trajectory prediction, resulting in increased computational complexity. To address this issue without compromising spatiotemporal understanding and performance, we propose the simple Deep Attention Driven Reinforcement Learning (DAD-RL) framework, which dynamically assigns and incorporates the significance of surrounding vehicles into the ego's RL-driven decision-making process. We introduce an AV-centric spatiotemporal attention encoding (STAE) mechanism for learning the dynamic interactions with different surrounding vehicles. To understand map and route context, we employ a context encoder to extract features from context maps. The spatiotemporal representations combined with contextual encoding provide a comprehensive state representation. The resulting model is trained using the Soft-Actor Critic (SAC) algorithm. We evaluate the proposed framework on the SMARTS urban benchmarking scenarios without traffic signals to demonstrate that DAD-RL outperforms recent state-of-the-art methods. Furthermore, an ablation study underscores the importance of the context-encoder and spatiotemporal attention encoder in achieving superior performance.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Artificial Intelligence Role in Promoting Saudi Arabia’s Smart Cities: Addressing SDGs for Socio-Cultural Challenges",
        "authors": "Sepehri B.",
        "journal": "Russian Sociological Review",
        "doi": "10.17323/1728-192x-2024-4-20-47",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85217736836",
        "scopus_id": "85217736836",
        "abstract": "The study explores the use of artificial intelligence (AI) to address socio-cultural challenges in Saudi Arabia while promoting Sustainable Development Goals (SDGs). Using a structured narrative review method with a critical approach, the study highlights AI’s versatility in analyzing complex social phenomena, understanding human behavior, and optimizing urban infrastructure. With its unique socio-cultural challenges, Saudi Arabia aims for sustainable development through Saudi Vision 2030 and various smart city projects, emphasizing the importance of addressing challenges like gender equality, cultural preservation, an increasing youth population, rapid urbanization, and climate change. The study identifies ten AI applications and models to address these challenges and promote relevant SDGs across six areas: Predictive Analytics and Forecasting, Optimization and Decision Support, Natural Language Processing, Computer Vision, Generative AI, and Geospatial AI. These AI models can help address issues like gender equality, youth education, and employment, as well as optimize water management, energy use, and urban planning to address rapid urbanization and climate change challenges. By aligning AI development with the goals outlined in the SDGs, Saudi Arabia can unlock the potential of AI to create sustainable, resilient, and inclusive smart cities that effectively address socio-cultural challenges. However, the study emphasizes the necessity of customizing AI applications in smart cities based on Saudi Arabia’s religious and cultural values to ensure ethical and culturally sensitive implementations. The findings of this study hold relevance not only for Saudi Arabia but also for other countries facing similar challenges. The study provides practical recommendations for policymakers, urban planners, and technology experts to leverage AI effectively for sustainable development. It also outlines future research directions to address the limitations identified, such as exploring implementation challenges and ethical considerations.",
        "author_keywords": [
            "AI",
            "NEOM",
            "NEOM",
            "Saudi Arabia",
            "Saudi Vision 2030",
            "SDGs",
            "Smart Cities",
            "Socio-cultural challenges",
            "Видение Саудовской Аравии 2030",
            "ИИ",
            "Саудовская Аравия",
            "Социокультурные вызовы",
            "Умные города",
            "ЦУР"
        ],
        "subject_areas": [
            "Cultural Studies",
            "Sociology and Political Science",
            "Philosophy",
            "Social Sciences (all)"
        ]
    },
    {
        "title": "AI-Driven Optimization for Urban and Vertical Agriculture Planning: A Multi-Model Approach",
        "authors": "Sayad I.E.",
        "journal": "5th International Conference on Electrical, Communication and Computer Engineering, ICECCE 2024",
        "doi": "10.1109/ICECCE63537.2024.10823499",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85217246180",
        "scopus_id": "85217246180",
        "abstract": "Urban agriculture has emerged as a critical strategy for enhancing food security, mitigating urban heat islands, and promoting community well-being in densely populated areas. However, the complexity of urban environments poses significant challenges for effective planning and implementation. This paper presents an AI-driven framework to optimize urban and vertical agriculture planning by leveraging advanced machine learning models, including Artificial Neural Networks (ANN), Spiking Neural Networks (SNN), and Large Language Models (LLM). The proposed framework integrates diverse dataset that includes as socioeconomic data, geographic information, and urban zoning regulations to provide actionable insights for decision-makers. The Spiking Neural Network model demon-strated superior predictive accuracy in identifying optimal sites for urban agriculture by effectively handling complex patterns and temporal dynamics in the data. Additionally, the integration of an LLM-powered chatbot into a user-friendly web application enhances interactivity and supports real-time decision-making, guiding users through the prediction process with context-specific recommendations. Experimental results validate the robustness and scalability of the framework across various urban settings, demonstrating its potential to transform urban agriculture practices by providing precise, data-driven recommendations. The findings of this study highlight the transformative potential of AI in urban planning and agriculture, offering a novel approach to fostering sustainable urban development and food security. Future research will focus on expanding the dataset, refining model performance, and enhancing the application's capabilities to support more complex user queries.",
        "author_keywords": [
            "Agricultural Technology",
            "Artificial Intelligence (AI)",
            "Artificial Neural Networks (ANN)",
            "Data Mining",
            "Machine Learning",
            "Spiking Neural Networks (SNN)",
            "Sustainability",
            "Urban Agriculture",
            "Urban Planning",
            "Vertical Farming"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Electrical and Electronic Engineering",
            "Safety, Risk, Reliability and Quality",
            "Control and Optimization",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "PAG-Road:Pseudo-Node Attention Guided Adversarial Generation for Hierarchical Road Network Topology",
        "authors": "Ye S.",
        "journal": "Proceedings of the 2024 8th CAA International Conference on Vehicular Control and Intelligence, CVCI 2024",
        "doi": "10.1109/CVCI63518.2024.10830018",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85217202980",
        "scopus_id": "85217202980",
        "abstract": "Road network generation plays a pivotal role in urban planning. Classifying and structuring the generated road networks not only mirrors the actual road distribution more accurately but also provides crucial data for autonomous driving simulation tests. Consequently, this paper focuses on employing a graph-based generative approach to create hierarchical road network topologies. Initially, the paper introduces a topological representation model for hierarchical road networks. Addressing the current lack of publicly available hierarchical road network topology datasets, we have developed a comprehensive dataset that includes data from 71 medium to large cities in China, thus filling this significant gap. Lastly, this paper proposes a novel adversarial generative model for hierarchical road network topologies that facilitates feature sharing and achieves task decoupling and feature coupling in generating both node attributes and links. Notably, we introduce an innovative pseudo-node attention mechanism that models global associations between connected and unconnected nodes in a semi-supervised manner. Comparative experiments with other methods demonstrate that our approach exhibits superior precision and robustness in generating node attributes and links, with performance metrics exceeding 98.5 %.",
        "author_keywords": [
            "Adversarial generation model",
            "Autonomous driving",
            "Hierarchical road network",
            "Pseudo-node attention"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Automotive Engineering",
            "Control and Optimization"
        ]
    },
    {
        "title": "Exploratory Application of Generative AI in Urban Planning and Design Processes",
        "authors": "Wang C.",
        "journal": "2024 3rd International Conference on Cloud Computing, Big Data Application and Software Engineering, CBASE 2024",
        "doi": "10.1109/CBASE64041.2024.10824586",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85217184325",
        "scopus_id": "85217184325",
        "abstract": "The technological innovation of generative AI tools has significantly changed the traditional logic of content production, offering new avenues for creative inspiration and expanding the possibilities within the fields of urban planning and design. Nowadays, as urban design is characterized by a transformation centered around digital technological methodologies, the empowerment of urban design through emerging technologies to achieve human-centric, refined, and intelligent design outcomes represents an inevitable trend in future development. This article introduces the concept and development status of generative AI, and proposes possible paths for generative AI to intervene in urban design at three stages: conceptual inspiration, spatial design, and outcome expression. It provides ideas for the application of artificial intelligence technology in urban space area.",
        "author_keywords": [
            "AIGC",
            "Generative AI",
            "Urban planning and design"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Software",
            "Information Systems and Management",
            "Control and Optimization"
        ]
    },
    {
        "title": "Person re-identification with transformers and image stacking",
        "authors": "Stojanovic D.",
        "journal": "2024 32nd Telecommunications Forum, TELFOR 2024 - Proceedings of Papers",
        "doi": "10.1109/TELFOR63250.2024.10819135",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216887833",
        "scopus_id": "85216887833",
        "abstract": "Person re-identification (ReID) is increasingly important due to the expansion of surveillance cameras. ReID can effectively operate in various conditions, making it suitable for security, retail analytics, and smart city applications. We propose a transformer-based model, DeepChangeVIT-ReID, fine-tuned with triplet loss, using the DeepChange dataset. We address long-term ReID challenges, including pose variations, camera angle differences, and clothing alterations. DeepChangeVIT-ReID achieves state-of-the-art performance, significantly improving Rank-1 accuracy compared to existing methods on the DeepChange dataset.",
        "author_keywords": [
            "Computer Vision",
            "Image Processing",
            "Person Re-identification",
            "Surveillance Systems",
            "Transformers"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Safety, Risk, Reliability and Quality",
            "Instrumentation",
            "Hardware and Architecture"
        ]
    },
    {
        "title": "Synthetic Trajectory Generation Through Convolutional Neural Networks",
        "authors": "Merhi J.",
        "journal": "2024 21st Annual International Conference on Privacy, Security and Trust, PST 2024",
        "doi": "10.1109/PST62714.2024.10788061",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216596580",
        "scopus_id": "85216596580",
        "abstract": "Location trajectories provide valuable insights for applications from urban planning to pandemic control. However, mobility data can also reveal sensitive information about individuals, such as political opinions, religious beliefs, or sexual orientations. Existing privacy-preserving approaches for publishing this data face a significant utility-privacy trade-off. Releasing synthetic trajectory data generated through deep learning offers a promising solution. Due to the trajectories' sequential nature, most existing models are based on recurrent neural networks (RNNs). However, research in generative adversarial networks (GANs) largely employs convolutional neural networks (CNNs) for image generation. This discrepancy raises the question of whether advances in computer vision can be applied to trajectory generation. In this work, we introduce a Reversible Trajectory-to-CNN Transformation (RTCT) that adapts trajectories into a format suitable for CNN-based models. We integrated this transformation with the well-known DCGAN in a proof-of-concept (PoC) and evaluated its performance against an RNN-based trajectory GAN using four metrics across two datasets. The PoC was superior in capturing spatial distributions compared to the RNN model but had difficulty replicating sequential and temporal properties. Although the PoC's utility is not sufficient for practical applications, the results demonstrate the transformation's potential to facilitate the use of CNNs for trajectory generation, opening up avenues for future research. To support continued research, all source code has been made available under an open-source license.",
        "author_keywords": [
            "Deep Learning",
            "Differential Privacy",
            "Generative Adversarial Networks",
            "Location Privacy",
            "Trajectory Privacy"
        ],
        "subject_areas": [
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality",
            "Health Informatics",
            "Computer Networks and Communications",
            "Information Systems"
        ]
    },
    {
        "title": "A Generative AI-Driven Architecture for Intelligent Transportation Systems",
        "authors": "Mangione F.",
        "journal": "2024 IEEE 10th World Forum on Internet of Things, WF-IoT 2024",
        "doi": "10.1109/WF-IoT62078.2024.10811280",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216534211",
        "scopus_id": "85216534211",
        "abstract": "The rapid acceleration of urbanization underscores the urgent need for developing intelligent transportation systems (ITS) to enhance the efficiency, safety, and sustainability of urban mobility. Within this context, accurately predicting vehicle trajectories is paramount for facilitating superior traffic management and control. To this end, the paper presents an innovative architecture that combines a Long Short-Term Memory (LSTM) module with a generative artificial intelligence (Gen-AI) component, specifically the RoBERTa Transformer model. By leveraging these sophisticated architecture, the LSTM network with a recursive decoder outperforms the teacher forcing decoder on clean datasets, showing higher robustness in time-series predictions. When video data was partially missing, performance decreased, but using the RoBERTa model to reconstruct the missing data significantly improved results for both decoders (from 37% up to 92%). The reconstructed data notably enhanced the performance of the LSTM models, particularly when larger portions of the video data were absent. These findings highlight the effectiveness of data reconstruction techniques in mitigating the challenges posed by uncontrollable events (common in real ITS scenarios) which can bear to incomplete information.",
        "author_keywords": [
            "Generative-AI",
            "Internet of Things",
            "ITS",
            "LSTM",
            "Smart cities",
            "Transformers",
            "Vehicle trajectory prediction"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Hardware and Architecture",
            "Information Systems",
            "Information Systems and Management",
            "Control and Optimization"
        ]
    },
    {
        "title": "Building Resilient Smart Cities: The Role of Digital Twins and Generative AI in Disaster Management Strategy",
        "authors": "Razavi H.",
        "journal": "Urban Sustainability",
        "doi": "10.1007/978-981-97-8483-7_5",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216105110",
        "scopus_id": "85216105110",
        "abstract": "The advent of Digital Twin (DT) technology represents a significant milestone in the evolution of smart city management, introducing virtual models and data-driven simulations that enhance our understanding, planning, and management of urban environments. Generative Artificial Intelligence (GenAI) integration enriches digital twins by boosting their predictive capabilities and simulating more realistic and interactive scenarios. By leveraging generative algorithms, digital twins can create synthetic data, to simulate a wide range of potential outcomes. These additional capabilities enable more accurate modeling of complex systems, predicting variations and potential issues. Moreover, Generative AI can contribute to creating high-quality simulations, improving the accuracy and reliability of digital twins in representing real-world environments and processes. This chapter provides an exploration of the synergies between GenAI and digital twins in the context of disaster management and smart cities. The chapter begins with an introduction, offering a contextual background integrating generative AI and digital twins for simulating disaster and emergency scenarios. It then delves into the foundations of generative AI, discussing its principles, applications, and success stories across various domains, with a specific focus on its relevance to urban disaster management. The subsequent sections clarify the evolution of digital twins and their pivotal role in predicting and mitigating disasters and emergency response. The chapter then navigates the intersection between generative AI and digital twins and the functionalities that GenAI brings to improving the simulation process, providing examples of successful integrations while addressing potential challenges and proposing solutions. Furthermore, it explores how smart cities contribute to disaster resilience, detailing the technologies and strategies employed for disaster preparedness. The chapter concludes with an in-depth analysis of specific GenAI-enhanced digital twins’ applications in disaster management, anticipating future challenges and developments in the field, and emphasizing emerging trends and potential directions.",
        "author_keywords": [
            "Data synthesis",
            "Digital twin",
            "Disaster and emergency management",
            "Generative AI",
            "Scenario generation",
            "Smart cities",
            "Urban intelligence",
            "Urban resilience"
        ],
        "subject_areas": [
            "Waste Management and Disposal",
            "Geography, Planning and Development",
            "Transportation",
            "Urban Studies"
        ]
    },
    {
        "title": "Generative AI and Retrieval-Augmented Generation (RAG) in an Agent-Based Simulation Framework for Urban Planning",
        "authors": "Bruzzone A.",
        "journal": "Proceedings of the International Conference on Modeling and Applied Simulation, MAS",
        "doi": "10.46354/i3m.2024.mas.021",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85216007089",
        "scopus_id": "85216007089",
        "abstract": "Urban planning is a multifaceted discipline that requires balancing economic growth, environmental sustainability and community needs. Traditional approaches often rely on static data and manual analyses, which can be time-consuming and less responsive to real-time changes. This paper proposes a conceptual framework that integrates Generative AI and Retrieval-Augmented Generation (RAG) with the principles of strategic engineering to enhance urban planning simulations. By leveraging real-time data and advanced modeling and simulation capabilities, this framework addresses the complexity inherent in urban systems. Generative AI, exemplified by models such as GPT-4, excels at producing coherent and contextually relevant text, while RAG ensures the incorporation of up-to-date, domain-specific information. The framework employs autonomous agents within the simulation software to dynamically model various urban development scenarios, providing planners with actionable insights that promote sustainability. The proposed system enhances decision-making, operational efficiency and community engagement by offering real-time, data-driven insights. Furthermore, it aligns urban development projects with long-term sustainability goals, fostering transparency and public trust. This interdisciplinary approach, rooted in strategic engineering, promises to transform urban planning into a more adaptive, inclusive and resilient practice.",
        "author_keywords": [
            "Agent",
            "Decision-Making",
            "Generative AI",
            "Retrieval-Augmented Generation (RAG)",
            "Simulation"
        ],
        "subject_areas": [
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Leveraging Digital Twins and Generative AI for Effective Urban Mobility Management",
        "authors": "Canzaniello M.",
        "journal": "Proceedings - 2024 IEEE Cyber Science and Technology Congress, CyberSciTech 2024",
        "doi": "10.1109/CyberSciTech64112.2024.00032",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215609280",
        "scopus_id": "85215609280",
        "abstract": "Rapid urbanization and population growth have created significant challenges in urban mobility management, including traffic congestion, inefficient public transportation, and environmental pollution. This paper presents the development and implementation of a Digital Twin (DT) for smart mobility, designed to address these issues. The DT platform integrates a diverse range of historical and real-time data, providing a comprehensive view of urban mobility conditions. Descriptive statistics are employed to identify patterns in parking occupancy and violation frequencies, while Machine Learning and Deep Learning algorithms enhance predictive and generative analytics for forecasting parking needs and simulating scenarios with other mobility aspects. Advanced analytics uncover hidden patterns and behaviors, and visualization tools map data onto the urban layout to facilitate spatial planning and resource allocation. Scenario simulation enables urban planners to assess the impact of different strategies in a virtual environment prior to real-world implementation. The integration of Generative Artificial Intel- ligence (GenAl) models further enhances predictive capabilities and scenario generation. Preliminary results demonstrate the DT platform's potential in improving urban mobility management, particularly in optimizing parking meter placement and enhancing user experience. Although limited data availability affects long-term prediction accuracy, the model exhibits robustness and adaptability for extended forecasting horizons.",
        "author_keywords": [
            "Data-Driven Decision Making",
            "Digital Twin",
            "Generative AI",
            "Smart Cities",
            "Urban Mobility Management"
        ],
        "subject_areas": [
            "Information Systems and Management",
            "Control and Optimization",
            "Modeling and Simulation",
            "Artificial Intelligence",
            "Computer Science Applications",
            "Information Systems"
        ]
    },
    {
        "title": "HSDFormer: an improved transformer for remote sensing image semantic segmentation",
        "authors": "Bai Y.",
        "journal": "Proceedings of SPIE - The International Society for Optical Engineering",
        "doi": "10.1117/12.3033799",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85215507707",
        "scopus_id": "85215507707",
        "abstract": "The extraction of building locations is crucial in the field of remote sensing, commonly applied in tasks such as emergency response, urban planning, and environmental monitoring. Existing methods often employ convolutional models such as ResNet and U-Net. however, these models struggle to capture long-range features of geographical objects, limiting their practical effectiveness. Meanwhile, Transformer based models face challenges due to their quadratic computational complexity. Additionally, the characteristics of remote sensing images, including dense arrangement, small scale, and class imbalance, pose difficulties for traditional patch-merging modules in downsampling, leading to the loss of significant building information. To address such limitations, we present the HSDFormer model in this paper. The model achieves a reduction in the computational complexity of self-attention calculation through a straightforward sequential reduction process. Additionally, our model has optimized the downsampling process specifically for remote sensing semantic segmentation tasks, effectively minimizing the loss of crucial information during layer-wise feature extraction. We evaluate the HSDFormer on the WHU Building Dataset and Satellite Dataset II (East Asia). The results demonstrate the model's effectiveness in accurately segmenting building locations, surpassing performance compared to other baseline models.",
        "author_keywords": [
            "Remote Sensing",
            "Semantic Segmentation",
            "Transformer"
        ],
        "subject_areas": [
            "Electronic, Optical and Magnetic Materials",
            "Condensed Matter Physics",
            "Computer Science Applications",
            "Applied Mathematics",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "HMP-LLM: Human Mobility Prediction Based on Pre-trained Large Language Models",
        "authors": "Zhong X.",
        "journal": "Proceedings - 2024 IEEE 4th International Conference on Digital Twins and Parallel Intelligence, DTPI 2024",
        "doi": "10.1109/DTPI61353.2024.10778764",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214873507",
        "scopus_id": "85214873507",
        "abstract": "Human mobility prediction is fundamental to designing intelligent cities and forecasting how people move during disasters and health emergencies, specifically in emergency responses. However, the existing method for human mobility prediction is mainly designed for normal scenarios and is incapable of handling the case of a pandemic. The COVID-19 pandemic has presented challenges over the past few years: the powerful pandemic has a fundamental and long-lasting influence on mobility, which is hard to model. Inspired by recent progress in the Large Language Model, we present the Human Mobility Prediction-Large Language Model (HMP-LLM), which utilizes LLMs with understanding and reasoning abilities to do human mobility prediction tasks. Especially to adapt LLMs to intervened time series prediction, we propose the following critical designs: 1) Seasonal Decompose. 2) Two-stage Prompts Designing. We convert the input data into textual prototypes so LLMs can understand it, then we use two-stage prompts to guide the language model in reasoning. Extensive experiments on real-world datasets confirm the superiority of HMP-LLM over existing methods. Besides, due to the zero-shot nature and the expansibility of our two-stage design, HMP-LLM is expected to be used in other public safety incidents.",
        "author_keywords": [
            "Human Mobility Prediction",
            "Large Language Models",
            "Smart Cities"
        ],
        "subject_areas": [
            "Instrumentation",
            "Artificial Intelligence",
            "Computer Science Applications",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Automated Smart City Planning through Personalized Large Language Model with Retrieval Augmented Generation",
        "authors": "Alamsyah N.",
        "journal": "Proceedings - 2024 International Conference on Information Technology and Computing, ICITCOM 2024",
        "doi": "10.1109/ICITCOM62788.2024.10762118",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214665198",
        "scopus_id": "85214665198",
        "abstract": "The rapid urbanization and the need for sustainable city management have driven the demand for intelligent and efficient smart city planning solutions. This paper explores an innovative approach to automated smart city planning using a personalized large language model (LLM) combined with Retrieval Augmented Generation (RAG). Our proposed system leverages the personalized mistral7b model, enabling the ingestion and analysis of multiple documents, including smart city master plans and government regulations. This methodology ensures tailored urban planning recommendations while maintaining data privacy by running the system locally. In light of the dangers of cyberattacks and the inherent risks associated with using foreign-run services, our approach provides a secure and autonomous solution for urban development planning.",
        "author_keywords": [
            "chatbot",
            "large language models",
            "retrieval augmented generation",
            "smart city"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Information Systems",
            "Information Systems and Management",
            "Control and Optimization",
            "Health Informatics"
        ]
    },
    {
        "title": "Efficient Federated Intrusion Detection in 5G Ecosystem Using Optimized BERT-Based Model",
        "authors": "Adjewa F.",
        "journal": "International Conference on Wireless and Mobile Computing, Networking and Communications",
        "doi": "10.1109/WiMob61911.2024.10770340",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214658409",
        "scopus_id": "85214658409",
        "abstract": "The fifth-generation (5G) offers advanced services, supporting applications such as intelligent transportation, con-nected healthcare, and smart cities within the Internet of Things (IoT). However, these advancements introduce significant security challenges, with increasingly sophisticated cyber-attacks. This paper proposes a robust intrusion detection system (IDS) using federated learning and large language models (LLMs). The core of our IDS is based on BERT, a transformer model adapted to identify malicious network flows. We modified this transformer to optimize performance on edge devices with limited resources. Experiments were conducted in both centralized and federated learning contexts. In the centralized setup, the model achieved an inference accuracy of 97.79 %. In a federated learning context, the model was trained across multiple devices using both IID (Independent and Identically Distributed) and non-IID data, based on various scenarios, ensuring data privacy and compliance with regulations. We also leveraged linear quantization to com-press the model for deployment on edge devices. This reduction resulted in a slight decrease of 0.02 % in accuracy for a model size reduction of 28.74 %. The results underscore the viability of LLMs for deployment in IoT ecosystems, highlighting their ability to operate on devices with constrained computational and storage resources.",
        "author_keywords": [
            "5G",
            "Cybersecurity",
            "Data privacy",
            "Federated Learning",
            "Internet of Things",
            "Intrusion detection system",
            "Large Language Models"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Hardware and Architecture",
            "Software"
        ]
    },
    {
        "title": "Future Tech Startups and Innovation in the Age of AI",
        "authors": "Khan I.U.",
        "journal": "Future Tech Startups and Innovation in the Age of AI",
        "doi": "10.1201/9781032715957",
        "publication_date": "2024",
        "document_type": "Book",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85214595228",
        "scopus_id": "85214595228",
        "abstract": "Our book, Future of Tech Startups and Innovations in the Age of AI, mainly focuses on artificial intelligence (AI) tools, AI-based startups, AI-enabled innovations, Autonomous AI Agents (Auto-GPT), AI-based marketing startups, machine learning for organizations, AI-internet of things (IoT) for new tech companies, AI-enabled drones for agriculture industry, machine learning (ML)/deep learning (DL)-based drip farming, AI-based driverless cars, AI-based weather prediction startups, AI tools for personal branding, AI-based teaching, AI-based doctor/hospital startups, AI for game companies, AI-based finance tools, AI for human resource management, AI-powered management tools, AI tools for future pandemics, AI/ML-based transportation companies, AI for media, AI for carrier counseling, AI for customer care, AI for next generation businesses, and many more applications. AI tools and techniques will revolutionize startups all over the world. Entrepreneurs, engineers, and practitioners have already moved toward AI-based solutions to reshape businesses. AI/ML will create possibilities and opportunities for improving human lifestyles. AI-enabled startups will work on cost-effective solutions to solve difficult problems. Recently, many research companies are interested in providing solutions and investing a lot in AI-based startups. AI-driven products will revolutionize the “smart world.” AI computing tech companies will help to model human speech recognition systems. Also, AI-based startups will focus on perception and reasoning of autonomous robotic systems. AI/ML-based tech startups will introduce smart online education systems for future pandemics. More interestingly, people are also moving for online job opportunities and trying to work from home. Future innovation needs closer relations between academia and industry. Therefore, online platforms need to be introduced that will only focus on academia and industry linkage. Future AI tech-based startups will focus more on research and development to introduce novel products to the market. Accordingly, engineers and many other people should be trained on AI tools and techniques to introduce innovative solutions for the smart world. In addition, integration of many new technologies with AI will be made possible. AI with IoT, smart cities, unmanned aerial vehicles (UAVs), wireless sensor networks, software-defined networks, network management, vehicular ad hoc networks, flying ad hoc networks, wireless communication technologies, ML, reinforcement learning, federated learning and other mechanisms will introduce new technological products.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Advanced Intelligent Traffic Management System(AITMS): A Generative AI-Enhanced Model",
        "authors": "Muriuki K.P.",
        "journal": "2024 IEEE PES/IAS PowerAfrica, PowerAfrica 2024",
        "doi": "10.1109/PowerAfrica61624.2024.10759478",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213396784",
        "scopus_id": "85213396784",
        "abstract": "In rapidly urbanizing cities with increasing populations, the challenges of managing traffic are becoming more pressing, highlighting the need for advanced technologies. The Advanced Intelligent Traffic Management System (AITMS) is a comprehensive solution designed to address the persistent challenges of traffic congestion, poor traffic management, and air pollution in densely populated urban areas. Current traffic management systems often rely on static algorithms and predetermined signal timings, which are insufficient to handle dynamic and unpredictable traffic patterns. This results in prolonged travel times, increased fuel consumption, and elevated levels of air pollution, posing serious threats to public health and environmental sustainability. AITMS integrates physical and digital infrastructures, leveraging Generative AI for real-time data collection, analysis, and decision-making. By incorporating sensors, IoT devices, and advanced data analytics, the system can predict traffic flow, optimize signal timings, and recommend alternate routes. It also communicates with connected vehicles to provide real-time updates. The incorporation of Generative AI enables the AITMS to continually adapt and learn from new data inputs and trends, ensuring sustainability and scalability in urban transportation. AITMS is an innovative framework enhanced by Generative AI, aimed at revolutionizing urban traffic management in smart cities. Similar frameworks demonstrate promising outcomes, including improved traffic management, reduced congestion, and enhanced driver safety. AITMS aims to transform urban transportation, elevate residents' quality of life, and foster more sustainable and resilient cities amidst urbanization challenges.",
        "author_keywords": [
            "AITMS",
            "GAN",
            "Generative AI",
            "LLM",
            "Scalability",
            "Smart Cities"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Strategy and Management",
            "Computer Networks and Communications",
            "Energy Engineering and Power Technology",
            "Renewable Energy, Sustainability and the Environment",
            "Electrical and Electronic Engineering",
            "Control and Optimization"
        ]
    },
    {
        "title": "Generative architectural plan drawings for early design decisions: data grounding and additional training for specific use cases",
        "authors": "Choi S.",
        "journal": "Architectural Engineering and Design Management",
        "doi": "10.1080/17452007.2024.2445033",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213256857",
        "scopus_id": "85213256857",
        "abstract": "This study shows the development of models for generating architectural plan drawings to support early design decisions in time–and cost-effective housing projects. Plan drawings are communicated through a combination of visual representations and accompanying textual descriptions. These elements play a crucial role in communicating design specifications to project stakeholders. In particular, by exploring the benefits of early decision-making during the planning phase, this paper explores specific use cases and demonstrates how existing data can be processed for additional training in image-generative models. These models have significantly advanced architectural visualization as a synthetic medium for visual representation. The methodology follows a structured approach: (1) evaluating the efficacy of default base models in generating plan drawings to determine the need for additional data grounding and training; (2) defining the scope of research through a theoretical examination of design requirements for specific use cases for training; (3) systematizing and generalizing the additional training process including data grounding (preparing and preprocessing data suitable for specific use cases), optimizing hyperparameters, and training (implementing models capable of generating images with the desired quality); and (4) demonstrating the proposed applications using the additional training model, specifically within the use case of ‘Korean urban residential housing projects’. This methodology aims to improve the efficiency of design communication during the initial stages of architectural design. By doing so, it enables more effective and strategic planning across a wide range of use cases and scenarios.",
        "author_keywords": [
            "additional training model",
            "Architectural design",
            "BIM",
            "design visualization",
            "generative AI"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Business, Management and Accounting (all)"
        ]
    },
    {
        "title": "Research progress of high-resolution remote sensing image scene classification",
        "authors": "Li Z.",
        "journal": "National Remote Sensing Bulletin",
        "doi": "10.11834/jrs.20243519",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213248710",
        "scopus_id": "85213248710",
        "abstract": "With the rapid advancement of remote sensing technology, the resolution of remote sensing satellites is improving, the number of spectral bands is increasing, and revisit periods are contracting. This progression empowers researchers to access more valuable data and information from remote sensing images. Concepts, such as remote sensing big data, remote sensing foundation models, and smart cities, have successively emerged in recent years, imposing increased demands on the intelligent extraction technology of massive remote sensing data, particularly regarding remote sensing image information. As an indispensable element of intelligent information extraction technology applied in fields, such as land use and cover, national land resource surveys, natural disaster observation, agricultural yield estimation, and forestry protection, remote sensing image classification exhibits substantial practical importance. Remote sensing image scene classification has been introduced in this context. The objective of scene classification in remote sensing images is to comprehensively and semantically categorize each given remote sensing image. This task entails summarizing and analyzing the extracted feature information at a high level and assigning different labels to areas of interest based on their features. In contrast with natural images, although they contain features, such as color, texture, and shape, remote sensing images encounter more challenges in classification due to the intricate scene content resulting from the overhead perspective, weak texture, and color information caused by low resolution. Nevertheless, as one of the technical means in remote sensing applications, remote sensing image scene classification technology plays a pivotal role in the development of practical application technologies. After years of development, numerous comprehensive review studies on remote sensing image scene classification have been conducted locally and abroad. However, the recent surge in remote sensing big data has introduced new challenges into scene classification. The ongoing evolution of deep learning technology, particularly the widespread application of Convolutional Neural Networks (CNNs) and transformers, has resulted in significant advancements in remote sensing image scene classification. In this context, self-supervised learning, as a method that is independent of annotated data, has become indispensable in the field of remote sensing image scene classification. Foundation models based on self-supervised learning have been successfully implemented in scene classification, presenting innovative solutions to this field. As the volume of remote sensing data continues to increase, the dataset scale for remote sensing image scene classification is expanding rapidly, giving rise to increasingly intricate classification tasks. Remote sensing image scene classification datasets are swiftly progressing toward the integration of multiple sources, the incorporation of multiple labels, and the inclusion of large-scale samples. Drawing from the findings of the current literature survey, this study systematically compiles a summary of deep learning methods within the domain of remote sensing image scene classification. Encompassing CNNs, visual transformers, and generative adversarial networks, this overview also introduces representative datasets and foundation models since the inception of scene classification. Several classical scene classification methods have undergone evaluation across various benchmark datasets. In addition, this study delves into primary challenges and prospects, paving the way for further research in the classification of scenes in remote sensing images.",
        "author_keywords": [
            "deep learning",
            "high-resolution remote sensing image",
            "image classification",
            "scene classification"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Instrumentation",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "LINKs: Large Language Model Integrated Management for 6G Empowered Digital Twin NetworKs",
        "authors": "Jiang S.",
        "journal": "IEEE Vehicular Technology Conference",
        "doi": "10.1109/VTC2024-Fall63153.2024.10757470",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213069194",
        "scopus_id": "85213069194",
        "abstract": "In the rapidly evolving landscape of digital twins (DT) and 6G networks, the integration of large language models (LLMs) presents a novel approach to network management. This paper explores the application of LLMs in managing 6G-empowered DT networks, with a focus on optimizing data retrieval and communication efficiency in smart city scenarios. The proposed framework leverages LLMs for intelligent DT problem analysis and radio resource management (RRM) in fully autonomous way without any manual intervention. Our proposed framework - LINKs, builds up a lazy loading strategy which can minimize transmission delay by selectively retrieving the relevant data. Based on the data retrieval plan, LLMs transform the retrieval task into an numerical optimization problem and utilizing solvers to build an optimal RRM, ensuring efficient communication across the network. Simulation results demonstrate the performance improvements in data planning and network management, highlighting the potential of LLMs to enhance the integration of DT and 6G technologies.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Assessing Urban Safety: A Digital Twin Approach Using Streetview and Large Language Models",
        "authors": "Cheng Y.",
        "journal": "IEEE Vehicular Technology Conference",
        "doi": "10.1109/VTC2024-Fall63153.2024.10757666",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85213041881",
        "scopus_id": "85213041881",
        "abstract": "This study explores a novel approach to reevaluating urban safety using Vision Large Language Models (VLLMs) integrated with digital twin technology. Our methodology involves randomly selecting street views across various U.S. cities and employing VLLMs to detect and analyze street safety. We incorporate existing user-reported data through an API to validate our findings. Preliminary results indicate that this new approach significantly enhances the accuracy and reliability of urban safety assessments. The integration of VLLMs with digital twin frameworks presents a promising avenue for urban planners and policymakers to achieve more dynamic and real-time insights into city safety, ultimately contributing to smarter and safer urban environments. Our findings suggest that this method holds substantial potential for broader applications in digital twin initiatives, facilitating more informed decision-making processes.",
        "author_keywords": [
            "Crime Mapping",
            "Street View",
            "Vision Large Languge Model"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Electrical and Electronic Engineering",
            "Applied Mathematics"
        ]
    },
    {
        "title": "Real-Time Context-Aware Early Filtering for High-Definition Video Analytics on Commodity Edge Devices Using GenAI for Data Augmentation",
        "authors": "Pontes F.A.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2024.3520807",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85212985788",
        "scopus_id": "85212985788",
        "abstract": "This work proposes a fast and accurate early filtering pipeline for video analytics in commodity Edge devices for Smart-Cities applications. This pipeline can run in real-time even on a small and GPU-less device such as a Raspberry Pi, while maintaining a good accuracy for video analytics queries. In addition to a novel Edge optimized pre-processing method, the pipeline uses a context-aware binary model, which is fine-tuned using semi-automatic synthetic data augmentation, Generative AI, and Cut-and-Paste techniques to contextualize the model to the input camera background and the Objects of Interest (e.g., car or person) from a user's video analytics query, in a fast process that requires only 10 seconds of original footage for training. This makes it the first Edge filtering with specialized models with a viable online training solution. Compared to a baseline state-of-art Nano-YoloV5 model, the proposed early filtering pipeline in its high speed profile shows an 48.8x increase in speed and is the first of its kind that is able to run on physical hardware (i.e., non-simulated) commodity Edge devices at more than 80 FPS in HD (1920 × 1080) resolution, with a small accuracy loss of 5% compared to the baseline. On the high accuracy setting the pipeline still runs at more than 41 FPS (26.9x faster than Nano-Yolo) and shows an increase of 2.5% in accuracy.",
        "author_keywords": [
            "Commodity edge",
            "deep neural networks",
            "generative AI",
            "real-time",
            "streaming"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "From Blueprint to Reality: A Design-Built Analysis of Kigali’s Urban Sustainability and Carbon Neutrality",
        "authors": "Spiegelhalter T.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-3-031-74723-6_35",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211919254",
        "scopus_id": "85211919254",
        "abstract": "This novel research into practice project explores Kigali, Rwanda’s transition towards carbon-neutral urban planning and its implications for sustainability and urban development in the Global South. Notably, African countries are leading in the shift towards renewable energy, inspiring smart city initiatives, particularly in Kigali. The study critically documents and reflects on real-world architectural and infrastructural transformations in Kigali, examining socio-technical elements facilitating these changes and the effectiveness of implemented strategies. Our methodology utilises cloud-based simulation analysis, generative design optimisation, and building physics tools, incorporating Kigali’s cultural, geographical and climatic specifics. These strategies have led to various initiatives, such as sustainable smart buildings, smart traffic management, and digitally enabled economic environments. A Kigali Innovation City (KIC) case study exemplifies Kigali’s sustainable vision but also reveals challenges like neglect of demographic and economic realities. Learning from these hurdles, the team, including the author, is working on the large 42-ha Vision City Phase 2, aiming for carbon neutrality and the International Well-Being Institute certification. This project illustrates the significance of embracing challenges to achieve urban sustainability targets, offering insights into other cities’ sustainability and carbon-neutral endeavours and required research benchmarking.",
        "author_keywords": [
            "AI",
            "Carbon neutrality",
            "Generative AI",
            "Generative design optimization",
            "Renewable energy",
            "Smart city initiatives"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Demonstration and analysing the performance of image caption generator: efforts for visually impaired candidates for Smart Cities 5.0",
        "authors": "Rastogi R.",
        "journal": "International Journal of Advanced Mechatronic Systems",
        "doi": "10.1504/IJAMECHS.2024.143152",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211622417",
        "scopus_id": "85211622417",
        "abstract": "Image caption generation has become a prominent area of research due to its potential applications in multimedia understanding and accessibility. This paper presents a comprehensive study of three state-of-the-art approaches for image caption generation, employing convolutional neural networks (CNN) with long short-term memory (LSTM) networks, attention mechanisms, and transformers. The first approach utilises a CNN-LSTM architecture, where the CNN acts as an encoder to extract meaningful visual features from input images. These features are then fed into an LSTM-based decoder, enabling the generation of descriptive captions. The second approach introduces the use of attention mechanisms, allowing the model to focus on specific regions of the image while generating captions. This technique improves the caption quality and ensures that the generated text corresponds more accurately to the content in the image. Lastly, the third approach incorporates the powerful transformer architecture to capture long-range dependencies in the generated captions, enabling better contextual understanding and coherence.",
        "author_keywords": [
            "attention mechanism",
            "benchmark",
            "CNN",
            "image caption",
            "LTSM",
            "NLP",
            "transformer"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Mechanical Engineering"
        ]
    },
    {
        "title": "Multiscale Recovery Diffusion Model with Unsupervised Learning for Video Anomaly Detection System",
        "authors": "Li B.",
        "journal": "IEEE Transactions on Industrial Informatics",
        "doi": "10.1109/TII.2024.3493390",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211498090",
        "scopus_id": "85211498090",
        "abstract": "The rapid development of intelligent industry and smart city increases the number of surveillance devices, greatly enhancing the need for unsupervised automatic anomaly detection in real-Time video surveillance, which uses raw data without laborious manual annotations. Existing video anomaly detection (VAD) methods encounter limitations when utilizing pretext tasks, such as reconstruction or prediction to identify abnormal events, as these tasks are not completely consistent and complementary with the essential objective of anomaly detection. Motivated by recent advances in diffusion models, we propose a multiscale recovery diffusion model, which relies on the proposed novel and effective pretext task named recovery to introduce the notion of generation speed. It utilizes critical step-by-step generation of diffusion probabilistic models in unsupervised anomaly detection scenarios. By incorporating a proposed multiscale spatial-Temporal subtraction module, our model captures more detailed appearance and motion information of foreground objects without relying on other high-level pretrained models. Furthermore, an innovative push-pull loss further extends the disparity between normal and abnormal events through pseudolabels. We validate our model on five established benchmarks: UCSD Ped1, UCSD Ped2, CUHK Avenue, ShanghaiTech, and UCF-Crime, achieving frame-level area under the curves of 86.01%, 99.23%, 92.35%, 82.49%, and 74.79%, respectively, surpassing other state-of-The-Art unsupervised VAD methods.",
        "author_keywords": [
            "Anomaly detection",
            "diffusion model (DM)",
            "intelligent industry",
            "pretext task",
            "real-Time video surveillance",
            "unsupervised learning"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Information Systems",
            "Computer Science Applications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Generative Artificial Intelligence in the Context of Urban Spaces",
        "authors": "Moreno-Ibarra M.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-3-031-77290-0_13",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211228098",
        "scopus_id": "85211228098",
        "abstract": "Urban areas face various challenges, including urban planning, waste management, pollution, public safety, and other issues. Information technologies and artificial intelligence have proven helpful in addressing these problems. This paper explores the potential of Generative Artificial Intelligence (GenAI) to address urban challenges through geospatial analysis. We cover various GenAI models used in urban contexts, such as Generative Adversarial Networks (GAN), Variational Autoencoders (VAEs), Transformer-based models (or General Pre-trained Transformer), Large Language Models (LLMs), and Generative Diffusion models. The paper explains how GenAI can be used for urban analysis applications from an information management perspective. It presents examples of the operations that can be achieved. Additionally, it describes studies related to energy and resource management, urban planning, natural disaster management, and traffic management, demonstrating the advantages of applying this type of technology. The use of GenAI, along with Geographic Information Science and Technology (GIS&T) and Smart Cities concepts and tools, is being discussed. It presents some points to consider when designing, developing, and implementing GenAI-based applications for urban space analysis.",
        "author_keywords": [
            "Generative Artificial Intelligence",
            "GIS",
            "Smart Cities"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "Automated Road Extraction from Aerial Images: A Generative Approach with W-FuseNet Model",
        "authors": "Muduli D.",
        "journal": "2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024",
        "doi": "10.1109/ICCCNT61001.2024.10724745",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211156096",
        "scopus_id": "85211156096",
        "abstract": "This research introduces an automated road extraction model utilizing deep learning techniques for high-resolution aerial imagery. Focused on applications in urban planning, disaster management, and logistics, the study employs convolutional neural networks (CNNs) and a conditional Generative Adversarial Network (cGAN) architecture. The Massachusetts Roads Dataset, comprising 1171 images, is subject to advanced preprocessing techniques, including resizing, concatenation, and normalization. The proposed model features a carefully crafted generator with an encoder-decoder architecture and a modified Pix2pix-based cGAN for semantic segmentation. Inspired by the PatchGAN concept, the discriminator assesses image patches to distinguish real from generated images. A literature survey evaluates methodologies, emphasizing the Road Structure Refined CNN (RSRCNN), generative learning approaches, and the fully convolutional network (FCN) for road extraction. Performance analysis demonstrates the model's competitive IoU score compared to existing approaches along with accuracy, precision, recall and f1-score. A novel road extraction model using the Massachusetts Roads Dataset is introduced, highlighting WFuseNet architecture and advanced pre-processing techniques.",
        "author_keywords": [
            "cGAN",
            "CNNs",
            "FCN",
            "PatchGAN",
            "Pix2pix",
            "RSRCNN"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Decision Sciences (miscellaneous)",
            "Information Systems and Management",
            "Health Informatics",
            "Communication"
        ]
    },
    {
        "title": "The Graph Neural Network with Wasserstein Generative Adversarial Network for botnet detection in smart city IoT",
        "authors": "Thota M.K.",
        "journal": "2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024",
        "doi": "10.1109/ICCCNT61001.2024.10724763",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85211134280",
        "scopus_id": "85211134280",
        "abstract": "One of the main risks to the security and stability of Internet of Things (IoT) networks in smart cities is botnet assaults. The identification of complex and emerging botnet attacks has not been entirely contained by traditional methods of botnet detection. In this study, we present a new hybrid approach, called GNN-WGAN, to efficiently detect bots in IoT-based smart city networks by integrating Graph Neural Network and Wasserstein Generative Adversarial Network. The suggested method, which ultimately aims to improve the precision and robustness against botnet detection in dynamic IoT networks, effectively uses WGANs to generate synthetic botnet traffic patterns to add more training data and GNNs to capture dependencies between and interactions across network topology. The experimental results demonstrate the effectiveness of the GNN-WGAN technique in accurately recognizing botnet activities, which enhances the security and resilience of IoT networks in smart cities.",
        "author_keywords": [
            "Cyber Attacks",
            "Graph Neural Networks",
            "Internet of Things",
            "Smart Cities",
            "Wasserstein Generative Adversarial Networks"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Decision Sciences (miscellaneous)",
            "Information Systems and Management",
            "Health Informatics",
            "Communication"
        ]
    },
    {
        "title": "Can AI Build a City?",
        "authors": "De Franco A.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-3-031-74679-6_30",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210894612",
        "scopus_id": "85210894612",
        "abstract": "Generative Artificial Intelligence is already used to build urban simulations, but how should this technology develop to build physical cities? To address this question, this paper takes the art and science of city making as an extreme case to identify opportunities and limits in the use of Generative Artificial Intelligence technologies for physical design. The paper is predominantly conceptual in nature proposing an exploration of the possibility to use AI for building physical cities. Subsequently, a critical review of key concepts for city making is discussed for virtual and tangible worlds. The paper concludes with a discussion and remarks addressing the main lessons learned.",
        "author_keywords": [
            "generative artificial intelligence",
            "physical design",
            "virtual cities"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "AI-Based Tools to Enhance Visioning and Urban Decision Making in Future Deliberative Processes Within the Web-Platform Decidim",
        "authors": "Bova P.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-3-031-74679-6_28",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210828352",
        "scopus_id": "85210828352",
        "abstract": "This contribution takes into consideration the possible integration of AI-based tools for the production of images within bottom-up decision-making processes, focusing urban planning when this involves the use of web platforms – for deliberative processes – like Decidim. Using Decidm, the only platform with open-source code useful for deliberative processes, and integrating in the use of the web platform a tool for the generation of images/ project vision based on Artificial Intelligence, this paper examines possible future scenarios in which AI-based tools play a role in deliberative processes in participatory urban planning. The contribution compares three of the main competitors among the different tools for generating images based on diffusion models, capable of processing and/or modifying images by predicting the position of individual pixels, to select the more suitable one to be integrated in a participatory process. Finally, by sytemising the Decidim platform and the AI-based Stable diffusion tools, the contribution exposes three possible integration scenarios taking into consideration in which steps of the “participation ladder” the participatory process would be positioned.",
        "author_keywords": [
            "AI-based tools",
            "Decidim",
            "deliberative processes",
            "participatory action-research",
            "social innovation"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Sustainable Smart Cities in African Digital Space",
        "authors": "Daudu B.O.",
        "journal": "Artificial Intelligence and Machine Learning for Sustainable Development: Innovations, Challenges, and Applications",
        "doi": "10.1201/9781003497189-8",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210826229",
        "scopus_id": "85210826229",
        "abstract": "Technology enhances the economic growth and development of a nation, and the 21st century is festooned with advanced technologies that make transactions and communication between government and its citizens, and between countries, easy. The use of technology, therefore, is a defining attribute of smart cities (Cairo, Algiers, Nairobi, Lagos, and Tunis, amongst others) across Africa. The technological impact of these cities has permeated the other aspects of life in the areas of e-government, e-education, e-commerce, e-communication, and e-advertisement, amongst others. With this, citizens also openly access data records and actively participate in public affairs. Despite the ample benefits of the use of technology, some citizens see technology as an avenue to carry out heinous cybercrimes such as fake news, internet fraud, and cyberbullying, amongst others. As such, our lead questions are: What impact do smart cities have on African digital space and the global economy? How best can the challenges confronting smart cities in Africa be dealt with? Where is the place of Africa in the 21st-century technological world? In this chapter, we adopt a qualitative method to bolster our argument that smart cities in Africa have progressed over the years and positively influenced African digital space and beyond. We also argue for generative artificial intelligence as an empowering tool in boosting smart cities in Africa and as a problem-solving tool for the likely challenges of smart governance of which African Luddite attitude towards technology is included.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Securing Machine Learning Against Data Poisoning Attacks",
        "authors": "Allheeib N.",
        "journal": "International Journal of Data Warehousing and Mining",
        "doi": "10.4018/IJDWM.358335",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210733729",
        "scopus_id": "85210733729",
        "abstract": "The emergence of intelligent networks has revolutionized the use of machine learning (ML), allowing it to be applied in various domains of human life. This literature review paper provides in-depth analysis of the existing research on data poisoning attacks and examines how intelligent networks can mitigate these threats. Specifically, the author explores how malicious users inject fake training data into adversarial networks, a technique known as a data poisoning attack, which can severely compromise the model’s integrity. Through a comparative evaluation of the attack strategies and defense mechanisms, such as robust optimization and model-based detection, the author assesses the strengths and limitations of current defenses. Real-world applications are discussed, including the use of these networks in cybersecurity, healthcare, and smart city systems. The author concludes by outlining the challenges and future directions in developing more effective defense strategies to detect and mitigate data poisoning attacks in real time, ensuring the security and privacy of intelligent networks.",
        "author_keywords": [
            "Adversarial Machine Learning",
            "Data Poisoning Attack",
            "Defense Strategies",
            "Emerging Security Challenges",
            "Security Threats"
        ],
        "subject_areas": [
            "Software",
            "Hardware and Architecture"
        ]
    },
    {
        "title": "mmPalm: Unlocking Ubiquitous User Authentication through Palm Recognition with mmWave Signals",
        "authors": "Xie Y.",
        "journal": "2024 IEEE Conference on Communications and Network Security, CNS 2024",
        "doi": "10.1109/CNS62487.2024.10735583",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85210595885",
        "scopus_id": "85210595885",
        "abstract": "Biometric authentication systems are increasingly needed across a broad range of applications including in smart city environments (e.g., entering hotels), and in smart home environments (e.g., controlling smart devices). Traditional methods, such as face-based and fingerprint-based authentication, usually incur high costs to be installed in all this kind of environments. In this paper, we develop a ubiquitous low-effort user authentication approach, mmPalm, based on palm recognition using millimeter wave (mmWave) signals. mmWave technology has been adopted by WiGig and 5G, making mmPalm a low-cost solution that can be widely adopted in public places. In addition, the high resolution of mmWave signals allows mmPalm to extract detailed palm characteristics (e.g., palm geometry, skin thickness, and texture) that can assemble distinctive palmprints for user authentication. Our innovative virtual antennas design further increases the spatial resolution of a commercial mmWave device, enabling it to fully capture the comprehensive palmprint features. Moreover, to address the challenge of small-scale environmental changes (e.g., variations in palm-device distances and palm orientations), we design a novel palm profile augmentation method, utilizing a Conditional Generative Adversarial Network (cGAN) to generate synthetic palm profiles for mitigating palm instability. Furthermore, we design a cross-environment adaptation framework based on transfer learning to address the challenge of large-scale environmental changes, including multipath variations introduced by human bodies and nearby furniture. Extensive experiments with 30 participants through 6 months demonstrate that mmPalm achieves 99% authentication accuracy with resilience against different types of attacks, including random, impersonation, and counterfeit.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Large Language Model for Low-Carbon Energy Transition: Roles and Challenges",
        "authors": "Cheng Y.",
        "journal": "Proceedings - 2024 4th Power System and Green Energy Conference, PSGEC 2024",
        "doi": "10.1109/PSGEC62376.2024.10721191",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85208916639",
        "scopus_id": "85208916639",
        "abstract": "The low-carbon energy transition is a pressing global challenge that requires innovative approaches and technologies to achieve sustainable development. This paper explores the potential applications of the Large Language Model (LLM) in facilitating the low-carbon energy transition from an artificial intelligence perspective and summarizes the LLM roles in three directions: simulator, decision-maker, and expert. LLM can simulate low-carbon power scenarios, carbon market dynamics, climate risk assessments, and urban planning strategies. They can also operate power system, integrate renewable energy sources, predict demand patterns, and improve energy efficiency. Furthermore, LLM can serve as an expert in carbon accounting, satellite data interpretation, database management, and sustainable supply chain management. The paper also discusses challenges and future outlooks, including data quality and accessibility, cybersecurity, LLM training costs, interdisciplinary collaboration, and evaluation benchmarks. In conclusion, applying LLM in the low-carbon energy transition holds significant potential for driving innovation and sustainability, and further research is needed to maximize their impact.",
        "author_keywords": [
            "artificial intelligence",
            "large language model",
            "low-carbon energy transition"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Energy Engineering and Power Technology",
            "Renewable Energy, Sustainability and the Environment",
            "Electrical and Electronic Engineering",
            "Control and Optimization",
            "Modeling and Simulation",
            "Transportation"
        ]
    },
    {
        "title": "Day and Night City View Image Translations Using Cycle GAN",
        "authors": "Somanna A.G.",
        "journal": "RAICS - IEEE Recent Advances in Intelligent Computational Systems",
        "doi": "10.1109/RAICS61201.2024.10689989",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85208286107",
        "scopus_id": "85208286107",
        "abstract": "CycleGAN, a type of Generative Adversarial Networks (GANs), is used in this study to tackle the difficult problem of translating cityscape photographs between day and night settings. Day-to-night picture translation is changing well-lit daytime images into nocturnal landscapes using artificial lighting, unique color palettes, and atmospheric effects, and vice versa. Previously, this work required labour-intensive manual involvement or specialised picture algorithms, but deep learning and GANs have introduced automation and better quality to this industry. CycleGAN excels at unpaired picture translation, even when there are no obvious correspondences between daylight and nighttime datasets. It makes use of the idea of cycle consistency to ensure proper translation between picture domains. This study focuses on training a CycleGAN model and found encouraging results. Beyond technical aspects, this paper highlights practical applications spanning film production, gaming, urban planning, traffic management, photography, environmental impact assessment, and more. CycleGAN's adaptability offers opportunities to enhance realism, aesthetics, and decision-making across various domains. In summary, this research underscores the potential of CycleGAN in day-to-night image translation, unlocking new possibilities in visualizing urban environments and influencing diverse industries and applications.",
        "author_keywords": [
            "Day and Night image translations using Cycle GAN"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Information Systems",
            "Control and Optimization",
            "Modeling and Simulation",
            "Instrumentation"
        ]
    },
    {
        "title": "ADC-CPANet：A remote sensing image classification method based on local-global feature fusion",
        "authors": "Wang W.",
        "journal": "National Remote Sensing Bulletin",
        "doi": "10.11834/jrs.20232658",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85208282948",
        "scopus_id": "85208282948",
        "abstract": "The rapid development of remote sensing technologies, such as satellites and unmanned aerial vehicles, has led to a surge in the amount and types of high-resolution remote sensing images. This advancement marks the onset of the“era of remote sensing big data.” Compared with low-resolution ones, high-resolution remote sensing images provide richer texture, detailed information, and a more complex structure, making them crucial for applications like urban planning. However, images within the same category can vary substantially, whereas images from different categories may appear similar. Therefore, multi-scale feature extraction is important for remote sensing image scene classification. Current methods for remote sensing image scene classification can be divided into two categories according to the feature representation: those based on manual design features and those based on deep learning. Those based manual design features cover scale-invariant feature transformation and gradient scale histogram. They can achieve good results for simple classification tasks, but the feature information they extract may be incomplete or redundant, so the accuracy of classification in complex scenes remains low. By contrast, the methods based on deep learning have made incredible progress in scene classification owing to their powerful feature extraction ability. Compared with traditional methods, Convolution Neural Networks (CNNs) are commonly used in visual tasks, particularly those that involve more complex connections and diverse convolution forms. CNNs are effective at extracting local features, but they struggle with capturing long-distance dependencies among features. The Transformer architecture, which has recently been applied to computer vision, addresses this limitation through its self-attention layer that enables global feature extraction. Recent studies show that hybrid architectures combining CNNs and Transformers can utilize their advantages. This study proposes an Aggregation Depth-wise Convolution (ADC) module and a Convolution Parallel Attention (CPA) module. The ADC module effectively extracts local feature information and enhances the robustness of the model to image flipping and rotation. The CPA module integrates global and local feature extraction, with a multi-group convolution head decomposition designed to expand the receptive field and enhance feature extraction capacity. A remote sensing image scene classification model called ADC-CPANet is designed on the basis of two modules. The ADC and CPA modules are stacked at each stage of the model, improving its ability to extract global and local features. The effectiveness of ADC-CPANet is validated using the RSSCN7 and Google Image datasets. Experimental results demonstrate that ADC-CPANet achieves classification accuracies of 96.43% on the RSSCN7 dataset and 96.04% on the Google Image dataset, outperforming other advanced models. ADC-CPANet excels in extracting global and local features, achieving competitive scene classification accuracy.",
        "author_keywords": [
            "ADC-CPANet model",
            "convolutional neural network",
            "Multi-Gconv Head Decomposition Attention",
            "remote sensing image",
            "scene classification",
            "Transformer"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Instrumentation",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Generative Design of Urban Facilities Using Knowledge Models of Building Codes",
        "authors": "Shcherbakov A.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-3-031-73344-4_62",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85207572860",
        "scopus_id": "85207572860",
        "abstract": "This paper explores the application of knowledge models of building codes in the context of generative design. This allows us to consider various requirements and restrictions set by standards and construction regulations. The main purpose of this work is to develop tools and methods that will automate the design process of urban facilities, taking into account not only aesthetic and functional aspects, but also compliance with building codes and safety regulations. To achieve this goal, we propose using design algorithms that will be integrated with knowledge models of building codes.",
        "author_keywords": [
            "Generative Design",
            "Infrastructure Design",
            "Knowledge Engineering",
            "Knowledge Models",
            "Ontological Models",
            "Urban Planning",
            "Urbanism"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Parametric Generation of Buildings and Structures Models Based on Data on Existing Infrastructure Objects",
        "authors": "Tevelev M.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-3-031-73344-4_39",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85207571694",
        "scopus_id": "85207571694",
        "abstract": "This article discusses the basic terms, theses, and methods of parametric modeling, as well as the application of all of the above to create a model of urban development based on OSM data. The data sources are considered and the completeness of the data content is considered. The possibility of editing and creating a unique facade style of a separate building based on data from OSM and algorithms that complement them, taking into account state standards, will also be considered. The practical significance of the study is represented by the development of a parametric approach based on OSM data, which further makes it possible to quickly recreate other cities or epochs in the form of chronotopes of urban development using the Houdini software package. A general overview of the Houdini software package and its tools is given, on the basis of which a study of the basics of parametric modeling and the construction of urban development was carried out. The main advantage of this complex is its node system and the ability to use the Python programming language, which makes building on the basis of nodes and parameters using algorithms in the Python programming language flexible and promising.",
        "author_keywords": [
            "Generative Modeling",
            "Modeling",
            "OSM Data Models",
            "Parametric Modeling",
            "Urban Planning"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Diffusion Models and Pseudo-Change: A Transfer Learning-Based Change Detection in Remote Sensing Images",
        "authors": "Wang J.X.",
        "journal": "IEEE Transactions on Geoscience and Remote Sensing",
        "doi": "10.1109/TGRS.2024.3484526",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85207375513",
        "scopus_id": "85207375513",
        "abstract": "Remote sensing (RS) image change detection (CD) has been a research hotspot in recent years, which plays an important role in urban planning and disaster assessment. However, since CD labels are difficult to obtain, how to utilize semantic information in RS images to improve the change prediction performance is a problem worth exploring. To solve this problem, we propose a transfer learning-based CD method that utilizes a diffusion generation model to translate high-level semantic information into low-level change information. First, we propose a pseudo-change image pair generation method that utilizes semantic labels to guide the diffusion model to generate change images. Then, the refined loss (RL) is designed to improve the model's ability to recognize change features based on the difference between pseudo-change image pairs and unlabeled image pairs. Experimental results on WHU-CD, LEVIR-CD, and GoogleGZ-CD datasets show that the proposed method effectively transfers the semantic information into change information and finally improves the model's feature recognition ability for change objects. Compared with recent CD and transfer learning methods, the proposed transfer learning model (TLM) achieves the best performance.",
        "author_keywords": [
            "Change detection (CD)",
            "diffusion model",
            "pseudo-label",
            "remote sensing (RS)"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Advancements in Image Fusion Techniques for IoT Systems: Current Trends and Applications",
        "authors": "Sharma S.",
        "journal": "2nd International Conference on Intelligent Cyber Physical Systems and Internet of Things, ICoICI 2024 - Proceedings",
        "doi": "10.1109/ICoICI62503.2024.10696732",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85207184288",
        "scopus_id": "85207184288",
        "abstract": "This research explores the transformative potential of integrating image fusion with the Internet of Things (IoT) in the field of smart healthcare. By combining multiple images from various sources, image fusion provides richer and more precise data, enhancing the capabilities of IoT devices. This synergy optimizes data quality and reliability in IoT systems, leading to improved diagnosis, patient monitoring, and telemedicine services in healthcare. The paper investigates the approaches and technologies used in combining image fusion with IoT, addressing challenges and limitations. Through case studies and current implementations, we highlight the transformative potential of this integration in creating smarter, more responsive, and efficient healthcare systems. Additionally, this study explores the implications for other sectors such as environmental monitoring, security, and smart cities.",
        "author_keywords": [
            "GAN",
            "Image Fusion",
            "IoT",
            "ML",
            "Remote Sensing"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Hardware and Architecture",
            "Information Systems and Management",
            "Industrial and Manufacturing Engineering",
            "Safety, Risk, Reliability and Quality"
        ]
    },
    {
        "title": "TGAIN: Geospatial Data Recovery Algorithm Based on GAIN-LSTM",
        "authors": "Yang L.",
        "journal": "Computers, Materials and Continua",
        "doi": "10.32604/cmc.2024.056379",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206794748",
        "scopus_id": "85206794748",
        "abstract": "Accurate geospatial data are essential for geographic information systems (GIS), environmental monitoring, and urban planning. The deep integration of the open Internet and geographic information technology has led to increasing challenges in the integrity and security of spatial data. In this paper, we consider abnormal spatial data as missing data and focus on abnormal spatial data recovery. Existing geospatial data recovery methods require complete datasets for training, resulting in time-consuming data recovery and lack of generalization. To address these issues, we propose a GAIN-LSTM-based geospatial data recovery method (TGAIN), which consists of two main works: (1) it uses a long-short-term recurrent neural network (LSTM) as a generator to analyze geospatial temporal data and capture its temporal correlation; (2) it constructs a complete TGAIN network using a cue-masked fusion matrix mechanism to obtain data that matches the original distribution of the input data. The experimental results on two publicly accessible datasets demonstrate that our proposed TGAIN approach surpasses four contemporary and traditional models in terms of mean absolute error (MAE), root mean square error (RMSE), mean square error (MSE), mean absolute percentage error (MAPE), coefficient of determination (R2) and average computational time across various data missing rates. Concurrently, TGAIN exhibits superior accuracy and robustness in data recovery compared to existing models, especially when dealing with a high rate of missing data. Our model is of great significance in improving the integrity of geospatial data and provides data support for practical applications such as urban traffic optimization prediction and personal mobility analysis.",
        "author_keywords": [
            "data recovery",
            "generative adversarial networks",
            "Geospatial data",
            "temporal correlation"
        ],
        "subject_areas": [
            "Biomaterials",
            "Modeling and Simulation",
            "Mechanics of Materials",
            "Computer Science Applications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "FROM SMART TO AUTONOMOUS CITIES ON THE EVE OF AI: Some Provocations for Architects and Designers",
        "authors": "Williams T.",
        "journal": "The Routledge Companion to Smart Design Thinking in Architecture &amp; Urbanism for a Sustainable, Living Planet",
        "doi": "10.4324/9781003384113-20",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206638846",
        "scopus_id": "85206638846",
        "abstract": "Most people on our planet increasingly live in cities and towns. For those who plan, design, deliver, and manage the built environment, they have become prime sites of creativity and production, real and virtual. In practice, architects and designers working in urban environments do so in three core contexts. The continuing evolution of the city’s physical fabric, core supporting networks, and planning and zoning frameworks. Changing environmental policies and shifting public priorities. Revolution in technology, digital networks, devices, and data-driven enterprises and services. In identifying these three contexts, we do not suggest that the potential of all is being fully realized or that interactions and integrations between them are fully explored. Instead, this chapter contends that Architecture and design have not always fully exploited the possibilities of the digital toolkit. Smart City initiatives have not been systematically pursued by as many cities as first envisaged. Opportunities for integration of smart buildings, smart precincts, and smart green infrastructure with Smart City systems and data-driven city governance have been implemented patchily. The arrival of Artificial Intelligence (AI), particularly generative AI, into city design, infrastructure, and management systems has resulted in a new combination that is being termed ‘Urban AI’ (Luusua et al., 2023). We suggest progress toward realizing Smart City objectives has been uneven and modest, particularly in cities of ‘the West.' This will have implications for tech adoption and future professional practice in built environments.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Generative AI (GenAI) and smart cities: Efficiency, cohesion, and sustainability",
        "authors": "Moreno-Ibarra M.",
        "journal": "Smart Cities: Lock-in, Path-dependence and Non-linearity of Digitalization and Smartification",
        "doi": "10.1201/9781003415930-11",
        "publication_date": "2024",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206611731",
        "scopus_id": "85206611731",
        "abstract": "Given the variability of challenges cities and urban areas face today, including most profoundly inclusion, safety, and resilience, the objective of this chapter is to examine how generative artificial intelligence (GenAI) may facilitate the process of addressing these challenges, thus fostering sustainable cities. By focusing explicitly on smart cities, in this chapter, it is argued that a great variety of GenAI-based applications exist, and these may bear great value for smart cities and their inhabitants. Indeed, by now, GenAI and GenAI-based applications have proven useful in integrating and analyzing information, thereby facilitating operations such as analysis, data management, and description. Accordingly, when utilized in the smart city and/or urban context, GenAI is of value in relation to urban planning, disaster preparedness and mitigation, traffic management, public safety, waste management, and last but not least improving the efficiency and quality of services’ provision to the city inhabitants. Clearly, the use of GenAI in this context presents challenges too, including data timeliness, different representations, and other issues related to the complexity of urban data. These considerations should be considered in the design, development, and implementation of GenAI-based applications to ensure their effectiveness, accuracy, and compliance with regulatory frameworks as well as with values and principles. None of these is possible without an explicit engagement of human beings, i.e., experts, who would provide monitoring and oversight over the GenAI-devised suggestions and recommendations.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Leveraging Trusted Input Framework to Correct and Forecast the Electricity Load in Smart City Zones Against Adversarial Attacks",
        "authors": "Kamilin M.H.B.",
        "journal": "ICFTSS 2024 - International Conference on Future Technologies for Smart Society",
        "doi": "10.1109/ICFTSS61109.2024.10690268",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206575794",
        "scopus_id": "85206575794",
        "abstract": "Recent cybersecurity research is shifting to favor adversarial attacks, which are harder to detect and counteract, as they are not apparent, and they exploit the vulnerability of the deployed machine learning model. With machine learning seeing wider adoption to forecast the electricity load in smart cities to help maintain grid stability and better integrate with renewable energies, the energy sector is at risk. Although several methods exist to mitigate the problem, adversarial training fails against the attack that utilizes a surrogate model. In addition, it cannot differentiate between the original and adversarial data without relying on adversarial detection. Furthermore, existing detections do not correct the data to keep the forecast running. In this paper, the Multivariable Convolutional Encoder implementation in a Trusted Input Framework was proposed, which utilizes hidden input data with a high correlation to act as a trap when creating the surrogate model, measuring the attack intensity, and improve the accuracy to 'correct' and 'forecast' on the target data. In the experiment, the proposed method not only fooled the surrogate but also achieved a coefficient of determination score of 0.9183 on the most robust Projected Gradient Descent-based adversarial attack, which is 13.933% better than the adversarial training.",
        "author_keywords": [
            "Cyberattack",
            "Forecast",
            "Smart Grids"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Control and Optimization",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Smart City Traffic Monitoring and Control: Integrating Wireless Sensors with KNN-TCGAN Model",
        "authors": "Manavadaria M.S.",
        "journal": "2nd IEEE International Conference on Data Science and Network Security, ICDSNS 2024",
        "doi": "10.1109/ICDSNS62112.2024.10690988",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85206560610",
        "scopus_id": "85206560610",
        "abstract": "A city's economic growth is heavily influenced by its transport infrastructure, since the demand to move workers, customers, and goods is on the rise. Intelligent transport systems (ITS) are an integral part of the smart cities project. These systems use state-of-the-art technology to solve traffic problems. There are a lot of ITS solutions in use all over the world right now. The approach consists of three phases, which are feature selection, feature extraction, and model training. The goal of feature selection in smart cities is to identify relevant qualities and exclude those that aren't essential in order to collect data that correctly represents the problem at hand while reducing inefficiencies. A variant of principal component analysis (PCA) that has gained favor in feature extraction, kernel-PCA allows one to understand nonlinearities in data. A KNN-TACGAN was used for the model's training. Compared to KNN and TACGAN, the proposed technique has a better average accuracy of 92.47%.",
        "author_keywords": [
            "smart cities",
            "tabular auxiliary classifier generative adversarial networks model (TACGAN)",
            "traffic surveillance and management"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality",
            "Health Informatics"
        ]
    },
    {
        "title": "Using Large Language Model and Speech Synthesis Technology to Achieve Realistic Interactive Experiences in Smart City Applications",
        "authors": "Zhou C.H.",
        "journal": "11th IEEE International Conference on Consumer Electronics - Taiwan, ICCE-Taiwan 2024",
        "doi": "10.1109/ICCE-Taiwan62264.2024.10674564",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205806188",
        "scopus_id": "85205806188",
        "abstract": "With the development of large language models, these technologies show tremendous potential in various areas of smart cities, particularly in enhancing urban services and residents' quality of life. There is an increasing acceptance among the public for highly interactive virtual entities. Leveraging large language models and speech synthesis technology has not only garnered attention in the entertainment industry but also holds great promise across various facets of smart cities. This study aims to integrate advanced language understanding and speech synthesis technologies to provide residents and visitors in smart cities with a more natural and interactive experience, ultimately contributing to the thriving development of smart cities in the consumer market.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "GANs the UAV Path Planner: UAV-Based RIS-Assisted Wireless Communication for Internet of Autonomous Vehicles",
        "authors": "Eskandari M.",
        "journal": "2024 IEEE 19th Conference on Industrial Electronics and Applications, ICIEA 2024",
        "doi": "10.1109/ICIEA61579.2024.10664697",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205723355",
        "scopus_id": "85205723355",
        "abstract": "Intelligent vehicles need wireless communication with other vehicles for sensor fusion and dynamic mapping for safe autonomous driving. However, the wireless communication channels in modern networks are fragile due to the blockages by buildings in dense urban environments. Particularly, moving vehicles may get off the beam direction, leading to a loss of signals. Therefore, in this paper, we deploy an unmanned aerial vehicle (UAV) to provide stable aerial wireless communication channels for Internet-of-autonomous vehicles (IoA Vs), assisted by ground reconfigurable intelligent surfaces (RISs). Nevertheless, the path planning for the UAV is challenging as the UAV should maneuver among the skyscrapers. This requires energy-efficient obstacle-free path planning while considering UAV kinematics, i.e., speed, nonholonomic constraints, etc. Besides, the UAV should fly through the paths that provide maximum line-of-sight (LoS) channels for IoA Vs, which increases the time complexity of the path planner. To tackle the issue, we introduce deep learning-based generative adversarial networks (GANs) as the UAV path planner for real-time path planning and autonomous navigation. Simulation results are provided to verify the effectiveness of the proposed technique.",
        "author_keywords": [
            "Autonomous navigation",
            "generative adversarial networks (GANs)",
            "internet of vehicles",
            "reconfigurable intelligent surfaces (RISs)",
            "unmanned aerial vehicles (UAVs)",
            "wireless communication"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering",
            "Industrial and Manufacturing Engineering",
            "Control and Optimization",
            "Mechanical Engineering",
            "Instrumentation"
        ]
    },
    {
        "title": "Adversarial Attacks and Defenses in Deep Learning",
        "authors": "Kashyap S.",
        "journal": "Proceedings - 2024 International Conference on Emerging Innovations and Advanced Computing, INNOCOMP 2024",
        "doi": "10.1109/INNOCOMP63224.2024.00059",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205549029",
        "scopus_id": "85205549029",
        "abstract": "Deep learning, a cornerstone of artificial intelligence (AI), has revolutionized a number of fields, including self-driving cars, image recognition, and intelligent medical applications. These developments have aided in the development of smart cities. That being said, new findings have shown that deep neural networks are susceptible to hostile attacks on security-critical tasks. This research paper investigates the related defensive strategies and explores the crucial problem of adversarial intrusions in deep learning. It draws attention to the adversarial attacks that deep neural networks are susceptible to, especially in high-security applications like network intrusion detection systems and radiofrequency identification. This paper presents the idea of adversarial intrusions, looks at their theoretical underpinnings, and evaluates how they affect different kinds of data, such as text, graphs, and images. The field of cybersecurity is given special attention, with attacks being categorized using adversarial examples and defensive measures being discussed. Additionally, the study introduces FIAT, a novel adversarial defense strategy based on feature-level interpretability. This paper intends to stimulate future research endeavors to guarantee the security and resilience of deep learning algorithms in real-world scenarios by offering a thorough overview of adversarial intrusions and defenses in the field of deep learning for Edge AI.",
        "author_keywords": [
            "Adversarial Attack",
            "Adversarial Defense",
            "Black-Box Attack",
            "Convolutional Neural Network",
            "Deep Learning",
            "Deep Neural Network (DNN)",
            "Feature-Level Interpretability",
            "Network Intrusion Detection",
            "Radiofrequency Fingerprinting Identification",
            "Robustness",
            "White-Box Attack"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Information Systems",
            "Signal Processing",
            "Media Technology"
        ]
    },
    {
        "title": "Generation of Building Plans Using ML and AI",
        "authors": "Dasari A.",
        "journal": "Lecture Notes in Civil Engineering",
        "doi": "10.1007/978-981-97-4844-0_69",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205390313",
        "scopus_id": "85205390313",
        "abstract": "Designing residential plans requires expertise and time. Traditional methods are prone to errors and are time-consuming. As a result, deep learning-based methods gained popularity in recent years. This research paper proposes a novel approach to generating building and residential plans using VAE and GANs. The project started with a VAE with Dall-e, which imposed more constraints on the output image. However, this led to pixelated images that were difficult to interpret. To overcome this, GANs were used, which required fewer constraints to produce more explicit output images. In GANs, two networks are trained simultaneously, a generator network that produces new samples and a discriminator network that evaluates the quality of the generated samples. Through adversarial training, the generator network learns to produce images that resemble the actual samples. The proposed GAN approach can overpower traditional residential plan design methods, producing accurate and high-resolution plans that are easier to interpret. However, using GANs is challenging, with instability in the training process leading to mode collapse or gradient vanishing. In conclusion, this research demonstrates the potential of deep learning-based methods for generating building or residential plans. The proposed approach using VAE and GANs can reduce the effort and time required to design a residential project, making it a valuable tool for architects and urban planners. However, further research is needed to address the challenges associated with GANs and improve the model's performance.",
        "author_keywords": [
            "Architectural design",
            "cGANs—conditional generative adversarial networks",
            "GANs—generative adversarial networks",
            "House plans",
            "Neural networks",
            "VAE—variable auto encoder"
        ],
        "subject_areas": [
            "Civil and Structural Engineering"
        ]
    },
    {
        "title": "HRNet: Differentially Private Hierarchical and Multi-Resolution Network for Human Mobility Data Synthesization",
        "authors": "Takagi S.",
        "journal": "Proceedings of the VLDB Endowment",
        "doi": "10.14778/3681954.3681983",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85205355337",
        "scopus_id": "85205355337",
        "abstract": "Human mobility data offers valuable insights for many applications such as urban planning and pandemic response, but its use also raises privacy concerns. In this paper, we introduce the Hierarchical and Multi-Resolution Network (HRNet), a novel deep generative model specifically designed to synthesize realistic human mobility data while guaranteeing differential privacy. We first identify the key difficulties inherent in learning human mobility data under differential privacy. In response to these challenges, HR Net integrates three components: a hierarchical location encoding mechanism, multi-task learning across multiple resolutions, and private pre-training. These elements collectively enhance the model’s ability under the constraints of differential privacy. Through extensive comparative experiments utilizing a real-world dataset, HRNet demonstrates a marked improvement over existing methods in balancing the utility-privacy trade-off.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Smart Urban Traffic Management: Leveraging Automatic Control and Intelligent Systems for Improved Safety in Commercial Vehicle Road Banning Operations",
        "authors": "Subbiah A.",
        "journal": "2024 6th IEEE Symposium on Computers and Informatics, ISCI 2024",
        "doi": "10.1109/ISCI62787.2024.10668243",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85204984863",
        "scopus_id": "85204984863",
        "abstract": "Urbanization presents formidable challenges to global urban transportation systems, accentuating safety concerns amidst burgeoning vehicular traffic. Commercial vehicles, owing to their prevalence and size, significantly contribute to congestion and accidents. Statistics from authoritative bodies such as Malaysia Highway Authority (LLM) underscore this severity, with large trucks notably implicated in a significant share of traffic fatalities. Asia, among rapid urbanization, grapples with heightened road safety issues, as emphasized by the World Health Organization (WHO). The alarming statistics reveal substantial involvement of commercial vehicles in traffic-related fatalities, necessitating urgent innovative interventions. In response, this research advocates for the Smart Urban Vehicular Traffic Management System, harnessing automatic control and intelligent systems integrated with Artificial Intelligence of Things (AIoT) in a cloud computing environment to boost safety and efficiency in commercial vehicle operations. Addressing challenges inherent in the traditional cloud computing paradigm, particularly with the increasing AIoT devices, we propose an edge-cloud architecture. Leveraging by the federated learning techniques, this architecture ensures privacy while optimizing service quality for AIoT devices essential to commercial vehicle management. Central to this proposal is the pursuit of scalability and adaptability, promising transformative impacts on urban traffic safety. Through meticulous analysis, this research underscores the imperative for innovative transportation management solutions, with proposed applications extending to the development of smart sensor devices for data-driven urban road traffic bans management, signalling a paradigm shift towards smarter cities.",
        "author_keywords": [
            "Cloud computing",
            "Commercial transportation road-banning",
            "Edge-cloud computing",
            "Smart Cities",
            "Vehicular management system"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Information Systems",
            "Information Systems and Management",
            "Computational Mathematics",
            "Control and Optimization",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Super-Resolution of Satellite Lidars for Forest Studies Via Generative Adversarial Networks",
        "authors": "Ramirez-Jaime A.",
        "journal": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "doi": "10.1109/IGARSS53475.2024.10641698",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85204902113",
        "scopus_id": "85204902113",
        "abstract": "This paper proposes an algorithm to enhance the resolution of satellite lidar data using Generative Adversarial Networks (GANs) under the hyperheight data cube framework. A super-resolution algorithm based on adversarial training is applied to overcome the challenges of long-range satellite lidar systems. The algorithm generates high-resolution super-resolved outputs from low-resolution inputs, improving the quality of several lidar representations such as canopy height models and profiles. This approach not only advances lidar-based models but also facilitates sophisticated lidar data analysis for various fields, such as environmental science, urban planning, and disaster management. The super-resolved lidar data provides a more precise depiction of the Earth's surface, opening up new avenues for research and applications in different domains. The framework's effectiveness was validated in the Florida Everglades National Park, where the resolution was increased from a 3m x 6m grid with 10m footprints to a 3m x 3m grid with 3m footprints, and the vertical resolution was enhanced from 0.5m to 0.25m.",
        "author_keywords": [
            "Canopy Height",
            "Generative Adversarial Networks",
            "Lidar"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "An Enhanced Trans-Involution Network for Building Footprint Extraction from High Resolution Orthoimagery",
        "authors": "He Z.",
        "journal": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "doi": "10.1109/IGARSS53475.2024.10640523",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85204878246",
        "scopus_id": "85204878246",
        "abstract": "The amalgamation of data visualization and geospatial insights has driven significantly advancements in remote sensing for applications like damage detection and urban planning, particularly building rooftop extraction from high spatial satellite imagery. However, building rooftop extraction using deep learning methods often results in outputs with unclear margin delineation. In this study, we propose a novel approach that combines Transformer architectures, involution, and an enhanced U-net (E-Unet) [1] to improve building footprint extraction performance. Our method demonstrates remarkable accuracy in complex urban environments in the Waterloo Building Dataset. Transformers, renowned for their success in natural language processing, have excelled in adeptness at analyzing sequential data. By using the embedding and multi-head attention blocks, this method is becoming increasingly valuable for building extraction. Involution, in turn, augments neural networks by providing spatial-specific adaptability, effectively extracting inter-band features and surpassing convolutional limitations. Through comprehensive comparative model experiments on the Waterloo building dataset, the optimal architecture was identified. The model significantly enhances accuracy when the Transformer architecture is integrated at the output of the E-Unet. Our proposed network achieves outstanding at the crucial metric values of IoU, mIoU, Precision, F1-score in 81.2, 91.9, 92.9, 89.8 (%), surpassing established frameworks such as FCN-8s, U-Net, DeepLab v3+, Fast Statistical Convolutional Neural Network (SCNN), High-Resolution Net (HRNet) v2, Mask R-CNN, as well as E-Unet.",
        "author_keywords": [
            "Building footprint extraction",
            "E-Unet",
            "Involution",
            "Transformer-based method"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Style Transfer of Computer-Generated Orthophoto Landscape Images Into a Realistic Look",
        "authors": "Krajšek N.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-71707-9_9",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85204626905",
        "scopus_id": "85204626905",
        "abstract": "In this paper, we present a novel application of Neural Style Transfer (NST) for converting procedurally generated orthophoto landscape images into highly realistic representations. Traditionally used to apply artistic styles to images, we adapt NST to transfer the photorealistic qualities of real aerial orthophoto images to synthetic terrain images. This enables the creation of realistic visuals from generated landscapes, addressing the common issues of stylization, abstraction, and inaccuracy in synthetic imagery. Our approach involves upgrading and modifying existing NST techniques and their comparison. The evaluation demonstrates that our methods produce more convincing and realistic results than general generative models. These findings highlight the potential of NST in enhancing the realism of computer-generated landscapes, with possible applications in urban planning, environmental simulations, video games, and the film industry.",
        "author_keywords": [
            "3D models",
            "neural style transfer",
            "orthophoto images",
            "terrain generation",
            "texturing",
            "virtual worlds"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Framework for Upscaling Missing Data in Electricity Consumption Datasets Using Generative Adversarial Networks",
        "authors": "Romero D.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-3-031-52517-9_13",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202812783",
        "scopus_id": "85202812783",
        "abstract": "One of the leading issues in adopting electricity load prediction today is the lack of high-quality and high-resolution real-world datasets. This poses a major problem especially in the context of electricity load prediction where high quality data are essential. To address this issue, this paper presents a framework that transforms datasets with missing values into high quality and high-resolution datasets using Generative Adversarial Networks (GANs). The capability of this framework was exhibited through a case study, the CIC-IPN electricity consumption dataset. Results show that the framework was able to successfully impute the missing values in the dataset while capturing the general patterns in the data. This framework can then be used to upscale other electricity datasets that contain missing values which can then be further used for electricity load prediction for smart cities and smart buildings.",
        "author_keywords": [
            "Electricity consumption dataset",
            "Generative Adversarial Networks",
            "Missing Data",
            "Upscaling"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "Spectral-Cascaded Diffusion Model for Remote Sensing Image Spectral Super-Resolution",
        "authors": "Chen B.",
        "journal": "IEEE Transactions on Geoscience and Remote Sensing",
        "doi": "10.1109/TGRS.2024.3450874",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202720090",
        "scopus_id": "85202720090",
        "abstract": "Hyperspectral remote sensing images (HSIs) have unique advantages in urban planning, precision agriculture, and ecology monitoring since they provide rich spectral information. However, hyperspectral imaging usually suffers from low spatial resolution and high cost, which limits the wide application of hyperspectral data. Spectral super-resolution provides a promising solution to acquire hyperspectral images with high spatial resolution and low cost, taking RGB images as input. Existing spectral super-resolution methods utilize neural networks following a single-shot framework, i.e., final results are obtained by one-stage spectral super-resolution, which struggles to capture and model the complex relationships between spectral bands. In this article, we propose a spectral-cascaded diffusion model (SCDM), a coarse-to-fine spectral super-resolution method based on the diffusion model. The diffusion model fits the real data distribution through stepwise denoising, which is naturally suitable for modeling rich spectral information. We cascade the diffusion model in the spectral dimension to gradually refine the spectral trends and enrich spectral information of the pixels. The cascade solves the highly ill-posed problem of spectral super-resolution step-by-step, mitigating the inaccuracies of previous single-shot approaches. To better utilize the potential of the diffusion model for spectral super-resolution, we design image condition mixture guidance (ICMG) to enhance the guidance of image conditions and progressive dynamic truncation (PDT) to limit cumulative errors in the sampling process. Experimental results demonstrate that our method achieves state-of-the-art performance in spectral super-resolution. Codes can be found at https://github.com/Mr-Bamboo/SCDM.",
        "author_keywords": [
            "Cascade-based methods",
            "diffusion model",
            "remote sensing",
            "spectral super-resolution"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Translating street view imagery to correct perspectives to enhance bikeability and walkability studies",
        "authors": "Ito K.",
        "journal": "International Journal of Geographical Information Science",
        "doi": "10.1080/13658816.2024.2391969",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202503671",
        "scopus_id": "85202503671",
        "abstract": "Street view imagery (SVI), an emerging geospatial dataset, is useful for evaluating active transportation infrastructure, but it faces potential biases from its vehicle-based capture method, diverging from pedestrians’ and cyclists’ perspectives. Existing literature lacks both an examination of these biases and a solution. This study identifies and quantifies these biases by comparing conventional SVI with views from the road shoulder/sidewalk. To mitigate such perspective biases, we introduce a novel framework with generative adversarial network (GAN)-based image generation models (Pix2Pix and CycleGAN), an image regression model (ResNet-50), and a tabular model (LightGBM). Experiments assessed model effectiveness in translating car-centric views to those from pedestrian and cyclist perspectives. Results show significant differences in semantic indicators (e.g. green view index) between road center and road shoulder/sidewalk SVI, with low Pearson’s correlation coefficients r (0.35–0.55 for road shoulders and 0.45–0.47 for sidewalks) indicating bias. The framework succeeded in creating realistic images and aligning pixel ratios between perspectives, achieving strong correlation coefficients (0.81 for road shoulders and 0.83 for sidewalks), thus reducing bias. This work contributes by providing a scalable and model-agnostic approach to produce accurate SVIs for urban planning and sustainability, setting a foundation for improving bikeability and walkability assessments and promoting active transportation.",
        "author_keywords": [
            "active mobility",
            "bikeability",
            "Generative adversarial networks",
            "spatial data infrastructures",
            "walkability"
        ],
        "subject_areas": [
            "Information Systems",
            "Geography, Planning and Development",
            "Library and Information Sciences"
        ]
    },
    {
        "title": "An LLM-driven Framework for Multiple-Vehicle Dispatching and Navigation in Smart City Landscapes",
        "authors": "Chen R.",
        "journal": "Proceedings - IEEE International Conference on Robotics and Automation",
        "doi": "10.1109/ICRA57147.2024.10610578",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202444138",
        "scopus_id": "85202444138",
        "abstract": "In the context of smart cities, autonomous vehicles, such as unmanned delivery vehicles and taxis are gradually gaining acceptance. However, their application scenarios remain significantly fragmented. Typically, an Autonomous Multi-Functional Vehicle (AMFV) is not engaged in other scenarios when idle in a specific one. Currently, a unified system capable of coordinating and using these resources efficiently is lacking. Moreover, there is an absence of an advanced navigation algorithm for facilitating coordinated navigation among Heterogeneous Vehicles (HVs). To address these issues, we propose the LLM-driven Multi-vehicle Dispatching and navigation (LiMeda) framework. It comprises an LLM-driven scheduling module that facilitates efficient allocation considering task scenarios and vehicle information, which addresses the issue of incompatible vehicle resources across various smart city scenarios. And the other is a navigation module, founded on the Heterogeneous Agent Reinforcement Learning (HARL) framework we previously proposed, which can effectively perform cooperative navigation tasks among heterogeneous agents, assisting the cooperative task completion by HVs in a smart city. Experimental results show our method outperforms both traditional scheduling algorithms and Reinforcement Learning navigation algorithms in metric terms. Additionally, it shows remarkable scalability and generalization under varying city scales, vehicle numbers, and task numbers.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Deepfake at Star Isle Real Estate Group",
        "authors": "Sipior J.C.",
        "journal": "Communications of the Association for Information Systems",
        "doi": "10.17705/1CAIS.05513",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202431865",
        "scopus_id": "85202431865",
        "abstract": "This paper is a teaching case based on a fictitious company inspired by the actual experiences of employees working at a UK-based engineering group intended for use in information systems or business courses at the undergraduate or graduate level. In this teaching case, students are introduced to Star Isle Real Estate Group, Inc. (“Star Isle”), a fictitious American real estate investment, development, and management company developing a planned community named Spiral Galaxy with smart city features. The teaching case provides the opportunity for students to explore real-time video deepfakes.",
        "author_keywords": [
            "Deepfake",
            "Deepfake in the Workplace",
            "Generative Artificial Intelligence",
            "Real-time Video Deepfake",
            "Social Engineering",
            "Teaching Case"
        ],
        "subject_areas": [
            "Information Systems"
        ]
    },
    {
        "title": "Traffic Data Augmentation Using GANs for ITS",
        "authors": "Dabboussi A.H.",
        "journal": "Proceedings - 2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things, DCOSS-IoT 2024",
        "doi": "10.1109/DCOSS-IoT61029.2024.00020",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85202353982",
        "scopus_id": "85202353982",
        "abstract": "Intelligent Transportation Systems (ITS) play a pivotal role in shaping the foundation of smart cities, providing data-driven solutions for traffic management, prediction, and safety. However, these applications often face a significant challenge - data scarcity. Insufficient data limits the effectiveness of machine learning models in the context of ITS. To address this issue, this paper presents a novel data augmentation solution using Generative Adversarial Networks (GANs). By collecting sensor-based traffic speed data with contextual labels and training a GAN-based model to generate realistic traffic data for specific days and times, this research successfully proposes a solution to the problem of data scarcity. The generated data undergoes comprehensive qualitative and quantitative evaluations, demonstrating its potential to enhance ITS applications. Furthermore, the generated data is utilized to augment the training data for multiple traffic prediction models, effectively enhancing their performance. This approach opens new avenues for the development of intelligent and sustainable transportation systems, ultimately contributing to the advancement of smarter and more resilient cities.",
        "author_keywords": [
            "GAN",
            "Intelligent Transportation Systems",
            "IoT",
            "Machine Learning",
            "Smart Cities",
            "Traffic Prediction",
            "Wasserstein GAN"
        ],
        "subject_areas": [
            "Modeling and Simulation",
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Hardware and Architecture",
            "Information Systems",
            "Information Systems and Management",
            "Control and Optimization"
        ]
    },
    {
        "title": "Novel Attention-Based Framework for Person Re-identification in Video Surveillance",
        "authors": "Cui L.",
        "journal": "Lecture Notes in Electrical Engineering",
        "doi": "10.1007/978-981-97-3682-9_72",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201938644",
        "scopus_id": "85201938644",
        "abstract": "Intelligent video surveillance systems, automatic entry and retail systems at theme parks, airport passenger flow control, and automated driving behavior analysis are a few applications where critical insights can be generated by detecting and identifying people through a camera network. In different public locations, such as train stations, airports, hospitals, shopping centers, etc., widespread camera networks are used daily, covering vast areas and having non-overlapping perspectives and providing a tremendous amount of relevant data. We cannot rely on manual monitoring to use this data efficiently for public safety applications and thus need reliable automated systems that can track the behavior of a person through several cameras. Person reidentification (PReID) is a simple task for this and plays a vital role in re-identifying persons from video surveillance cameras. In this paper, we leverage the attention-based mechanism to re-identify persons from video surveillance cameras by using the image modality translation and CycleGAN, which served as data augmentation in our proposed network. We outperformed against all measures compared to other state-of-the-art methods.",
        "author_keywords": [
            "Generative Adversarial Network",
            "Person Reidentification",
            "Smart Cities",
            "Video Surveillance"
        ],
        "subject_areas": [
            "Industrial and Manufacturing Engineering"
        ]
    },
    {
        "title": "The Smart City Waste Classification Management System: Strategies and Applications Based on Computer Vision",
        "authors": "Cai W.",
        "journal": "Journal of Organizational and End User Computing",
        "doi": "10.4018/JOEUC.351242",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201870469",
        "scopus_id": "85201870469",
        "abstract": "In response to the growing demands of urbanization, our research presents a pioneering Smart City Waste Classification Management System utilizing advanced computer vision techniques for efficient and accurate waste sorting. This system integrates the innovative CT-Net algorithm, which synergizes the strengths of Convolutional Neural Networks (CNNs) and Transformer architectures to tackle the complex challenges posed by varied and unpredictable urban waste characteristics. Extensive evaluations on multiple datasets, including the proprietary Huawei Cloud waste dataset, demonstrate that our model significantly outperforms existing methodologies in terms of precision, robustness, and processing speed. By deploying this technology within urban waste management frameworks, cities can achieve remarkable improvements in sustainability and operational efficiency.",
        "author_keywords": [
            "Deep Learning",
            "Object Detection",
            "Object Recognition",
            "System Construction"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Science Applications",
            "Strategy and Management"
        ]
    },
    {
        "title": "Urban Vehicle Trajectory Generation Based on Generative Adversarial Imitation Learning",
        "authors": "Wang M.",
        "journal": "IEEE Transactions on Vehicular Technology",
        "doi": "10.1109/TVT.2024.3437412",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201761495",
        "scopus_id": "85201761495",
        "abstract": "With the rapid development of smart cities, the collection of vehicle trajectory data through sensors has increased significantly. While many studies have utilized calibrated physical car-following models (CFM) and machine learning techniques for trajectory prediction, these approaches often falter in complex, dynamic traffic scenarios. Addressing this gap, this paper introduces PS-TrajGAIL, a generative adversarial imitation learning framework tailored for urban vehicle trajectory generation. Contrary to conventional discriminative models, PS-TrajGAIL employs a generative model to capture the inherent distribution of urban vehicle trajectories. This framework models the tasks of trajectory generation as a partially observable Markov decision process based on imitation learning. PS-TrajGAIL's architecture features a generator, which simulates vehicle behavior to produce synthetic trajectories, and a discriminator that distinguishes between authentic and generated trajectories. In addition, the driving policy within the generator is fine-tuned using the Trust Region Policy Optimization (TRPO) algorithm, ensuring safety in vehicle driving. Experimental evaluations on both synthetic and real-world datasets highlight that PS-TrajGAIL notably surpasses existing baselines and state-of-the-art approaches in trajectory generation.",
        "author_keywords": [
            "Generative adversarial learning",
            "imitation learning",
            "traffic simulation",
            "trajectory data generation",
            "urban vehicle trajectories"
        ],
        "subject_areas": [
            "Automotive Engineering",
            "Aerospace Engineering",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "NxLFTNet: NARX LSTM Forward Taylor Network for Traffic Forecasting",
        "authors": "Mangali S.",
        "journal": "International Journal of Intelligent Engineering and Systems",
        "doi": "10.22266/ijies2024.1031.14",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201501001",
        "scopus_id": "85201501001",
        "abstract": "Due to the growing level of transportation systems, numerous social troubles arise and create serious hazards like air pollution, the greenhouse effect, and traffic congestion. Hence, Traffic forecasting is essential for providing numerous applications in smart city management like congestion avoidance, navigation guidance, and urban traffic control. Still, the traffic prediction is difficult, since each road network is greatly dependent on other networks in a temporally and spatially manner. For capturing the temporal and spatial dependency, the Nonlinear autoregressive models with exogenous inputs (NARX) - Long Short Term Memory (LSTM) Forward Taylor Network (NxLFTN)based traffic forecasting is proposed in this paper. The traffic network is considered as a graph, which contains the spatio-temporal data. The spatio-temporal data is high-dimensional and complex. To embed the data into a low-dimensionality region, the spatio-temporal embedding (STE) generator is employed. Moreover, the STE generator is used for predicting the daily embedding and the weekly embedding of the time related to the present traffic signal. At last, the traffic forecasting is carried out using the NxLFTNet. In addition, the Mean absolute percentage error (MAPE), Root Mean square error (RMSE), and Mean Absolute Error (MAE) are used to validate the effectiveness of the NxLFTNet. It offered the finest MAPE, RMSE, and MAE of 0.003, 0.046, and 0.04 when considering the data from the Contra Costa country in Greater Bay Area (GBA) of LargeST dataset for delay is 50 minutes.",
        "author_keywords": [
            "Long short term memory (LSTM)",
            "Nonlinear autoregressive models with exogenous inputs (NARX)",
            "Spatio-temporal embedding (STE) generator",
            "Traffic forecasting",
            "Traffic signal"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "A Multimodal Deep Learning Approach for High-Resolution Land Surface Temperature Estimation",
        "authors": "Khedher I.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-981-97-2004-0_26",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85201018362",
        "scopus_id": "85201018362",
        "abstract": "Urban Heat Islands (UHI), characterized by elevated temperatures, present important challenges to sustainability. This study introduces a novel multimodal approach for high-resolution Land Surface Temperature (LST) estimation, a critical component in addressing UHI. The methodology initially employs RGB orthophotography for LST estimation and progressively integrates additional relevant variables correlated with LST, including elevation and land cover. Leveraging conditional Generative Adversarial Networks (cGANs), LST maps are generated, enabling informed urban planning. Experimental results highlight the potential of this multimodal approach, emphasizing that the combination of all data variables yields the most favorable outcomes. These findings advance UHI research and support data-driven urban climate management.",
        "author_keywords": [
            "conditional Generative Adversarial Networks (cGANs)",
            "Land Surface Temperature (LST) Estimation",
            "Multimodal approach",
            "Urban Heat Islands (UHI)"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Geospatial Big Data: Survey and Challenges",
        "authors": "Wu J.",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "doi": "10.1109/JSTARS.2024.3438376",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200804056",
        "scopus_id": "85200804056",
        "abstract": "In recent years, geospatial big data (GBD) has obtained attention across various disciplines, categorized into big Earth observation data and big human behavior data. Identifying geospatial patterns from GBD has been a vital research focus in the fields of urban management and environmental sustainability. This article reviews the evolution of GBD mining and its integration with advanced artificial intelligence techniques. GBD consists of data generated by satellites, sensors, mobile devices, and geographical information systems, and we categorize geospatial data based on different perspectives. We outline the process of GBD mining and demonstrate how it can be incorporated into a unified framework. In addition, we explore new technologies, such as large language models, the metaverse, and knowledge graphs, and how they could make GBD even more useful. We also share examples of GBD helping with city management and protecting the environment. Finally, we discuss the real challenges that come up when working with GBD, such as issues with data retrieval and security. Our goal is to give readers a clear view of where GBD mining stands today and where it might go next.",
        "author_keywords": [
            "Artificial intelligence (AI)",
            "big data",
            "geospatial big data (GBD)",
            "geospatial data"
        ],
        "subject_areas": [
            "Computers in Earth Sciences",
            "Atmospheric Science"
        ]
    },
    {
        "title": "The STVchrono Dataset: Towards Continuous Change Recognition in Time",
        "authors": "Sun Y.",
        "journal": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
        "doi": "10.1109/CVPR52733.2024.01338",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200611744",
        "scopus_id": "85200611744",
        "abstract": "Recognizing continuous changes offers valuable insights into past historical events, supports current trend analysis, and facilitates future planning. This knowledge is crucial for a variety of fields, such as meteorology and agriculture, environmental science, urban planning and construction, tourism, and cultural preservation. Currently available datasets in the field of scene change understanding primarily concentrate on two main tasks: the detection of changed regions within a scene and the linguistic description of the change content. Existing datasets focus on recognizing discrete changes, such as adding or deleting an object from two images, and largely rely on artificially generated images. Consequently, the existing change understanding methods primarily focus on identifying distinct object differences, overlooking the importance of continuous, gradual changes occurring over extended time intervals. To address the above issues, we propose a novel benchmark dataset, STVchrono, targeting the localization and description of long-term continuous changes in real-world scenes. The dataset consists of 71,900 photographs from Google Street View API taken over an 18-year span across 50 cities all over the world. Our STVchrono dataset is designed to support real-world continuous change recognition and description in both image pairs and extended image sequences, while also enabling the segmentation of changed regions. We conduct experiments to evaluate state-of-the- art methods on continuous change description and segmentation, as well as multimodal Large Language Models for describing changes. Our findings reveal that even the most advanced methods lag human performance, emphasizing the need to adapt them to continuously changing real-world scenarios. We hope that our benchmark dataset will further facilitate the research of temporal change recognition in a dynamic world. The STVchrono dataset is available at STVchrono Dataset.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "From Simulation to Prediction: Enhancing Digital Twins with Advanced Generative AI Technologies",
        "authors": "Huang Y.",
        "journal": "IEEE International Conference on Control and Automation, ICCA",
        "doi": "10.1109/ICCA62789.2024.10591881",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200403032",
        "scopus_id": "85200403032",
        "abstract": "The integration of Generative Artificial Intelli-gence (GAI) into Digital Twins (DTs) marks a revolutionary stride in the evolution of virtual replicas for physical systems. This paper explores the cutting-edge advancements brought about by the incorporation of GAI technologies, specifically Large Language Models (LLMs), into DTs. These technologies herald a significant transformation, propelling DTs beyond their current capabilities to become more dynamic, predictive, and interactive tools that can simulate complex scenarios and anticipate future conditions with remarkable accuracy. By systematically examining the levels of GAI integration within DTs, this study delves into the methodologies and strategies for embedding AI capabilities into these virtual models. It outlines how GAI can enhance the functionality of DTs, enabling them to generate synthetic datasets, simulate unprecedented events, and provide actionable insights with LLM-based agents for decision-making. Furthermore, the paper highlights the extended applications of DTs, enriched by GAI, across various domains such as healthcare, urban planning, and beyond. The implications of this integration for operational efficiency, innovation, and decision-making processes are profound. By offering a comprehensive overview of the current state of technology and projecting future trends, this paper aims to provide stakeholders with a deep understanding of the syner-gistic potential between GAI and DTs. It sets the stage for a new era of DT technologies, where the boundaries of what can be achieved with virtual models are continually expanding.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "RAM-Based Firmware Attestation for IoT Security: A Representation Learning Framework",
        "authors": "Iqbal A.",
        "journal": "IEEE Internet of Things Journal",
        "doi": "10.1109/JIOT.2024.3436057",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85200217972",
        "scopus_id": "85200217972",
        "abstract": "With the proliferation of 4G and 5G mobile networks in smart cities, the adoption of Internet of Things (IoT) devices has surged, emphasizing the critical need for robust security measures. Existing firmware attestation techniques often require high computational budget or access to the device's authentic firmware, posing challenges due to resource and proprietary constraints. To counter these two fundamental challenges, this article introduces a novel software-based attestation framework utilizing RAM traces from IoT devices for remote verification. In the proposed framework, the need for an authentic firmware copy is eliminated, and the most computationally intensive task is assigned to the gateway node of the IoT ecosystem. This approach yields a robust and highly accurate device attestation strategy, while imposing minimal computational demands on the verification device itself. Employing deep learning models trained in a representation learning paradigm, our framework enables the remote verifier to authenticate the internal state of IoT devices. Leveraging data collected from real-world prototype devices, under eight different applications, our approach achieves a remarkable 100% accuracy in detecting critical attacks on IoT devices with a false positive rate of 10-3 Notably, our framework preserves device availability and maintains low authentication latency, underscoring its efficacy and practicality for securing IoT ecosystems.",
        "author_keywords": [
            "Device attestation",
            "firmware",
            "Internet of Things (IoT)",
            "RAM trace",
            "variational autoencoder (VAE)"
        ],
        "subject_areas": [
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "STAGE: a spatiotemporal-knowledge enhanced multi-task generative adversarial network (GAN) for trajectory generation",
        "authors": "Cao Z.",
        "journal": "International Journal of Geographical Information Science",
        "doi": "10.1080/13658816.2024.2381146",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85199966210",
        "scopus_id": "85199966210",
        "abstract": "Individual trajectory data play a pivotal role in various application fields, such as urban planning, traffic control, and epidemic simulation. Despite the diverse means for data collection in current times, the real-world trajectory data in practical application remains severely limited due to concerns over personal privacy. In this study, we designed a Spatiotemporal-knowledge enhanced multi-TAsk GEnerative adversarial network (GAN), named STAGE, to generate synthetic trajectories that statistically resemble the real data without recycling personal information. In STAGE, we designed a multi-task generator with three stages of spatio-temporal generation tasks, i.e. activity-sequence generation task, township-level trajectory generation task, and neighborhood-level trajectory generation task, with the last one as the main task while the other two as auxiliary tasks. Meanwhile, we designed a spatial consistency loss in the adversarial training process to assess the spatial consistency of generated trajectories at different spatial scales. Experiment results show that compared to the baselines, trajectories generated by our method have closer data distributions to the real ones. We argued that the designs of spatiotemporal-knowledge enhanced generation tasks and training loss benefit the spatiotemporal generation processes, which help reproduce the temporal patterns of human daily activities and spatial distribution of human movements.",
        "author_keywords": [
            "generative adversarial network",
            "knowledge-guided GeoAI",
            "multi-task learning",
            "spatial consistency loss",
            "Trajectory generation"
        ],
        "subject_areas": [
            "Information Systems",
            "Geography, Planning and Development",
            "Library and Information Sciences"
        ]
    },
    {
        "title": "Data on the Move: Traffic-Oriented Data Trading Platform Powered by AI Agent with Common Sense",
        "authors": "Yu Y.",
        "journal": "IEEE Intelligent Vehicles Symposium, Proceedings",
        "doi": "10.1109/IV55156.2024.10588800",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85199752241",
        "scopus_id": "85199752241",
        "abstract": "In the digital era, data has become a pivotal asset, advancing technologies such as autonomous driving. Despite this, data trading faces challenges like the absence of robust pricing methods and the lack of trustworthy trading mechanisms. To address these challenges, we introduce a traffic-oriented data trading platform named Data on The Move (DTM), integrating traffic simulation, data trading, and Artificial Intelligent (AI) agents. The DTM platform supports evident-based data value evaluation and AI-based trading mechanisms. Leveraging the common sense capabilities of Large Language Models (LLMs) to assess traffic state and data value, DTM can determine reasonable traffic data pricing through multi-round interaction and simulations. Moreover, DTM provides a pricing method validation by simulating traffic systems, multi-agent interactions, and the heterogeneity and irrational behaviors of individuals in the trading market. Within the DTM platform, entities such as connected vehicles and traffic light controllers could engage in information collecting, data pricing, trading, and decision-making. Simulation results demonstrate that our proposed AI agent-based pricing approach enhances data trading by offering rational prices, as evidenced by the observed improvement in traffic efficiency. This underscores the effectiveness and practical value of DTM, offering new perspectives for the evolution of data markets and smart cities. To the best of our knowledge, this is the first study employing LLMs in data pricing and a pioneering data trading practice in the field of intelligent vehicles and smart cities.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Deciphering Human Mobility: Inferring Semantics of Trajectories with Large Language Models",
        "authors": "Luo Y.",
        "journal": "Proceedings - IEEE International Conference on Mobile Data Management",
        "doi": "10.1109/MDM61037.2024.00060",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85199591473",
        "scopus_id": "85199591473",
        "abstract": "Understanding human mobility patterns is essential for various applications, from urban planning to public safety. The individual trajectory such as mobile phone location data, while rich in spatio-temporal information, often lacks semantic detail, limiting its utility for in-depth mobility analysis. Existing methods can infer basic routine activity sequences from this data, lacking depth in understanding complex human behaviors and users' characteristics. Additionally, they struggle with the dependency on hard-to-obtain auxiliary datasets like travel surveys. To address these limitations, this paper defines trajectory semantic inference through three key dimensions: user occupation category, activity sequence, and trajectory description, and proposes the Trajectory Semantic Inference with Large Language Models (TSI-LLM) framework to leverage LLMs infer trajectory semantics comprehensively and deeply. We adopt spatio-temporal attributes enhanced data formatting (STFormat) and design a context-inclusive prompt, enabling LLMs to more effectively interpret and infer the semantics of trajectory data. Experimental validation on real-world trajectory datasets demonstrates the efficacy of TSI-LLM in deciphering complex human mobility patterns. This study explores the potential of LLMs in enhancing the semantic analysis of trajectory data, paving the way for more sophisticated and accessible human mobility research.",
        "author_keywords": [
            "Human mobility analysis",
            "Large language models",
            "Trajectory semantic inference"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Low Light Enhancement in Street Scenes Based on Diffusion Model",
        "authors": "Xia R.",
        "journal": "Proceedings of the 2024 27th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2024",
        "doi": "10.1109/CSCWD61410.2024.10580863",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85199042190",
        "scopus_id": "85199042190",
        "abstract": "Street view images constitute an important part of urban computing, providing data support for tasks such as autonomous driving and landscape planning, and promoting the interaction and collaboration between machines and the urban environment. However, in current practice, the usability of street view images is hindered by low-light conditions, and existing low-light enhancement methods often overlook the high-frequency characteristics specific to street views. Therefore, this paper proposes a conditional diffusion model called SVBoost that incorporates high-frequency information and color balance to achieve targeted enhancement of street view images. The proposed model demonstrates favorable performance in terms of image quality, and the enhancement effect observed in semantic segmentation tasks suggests the potential of this method for downstream applications.",
        "author_keywords": [
            "Diffusion Model",
            "Image Restoration",
            "Low Light Enhancement",
            "Urban Computing"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Graphics and Computer-Aided Design",
            "Computer Networks and Communications",
            "Computer Vision and Pattern Recognition",
            "Control and Optimization",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Super-Resolution of Satellite Lidars for Forest Studies Using Diffusion Generative Models",
        "authors": "Ramirez-Jaime A.",
        "journal": "2024 IEEE Conference on Computational Imaging Using Synthetic Apertures, CISA 2024",
        "doi": "10.1109/CISA60639.2024.10576270",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85198549226",
        "scopus_id": "85198549226",
        "abstract": "This paper presents a novel algorithm for satellite lidar super-resolution using conditional Denoising Diffusion Probabilistic Models (DDPM) in the hyperheight data cube framework. The method employs a conditional reverse diffusion process to overcome challenges in long-range lidar systems, yielding high-resolution outputs from low-resolution inputs. Enhancing lidar products like canopy height models, it improves lidar-based modeling and facilitates advanced data analysis in fields such as environmental science, urban planning, and disaster management. The approach significantly enhances Earth's surface representation, creating research and application opportunities across disciplines. The framework's efficacy was validated in the Florida Everglades National Park, showcasing an enhancement from a 3m x 6m grid with 10m footprints to a 3m x 3m grid with 3m footprints, along with an increase in vertical resolution from 0.5m to 0.25m.",
        "author_keywords": [
            "Canopy Height Model",
            "Canopy Height Profile",
            "Denoising Diffusion Probabilistic Model",
            "Lidar"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Vision and Pattern Recognition",
            "Instrumentation"
        ]
    },
    {
        "title": "Demo Abstract: Embodied Aerial Agent for City-level Visual Language Navigation Using Large Language Model",
        "authors": "Zhang W.",
        "journal": "Proceedings - 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks, IPSN 2024",
        "doi": "10.1109/IPSN61024.2024.00033",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85198542490",
        "scopus_id": "85198542490",
        "abstract": "As unmanned aerial vehicles (UAVs) become more prevalent in smart cities, their capacity for visual language navigation (VLN) is garnering increasing interest. VLN in cities has significant applications in delivery, rescue, and security patrol, among other fields. One of the most representative tasks is to navigate to specific locations following the language instructions. While some current methods have achieved notable results in indoor settings, challenges persist outdoors, including agents' inaccurate spatial understanding and ambiguous language instructions. In this work, we explore an embodied navigation agent design, in which a fine-grained spatial verbalizer and a history path memory are proposed to guarantee accurate VLN in open 3D urban environments.",
        "author_keywords": [
            "embodied navigation agent",
            "urban",
            "Visual language navigation"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Information Systems",
            "Safety, Risk, Reliability and Quality",
            "Instrumentation"
        ]
    },
    {
        "title": "Enhancing Cognitive Digital Twin Interaction using an LLM Agent",
        "authors": "Šturm J.",
        "journal": "2024 47th ICT and Electronics Convention, MIPRO 2024 - Proceedings",
        "doi": "10.1109/MIPRO60963.2024.10569919",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85198223673",
        "scopus_id": "85198223673",
        "abstract": "This paper introduces a conceptual architecture design aimed at enhancing interactions with cognitive digital twins of countries through an Large Language Model (LLM) agent. By leveraging sophisticated data retrieval and summarization techniques, the architecture integrates data from diverse sources, including environmental sensors, web pages, and human inputs, to create a dynamic and comprehensive digital twin. The LLM agent facilitates intuitive conversational interfaces, allowing users to query and interact with the digital twin in a natural manner. Through advanced natural language processing and prompt engineering, the agent can understand complex queries, retrieve relevant data, and provide transparent and explainable insights. Additionally, the system incorporates a feedback loop for continuous improvement based on user interactions. This approach addresses significant challenges in data acquisition and management, offering a scalable solution for creating accurate and real-time representations of countries. The architecture aims to empower decision-makers with precise, actionable insights for policy-making, urban planning, and resource management, demonstrating a significant step towards realizing the potential of digital twins in understanding and managing complex national systems.",
        "author_keywords": [
            "cognitive digital twin",
            "LLM agent",
            "multimodal data",
            "real-time retrieval"
        ],
        "subject_areas": [
            "Computer Vision and Pattern Recognition",
            "Electrical and Electronic Engineering",
            "Control and Optimization",
            "Artificial Intelligence",
            "Computer Science Applications"
        ]
    },
    {
        "title": "VAE-GAN for Robust IoT Malware Detection and Classification in Intelligent Urban Environments: An Image Analysis Approach",
        "authors": "Dong H.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-61231-2_13",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85197353869",
        "scopus_id": "85197353869",
        "abstract": "The Internet of Things (IoT) has revolutionised technology in intelligent urban environments. Meanwhile, security and privacy risks have emerged, including the presence of various malware, resulting in detrimental consequences. Generative attack networks (GAN) can not only build superior representations for complex and multi-dimensional data but also maximise prediction performance due to their min-max optimisation manner. This paper proposes a GAN approach, utilising an autoencoder (AE) as the generator and a transfer learning for the discriminator, to identify various types of malware threats that exploit the IoT network using RGB images collected directly from malware samples. The generator is built for effective data reconstruction, with different AE structures and denoising manner; the discriminator utilises a pre-trained MobileNet for maximised performance. Two well-known image classification models, VGG19 and Xception, are used for performance comparison. The experiment proves that the Variational AE-GAN is highly implementable and scalable for the malware classification task, in both detection performance and generalizability.",
        "author_keywords": [
            "autoencoder",
            "generative attack networks",
            "Internet of Things",
            "malware detection"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Generative AI-based Land Cover Classification via Federated Learning CNNs: Sustainable Insights from UAV Imagery",
        "authors": "Jockusch O.",
        "journal": "2024 IEEE Conference on Technologies for Sustainability, SusTech 2024",
        "doi": "10.1109/SusTech60925.2024.10553449",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85197307948",
        "scopus_id": "85197307948",
        "abstract": "This paper introduces a novel approach method for decentralized land cover and land use classification, utilizing federated learning in conjunction with Convolutional Neural Networks (CNNs) on imagery obtained from Unmanned Aerial Vehicles (UAVs). Integration of UAV imagery provides high-resolution spatial data, facilitating precise classification of land cover types. Federated learning (FL) ensures data privacy and reduces communication bandwidth usage by enabling model training on local devices (e.g., UAVs) without the need to share data with a centralized server. However, these UAVs have limited resources and often struggle to capture a sufficient number of images for training a model without encountering overfitting. We address the challenges of scarce data samples on UAVs by leveraging DCGAN (Deep Convolutional Generative Adversarial Networks) to generate synthetic images, promoting sustainability by minimizing the need for extensive data collection. These synthetic images are used to train local models of UAVs, offering enhanced results while combating overfitting. Our developed FL model achieved an accuracy exceeding 97%, indicating a 7% improvement over Vanilla FL. The proposed sustainable approach exhibits promising outcomes in achieving accurate and scalable land cover and land use classification, showcasing its applicability in environmental monitoring, urban planning, and precision agriculture.",
        "author_keywords": [
            "Federated learning",
            "Generative Adversarial Networks",
            "global model",
            "local model",
            "sustainability",
            "unmanned aerial vehicles"
        ],
        "subject_areas": [
            "Energy Engineering and Power Technology",
            "Renewable Energy, Sustainability and the Environment",
            "Control and Optimization"
        ]
    },
    {
        "title": "TERRITORIAL SABOTAGE: FROM TRACING SEOUL’S POSSIBILITIES TO RECOMPOSITING ITS URBAN IDENTITY",
        "authors": "Kim D.",
        "journal": "Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia",
        "doi": "10.52842/conf.caadria.2023.2.159",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196763673",
        "scopus_id": "85196763673",
        "abstract": "This paper explores the evolution of architecture within an urban scale, utilizing Generative Adversarial Networks (GANs) to increase diversity and suggest various alternatives. Drawing inspiration from Henri Bergson's concepts of creative evolution, GANs' non deterministic nature echoes Bergson's emphasis on creativity with in evolutionary processes in urban design. Leveraging GANs' latent space, this study envisions a framework for AI-driven architectural generation, merging Bergson's ideas of creative intuition with AI's adaptive potential. Using Seoul as a case study, integrating Kevin Lynch's principles and symbolic representation techniques like the Nolli map, the research navigates urban spaces to create cohesive morphologies. Employing 2D GAN-based analysis and integrating 3D GAN, the study discerns urban layouts and building configurations. Additional diffusion models refine the 3D GAN outputs, expediting rendering and visualization phases, suggesting an innovative, data-driven architectural design methodology. By amalgamating diverse AI models into a cohesive workflow, it blends traditional architectural wisdom with cutting-edge computational capabilities, heralding a paradigm shift in architectural innovation.",
        "author_keywords": [
            "3D GAN",
            "Cartography",
            "Generative Adversarial Networks",
            "Nolli map",
            "Stable Diffusion"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Computer Graphics and Computer-Aided Design",
            "Materials Science (miscellaneous)",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "URBAN ANALYTICS AND GENERATIVE DEEP LEARNING FOR CONTEXT RESPONSIVE DESIGN IN DIGITAL TWINS A Singapore Study",
        "authors": "Nazim I.",
        "journal": "Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia",
        "doi": "10.52842/conf.caadria.2022.2.495",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196748451",
        "scopus_id": "85196748451",
        "abstract": "City Digital Twins (CDT) can play a pivotal role in consolidating and visualising complex urban big data, promoting rapid and informed decision making in contemporary cities. Beyond rich contextual data, these tools offer features like interactivity, 3D models and data visualisation, making them ideal for urban planning and design explorations. However current CDT implementations primarily focus on data visualisation and lack any robust design support. Simultaneously, generative urban prototyping occurs in specialised tools, detached from this rich contextual data. This study, on the Virtual Singapore (VSg) CDT platform, explores how the platform’s existing data, interactivity and 3D visualisation capabilities can facilitate rapid proto typing through generative machine learning techniques trained on the city’s unique planning texture; and discusses the challenges and limitations of the platform in supporting the development of such tools, along with potential improvements. The study aims to advance CDTs beyond static data consumption and visualisation towards generative tools for urban planning and decision-making processes.",
        "author_keywords": [
            "City Digital Twins",
            "Generative design",
            "Planning Support",
            "Smart City",
            "Virtual Singapore"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Computer Graphics and Computer-Aided Design",
            "Materials Science (miscellaneous)",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "TEXT-TO-CITY: Controllable 3D Urban Block Generation with Latent Diffusion Model",
        "authors": "Zhuang J.",
        "journal": "Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia",
        "doi": "10.52842/conf.caadria.2023.2.169",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196720664",
        "scopus_id": "85196720664",
        "abstract": "The rise of deep learning has introduced novel computational tools for urban block design. Many researchers have explored generative urban block design using either rule-based or deep learning methods. However, these methods often fall short inadequately capturing morphological features and essential design indicators like building density. Latent diffusion models, particularly in the context of urban design, offer a ground breaking solution. These models can generate cityscapes directly from text descriptions, incorporating a wide array of design indicators. This paper introduces a novel workflow that utilizes Stable Diffusion, a state-of-the-art latent diffusion model, to generate 3D urban environments. The process involves reconstructing 3D urban block models from generated depth images, employing a systematic depth-to-height mapping technique. Additionally, the paper explores the extrapolation between various urban morphological characteristics, aiming to generate novel urban forms that transcend existing city models. This innovative approach not only facilitates the accurate generation of urban blocks with specific mor phological characteristics and design metrics, such as building density, but also demonstrates its versatility through application to thre edistinct cities. This methodology, tested on select cities, holds potential for broader range of urban environments and more design indicators, setting the stage for future computational urban design research.",
        "author_keywords": [
            "artificial intelligence",
            "deep learning",
            "generative design",
            "latent diffusion model",
            "urban block morphology"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Computer Graphics and Computer-Aided Design",
            "Materials Science (miscellaneous)",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Satellite Image Segmentation via Image Quality Enhancement and Modified Unet Architecture",
        "authors": "Pathak A.",
        "journal": "Proceedings - 2nd International Conference on Advancement in Computation and Computer Technologies, InCACCT 2024",
        "doi": "10.1109/InCACCT61598.2024.10551252",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196634598",
        "scopus_id": "85196634598",
        "abstract": "Satellite imaging is essential for urban planning and crisis management as it records detailed spatial information such as buildings, roads, and different types of land cover. Satellite image segmentation is necessary to analyze pictures and extract particular information for applications including urban planning, vegetation monitoring, and time series data analysis due to their complexity. Most segmentation models need input images of size (512,512), which may lead to pixelation or quality reduction due to cropping or zooming. High resolution input data might provide challenges in multiclass segmentation due to its extensive coverage area. This paper present a remodeled Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) to enhance picture quality and maintain crucial data for precise segmentation tasks. The segmentation process involves utilizing a U-Net architecture integrated with a ResNet50 encoder. This decision was taken to utilise ResNet50's advanced feature extraction skills while preserving U-Net's efficacy in obtaining contextual information for accurate segmentation. The network incorporates the Tversky loss function to effectively adjust the influence of various classes in the input data throughout the training process. The model demonstrates an accuracy of 0.94 and a mean Intersection over Union (IOU) of 0.83 in multiclass segmentation tasks, properly outlining different land cover classes such as houses, woodlands, water bodies, and roads.",
        "author_keywords": [
            "ESRGAN (Enhanced Super Resolution Generative Adversarial Network)",
            "Intersection over union (IOU)",
            "RESNET",
            "Segmentation",
            "UNET (U Shaped-Network)"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Hardware and Architecture",
            "Information Systems and Management",
            "Statistics, Probability and Uncertainty"
        ]
    },
    {
        "title": "Generation method of hand-drawn feature sketch virtual terrain based on improved generative adversarial network",
        "authors": "Zhang X.",
        "journal": "National Remote Sensing Bulletin",
        "doi": "10.11834/jrs.20233090",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196499989",
        "scopus_id": "85196499989",
        "abstract": "The 3D virtual terrain generation is currently used in geography teaching and setting up relevant virtual scenes according to the teaching content, which can visually display the verification experimental conditions and results and enhance the universality of virtual geography experiments. In the field of digital twin smart city, traffic, and water simulation, constructing virtual terrain according to the real terrain can provide the basic environment for subsequent development and experiments. In military simulation, it can quickly build beyond the real scenes of extreme training environment, which has a key role in improving military training and enhancing combat capabilities. Hand-drawn feature sketches can express 3D virtual terrain under human subjective perception. Therefore, how to use hand-drawn feature sketches to build 3D terrain environment quickly and generate realistic virtual geographic environment is a hot spot and difficult point for the creation and development of geographic metaverse with virtual geographic environment as the core in the future. Although the traditional method of generating 3D virtual terrain provides an important reference for image cross-domain generation from hand-drawn feature sketch to virtual terrain, problems such as insufficient realism of the generated terrain remain. Especially when the terrain feature outline is too sparse, the generated terrain will have duplicate terrain blocks and grid artifacts. On this basis, a hand-drawn feature sketch virtual terrain generation method with improved generative adversarial network is proposed. The model is based on extracted data samples and hand-drawn sketch characteristics, and the input terrain feature information is involved in the sampling of each layer by improving the generator U-Net network, which enhances the control role of terrain features in the invisible space, reduces the possibility of model collapse, increases the random noise input, and improves the realism of the generated terrain, especially the detail when the terrain feature elements in the sketch are sparse. L1 loss (mean absolute value error function) and L2 loss (mean variance error function) are combined to form smooth L1 loss, and then optimized with CGAN loss function to form a new generator loss function to improve the stability and efficiency of model training. The Digital Elevation Model (DEM) data of some areas of the Loess Plateau with high accuracy is selected to produce data. The DEM data with high accuracy are selected and used for model training to compare and evaluate the terrain generation enhancement effect quantitatively before and after model improvement. Finally, the model inference process from hand-drawn feature sketch to virtual terrain is completely constructed. The experimental results show the improved virtual terrain generation model with the Loess Plateau terrain data can represent the hand-drawn feature sketch well, and the generated terrain conforms to the distribution and orientation of the terrain features described in the sketch, especially in the case of sparse sketch, and the generated terrain has high realistic surface details. This model is applied to the real natural landscape display and terrain evolution, and it can meet the user’s needs to obtain the virtual terrain with high realistic feeling after inputting the hand-drawn terrain feature sketch. This improved model proposed in this paper has good prospects for 3D terrain modeling and editing.",
        "author_keywords": [
            "3D virtual terrain",
            "CGANs",
            "DEM",
            "hand-drawn feature sketch",
            "remote sensing"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Instrumentation",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Equipping Participation Formats with Generative AI: A Case Study Predicting the Future of a Metropolitan City in the Year 2040",
        "authors": "von Brackel-Schmidt C.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-61315-9_19",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196170709",
        "scopus_id": "85196170709",
        "abstract": "Urban planning is a complex field that requires the integration of diverse skills, knowledge, and perspectives. Engaging the public in this process promises to achieve high acceptance for resulting endeavors but poses significant challenges, particularly due to the varying levels of technical and artistic skills among participants. Moreover, discussions and collaborative efforts in urban planning often lack practical visualization tools, making it difficult to imagine and debate future urban scenarios. Generative Artificial Intelligence (GenAI) has emerged as a promising technology capable of bridging these gaps. GenAI can generate natural language output and visual content from textual descriptions, offering a novel way to facilitate more inclusive and productive participation in urban planning processes. In this paper, we explore the application of GenAI in a participatory urban planning event utilizing the novel Prompt-a-thon format. We conducted a study involving 64 participants who utilized GenAI in small groups to envision, design, and discuss the future urban landscape of the metropolitan city of Hamburg in Germany. Through this process, we examined the human-AI collaboration, assessing the technology's ability to accommodate varying skills and improve visualization in planning discussions. Our findings indicate that GenAI contributes to leveling diverse skill sets of participants, enabling more people to contribute insights into urban planning discussions. The technology also proved effective in overcoming visualization barriers, thus facilitating more engaging and fruitful discussions about future urban scenarios. These results underscore the potential of GenAI as a valuable tool in the evolving landscape of urban planning and public participation.",
        "author_keywords": [
            "GenAI",
            "Generative Artificial Intelligence",
            "Human-AI Collaboration",
            "Public Participation",
            "Urban Planning"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Multi-scale Intervention Planning Based on Generative Design",
        "authors": "Kavouras I.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-63031-6_20",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85196086824",
        "scopus_id": "85196086824",
        "abstract": "The scarcity of green spaces, in urban environments, consists a critical challenge. There are multiple adverse effects, impacting the health and well-being of the citizens. Small scale interventions, e.g. pocket parks, is a viable solution, but comes with multiple constraints, involving the design and implementation over a specific area. In this study, we harness the capabilities of generative AI for multi-scale intervention planning, focusing on nature based solutions. By leveraging image-to-image and image inpainting algorithms, we propose a methodology to address the green space deficit in urban areas. Focusing on two alleys in Thessaloniki, where greenery is lacking, we demonstrate the efficacy of our approach in visualizing NBS interventions. Our findings underscore the transformative potential of emerging technologies in shaping the future of urban intervention planning processes.",
        "author_keywords": [
            "Artificial Intelligence",
            "Generative Design",
            "Multi-scale Intervention Planning"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Synthesis and evaluation of seamless, large-scale, multispectral satellite images using Generative Adversarial Networks on land use and land cover and Sentinel-2 data",
        "authors": "Dedring T.",
        "journal": "GIScience and Remote Sensing",
        "doi": "10.1080/15481603.2024.2364460",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195913232",
        "scopus_id": "85195913232",
        "abstract": "Artificial intelligence (AI) began to make its way into geoinformation science several decades ago and since then has constantly brought forth new cutting-edge approaches for diverse geographic use cases. AI and deep learning methods have become essential approaches for land use and land cover (LULC) classifications, which are important in urban planning and regional management. While the extraction of LULC information from multispectral satellite images has been a well-studied part of past and present research, only a few studies emerged about the recovery of spectral properties from LULC information. Estimates of the spectral characteristics of LULC categories could enrich LULC forecasting models by providing necessary information to delineate vegetation indices or microclimatic parameters. We train two identical Conditional Generative Adversarial Networks (CGAN) to synthesize a multispectral Sentinel-2 image based on different combinations of open-source LULC data sets. Large-scale synthetic multispectral satellite images of the administrative region of Bonn and Rhein-Sieg in Germany are generated with a Euclidean distance-based patch-fusion method. The approach generated a realistic-looking satellite image without noticeable seams between patch borders. Based on several metrics, such as difference calculations, the spectral information divergence (SID), and the Fréchet inception distance (FID), we evaluate the resulting images. The models reach mean SIDs as low as 0.026 for urban fabrics and forests and FIDs below 90 for bands B2 and B5 showing that the CGAN is capable of synthesizing distinct synthetic features matching with features typical for respective LULC categories and manages to mimic multispectral signatures. The method used in this paper to generate large-scale synthetic multispectral satellite images can be used as an approach to support scenario-oriented sustainable urban planning.",
        "author_keywords": [
            "Deep Fake Geography",
            "Generative Adversarial Network",
            "patch fusion",
            "Sentinel-2",
            "Synthetic satellite images"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "GAN-based Transportation Noise Prediction via Satellite Maps: A Case Study in New York",
        "authors": "Liu Z.",
        "journal": "Journal of Digital Landscape Architecture",
        "doi": "10.14627/537752005",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195557928",
        "scopus_id": "85195557928",
        "abstract": "Traditional noise prediction models, reliant on on-site monitoring, are hindered by data and computational constraints. This research addresses this challenge by introducing Generative Adversarial Networks (GAN) in conjunction with satellite maps. Based on the inherent interconnectedness between traffic noise and urban morphology elements, the research proposes a GAN model-based framework capable of generating noise heat maps from high-resolution satellite maps, offering a cost-effective and efficient alternative. This research also examines how model performance is influenced by input images through qualitative and quantitative methods. Using New York City as a case study, the proposed GAN-based models demonstrate accuracy in predicting noise distributions. Three parameters of input images likely to be influential in noise prediction accuracy were proposed. We also compare the model performance in different urban contexts. The study presents a valuable tool for architects and urban planners, enabling optimized urban planning and design strategies.",
        "author_keywords": [
            "generative adversarial networks",
            "satellite maps",
            "Transportation noise prediction",
            "urban plans"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Architecture",
            "Computer Science Applications",
            "Nature and Landscape Conservation"
        ]
    },
    {
        "title": "Automatic Estimation for Visual Quality Changes of Street Space via Street-View Images and Multimodal Large Language Models",
        "authors": "Liang H.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2024.3408843",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195410193",
        "scopus_id": "85195410193",
        "abstract": "Estimating Visual Quality of Street Space (VQoSS) is pivotal for urban design, environmental sustainability, civic engagement, etc. Recent advancements, notably in deep learning, have enabled large-scale analysis. However, traditional deep learning approaches are hampered by extensive data annotation requirements and limited adaptability across diverse VQoSS tasks. Multimodal Large Language Models (MLLMs) have recently demonstrated proficiency in various computer vision tasks, positioning them as promising tools for automated VQoSS assessment. In this paper, we pioneer the application of MLLMs to VQoSS change estimation, with our empirical findings affirming their effectiveness. In addition, we introduce Street Quality Generative Pre-trained Transformer (SQ-GPT), a model that distills knowledge from the current most powerful but inaccessible (not free) GPT-4V, requiring no human efforts. SQ-GPT approaches GPT-4V's performance and is viable for large-scale VQoSS change estimation. In a case study of Nanjing, we showcase the practicality of SQ-GPT and knowledge distillation pipeline. Our work promises to be a valuable asset for future urban studies research.",
        "author_keywords": [
            "deep learning",
            "multimodal large language models",
            "Smart city",
            "visual quality"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "Leveraging Generative and Explainable AI for Electric Vehicle Energy Toward Sustainable, Consumer-Centric Transportation",
        "authors": "Kumar Mohanty P.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2024.3405959",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85194878441",
        "scopus_id": "85194878441",
        "abstract": "In Industry 5.0, predicting electric vehicle energy usage enhances efficiency and sustainability, optimizes charging infrastructure, and meets consumer demands. Leveraging IoT, AI, and analytics enables smart charging that aligns with renewable energy goals, addresses infrastructure limitations, and promotes sustainable transportation by improving user experience, cutting costs, and boosting trust in electric vehicles. This research aims to create a synthetic data set for electric vehicles using an enhanced Generative adversarial network model and, from that, predict the energy for charging electric vehicles using ensemble Machine Learning algorithms. The importance of more detailed features for the best-performing machine learning model has been done utilizing Explainable Artificial Intelligence, specifically, the Shapley Additive Explanations approach, to provide more understanding and derive the inter-dependency among features. The enhanced TemporalCharge Generative adversarial network model provides Skewness and Kurtosis values as -0.51 and -0.182, respectively, for synthetically generated data for the city of Berhampur, Odisha, India, which is very close to four-wheeler electric vehicle charging data of the city. Several plots illustrate the influence of key features on electric vehicle energy consumption during charging, which enhances user optimization, owner empowerment, and ecosystem sustainability.",
        "author_keywords": [
            "consumer-centric technology",
            "electric vehicle energy use",
            "Electric vehicles",
            "generative adversarial network",
            "interpretability",
            "shapley additive explanations"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "An Enhanced Multiview Transformer for Population Density Estimation Using Cellular Mobility Data in Smart City",
        "authors": "Zhou Y.",
        "journal": "Computers, Materials and Continua",
        "doi": "10.32604/cmc.2024.047836",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191702055",
        "scopus_id": "85191702055",
        "abstract": "This paper addresses the problem of predicting population density leveraging cellular station data. As wireless communication devices are commonly used, cellular station data has become integral for estimating population figures and studying their movement, thereby implying significant contributions to urban planning. However, existing research grapples with issues pertinent to preprocessing base station data and the modeling of population prediction. To address this, we propose methodologies for preprocessing cellular station data to eliminate any irregular or redundant data. The preprocessing reveals a distinct cyclical characteristic and high-frequency variation in population shift. Further, we devise a multi-view enhancement model grounded on the Transformer (MVformer), targeting the improvement of the accuracy of extended time-series population predictions. Comparative experiments, conducted on the above-mentioned population dataset using four alternate Transformer-based models, indicate that our proposed MVformer model enhances prediction accuracy by approximately 30% for both univariate and multivariate time-series prediction assignments. The performance of this model in tasks pertaining to population prediction exhibits commendable results.",
        "author_keywords": [
            "multiview learning",
            "Population density estimation",
            "smart city",
            "transformer"
        ],
        "subject_areas": [
            "Biomaterials",
            "Modeling and Simulation",
            "Mechanics of Materials",
            "Computer Science Applications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "High-Resolution Image-to-Image Translation for Aesthetic Enhancements Using Generative Adversarial Network",
        "authors": "Chitale M.",
        "journal": "2024 2nd International Conference on Disruptive Technologies, ICDT 2024",
        "doi": "10.1109/ICDT61202.2024.10489200",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191231840",
        "scopus_id": "85191231840",
        "abstract": "Urbanization poses numerous challenges in handling cities' growth and increasing populations. This research em-phasizes the significance of architecture enhancement in urban development and the conversion of satellite images into clear map representations using generator and discriminator models. Architectural enhancement is crucial for improving both the aesthetic appeal and functionality of buildings. Architectural enhancement through Generative Adversarial Networks (GANs) is a transformative approach to renovating old structures. This method facilitates the preservation of original design aesthetics, allowing for virtual restoration and the recreation of missing elements while ensuring accuracy. Concurrently, converting satel-lite images to precise maps aids city planning by providing a comprehensive understanding of spatial layouts and facilitating accurate land-use analysis. Hence, employing GANs enables the generation of high-resolution, realistic images that support object manipulation and diverse outcomes from a single input. This method not only enhances image synthesis techniques but also unlocks numerous applications in urban planning and design.",
        "author_keywords": [
            "Architectural enhancement",
            "Generative Adversarial Networks (GANs)",
            "High-resolution",
            "Image to image translation",
            "map images",
            "satellite images",
            "urban planning"
        ],
        "subject_areas": [
            "Strategy and Management",
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems and Management",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "AI AND BLOCKCHAIN FRAMEWORK FOR HEALTHCARE APPLICATIONS",
        "authors": "Ramachandran M.",
        "journal": "Facta Universitatis, Series: Electronics and Energetics",
        "doi": "10.2298/FUEE2401169R",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85191023019",
        "scopus_id": "85191023019",
        "abstract": "Artificial Intelligence (AI) has impacted global economy, workforce productivity, smart health, smart cities, smart transport, and much more to come. Large Language Models (LLM) such as ChatGPT and Google’s Gemini, have been widely adopted in various applications. Blockchain Technology stands as a towering disruptor in today's tech landscape, offering assurances of enhanced security and scalability for various applications. Within the realm of healthcare, its adoption has surged, spanning from streamlined record-keeping to bolstered clinical trials, fortified medical supply chains, and vigilant patient monitoring. These applications harness the intrinsic attributes of blockchain to elevate standards of safety, privacy, and security within the healthcare sector. The combined power of AI and blockchain has the potential to revolutionize healthcare delivery, ensuring improved security, transparency, and efficiency. Nevertheless, Porru et al. [1] have highlighted deficiencies in the processes, tools, and techniques within this domain. Hence, this paper aims to furnish a structured framework that ensures both security and sustainability in the development of healthcare blockchain applications. This paper also provides an overview of societal impact on both technologies. This article has evolved best practice guidelines and a systematic development framework for AI-Blockchain integration, known as AI-BlockchainOps. This research has also developed a reference architecture, exemplifying the modeling of an Electronic Health Record (EHR) using BPMN and simulation. Within this Electronic Health Record (EHR) scenario encompassing 100 user requests, the simulation absorbed 97.09% of cloud resources, with 76.33% allocated to knowledge discovery, and a utilization rate of 93.20% for blockchain scientists, alongside various other contributing factors.",
        "author_keywords": [
            "AI",
            "Blockchain",
            "Requirements Engineering for AI-Blockchain (RE-AIBC)",
            "Secure and Sustainable Software Engineering Framework for AI-Blockchain (AI-BlockchainOps)",
            "Smart Contract"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Towards Generating 3D City Models with GAN and Computer Vision Methods",
        "authors": "Poolkrajang S.",
        "journal": "Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",
        "doi": "10.5220/0012315000003660",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190872873",
        "scopus_id": "85190872873",
        "abstract": "City generation for video games is a resource and time-consuming task. With the increasing popularity of open-world games, studies on building virtual environments have become increasingly important for the game research community and industry. The game development team must engage in urban planning, designate important locations, create population assets, integrate game design, and assemble these elements into a cohesivelooking city. Based on our limited knowledge and survey, we are the first to propose a holistic approach that integrates all features in generating a city, including the natural features surrounding it. We employ a generative adversarial network architecture to create a realistic layout of an entire city from scratch. Subsequently, we utilize classical computer vision techniques to post-process the layout into separate features. The chosen model is a simple Convolutional GAN, trained on a modest dataset of 2x2 km² snippets from over two thousand cities around the world. Although the method is somewhat constrained by the resolution of the images, the results indicate that it can serve as a solid foundation for building realistic 3D cities.",
        "author_keywords": [
            "City Generation",
            "Computer Vision",
            "Generative Adversarial Networks",
            "Neural Networks"
        ],
        "subject_areas": [
            "Computer Graphics and Computer-Aided Design",
            "Computer Vision and Pattern Recognition",
            "Human-Computer Interaction"
        ]
    },
    {
        "title": "Identifying Key Nodes in Urban Transportation Systems Using the Information Diffusion Model",
        "authors": "He Y.",
        "journal": "Lecture Notes in Civil Engineering",
        "doi": "10.1007/978-981-99-9947-7_79",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190791394",
        "scopus_id": "85190791394",
        "abstract": "Urban transporting networks are a type of complex systems, widely existing in modern society. The identification of nodes with significant influential ability is crucial for scientific researches and practical applications including urban planning and city management. Through the survey of relevant literature, most of existing methods for determining influential nodes in cities ignore the topological performance or only consider an agent-based approach using structural metrics for nodal detections, which requires multi-dimensional data, resulting in insufficient robustness. To address such shortcomings, this paper first designs a metric to assess the influential ability of nodes via their structural information. Equipped with the metric, an evolution algorithm is implemented to detect a set of nodes with distinct influential ability. In the experiment, a road network data processor using Pipe4data is developed to process urban road networks from Haizhu District, Guangzhou. The effectiveness of the proposed method has been experimentally verified.",
        "author_keywords": [
            "Complex networks",
            "The influence maximization problem",
            "Urban transportation network"
        ],
        "subject_areas": [
            "Civil and Structural Engineering"
        ]
    },
    {
        "title": "Remote Sensing Single-Image Super-Resolution Using Convolutional Block Attention Residual Network With Joint Adversarial Mechanisms",
        "authors": "Patnaik A.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2024.3387981",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190345953",
        "scopus_id": "85190345953",
        "abstract": "As super-resolution techniques continue to evolve, there is a growing requirement for more advanced methods to capture finer details, particularly when dealing with the smaller pixels within an image. In remote sensing, enhanced spatial details can find utility in diverse applications, such as disaster management, urban planning, and environmental change detection. Many existing image super-resolution algorithms are there to improve image resolution. However, they are not explicitly crafted to accommodate the distinctive attributes of remote-sensing images, rendering them less effective in restoring the details of the images. Therefore, we proposed a convolutional block attention residual network with joint adversarial mechanisms (CRNJAM) to capture finer details in remote sensing images. We first designed a generator based on the residual network and attention mechanism. This has the ability to produce high-quality images with superior resolution, even when the input is of low quality. Then, we train the super-resolved images with high-resolution images with the help of two types of discriminators to generate more realistic images. The first discriminator evaluates an input sample's local regions or patches. On the other hand, the second discriminator evaluates the entire input sample as a whole. The result shows that the proposed model can significantly reduce the noise in the generated super-resolved image; also, the SR image generated using the proposed method provides competitive advantages over the images generated using other models.",
        "author_keywords": [
            "Adversarial mechanisms",
            "attention module",
            "super-resolution"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "Artificial intelligence: another intelligence?",
        "authors": "Tijus C.",
        "journal": "Enfance",
        "doi": "10.3917/enf2.241.0051",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85189341173",
        "scopus_id": "85189341173",
        "abstract": "Analogy allowing distinction, specificity and knowledge, in line with the articles in this thematic issue on the measurement of human intelligence, we question what artificial intelligence is as compared to human. What's about it? What are these human built technical systems, computers, robots, but also things where we live in, that are qualified as intelligent : smart clothes, smart cars, smart homes, smart cities? Are they intended to solve human problems? Can we measure their intelligence? In the era of generative AI and human digital twins, we recommend that artificial intelligence be measured by its adaptation to humans: knowing to what extent the machine is adapted to the smartness of its human user.",
        "author_keywords": [
            "ARTIFICIAL INTELLIGENCE",
            "AUTONOMOUS SYSTEMS",
            "PROBLEM SOLVING"
        ],
        "subject_areas": [
            "Pediatrics, Perinatology and Child Health",
            "Health (social science)",
            "Education",
            "Developmental and Educational Psychology",
            "Arts and Humanities (miscellaneous)"
        ]
    },
    {
        "title": "Deep Umbra: A Generative Approach for Sunlight Access Computation in Urban Spaces",
        "authors": "Omar K.S.",
        "journal": "IEEE Transactions on Big Data",
        "doi": "10.1109/TBDATA.2024.3382964",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85189165124",
        "scopus_id": "85189165124",
        "abstract": "Sunlight and shadow play critical roles in how urban spaces are utilized, thrive, and grow. While access to sunlight is essential to the success of urban environments, shadows can provide shaded places to stay during the hot seasons, mitigate heat island effect, and increase pedestrian comfort levels. Properly quantifying sunlight access and shadows in large urban environments is key in tackling some of the important challenges facing cities today. In this paper, we propose Deep Umbra, a novel computational framework that enables the quantification of sunlight access and shadows at a global scale. Our framework is based on a conditional generative adversarial network that considers the physical form of cities to compute high-resolution spatial information of accumulated sunlight access for the different seasons of the year. We use data from seven different cities to train our model, and show, through an extensive set of experiments, its low overall RMSE (below 0.1) as well as its extensibility to cities that were not part of the training set. Additionally, we contribute a set of case studies and a comprehensive dataset with sunlight access information for more than 100 cities across six continents of the world. Deep Umbra is available at http://urbantk.org/shadows .",
        "author_keywords": [
            "Big Data",
            "Buildings",
            "Generative adversarial networks",
            "Generative adversarial networks",
            "Shadow",
            "Sunlight access",
            "Task analysis",
            "Training",
            "Urban analytics",
            "Urban areas",
            "Urban computing",
            "Urban planning"
        ],
        "subject_areas": [
            "Information Systems",
            "Information Systems and Management"
        ]
    },
    {
        "title": "Road Graph Extraction via Transformer and Topological Representation",
        "authors": "Zao Y.",
        "journal": "IEEE Geoscience and Remote Sensing Letters",
        "doi": "10.1109/LGRS.2024.3380593",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85188903350",
        "scopus_id": "85188903350",
        "abstract": "Road graph extraction from remote sensing images aims at extracting topological maps composed of road vertices and edges, which has broad prospects in urban planning, traffic management, and other applications. However, existing methods are easily affected by complex remote sensing scenes, and also have shortcomings such as poor continuity and slow processing speed. In this letter, we propose a novel end-to-end road extraction method named 'Road2Graph', which encodes road graphs into topological representations for prediction. We proposed a transformer-based model to encode the deep convolutional features, and then fuse them with the output of the feature extractor to make the network pay more attention to the global multiscale road topology context. We also design an efficient topological representation that encodes attributes such as road segmentation, midpoint map, vertex map, and connection relationships with few parameters and low redundancy. The obtained topological representation can be decoded to obtain the road extraction result in graph format. We conduct experiments on two public datasets - CityScale dataset and SpaceNet dataset. The results show that our method achieves the state-of-art and improves both accuracy (TOPO-F1 +1.55% on CityScale dataset and +2.23% on SpaceNet dataset) and continuity (APLS +7.03% on CityScale dataset and +3.05% on SpaceNet dataset) compared to the other methods.",
        "author_keywords": [
            "Remote sensing",
            "road graph extraction",
            "topological representation",
            "transformer"
        ],
        "subject_areas": [
            "Geotechnical Engineering and Engineering Geology",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Deciphering Public Voices in the Digital Era: Benchmarking ChatGPT for Analyzing Citizen Feedback in Hamilton, New Zealand",
        "authors": "Fu X.",
        "journal": "Journal of the American Planning Association",
        "doi": "10.1080/01944363.2024.2309259",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85188587371",
        "scopus_id": "85188587371",
        "abstract": "Problem, research strategy, and findings: Planners are increasingly using online public engagement approaches to broaden their reach in communities. This results in substantial volumes of digital, text-based public feedback data, making it difficult to analyze efficiently and derive meaningful insights. We explored the use of the novel large language model (LLM), ChatGPT, in analyzing a public feedback data set collected via online submissions in Hamilton City (New Zealand) in response to a proposed local plan change. Specifically, we initially employed zero-shot prompts with ChatGPT for tasks like summarizing, topic identification, and sentiment analysis and compared the results with those obtained by human planners and two standard natural language processing (NLP) techniques: latent Dirichlet allocation (LDA) topic modeling and lexicon-based sentiment analysis. The findings show that zero-shot prompting effectively identified political stances (accuracy: 81.7%), reasons (87.3%), decisions sought (85.8%), and associated sentiments (94.1%). Although subject to several limitations, ChatGPT demonstrates promise in automating the analysis of public feedback, offering substantial time and cost savings. In addition, few-shot prompting enhanced performance in more complex tasks, such as topic identification involving planning jargon. We also provide insights for urban planners to better harness the power of ChatGPT to analyze citizen feedback. Takeaway for practice: ChatGPT presents a transformative opportunity for planners, particularly those dealing with growing volumes of public feedback data. However, it cannot be entirely relied upon. Planners must be mindful of ChatGPT’s limitations, including its sensitivity to prompt phrasing, inherent biases from training data, tendency to overgeneralize, and occasional omission of nuanced details. To enhance accuracy, planners should prescreen data for consistency, provide clear and iteratively tested prompts, use few-shot prompts for complex analysis, and explore various combinations of prompting strategies to develop an effective local approach. It is also crucial to ensure human review of the results.",
        "author_keywords": [
            "ChatGPT",
            "citizen engagement",
            "natural language processing",
            "public feedback",
            "urban planning"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Development",
            "Urban Studies"
        ]
    },
    {
        "title": "5GT-GAN-NET: Internet Traffic Data Forecasting With Supervised Loss Based Synthetic Data Over 5G",
        "authors": "Pandey C.",
        "journal": "IEEE Transactions on Mobile Computing",
        "doi": "10.1109/TMC.2024.3364655",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85187004875",
        "scopus_id": "85187004875",
        "abstract": "In an era of 5G smart cities, precise traffic prediction remains elusive due to limited real-world data. Our paper introduces a novel approach using Generative Adversarial Networks (GANs) to create synthetic traffic data that closely mimics real-world statistics. This artificial dataset enhances our new 5GT-GAN-NET-based prediction model. The result is a significant boost in prediction accuracy, with Mean Square Error (MSE) reduced to 0.000346 and Mean Absolute Error (MAE) to 0.00685. Compared to benchmarks, our model improves MSE and MAE by up to 95.45% with respect to the ARIMA model and 87.31% with respect to the NARNN model respectively. User privacy remains a cornerstone of our approach, crucial for smart city applications. Our predictive capabilities enable more efficient resource allocation by service providers, increasing communication infrastructure reliability. Although tailored for smart cities, the approach is adaptable to other fields facing data scarcity and privacy concerns. Our research highlights the potential of GANs in generating large, accurate datasets for traffic prediction in 5G environments while prioritizing user privacy.",
        "author_keywords": [
            "5G",
            "cellular traffic forecasting",
            "deep learning",
            "generative adversarial network (GAN)",
            "internet traffic",
            "mobile edge computing (MEC)",
            "synthetic data"
        ],
        "subject_areas": [
            "Software",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Enhancing RF Fingerprinting for Indoor Positioning Systems Using Data Augmentation",
        "authors": "Junoh S.A.",
        "journal": "Digest of Technical Papers - IEEE International Conference on Consumer Electronics",
        "doi": "10.1109/ICCE59016.2024.10444463",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85186968339",
        "scopus_id": "85186968339",
        "abstract": "Indoor Positioning Systems (IPS) have recently emerged as a crucial technology in the Internet of Things (IoT), with widespread applications in smart cities and homes. Radio frequency-based fingerprinting, enabling location estimation through signal observations, requires manual surveys for constructing location maps. This process involves annotating radio signatures with corresponding locations, rendering it time-consuming and labor-intensive. To address this challenge, our paper proposes a data augmentation method that leverages a conditional generative adversarial network with LSTM and CNN. This approach effectively captures patterns in the training data, generating synthetic data that aligns with the distribution. Experiments in a real scenario demonstrate an average localization error of 1.966 and 1.218 m for Wi-Fi and Bluetooth low energy (BLE), surpassing traditional fingerprinting and comparable to the baseline data augmentation methods.",
        "author_keywords": [
            "Bluetooth low energy (BLE)",
            "data augmentation",
            "fingerprinting localization",
            "Generative adversarial network (GAN)",
            "Internet of Things",
            "Wi-Fi"
        ],
        "subject_areas": [
            "Industrial and Manufacturing Engineering",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Taxonomy Mining from a Smart City CMS using the Multidimensional Knowledge Representation Approach",
        "authors": "Zenkert J.",
        "journal": "2024 IEEE 14th Annual Computing and Communication Workshop and Conference, CCWC 2024",
        "doi": "10.1109/CCWC60891.2024.10427816",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85186748332",
        "scopus_id": "85186748332",
        "abstract": "Taxonomy mining plays an important role for organizing and structuring of data in Content Management Systems (CMS). In this paper, we propose a novel approach that leverages multidimensional knowledge representation (MKR) for taxonomy mining from text documents and enriching the extracted information via Large Language Model (LLM). The data originates from a Smart City project in Germany, which addresses housing, care and health for elderly people. The applied method involves the extraction of relevant keywords from text and the utilization of the MKR framework to analyze and represent the information. Results are provided for a context builder that utilizes GPT-4 to enrich the taxonomy. The enriched taxonomy is then used in a WordPress CMS for information search, structuring and tagging of the blog entries accordingly.",
        "author_keywords": [
            "CMS",
            "Content Management System",
            "Knowledge Representation",
            "Smart City",
            "Taxonomy Mining"
        ],
        "subject_areas": [
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Structure similarity virtual map generation network for optical and SAR image matching",
        "authors": "Chen S.",
        "journal": "Frontiers in Physics",
        "doi": "10.3389/fphy.2024.1287050",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185884591",
        "scopus_id": "85185884591",
        "abstract": "Introduction: Optical and SAR image matching is one of the fields within multi-sensor imaging and fusion. It is crucial for various applications such as disaster response, environmental monitoring, and urban planning, as it enables comprehensive and accurate analysis by combining the visual information of optical images with the penetrating capability of SAR images. However, the differences in imaging mechanisms between optical and SAR images result in significant nonlinear radiation distortion. Especially for SAR images, which are affected by speckle noises, resulting in low resolution and blurry edge structures, making optical and SAR image matching difficult and challenging. The key to successful matching lies in reducing modal differences and extracting similarity information from the images. Method: In light of this, we propose a structure similarity virtual map generation network (SVGNet) to address the task of optical and SAR image matching. The core innovation of this paper is that we take inspiration from the concept of image generation, to handle the predicament of image matching between different modalities. Firstly, we introduce the Attention U-Net as a generator to decouple and characterize optical images. And then, SAR images are consistently converted into optical images with similar textures and structures. At the same time, using the structural similarity (SSIM) to constrain structural spatial information to improve the quality of generated images. Secondly, a conditional generative adversarial network is employed to further guide the image generation process. By combining synthesized SAR images and their corresponding optical images in a dual channel, we can enhance prior information. This combined data is then fed into the discriminator to determine whether the images are true or false, guiding the generator to optimize feature learning. Finally, we employ least squares loss (LSGAN) to stabilize the training of the generative adversarial network. Results and Discussion: Experiments have demonstrated that the SVGNet proposed in this paper is capable of effectively reducing modal differences, and it increases the matching success rate. Compared to direct image matching, using image generation ideas results in a matching accuracy improvement of more than twice.",
        "author_keywords": [
            "deep learning",
            "generative adversarial networks",
            "image matching",
            "multi-sensor",
            "SAR images",
            "structural similarity",
            "virtual map"
        ],
        "subject_areas": [
            "Biophysics",
            "Materials Science (miscellaneous)",
            "Mathematical Physics",
            "Physics and Astronomy (all)",
            "Physical and Theoretical Chemistry"
        ]
    },
    {
        "title": "Autonomous Driving Road Network Generation and Evaluation based on Generative Artificial Intelligence",
        "authors": "Ye S.",
        "journal": "Proceedings of SPIE - The International Society for Optical Engineering",
        "doi": "10.1117/12.3024107",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185704669",
        "scopus_id": "85185704669",
        "abstract": "The increasing number of vehicles has led to issues such as traffic congestion, air pollution, and energy consumption. Intelligent connected autonomous driving (AD) offers a solution to these transportation challenges, but it requires cooperation among dedicated AD road networks, connected cloud-based control and dispatch systems, and intelligent vehicle sensing. To harness the potential of AD, it is crucial to consider the requirements of autonomous vehicles (AVs) when planning road networks. Well-designed road networks can enhance travel experiences, reduce energy consumption, and promote urban sustainability. In order to meet the needs of AD while ensuring the operational efficiency of urban transportation networks, this paper introduces a road network evaluation framework that encompasses both static and dynamic assessment criteria, following a detailed exploration and analysis of various road network generation methods. This evaluation framework addresses the deficiency in existing road network generation methods, which lack dynamic assessment of traffic networks. To validate the proposed approach, we have chosen a road network generation method based on conditional generative adversarial network (CGAN) as an application example. Through carefully designed experiments, we confirm the feasibility and effectiveness of the proposed method for generating and evaluating road networks tailored for AD scenarios.",
        "author_keywords": [
            "Autonomous driving",
            "evaluation framework",
            "generative adversarial network",
            "road network generation"
        ],
        "subject_areas": [
            "Electronic, Optical and Magnetic Materials",
            "Condensed Matter Physics",
            "Computer Science Applications",
            "Applied Mathematics",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Full-automatic high-precision scene 3D reconstruction method with water-area intelligent complementation and mesh optimization for UAV images",
        "authors": "Guo B.",
        "journal": "International Journal of Digital Earth",
        "doi": "10.1080/17538947.2024.2317441",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185223612",
        "scopus_id": "85185223612",
        "abstract": "Fast and high-precision urban scene 3D modeling is the foundational data infrastructure for the digital earth and smart cities. However, due to challenges such as water-area matching difficulties and issues like data redundancy and insufficient observations, existing full-automatic 3D modeling methods often result in water-area missing and many small holes in the models and insufficient local-model accuracy. To overcome these challenges, full-automatic high-precision scene 3D reconstruction method with water-area intelligent complementation on depth maps and mesh optimization is proposed. Firstly, SfM was used to calculated image poses and PatchMatch was used to generated initial depth maps. Secondly, a simplified GAN extracted water-area masks and ray tracing was used achieve high-precision auto-completed water-area depth values. Thirdly, fully connected CRF optimized water-areas and arounds in depth maps. Fourthly, high-precision 3D point clouds were obtained using depth map fusion based on clustering culling and depth least squares. Then, mesh was generated and optimized using similarity measurement and vertex gradients to obtain refined mesh. Finally, high-precision scene 3D models without water-area missing or holes were generated. The results showed that: to compare with the-state-of-art ContextCapture, the proposed method enhances model completeness by 14.3%, raises average accuracy by 14.5% and improves processing efficiency by 63.6%.",
        "author_keywords": [
            "depth map optimization",
            "High-completeness scene 3D modeling",
            "mesh refinement",
            "UAV images",
            "water-area intelligent complementation"
        ],
        "subject_areas": [
            "Software",
            "Computer Science Applications",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Generating Synthetic Data to Improve Intrusion Detection in Smart City Network Systems",
        "authors": "Čech P.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-52426-4_3",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85184132464",
        "scopus_id": "85184132464",
        "abstract": "Fast and reliable identification of cyber attacks in network systems of smart cities is currently a critical and demanding task. Machine learning algorithms have been used for intrusion detection, but the existing data sets intended for their training are often imbalanced, which can reduce the effectiveness of the proposed model. Oversampling and undersampling techniques can solve the problem but have limitations, such as the risk of overfitting and information loss. Furthermore, network data logs are noisy and inconsistent, making it challenging to capture essential patterns in the data accurately. To address these issues, this study proposes using Generative Adversarial Networks to generate synthetic network traffic data. The results offer new insight into developing more effective intrusion detection systems, especially in the context of smart cities’ network infrastructure.",
        "author_keywords": [
            "generative adversarial networks",
            "imbalanced datasets",
            "intrusion detection",
            "smart cities"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Signal Processing in Smart Fiber-Optic Distributed Acoustic Sensor",
        "authors": "Wu H.",
        "journal": "Guangxue Xuebao/Acta Optica Sinica",
        "doi": "10.3788/AOS231384",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85182744138",
        "scopus_id": "85182744138",
        "abstract": "Significance Optical fiber sensors play an increasingly important role in safety monitoring areas in the smart Internet of Things (IoT). Particularly, a fiber-optic distributed acoustic sensor (fiber-optic DAS) based on the phase-sensitive optical time-domain reflectometry (Φ‑OTDR) technology provides a highly dense, cost-effective, and continuous environment measurement way over a wide range. All kinds of vibration sources can be sensed and located with high sensitivity and precision utilizing the widely laid ordinary telecommunication cables, and thus fiber-optic DAS has been applied in various ground listening applications, such as natural disaster prediction of ocean-floor seismic activity, volcanic events, and earthquake, energy exploration in oil and gas industry, and civil infrastructure monitoring in the pipelines, railways, and perimeters. It leads to a new generation of large-scale fiber-optic IoT for ground and underwater listening technology. From the current research status in China and abroad, DAS is becoming mature in its hardware performance, such as the demodulation fidelity, sensing distance, detection bandwidth, and sensitivity, which are all approaching their perfection. However, with the rapid advance of DAS applications, the complicated and ever-changing environments for large-scale monitoring have brought about challenges of high false alarm rates due to its advantages of high sensitivity. It is difficult to achieve high-precision detection, recognition, and positioning of perceived vibration and acoustic targets, which has become the biggest technical bottleneck restricting the large-scale application of DAS technology. In recent years, driven by the development of advanced signal processing and artificial intelligence (AI) technology, the signal processing methods of fully intelligent DAS with high accuracy and real-time performance in practical complex environments have become a research hotspot and focus in the field of fiber-optic sensing. The signal processing method in DAS plays a crucial and decisive role in improving the intelligent perception ability of the entire system. Progress We review the current research status of signal processing methods in smart fiber-optic DAS entering the deep learning stage, from mainstream supervised learning to unsupervised, semi-supervised, and transfer learning, from single-source detection to multi-source aliasing detection, and from single-task recognition or localization to simultaneous implementation of recognition and localization tasks, and we predict possible research directions for further improving the intelligent processing performance and perception ability of DAS in the future. Firstly, the typical fiber-optic DAS system structure and its vibration/sound sensing mechanism (Fig. 2), and the smart DAS and its signal processing architecture in smart city monitoring applications (Fig. 3) are introduced. Then, the signal processing methods based on deep learning are explained in detail, which includes the main stream of supervised learning methods based on multi-dimensional information extraction, and semi-supervised, unsupervised learning, and cross-scene transfer learning methods in DAS. For the supervised learning method, it includes DAS signal recognition models based on temporal information extraction, such as one-dimensional convolutional neural networks (1D-CNNs) (Fig. 4), multi-scale convolutional neural networks (MS-CNNs) (Fig. 5), multi-scale and contextual temporal relationship mining methods (Figs. 6-7), and the two-dimensional recognition models based on time-frequency (Figs. 8-11), time-space (Figs. 12-14), and space-frequency (Fig. 15) information extraction technologies. Besides, some other supervised methods are also included, for example, recognition models based on attention-based long short-term memory (Fig. 16) and the fusion of manual features and deep features. It proves that the combination of traditional empirical rules and deep learning networks can further reduce the false alarm rate of the system. In response to the problem of insufficient labeled samples in new scenarios in practical applications, several semi-supervised recognition methods based on the 1D-SSGAN (one-dimensional semi-supervised generative adversarial network), SSAE (sparse stacked autoencoder), and FixMatch models have been involved to achieve accurate recognition of DAS signals with a small amount of labeled data and a large amount of unlabeled data. Furthermore, the SNN-based DAS unsupervised learning network (Fig. 17) and the cross-scene transfer learning network based on AlexNet+SVM (Fig. 18) also appear to improve the generalization ability of DAS signal recognition methods. In order to evaluate the performance of these recognition models, we introduce seven indicators for evaluating the recognition accuracy and four indicators for the processing time of the algorithms. The above key DAS recognition methods and their performance are statistically compared in Table 2. At last, the new challenges of smart DAS sensing, from single-source detection to multi-source aliasing detection, from target recognition to localization, and from a single task to multi-task processing, as well as other methods to enhance its intelligent perception capabilities, have also been introduced. Conclusions and Prospects Further improvement of signal processing and its sensing capabilities still faces new challenges and opportunities and will open a new chapter in fully intelligent DAS. Stable, accurate, real-time, and efficient signal recognition in DAS in new complicated application scenarios remains a research hotspot in the field of distributed fiber-optic sensing in the future, including: 1) improving the generalization ability of DAS recognition models in cross scenarios; 2) significant improvement in real-time processing capabilities in DAS; 3) improvement of multi-task processing ability in DAS; 4) implementation of high-performance on-chip DAS.",
        "author_keywords": [
            "fiber-optic distributed acoustic sensor",
            "fiber-optic Internet of Things",
            "phase-sensitive optical time domain reflectometry",
            "signal processing",
            "smart sensing"
        ],
        "subject_areas": [
            "Electronic, Optical and Magnetic Materials",
            "Atomic and Molecular Physics, and Optics"
        ]
    },
    {
        "title": "Personalizing Text-to-Image Diffusion Models by Fine-Tuning Classification for AI Applications",
        "authors": "Hidalgo R.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-3-031-47721-8_44",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85182514364",
        "scopus_id": "85182514364",
        "abstract": "Stable Diffusion is a captivating text-to-image model that generates images based on text input. However, a major challenge is that it is pretrained on a specific dataset, limiting its ability to generate images outside of the given data. In this paper, we propose to harness two models based on neural networks, Hypernetworks and DreamBooth, to allow the introduction of any image into Stable Diffusion, addressing versatility with minimal additional training data. This work targets AI applications such as augmenting next-generation multipurpose robots, enhancing human-robot collaboration, feeding intelligent tutoring systems, training autonomous cars, injecting subjects for photo personalization, producing high quality movie animations etc. It can contribute to AI in smart cities: facets such as smart living and smart mobility.",
        "author_keywords": [
            "ANN",
            "Data mining",
            "Image processing",
            "Movie animations",
            "Photo personalization",
            "Stable diffusion",
            "Text-to-image creation"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Spatial analysis and technological influences on smart city development in Kazakhstan",
        "authors": "Nurbatsin A.",
        "journal": "Journal of Infrastructure, Policy and Development",
        "doi": "10.24294/jipd.v8i2.3012",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85182471890",
        "scopus_id": "85182471890",
        "abstract": "This study delves into the evolving landscape of smart city development in Kazakhstan, a domain gaining increasing relevance in the context of urban modernization and digital transformation. The research is anchored in the quest to understand how specific technological factors influence the formation of smart cities within the region. To this end, the study adopts a Spatial Autoregressive Model (SAR) as its core analytical tool, leveraging data on server density, cloud service usage, and electronic invoicing practices across various Kazakhstani cities. The crux of the research revolves around assessing the impact of these selected technological variables on the smart city development process. The SAR model’s application facilitates a nuanced understanding of the spatial dynamics at play, offering insights into how these factors vary in influence across different urban areas. A key finding of this investigation is the significant positive correlation between the adoption of electronic invoicing and smart city development, a result that stands in contrast to the relatively insignificant impact of server density and cloud service usage. The conclusion drawn from these findings underscores the pivotal role of digital administrative processes, particularly electronic invoicing, in driving the smart city agenda in Kazakhstan. This insight not only contributes to the academic discourse on smart cities but also holds practical implications for policymakers and urban planners. It suggests a strategic shift towards prioritizing digital administrative innovations over mere infrastructural or technological upgrades. The study’s outcomes are poised to guide future smart city initiatives in Kazakhstan and offer a reference point for similar emerging economies embarking on their smart city journeys.",
        "author_keywords": [
            "city",
            "data connectivity",
            "e-mobility",
            "Internet of Things",
            "Kazakhstan",
            "smart cities",
            "spatial analysis",
            "spatial autoregressive model",
            "technological factors"
        ],
        "subject_areas": [
            "Development",
            "Social Sciences (miscellaneous)",
            "Urban Studies",
            "Public Administration"
        ]
    },
    {
        "title": "Efficient Road Segmentation Techniques with Attention-Enhanced Conditional GANs",
        "authors": "George G.V.",
        "journal": "SN Computer Science",
        "doi": "10.1007/s42979-023-02535-0",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85181937870",
        "scopus_id": "85181937870",
        "abstract": "Road segmentation from aerial images is a challenging yet crucial task, underpinning significant applications in urban planning, navigation, and transportation systems. In this study, we employ a conditional Generative Adversarial Network (GAN) architecture that synergistically integrates the strengths of Attention U-Net and PatchGAN to address this task. The Attention U-Net, serving as the generator, is trained on the publicly available Massachusetts Roads dataset, with an emphasis on critical regions while concurrently disregarding the irrelevant ones, thereby enhancing the accuracy of road segmentation. Simultaneously, the PatchGAN discriminator ensures the generation of sharp, high-quality segmentations. Through this cooperative approach, we have achieved an overall accuracy of 98.2%, a recall of 82.30%, a precision of 78.66%, an Intersection over Union (IoU) of 67.19%, and an F1 score of 80.44% on our dataset. While these results are promising, they also highlight areas for improvement, particularly in reducing false positives and enhancing the identification of all road pixels, underscoring the potential for future refinements in this research domain.",
        "author_keywords": [
            "Aerial image analysis",
            "Attention U-Net",
            "Conditional generative adversarial network (CGAN)",
            "Deep learning-artificial neural network",
            "Road segmentation"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Computer Science Applications",
            "Computer Networks and Communications",
            "Computer Graphics and Computer-Aided Design",
            "Computational Theory and Mathematics",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Smart cities for people with disabilities: a systematic literature review and future research directions",
        "authors": "Zhou S.",
        "journal": "European Journal of Information Systems",
        "doi": "10.1080/0960085X.2023.2297974",
        "publication_date": "2024",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85180902267",
        "scopus_id": "85180902267",
        "abstract": "Smart cities are promising communities that leverage intelligent technologies to connect citizens through internet devices, thereby improving their quality of life. This is especially crucial for citizens with disabilities, who face significant challenges in urban living. This paper reviews, summarises, and synthesises the current literature on smart cities for people with disabilities. The analysis is grounded in a sociotechnical framework and the Quadruple Helix Model, with a focus on effective collaborations among various stakeholders to provide sustainable and inclusive smart cities. In examining 83 peer-reviewed articles, our literature analysis reveals that, despite the growing number of studies on smart cities, very few have explored the challenges and opportunities for people with disabilities from a socio-technical and collaborative perspective. Accordingly, we call for interdisciplinary research to understand how smart technologies should be developed, implemented, and used to address the special needs of people with disabilities and to build inclusive and technologically advanced smart cities. This study contributes to both research and practice by highlighting the underexamined area of inclusive smart cities. It provides a conceptual framework that can serve as a guideline to address and enhance the understanding of the critical role of smart cities in fostering social inclusion.",
        "author_keywords": [
            "generative AI",
            "internet of things",
            "people with disabilities",
            "quadruple helix model",
            "Smart cities",
            "social inclusion"
        ],
        "subject_areas": [
            "Management Information Systems",
            "Information Systems",
            "Library and Information Sciences",
            "Information Systems and Management"
        ]
    },
    {
        "title": "Enhancing Semantic Image Synthesis: A GAN-Based Approach with Multi-Feature Adaptive Denormalization Layer",
        "authors": "Magdy K.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-49333-1_24",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85180741115",
        "scopus_id": "85180741115",
        "abstract": "Semantic image synthesis, a pivotal task in image-to-image translation, has been widely addressed using generative adversarial network (GAN) models. However, existing GAN-based approaches often suffer from inadequate incorporation of structural and spatial information, resulting in unsatisfactory quality of the synthesized images and a pronounced disparity between photo-realistic and generated images. In this paper, we propose a novel GAN-based methodology to address these limitations, enabling the generation of high-resolution images from semantic label maps while bridging the quality gap and preserving detailed information in the generated outputs. The proposed approach leverages a two-step process, starting with a local binary pattern convolutional generator that produces a local binary pattern feature map. Subsequently, a global convolutional generator is fed with the segmentation map and the feature map through a learned modulation scheme facilitated by a multi-feature adaptive denormalization layer (MFADE) during the training process to generate photo-realistic images. Extensive experiments using Cityscapes, ADE20K, and COCO-stuff datasets validate the performance of our proposed method and showcase its accuracy and robustness in addressing semantic image synthesis tasks, thereby paving the way for its potential applications in enhancing urban sensing and data analytics in Smart Cities. The source code is available at https://github.com/karimmagdy/ULBPGAN.",
        "author_keywords": [
            "Generative Adversarial Networks (GANs)",
            "Local Binary Pattern (LBP)",
            "Semantic Image Synthesis"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Applications, Approaches, and Ethics of the Extended Reality in Urban Design and Planning",
        "authors": "Hajrasouliha A.H.",
        "journal": "Journal of the American Planning Association",
        "doi": "10.1080/01944363.2023.2275123",
        "publication_date": "2024",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85180200496",
        "scopus_id": "85180200496",
        "abstract": "Problem, research strategy, and findings: Urban planners can benefit from extended reality (XR) technology to better understand data, history, design, and planning options through immersive sensory experiences. Though there are many examples of XR-assisted urban planning, there is little guidance on how to use it effectively. In this review I provide a comprehensive overview of XR in urban planning by examining recent literature. I begin by defining XR concepts and other influential technologies like metaverse, digital twins, generative artificial intelligence, and blockchain. Then, I review six key planning goals for using XR, including urban design, place marketing, planning support, education, research, and planning for metaverse platforms. In addition, practical considerations are discussed, such as public participation, ethics, and technical considerations. Takeaway for practice: Planners can benefit from innovative applications of XR in planning. However, rather than focusing only on the technology, planners must examine and understand the critical factors for using XR effectively and ethically. Planners who choose to use XR in their projects must stay current with technological advancements and related knowledge, skills, and values.",
        "author_keywords": [
            "city planning",
            "ethics",
            "extended reality",
            "metaverse",
            "urban design"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Development",
            "Urban Studies"
        ]
    },
    {
        "title": "Generating Spatiotemporal Trajectories with GANs and Conditional GANs",
        "authors": "Zhao K.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-981-99-8126-7_32",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85178636654",
        "scopus_id": "85178636654",
        "abstract": "Modeling the movements of individual and populations, and generating synthetic spatiotemporal trajectory data play an important role in lots of (privacy-aware) analysis and applications, such as urban planning and route navigation. A key challenge in trajectory generation is to best capture the basic characteristics of the long sequences of location points. This is non-trivial considering the inherent sequentiality and high-dimensionality of trajectory data. This paper presents TS-TrajGAN, a two-stage model to generate spatiotemporal trajectory data by combining a Generative Adversarial Network (GAN) and a conditional GAN. We train the GAN of stage I to simulate the distribution of the initial trajectory segments such that the basic characteristics of the length-limited initial trajectory segments can be well depicted. In stage II, the conditional GAN is used to predict the next location point for the current generated trajectory and preserve the variability in individuals’ mobility. In addition, a predictor network is added to the GAN of stage I for trajectory length prediction. Experiments on a real-world taxi dataset demonstrate that TS-TrajGAN is not only able to generate trajectories that have similar characteristics with the real ones, but also outperforms the state-of-the-art methods in terms of data utility. Our code is available at https://github.com/kfZhao726/TS-TrajGAN.",
        "author_keywords": [
            "Conditional GAN",
            "Generative Adversarial Network",
            "Trajectory Generation",
            "Two-Stage"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "Semantic Segmentation of Remote Sensing Architectural Images Based on GAN and UNet3+ Model",
        "authors": "Ding W.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-981-99-7019-3_25",
        "publication_date": "2024",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85177178513",
        "scopus_id": "85177178513",
        "abstract": "Semantic segmentation of remote sensing building images can provide important data support for urban planning and resource management. It also plays a crucial role in assessing building density, monitoring urban expansion, and optimizing traffic planning. In recent times, with the continuous integration of computer vision and deep learning, Convolutional Neural Networks (CNNs) have achieved outstanding results in semantic segmentation tasks for remote sensing images. Although deep CNNs can significantly improve the accuracy of semantic segmentation for remote sensing images, some network models used for segmentation tasks still have limitations, such as low segmentation precision and inadequate feature extraction. In this paper, we propose an adversarial semantic segmentation network based on Generative Adversarial Networks (GANs). To better extract the features and semantics of buildings in remote sensing images, we introduce the UNet3+ network as the segmentation network of the adversarial network for the first time and make improvements to the UNet3+ network. We add the scSE (Spatial Channel Squeeze and Excitation) attention mechanism to the network, the scSE attention mechanism enhances the network’s perception of different channel features by considering their correlations in the channel dimension, allowing it to capture fine-grained details and coarse-grained semantics at the full scale. In this paper, we conduct experiments on the Inria Aerial Image Labeling dataset, and the results show that our method outperforms other network models mentioned in the paper in terms of performance.",
        "author_keywords": [
            "Generate adversarial network",
            "Remote sensing image",
            "Semantic segmentation",
            "UNet3+"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Low-light image enhancement base on brightness attention mechanism generative adversarial networks",
        "authors": "Fu J.",
        "journal": "Multimedia Tools and Applications",
        "doi": "10.1007/s11042-023-15815-x",
        "publication_date": "2024",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85162987014",
        "scopus_id": "85162987014",
        "abstract": "With the development of the field of deep learning, image recognition, enhancement and other technologies have been widely used.However, dark lighting environments in reality, such as insufficient light at night, cause or block photographic images in low brightness, severe noise, and a large number of details are lost, resulting in a huge loss of image content and information, which hinders further analysis and use. Such problems not only exist in the traditional deep learning field, but also exist in criminal investigation, scientific photography and other fields, such as the accuracy of low-light image. However, in the current research results, there is no perfect means to deal with the above problems. Therefore, the study of low-light image enhancement has important theoretical significance and practical application value for the development of smart cities. In order to improve the quality of low-light enhanced images, this paper tries to introduce the luminance attention mechanism to improve the enhancement efficiency. The main contents of this paper are summarized as follows: using the attention mechanism, we proposed a method of low-light image enhancement based on the brightness attention mechanism and generative adversarial networks. This method uses brightness attention mechanism to predict the illumination distribution of low-light image and guides the enhancement network to enhance the image adaptiveness in different luminance regions. At the same time, u-NET network is designed and constructed to improve the modeling process of low-light image. We verified the performance of the algorithm on the synthetic data set and compared it with traditional image enhancement methods (HE, SRIE) and deep learning methods (DSLR). The experimental results show that our proposed network model has relatively good enhancement quality for low-light images, and improves the overall robustness, which has practical significance for solving the problem of low-light image enhancement.",
        "author_keywords": [
            "Attention mechanism",
            "Generative adversarial networks",
            "Low-light image enhancement"
        ],
        "subject_areas": [
            "Software",
            "Media Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Classifying Crowdsourced Citizen Complaints through Data Mining: Accuracy Testing of k-Nearest Neighbors, Random Forest, Support Vector Machine, and AdaBoost",
        "authors": "Madyatmadja E.D.",
        "journal": "Informatics",
        "doi": "10.3390/informatics10040084",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85180679038",
        "scopus_id": "85180679038",
        "abstract": "Crowdsourcing has gradually become an effective e-government process to gather citizen complaints over the implementation of various public services. In practice, the collected complaints form a massive dataset, making it difficult for government officers to analyze the big data effectively. It is consequently vital to use data mining algorithms to classify the citizen complaint data for efficient follow-up actions. However, different classification algorithms produce varied classification accuracies. Thus, this study aimed to compare the accuracy of several classification algorithms on crowdsourced citizen complaint data. Taking the case of the LAKSA app in Tangerang City, Indonesia, this study included k-Nearest Neighbors, Random Forest, Support Vector Machine, and AdaBoost for the accuracy assessment. The data were taken from crowdsourced citizen complaints submitted to the LAKSA app, including those aggregated from official social media channels, from May 2021 to April 2022. The results showed SVM with a linear kernel as the most accurate among the assessed algorithms (89.2%). In contrast, AdaBoost (base learner: Decision Trees) produced the lowest accuracy. Still, the accuracy levels of all algorithms varied in parallel to the amount of training data available for the actual classification categories. Overall, the assessments on all algorithms indicated that their accuracies were insignificantly different, with an overall variation of 4.3%. The AdaBoost-based classification, in particular, showed its large dependence on the choice of base learners. Looking at the method and results, this study contributes to e-government, data mining, and big data discourses. This research recommends that governments continuously conduct supervised training of classification algorithms over their crowdsourced citizen complaints to seek the highest accuracy possible, paving the way for smart and sustainable governance.",
        "author_keywords": [
            "citizen science",
            "crowdsourcing",
            "generative AI",
            "knowledge extraction",
            "large language model",
            "machine learning",
            "public complaint",
            "smart city",
            "sustainable city",
            "text mining"
        ],
        "subject_areas": [
            "Communication",
            "Human-Computer Interaction",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Prediction of transportation index for urban patterns in small and medium-sized Indian cities using hybrid RidgeGAN model",
        "authors": "Thottolil R.",
        "journal": "Scientific Reports",
        "doi": "10.1038/s41598-023-49343-3",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85179323425",
        "scopus_id": "85179323425",
        "abstract": "The rapid urbanization trend in most developing countries including India is creating a plethora of civic concerns such as loss of green space, degradation of environmental health, scarcity of clean water, rise in air pollution, and exacerbated traffic congestion resulting in significant delays in vehicular transportation. To address the intricate nature of transportation issues, many researchers and planners have analyzed the complexities of urban and regional road systems using transportation models by employing transportation indices such as road length, network density, accessibility, and connectivity metrics. This study addresses the complexities of predicting road network density for small and medium-sized Indian cities that come under the Integrated Development of Small and Medium Towns (IDSMT) project at a national level. A hybrid framework based on Kernel Ridge Regression (KRR) and the CityGAN model is introduced to predict network density using spatial indicators of human settlements. The major goal of this study is to generate hyper-realistic urban patterns of small and medium-sized Indian cities using an unsupervised CityGAN model and to study the causal relationship between human settlement indices (HSIs) and transportation index (network density) using supervised KRR for the real cities. The synthetic urban universes mimic Indian urban patterns and evaluating their landscape structures through the settlement indices can aid in comprehending urban landscape, thereby enhancing sustainable urban planning. We analyzed 503 real cities to find the actual relationship between the urban settlements and their road density. The nonlinear KRR model may help urban planners in deriving the network density for GAN-generated futuristic urban patterns through the settlement indicators. The proposed hybrid process, termed as RidgeGAN model, can gauge the sustainability of urban sprawl tied to infrastructure and transportation systems in sprawling cities. Analysis results clearly demonstrate the utility of RidgeGAN in predicting network density for different kinds of human settlements, particularly for small and medium Indian cities. By predicting future urban patterns, this study can help in the creation of more livable and sustainable areas, particularly by improving transportation infrastructure in developing cities.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "PredLife: Predicting Fine-Grained Future Activity Patterns",
        "authors": "Li W.",
        "journal": "IEEE Transactions on Big Data",
        "doi": "10.1109/TBDATA.2023.3310241",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85169689406",
        "scopus_id": "85169689406",
        "abstract": "Activity pattern prediction is a critical part of urban computing, urban planning, intelligent transportation, and so on. Based on a dataset with more than 10 million GPS trajectory records collected by mobile sensors, this research proposed a CNN-BiLSTM-VAE-ATT-based encoder-decoder model for fine-grained individual activity sequence prediction. The model combines the long-term and short-term dependencies crosswise and also considers randomness, diversity, and uncertainty of individual activity patterns. The proposed results show higher accuracy compared to the ten baselines. The model can generate high diversity results while approximating the original activity patterns distribution. Moreover, the model also has interpretability in revealing the time dependency importance of the activity pattern prediction.",
        "author_keywords": [
            "Activity pattern prediction",
            "Big GPS data",
            "Human mobility",
            "LSTM",
            "Variational autoencoder"
        ],
        "subject_areas": [
            "Information Systems",
            "Information Systems and Management"
        ]
    },
    {
        "title": "GAN-FuzzyNN: Optimization Based Generative Adversarial Network and Fuzzy Neural Network Classification for Change Detection in Satellite Images",
        "authors": "Gite K.R.",
        "journal": "Sensing and Imaging",
        "doi": "10.1007/s11220-022-00404-3",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85145509453",
        "scopus_id": "85145509453",
        "abstract": "Nowadays, change detection with satellite images plays an essential role in urban planning, resources survey, and understanding global environmental changes. However, numerous satellite images are persistently acquired each and every second and they possess a significant source of data for the assessment of the spatiotemporal case. Moreover, obtaining reference data associated with satellite images dealing with land cover changes still remains a major challenging issue. Besides, traditional techniques for change detection are not valuable because of complex texture features. To cope up with such limitations, an effective mechanism is proposed for change detection by exploiting Fuzzy Neural Network (FNN) classification, which is an integration of the Fuzzy concept with Neural Network (NN), and also segmentation is done using Taylor Shuffled Shepherd Optimization (TSSO)-based Generative Adversarial Network (GAN). The proposed TSSO is obtained by incorporating the Taylor series and Shuffled shepherd Optimization (SSO) and the proposed approach achieved a maximum overall accuracy of 0.932, minimum overall error of 0.0704, and maximum kappa coefficient of 0.911. The accuracy of the devised TSSO-based GAN + Fuzzy NN is 2.28%, 4.78%, 0.33%, and 13.26% improved than the Kernel Principal Component Analysis Convolutional Mapping Network (KPCA-MNet), Multiclass Support Vector Machine (MSVM), Patchlevel and pixel-level change detection network (PPCNET), and Image Fusion Network (IFN), respectively, for Image-1.",
        "author_keywords": [
            "Change detection",
            "Fuzzy neural network",
            "Generative adversarial network",
            "Shuffled shepherd optimization algorithm",
            "Taylor series"
        ],
        "subject_areas": [
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Towards Generative Modeling of Urban Flow through Knowledge-enhanced Denoising Diffusion",
        "authors": "Zhou Z.",
        "journal": "GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems",
        "doi": "10.1145/3589132.3625641",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85180602130",
        "scopus_id": "85180602130",
        "abstract": "Although generative AI has been successful in many areas, its ability to model geospatial data is still underexplored. Urban flow, a typical kind of geospatial data, is critical for a wide range of applications from public safety and traffic management to urban planning. Existing studies mostly focus on predictive modeling of urban flow that predicts the future flow based on historical flow data, which may be unavailable in data-sparse areas or newly planned regions. Some other studies aim to predict OD flow among regions but they fail to model dynamic changes of urban flow over time. In this work, we study a new problem of urban flow generation that generates dynamic urban flow for regions without historical flow data. To capture the effect of multiple factors on urban flow, such as region features and urban environment, we employ diffusion model to generate urban flow for regions under different conditions. We first construct an urban knowledge graph (UKG) to model the urban environment and relationships between regions, based on which we design a knowledge-enhanced spatio-temporal diffusion model (KSTDiff) to generate urban flow for each region. Specifically, to accurately generate urban flow for regions with different flow volumes, we design a novel diffusion process guided by a volume estimator, which is learnable and customized for each region. Moreover, we propose a knowledge-enhanced denoising network to capture the spatio-temporal dependencies of urban flow as well as the impact of urban environment in the denoising process. Extensive experiments on four real-world datasets validate the superiority of our model over state-of-the-art baselines in urban flow generation. Further in-depth studies demonstrate the utility of generated urban flow data and the ability of our model for long-term flow generation and urban flow prediction. Our code is released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.",
        "author_keywords": [
            "diffusion model",
            "generative model",
            "knowledge graph",
            "urban flow"
        ],
        "subject_areas": [
            "Earth-Surface Processes",
            "Computer Science Applications",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Information Systems"
        ]
    },
    {
        "title": "Land Use and Land Cover Classification Meets Deep Learning: A Review",
        "authors": "Zhao S.",
        "journal": "Sensors (Basel, Switzerland)",
        "doi": "10.3390/s23218966",
        "publication_date": "2023",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85176892418",
        "scopus_id": "85176892418",
        "abstract": "As one of the important components of Earth observation technology, land use and land cover (LULC) image classification plays an essential role. It uses remote sensing techniques to classify specific categories of ground cover as a means of analyzing and understanding the natural attributes of the Earth's surface and the state of land use. It provides important information for applications in environmental protection, urban planning, and land resource management. However, remote sensing images are usually high-dimensional data and have limited available labeled samples, so performing the LULC classification task faces great challenges. In recent years, due to the emergence of deep learning technology, remote sensing data processing methods based on deep learning have achieved remarkable results, bringing new possibilities for the research and development of LULC classification. In this paper, we present a systematic review of deep-learning-based LULC classification, mainly covering the following five aspects: (1) introduction of the main components of five typical deep learning networks, how they work, and their unique benefits; (2) summary of two baseline datasets for LULC classification (pixel-level, patch-level) and performance metrics for evaluating different models (OA, AA, F1, and MIOU); (3) review of deep learning strategies in LULC classification studies, including convolutional neural networks (CNNs), autoencoders (AEs), generative adversarial networks (GANs), and recurrent neural networks (RNNs); (4) challenges faced by LULC classification and processing schemes under limited training samples; (5) outlooks on the future development of deep-learning-based LULC classification.",
        "author_keywords": [
            "deep learning",
            "image classification",
            "LULC",
            "remote sensing"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Information Systems",
            "Atomic and Molecular Physics, and Optics",
            "Biochemistry",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "A hybrid Cycle GAN-based lightweight road perception pipeline for road dataset generation for Urban mobility",
        "authors": "Rajagopal B.G.",
        "journal": "PLoS ONE",
        "doi": "10.1371/journal.pone.0293978",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85178511616",
        "scopus_id": "85178511616",
        "abstract": "One of the major problems that cause continual trouble in deep learning networks is that training a large network requires massive labelled datasets. The preparation of a massive labelled dataset is a cumbersome task and requires lot of human interventions. This paper proposes a novel generator network ‘Sim2Real’ transfer is a recent and fast-developing field in machine learning used to bridge the gap between simulated and real data. Training with simulated datasets often converges due to its size but fails to generalize real-world applications. Simulated datasets can be used to train and test deep learning models, enables the development and evaluation of new algorithms and architectures. By simulating road dataset, researchers can generate large amounts of realistic road-traffic dataset that can be used to study and understand several problems such as vehicular object tracking and classification, traffic situation analysis etc. The main advantage of such a transfer algorithm is to use the abundance of a simulated dataset to generate huge realistic-looking datasets to solve data-intense tasks. This work presents a novel, robust sim2real algorithm that converts the labels of a semantic segmentation map to a realistic-looking street view using the Cityscapes dataset and aims to achieve robust urban mobility for smart cities. Further, the generalizability of the Cycle Generative Adversarial Network (CycleGAN) architecture was tested by using an origami robot dataset for sim2real transfer. We show that the results were found to be qualitatively satisfactory for different traffic analysis applications. In addition, road perception was done using a lightweight SVM pipeline and evaluated on the KITTI dataset. We have incorporated Cycle Consistency Loss and Identity Loss as the metrics to evaluate the performance of the proposed Cycle GAN model. We inferred that the proposed Cycle GAN model provides an Identity loss of less than 0.2 in both the Cityscapes dataset and KITTI datasets. Also, we understand that the super-pixel resolution has a good impact on the quantitative results of the proposed Cycle GAN models.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Virtual Scenarios of Earthquake Early Warning to Disaster Management in Smart Cities Based on Auxiliary Classifier Generative Adversarial Networks",
        "authors": "Ahn J.K.",
        "journal": "Sensors",
        "doi": "10.3390/s23229209",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85177745131",
        "scopus_id": "85177745131",
        "abstract": "Effective response strategies to earthquake disasters are crucial for disaster management in smart cities. However, in regions where earthquakes do not occur frequently, model construction may be difficult due to a lack of training data. To address this issue, there is a need for technology that can generate earthquake scenarios for response training at any location. We proposed a model for generating earthquake scenarios using an auxiliary classifier Generative Adversarial Network (AC-GAN)-based data synthesis. The proposed ACGAN model generates various earthquake scenarios by incorporating an auxiliary classifier learning process into the discriminator of GAN. Our results at borehole sensors showed that the seismic data generated by the proposed model had similar characteristics to actual data. To further validate our results, we compared the generated IM (such as PGA, PGV, and SA) with Ground Motion Prediction Equations (GMPE). Furthermore, we evaluated the potential of using the generated scenarios for earthquake early warning training. The proposed model and algorithm have significant potential in advancing seismic analysis and detection management systems, and also contribute to disaster management.",
        "author_keywords": [
            "borehole-seismometer",
            "earthquake early warning",
            "Generative Adversarial Network",
            "seismic sensor",
            "virtual seismic scenarios"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Information Systems",
            "Atomic and Molecular Physics, and Optics",
            "Biochemistry",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Automatic responsive-generation of 3D urban morphology coupled with local climate zones using generative adversarial network",
        "authors": "Zhou S.",
        "journal": "Building and Environment",
        "doi": "10.1016/j.buildenv.2023.110855",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85173564570",
        "scopus_id": "85173564570",
        "abstract": "Decoupling the intricate relationship between three-dimensional (3D) urban morphology and local climate is paramount importance in the realm of adaptive urban planning. Research based on Local Climate Zone (LCZ) has exhibited promising potential for disentangling the interactive mechanisms between urban morphology and local climate. In this study, generative adversarial networks (GAN) were employed as surrogate models to facilitate the integration of LCZ and urban morphology data from six metropolises for associative training. Through comparative experiments involving quantitative and qualitative evaluations, a rapid and responsive 3D morphology prediction model was developed for LCZ classifications. The results demonstrated the superior convergence capabilities and accuracy of the Pix2pix model (RMSE = 0.187 and R2 = 0.878) when compared to the CycleGAN model (RMSE = 0.344 and R2 = 0.674). The predicted 3D morphologies showcased a pronounced alignment with their respective LCZs, as evidenced by the precise representation of open low-rise buildings and their interrelationships with the coastline in the Sydney sample, as well as the accurate portrayal of the complex urban morphology shaped by compact high-rise buildings and road networks in the Tokyo sample. Utilizing indices calculated from the 3D morphology, the model yielded an average overall accuracy (OA), kappa coefficient, and F1 score of 85.2%, 0.83, and 0.86, respectively, indicating the robustness and adaptability of the model. The framework presented in this research offers practitioners a solid foundation and valuable insights for enhancing the local climate in urban areas through the implementation of 3D generative design techniques.",
        "author_keywords": [
            "3D urban morphology",
            "Generative adversarial network",
            "Local climate zones",
            "Responsive design",
            "Surrogate model",
            "Urban climate"
        ],
        "subject_areas": [
            "Environmental Engineering",
            "Civil and Structural Engineering",
            "Geography, Planning and Development",
            "Building and Construction"
        ]
    },
    {
        "title": "Multi-scale spatial-temporal aware transformer for traffic prediction",
        "authors": "Tian R.",
        "journal": "Information Sciences",
        "doi": "10.1016/j.ins.2023.119557",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85169003980",
        "scopus_id": "85169003980",
        "abstract": "Traffic prediction is an important part of smart city management. Accurate traffic prediction can be deployed in urban applications such as congestion alerting and route planning, thus providing sustainable services to the public or relevant departments. Although some improvements have been made in existing traffic prediction methods, there are challenges due to the following: (1) Time series has multi-scale nature, that is, from different scale time ranges, traffic flow changes show different trends; (2) Spatial heterogeneity, meaning that traffic conditions in similar functional areas are usually similar. This task remains difficult. To address the above challenges, we propose a new spatial-temporal prediction method, namely Multi-Scale Spatial-Temporal Aware Transformer (MSSTAT), which is a Transformer architecture with multi-scale characteristics. Specifically, compared to the input of encoder, the input of different decoder layers has different scale information, MSSTAT synchronizes model the connection between time steps and scale information by a kind of Parallel Cross Multi-Head Attention, which gives each time step several times the perceived field while also being able to weaken the impact brought by anomaly point. In addition, to add connections between regions with similar functions, we map the traffic data of each node as a probability distribution and then measure the similarity between the nodes by the Wasserstein Distance, which leads to our proposed spatial-temporal aware adjacency matrix. Experimental results on four traffic flow datasets show that MSSTAT outperforms the state-of-the-art baseline.",
        "author_keywords": [
            "Multi-scale",
            "Spatial heterogeneity",
            "Traffic prediction",
            "Transformer"
        ],
        "subject_areas": [
            "Software",
            "Control and Systems Engineering",
            "Theoretical Computer Science",
            "Computer Science Applications",
            "Information Systems and Management",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "MDMASNet: A dual-task interactive semi-supervised remote sensing image segmentation method",
        "authors": "Zhang L.",
        "journal": "Signal Processing",
        "doi": "10.1016/j.sigpro.2023.109152",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85162129303",
        "scopus_id": "85162129303",
        "abstract": "Remote sensing image (RSIs) segmentation is widely used in urban planning, natural disaster detection and many other fields. Compared with natural scene images, RSIs have higher resolution, complex imaging, and diverse object shapes and sizes, while semantic segmentation methods based on deep learning often require many data labels. In this paper, we propose a semi-supervised RSIs segmentation network with multi-scale deformable threshold feature extraction module and mixed attention (MDMANet). First, a pyramid ensemble structure is used, which incorporates deformable convolution and bole convolution, to extract features of objects with different shapes and sizes and reduce the influence of redundant features. Meanwhile, a mixed attention (MA) is proposed to aggregate long-range contextual relationships and fuse low-level features with high-level features. Second, an FCN-based full convolution discriminator task network is designed to help evaluate the feasibility of unlabeled image prediction results. We performed experimental validation on three datasets, and the results show that MDMANet segmentation provides more significant improvement in accuracy and better generalization than existing segmentation networks.",
        "author_keywords": [
            "Attention mechanism",
            "GAN",
            "Semantic segmentation",
            "Semi-supervised learning"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Software",
            "Signal Processing",
            "Computer Vision and Pattern Recognition",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "ReCo: A Dataset for Residential Community Layout Planning",
        "authors": "Chen X.",
        "journal": "MM 2023 - Proceedings of the 31st ACM International Conference on Multimedia",
        "doi": "10.1145/3581783.3612465",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85179554422",
        "scopus_id": "85179554422",
        "abstract": "Layout planning is centrally important in the field of architecture and urban design. Among the various basic units carrying urban functions, residential community plays a vital part for supporting human life. Therefore, the layout planning of residential community has always been of concern, and has attracted particular attention since the advent of deep learning that facilitates the automated layout generation and spatial pattern recognition. However, the research circles generally suffer from the insufficiency of residential community layout benchmark or high-quality datasets, which hampers the future exploration of data-driven methods for residential community layout planning. The lack of datasets is largely due to the difficulties of large-scale real-world residential data acquisition and long-term expert screening. In order to address the issues and advance a benchmark dataset for various intelligent spatial design and analysis applications in the development of smart city, we introduce Residential Community Layout Planning (ReCo) Dataset, which is the first and largest open-source vector dataset related to real-world community to date. ReCo Dataset is presented in multiple data formats with 37,646 residential community layout plans, covering 598,728 residential buildings with height information. ReCo can be conveniently adapted for residential community layout related urban design tasks, e.g., generative layout design, morphological pattern recognition and spatial evaluation. To validate the utility of ReCo in automated residential community layout planning, two Generative Adversarial Network (GAN) based generative models are further applied to the dataset. We expect ReCo Dataset to inspire more creative and practical work in intelligent design and beyond. The ReCo Dataset is published at: https://www.kaggle.com/fdudsde/reco-dataset and related code can be found at: \\urlhttps://github.com/FDUDSDE/ReCo-Dataset.",
        "author_keywords": [
            "dataset",
            "layout generation",
            "layout planning and design",
            "residential community layout"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Graphics and Computer-Aided Design",
            "Human-Computer Interaction",
            "Software"
        ]
    },
    {
        "title": "Enhancing the Robustness via Adversarial Learning and Joint Spatial-Temporal Embeddings in Traffic Forecasting",
        "authors": "Jiang J.",
        "journal": "International Conference on Information and Knowledge Management, Proceedings",
        "doi": "10.1145/3583780.3614868",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85178138518",
        "scopus_id": "85178138518",
        "abstract": "Traffic forecasting is an essential problem in urban planning and computing. The complex dynamic spatial-temporal dependencies among traffic objects (e.g., sensors and road segments) have been calling for highly flexible models; unfortunately, sophisticated models may suffer from poor robustness especially in capturing the trend of the time series (1st-order derivatives with time), leading to unrealistic forecasts. To address the challenge of balancing dynamics and robustness, we propose TrendGCN, a new scheme that extends the flexibility of GCNs and the distribution-preserving capacity of generative and adversarial loss for handling sequential data with inherent statistical correlations. On the one hand, our model simultaneously incorporates spatial (node-wise) embeddings and temporal (time-wise) embeddings to account for heterogeneous space-and-time convolutions; on the other hand, it uses GAN structure to systematically evaluate statistical consistencies between the real and the predicted time series in terms of both the temporal trending and the complex spatial-temporal dependencies. Compared with traditional approaches that handle step-wise predictive errors independently, our approach can produce more realistic and robust forecasts. Experiments on six benchmark traffic forecasting datasets and theoretical analysis both demonstrate the superiority and the state-of-the-art performance of TrendGCN. Source code is available at https://github.com/juyongjiang/TrendGCN.",
        "author_keywords": [
            "Robustness",
            "Spatial-Temporal Embeddings",
            "Traffic Forecasting"
        ],
        "subject_areas": [
            "Business, Management and Accounting (all)",
            "Decision Sciences (all)"
        ]
    },
    {
        "title": "DiffUFlow: Robust Fine-grained Urban Flow Inference with Denoising Diffusion Model",
        "authors": "Zheng Y.",
        "journal": "International Conference on Information and Knowledge Management, Proceedings",
        "doi": "10.1145/3583780.3614842",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85178093216",
        "scopus_id": "85178093216",
        "abstract": "Inferring the fine-grained urban flows based on the coarse-grained flow observations is practically important to many smart city-related applications. However, the collected urban flows are usually rather unreliable, may contain noise and sometimes are incomplete, thus posing great challenges to existing approaches. In this paper, we present a pioneering study on robust fine-grained urban flow inference with noisy and incomplete urban flow observations, and propose a denoising diffusion model named DiffUFlow to effectively address it with an improved reverse diffusion strategy. Specifically, a spatial-temporal feature extraction network called STFormer and a semantic features extraction network called ELFetcher are proposed. Then, we overlay the extracted spatial-temporal feature map onto the coarse-grained flow map, serving as a conditional guidance for the reverse diffusion process. We further integrate the semantic features extracted by ELFetcher to cross-attention layers, enabling the comprehensive consideration of semantic information for fine-grained flow inference. Extensive experiments on two large real-world datasets validate the effectiveness of our method compared with the state-of-the-art baselines.",
        "author_keywords": [
            "Denoising diffusion model",
            "Spatial-temporal data mining",
            "Urban flow inference"
        ],
        "subject_areas": [
            "Business, Management and Accounting (all)",
            "Decision Sciences (all)"
        ]
    },
    {
        "title": "ViFi-Loc: Multi-modal Pedestrian Localization using GAN with Camera-Phone Correspondences",
        "authors": "Liu H.",
        "journal": "ACM International Conference Proceeding Series",
        "doi": "10.1145/3577190.3614119",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85175789306",
        "scopus_id": "85175789306",
        "abstract": "In Smart City and Vehicle-to-Everything (V2X) systems, acquiring pedestrians' accurate locations is crucial to traffic and pedestrian safety. Current systems adopt cameras and wireless sensors to estimate people's locations via sensor fusion. Standard fusion algorithms, however, become inapplicable when multi-modal data is not associated. For example, pedestrians are out of the camera field of view, or data from the camera modality is missing. To address this challenge and produce more accurate location estimations for pedestrians, we propose a localization solution based on a Generative Adversarial Network (GAN) architecture. During training, it learns the underlying linkage between pedestrians' camera-phone data correspondences. During inference, it generates refined position estimations based only on pedestrians' phone data that consists of GPS, IMU, and FTM. Results show that our GAN produces 3D coordinates at 1 to 2 meters localization error across 5 different outdoor scenes. We further show that the proposed model supports self-learning. The generated coordinates can be associated with pedestrians' bounding box coordinates to obtain additional camera-phone data correspondences. This allows automatic data collection during inference. Results show that after fine-tuning the GAN model on the expanded dataset, localization accuracy is further improved by up to 26%.",
        "author_keywords": [
            "Computer Vision",
            "GAN",
            "IMU",
            "Localization",
            "Multi-modal",
            "WiFi FTM"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Networks and Communications",
            "Computer Vision and Pattern Recognition",
            "Software"
        ]
    },
    {
        "title": "ViFiT: Reconstructing Vision Trajectories from IMU and Wi-Fi Fine Time Measurements",
        "authors": "Cao B.B.",
        "journal": "ISACom 2023 - Proceedings of the 2023 3rd ACM MobiCom Workshop on Integrated Sensing and Communication Systems",
        "doi": "10.1145/3615984.3616503",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85176132303",
        "scopus_id": "85176132303",
        "abstract": "Tracking subjects in videos is one of the most widely used functions in camera-based IoT applications such as security surveillance, smart city traffic safety enhancement, vehicle to pedestrian communication and so on. In computer vision domain, tracking is usually achieved by first detecting subjects, then associating detected bounding boxes across video frames. Typically, frames are transmitted to a remote site for processing, incurring high latency and network costs. To address this, we propose ViFiT, a transformer-based model that reconstructs vision bounding box trajectories from phone data (IMU and Fine Time Measurements). It leverages a transformer's ability of better modeling long-term time series data. ViFiT is evaluated on Vi-Fi Dataset, a large-scale multimodal dataset in 5 diverse real world scenes, including indoor and outdoor environments. Results demonstrate that ViFiT outperforms the state-of-the-art approach for cross-modal reconstruction in LSTM Encoder-Decoder architecture X-Translator and achieves a high frame reduction rate as 97.76% with IMU and Wi-Fi data.",
        "author_keywords": [
            "Efficient Video System",
            "IMU",
            "Multimodal Learning",
            "Multimodal Reconstruction",
            "Object Detection",
            "Tracking",
            "Transformer"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems"
        ]
    },
    {
        "title": "Generating Synthetic Dataset for ML-Based IDS Using CTGAN and Feature Selection to Protect Smart IoT Environments",
        "authors": "Alabdulwahab S.",
        "journal": "Applied Sciences (Switzerland)",
        "doi": "10.3390/app131910951",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85174190917",
        "scopus_id": "85174190917",
        "abstract": "Networks within the Internet of Things (IoT) have some of the most targeted devices due to their lightweight design and the sensitive data exchanged through smart city networks. One way to protect a system from an attack is to use machine learning (ML)-based intrusion detection systems (IDSs), significantly improving classification tasks. Training ML algorithms require a large network traffic dataset; however, large storage and months of recording are required to capture the attacks, which is costly for IoT environments. This study proposes an ML pipeline using the conditional tabular generative adversarial network (CTGAN) model to generate a synthetic dataset. Then, the synthetic dataset was evaluated using several types of statistical and ML metrics. Using a decision tree, the accuracy of the generated dataset reached 0.99, and its lower complexity reached 0.05 s training and 0.004 s test times. The results show that synthetic data accurately reflect real data and are less complex, making them suitable for IoT environments and smart city applications. Thus, the generated synthetic dataset can further train models to secure IoT networks and applications.",
        "author_keywords": [
            "advanced persistent threat",
            "CTGAN",
            "information security",
            "intrusion detection system",
            "IoT",
            "machine learning"
        ],
        "subject_areas": [
            "Materials Science (all)",
            "Instrumentation",
            "Engineering (all)",
            "Process Chemistry and Technology",
            "Computer Science Applications",
            "Fluid Flow and Transfer Processes"
        ]
    },
    {
        "title": "IoT Anomaly Detection to Strengthen Cybersecurity in the Critical Infrastructure of Smart Cities",
        "authors": "Villegas-Ch W.",
        "journal": "Applied Sciences (Switzerland)",
        "doi": "10.3390/app131910977",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85174173086",
        "scopus_id": "85174173086",
        "abstract": "This study addresses anomaly detection in smart city environments driven by the Internet of Things. In these cities, digital interconnection and the extensive network of sensors generate enormous amounts of data, which are essential to improving citizens’ efficiency and quality of life. However, this data may also contain strange events that require early detection to ensure the proper functioning of urban systems. For this, anomaly detection models are explored to identify unusual patterns in urban data. The work focuses on the applicability and effectiveness of these models in different urban scenarios supported by the Internet of Things. Furthermore, its performance is evaluated by comparing it with existing approaches, and its advantages and limitations are analyzed. The results show that the proposed models, including Isolation Forest, recurrent neural network, and variational autoencoder, are highly effective in detecting anomalies in urban data. This work contributes to the field of smart cities by improving the safety and efficiency of urban systems. Early detection of anomalies makes it possible to prevent unplanned interruptions, ensure the safety of citizens, and maintain the integrity of urban systems. Furthermore, the relevance of this work in the existing literature and its importance for the evolution of smart cities supported by the Internet of Things are highlighted.",
        "author_keywords": [
            "anomaly detection in IoT",
            "critical infrastructure security",
            "machine learning for anomaly detection"
        ],
        "subject_areas": [
            "Materials Science (all)",
            "Instrumentation",
            "Engineering (all)",
            "Process Chemistry and Technology",
            "Computer Science Applications",
            "Fluid Flow and Transfer Processes"
        ]
    },
    {
        "title": "Application of deep generative networks for SAR/ISAR: a review",
        "authors": "Zhang J.",
        "journal": "Artificial Intelligence Review",
        "doi": "10.1007/s10462-023-10469-5",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85151244527",
        "scopus_id": "85151244527",
        "abstract": "Military, agricultural, and urban planning have all made extensive use of SAR/ISAR in the realm of remote sensing. SAR/ISAR images are more capable of identifying the details of the targets than optical images and can be taken in any condition. Due to the challenges associated with SAR/ISAR imaging, the lack of data causes many jobs relying on data-driven deep learning algorithms to perform less than satisfactorily. Cropping, rotation, and other procedures are examples of classic data augmentation techniques now in use, although they do not fundamentally differ from basic replication and cannot increase the model’s stability and robustness. Deep generative models are used to generate SAR/ISAR images, which is a more efficient way than the conventional ones. The generation techniques are outlined and organized depending on the application fields in this review, including SAR/ISAR data augmentation (26 papers), SAR/ISAR image translation (29 papers), SAR/ISAR image enhancement (22 papers), azimuth interpolation (9 papers), and deceptive jamming (1 paper). The connected works are then summarized based on several deep generative models. 87 linked studies and 5 associated survey papers from 2017 to 2022 are compiled in this review. Finally, the summarized works are systematically analyzed. There are 27 papers using MSTAR for image generation, which is the mostly applied dataset. For evaluation, the combination of SSIM and PSNR is applied most widely (32.19%). In conclusion, this review offers fresh perspectives on the direction in which deep generative models for SAR/ISAR image generation are headed. The cutting-edge methods outlined in this paper are also available to researchers in other domains.",
        "author_keywords": [
            "Artificial intelligence",
            "Deep learning",
            "Generative adversarial network",
            "Image generation",
            "Synthetic aperture radar image"
        ],
        "subject_areas": [
            "Language and Linguistics",
            "Linguistics and Language",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Game patrol strategy for hazardous gas leakage in chemical parks",
        "authors": "Chen Y.",
        "journal": "Chinese Journal of Intelligent Science and Technology",
        "doi": "10.11959/j.issn.2096-6652.202338",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85175328624",
        "scopus_id": "85175328624",
        "abstract": "In the context of promoting the integration of smart cities, the pace of construction of smart chemical parks is gradually accelerating. Since accidents in China’s chemical industry have occurred frequently in recent years, causing great damage and loss to public safety, improving the safety management and emergency response capability of chemical parks is an urgent need to be solved. For this kind of safety problems, this paper proposed a game patrol strategy for hazardous gas leakage in chemical parks. Firstly, the convective diffusion model was used to describe the process of hazardous gas leakage. Secondly, game theory was introduced to model the confrontation process between the attacking and defending parties in the patrol problem, and the response time of the defenders to a safety incident was correlated with its benefit. Then, a multilinear programming-based GGC algorithm was proposed to solve this game model. Finally, the gains of the game model in this paper were compared with the other two basic methods in the scenarios of three real chemical park case with different sizes. The results show that the model can effectively improve the gains of the defender and reduce the gains of the attacker.",
        "author_keywords": [
            "chemical park",
            "game patrol",
            "game theory",
            "gas leakage",
            "response time"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Computer Science Applications",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Practical Synthetic Human Trajectories Generation Based on Variational Point Processes",
        "authors": "Long Q.",
        "journal": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "doi": "10.1145/3580305.3599888",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85168155355",
        "scopus_id": "85168155355",
        "abstract": "Human trajectories, reflecting people's travel patterns and the range of activities, are crucial for the applications like urban planning and epidemic control. However, the real-world human trajectory data tends to be limited by user privacy or device acquisition issues, leading to its insufficient quality to support the above applications. Hence, generating human trajectory data is a crucial but challenging task, which suffers from the following two critical challenges: 1) how to capture the user distribution in human trajectories (group view), and 2) how to model the complex mobility patterns of each user trajectory (individual view). In this paper, we propose a novel human trajectories generator (named VOLUNTEER), consisting of a user VAE and a trajectory VAE, to address the above challenges. Specifically, in the user VAE, we propose to learn the user distribution with all human trajectories from a group view. In the trajectory VAE, from the individual view, we model the complex mobility patterns by decoupling travel time and dwell time to accurately simulate individual trajectories. Extensive experiments on two real-world datasets show the superiority of our model over the state-of-the-art baselines. Further application analysis in the industrial system also demonstrates the effectiveness of our model.",
        "author_keywords": [
            "generation model",
            "mobility trajectory",
            "temporal point process",
            "variational auto-encoder"
        ],
        "subject_areas": [
            "Software",
            "Information Systems"
        ]
    },
    {
        "title": "Profiling Public Transit Passenger Mobility Using Adversarial Learning",
        "authors": "Li Y.",
        "journal": "ISPRS International Journal of Geo-Information",
        "doi": "10.3390/ijgi12080338",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85169163791",
        "scopus_id": "85169163791",
        "abstract": "It is important to capture passengers’ public transit behavior and their mobility to create profiles, which are critical for analyzing human activities, understanding the social and economic structure of cities, improving public transportation, assisting urban planning, and promoting smart cities. In this paper, we develop a generative adversarial machine learning network to characterize the temporal and spatial mobility behavior of public transit passengers, based on massive smart card data and road network data. The Apriori algorithm is extended with spatio-temporal constraints to extract frequent transit mobility patterns of individual passengers based on a reconstructed personal trip dataset. This individual-level pattern information is used to construct personalized feature vectors. For regular and frequent public transit passengers, we identify similar transit mobility groups using spatio-temporal constraints to construct a group feature vector. We develop a generative adversarial network to embed public transit mobility of passengers. The proposed model’s generator consists of an auto-encoder, which extracts a low-dimensional and compact representation of passenger behavior, and a pre-trained sub-generator containing generalization features of public transit passengers. Shenzhen City is taken as the study area in this paper, and experiments were carried out based on smart card data, road network data, and bus GPS data. Clustering analysis of embedding vector representation and estimation of the top K transit destinations were conducted, verifying that the proposed method can profile passenger transit mobility in a comprehensive and compact manner.",
        "author_keywords": [
            "generative adversarial network",
            "public transit",
            "smart card data",
            "transit mobility embedding"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Prediction of Urban Trees Planting Base on Guided Cellular Automata to Enhance the Connection of Green Infrastructure",
        "authors": "Le Y.",
        "journal": "Land",
        "doi": "10.3390/land12081479",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85168915021",
        "scopus_id": "85168915021",
        "abstract": "Urbanization and climate change pose significant challenges to urban ecosystems, underscoring the necessity for innovative strategies to enhance urban green infrastructure. Tree planting, a crucial aspect of green infrastructure, has been analyzed for optimized positioning using data metrics, priority scoring, and GIS. However, due to the dynamic nature of environmental information, the accuracy of current approaches is compromised. This study aims to present a novel approach integrating deep learning and cellular automata to prioritize urban tree planting locations to anticipate the optimal urban tree network. Initially, GIS data were collated and visualized to identify a suitable study site within London. CycleGAN models were trained using cellular automata outputs and forest mycorrhizal network samples. The comparison validated cellular automata’s applicability, enabled observing spatial feature information in the outputs and guiding the parameter design of our 3D cellular automata system for predicting tree planting locations. The locations were optimized by simulating the network connectivity of urban trees after planting, following the spatial-behavioral pattern of the forest mycorrhizal network. The results highlight the role of robust tree networks in fostering ecological stability and cushioning climate change impacts in urban contexts. The proposed approach addresses existing methodological and practical limitations, providing innovative strategies for optimal tree planting and prioritization of urban green infrastructure, thereby informing sustainable urban planning and design. Our findings illustrate the symbiotic relationship between urban trees and future cities and offer insights into street tree density planning, optimizing the spatial distribution of trees within urban landscapes for sustainable urban development.",
        "author_keywords": [
            "carbon emissions",
            "ecological system",
            "green infrastructure",
            "urban forestry",
            "urban planting"
        ],
        "subject_areas": [
            "Global and Planetary Change",
            "Ecology",
            "Nature and Landscape Conservation"
        ]
    },
    {
        "title": "Ebola optimization with modified DarkNet‐53 model for scene classification and security on Internet of Things in smart cities",
        "authors": "Al-Jabbar M.",
        "journal": "Alexandria Engineering Journal",
        "doi": "10.1016/j.aej.2023.05.049",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85163328105",
        "scopus_id": "85163328105",
        "abstract": "Remote sensing (RS) has developed significantly with the progress of the Internet of Things (IoT) which is allowed the cheap and fast acquisition of data in millions and billions of interrelated devices utilized throughout the whole world. RS scene classifier that purposes for classifying scene types for RS images has wide applications in several domains like urban planning, national defence security, environmental monitoring, and natural hazard detection. State-of-the-art deep learning (DL) successes are performed in a novel wave of RS scene classification applications, but it is the absence of explainability and trustworthiness. An intrusion detection system (IDS) plays a vital role to ensure security in the RS-based IoT environment. In this aspect, this study presents an ebola optimization algorithm with deep learning-based scene classification and intrusion detection (EOADL-SCID) technique on IoT-enabled remote sensing images. The aim of the EOADL-SCID system lies in the effectual scene classification of remote sensing images and intrusion detection. It involves a two-stage procedure. In the initial stage, the EOADL-SCID algorithm involves a modified DarkNet-53 feature extractor, EOA-based hyperparameter tuning, and graph convolution network (GCN) based classification. Next, in the second stage, the intrusion detection process takes place via two subprocesses namely variational autoencoder (VAE) based intrusion detection and skill optimization algorithm (SOA) based parameter tuning. The simulation outcomes of the EOADL-SCID approach are tested utilizing two benchmark databases and the experimental outcomes highlighted the improved performance of the EOADL-SCID algorithm on scene classification and intrusion classification processes.",
        "author_keywords": [
            "Ebola optimization algorithm",
            "Image classification",
            "Internet of Things",
            "Intrusion detection",
            "Remote sensing",
            "Scene classification",
            "Security"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "An advanced deep learning model for maneuver prediction in real-time systems using alarming-based hunting optimization",
        "authors": "Jaiswal S.",
        "journal": "International Journal of Advances in Intelligent Informatics",
        "doi": "10.26555/ijain.v9i2.1048",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85167421193",
        "scopus_id": "85167421193",
        "abstract": "The increasing trend of autonomous driving vehicles in smart cities emphasizes the need for safe travel. However, the presence of obstacles, potholes, and complex road environments, such as poor illumination and occlusion, can cause blurred road images that may impact the accuracy of maneuver prediction in visual perception systems. To address these challenges, a novel ensemble model, named ABHO-based deep CNN-BiLSTM has been proposed for traffic sign detection. This model combines a hybrid convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM) with the alarming-based hunting optimization (ABHO) algorithm to improve maneuver prediction accuracy. Additionally, a modified hough-enabled lane generative adversarial network (ABHO based HoughGAN) has been proposed, which is designed to be robust to blurred images. The ABHO algorithm, inspired by the defending and social characteristics of starling birds and Canis latrans, allows the model to efficiently search for the optimal solution from the available solutions in the search space. The proposed ensemble model has shown significantly improved accuracy, sensitivity, and specificity in maneuver prediction compared to previously utilized methods, with minimal error during lane detection. Overall, the proposed ensemble model addresses the challenges faced by autonomous driving vehicles in complex and obstructed road environments, offering a promising solution for enhancing safety and reliability in smart cities.",
        "author_keywords": [
            "Autonomous vehicle driving",
            "Controller optimization",
            "Deep learning",
            "Lane prediction",
            "Traffic sign detection"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "A Hybrid Approach Based on GAN and CNN-LSTM for Aerial Activity Recognition",
        "authors": "Bousmina A.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs15143626",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85166261380",
        "scopus_id": "85166261380",
        "abstract": "Unmanned aerial vehicles (UAVs), known as drones, have played a significant role in recent years in creating resilient smart cities. UAVs can be used for a wide range of applications, including emergency response, civil protection, search and rescue, and surveillance, thanks to their high mobility and reasonable price. Automatic recognition of human activity in aerial videos captured by drones is critical for various tasks for these applications. However, this is difficult due to many factors specific to aerial views, including camera motion, vibration, low resolution, background clutter, lighting conditions, and variations in view. Although deep learning approaches have demonstrated their effectiveness in a variety of challenging vision tasks, they require either a large number of labelled aerial videos for training or a dataset with balanced classes, both of which can be difficult to obtain. To address these challenges, a hybrid data augmentation method is proposed which combines data transformation with the Wasserstein Generative Adversarial Network (GAN)-based feature augmentation method. In particular, we apply the basic transformation methods to increase the amount of video in the database. A Convolutional Neural Network–Long Short-Term Memory (CNN-LSTM) model is used to learn the spatio-temporal dynamics of actions, then a GAN-based technique is applied to generate synthetic CNN-LSTM features conditioned on action classes which provide a high discriminative spatio-temporal features. We tested our model on the YouTube aerial database, demonstrating encouraging results that surpass those of previous state-of-the-art works, including an accuracy rate of 97.83%.",
        "author_keywords": [
            "CNN-LSTM",
            "data augmentation",
            "deep learning",
            "human action recognition",
            "UAVs",
            "WGAN-GP"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Building Detection in High-Resolution Remote Sensing Images by Enhancing Superpixel Segmentation and Classification Using Deep Learning Approaches",
        "authors": "Benchabana A.",
        "journal": "Buildings",
        "doi": "10.3390/buildings13071649",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85166236072",
        "scopus_id": "85166236072",
        "abstract": "Accurate building detection is a critical task in urban development and digital city mapping. However, current building detection models for high-resolution remote sensing images are still facing challenges due to complex object characteristics and similarities in appearance. To address this issue, this paper proposes a novel algorithm for building detection based on in-depth feature extraction and classification of adaptive superpixel shredding. The proposed approach consists of four main steps: image segmentation into homogeneous superpixels using a modified Simple Linear Iterative Clustering (SLIC), in-depth feature extraction using an variational auto-encoder (VAE) scale on the superpixels for training and testing data collection, identification of four classes (buildings, roads, trees, and shadows) using extracted feature data as input to an Convolutional Neural Network (CNN), and extraction of building shapes through regional growth and morphological operations. The proposed approach offers more stability in identifying buildings with unclear boundaries, eliminating the requirement for extensive prior segmentation. It has been tested on two datasets of high-resolution aerial images from the New Zealand region, demonstrating superior accuracy compared to previous works with an average F1 score of 98.83%. The proposed approach shows potential for fast and accurate urban monitoring and city planning, particularly in urban areas.",
        "author_keywords": [
            "arial imagery",
            "building detection",
            "CNN",
            "superpixels segmentation",
            "VAE"
        ],
        "subject_areas": [
            "Architecture",
            "Civil and Structural Engineering",
            "Building and Construction"
        ]
    },
    {
        "title": "MS-AGAN: Road Extraction via Multi-Scale Information Fusion and Asymmetric Generative Adversarial Networks from High-Resolution Remote Sensing Images under Complex Backgrounds",
        "authors": "Lin S.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs15133367",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85164919149",
        "scopus_id": "85164919149",
        "abstract": "Extracting roads from remote sensing images is of significant importance for automatic road network updating, urban planning, and construction. However, various factors in complex scenes (e.g., high vegetation coverage occlusions) may lead to fragmentation in the extracted road networks and also affect the robustness of road extraction methods. This study proposes a multi-scale road extraction method with asymmetric generative adversarial learning (MS-AGAN). First, we design an asymmetric GAN with a multi-scale feature encoder to better utilize the context information in high-resolution remote sensing images (HRSIs). Atrous spatial pyramid pooling (ASPP) and feature fusion are integrated into the asymmetric encoder–decoder structure to avoid feature redundancy caused by multi-level cascading operations and enhance the generator network’s ability to extract fine-grained road information at the pixel level. Second, to maintain road connectivity, topologic features are considered in the pixel segmentation process. A linear structural similarity loss ((Formula presented.)) is introduced into the loss function of MS-AGAN, which guides MS-AGAN to generate more accurate segmentation results. Finally, to fairly evaluate the performance of deep models under complex backgrounds, the Bayesian error rate (BER) is introduced into the field of road extraction for the first time. Experiments are conducted via Gaofen-2 (GF-2) high-resolution remote sensing images with high vegetation coverage in the Daxing District of Beijing, China, and the public DeepGlobe dataset. The performance of MS-AGAN is compared with a list of advanced models, including RCFSNet, CoANet, UNet, DeepLabV3+, and DiResNet. The final results show that (1) with respect to road extraction performance, the Recall, F1, and IoU values of MS-AGAN on the Daxing dataset are 2.17%, 0.04%, and 2.63% higher than the baselines. On DeepGlobe, the Recall, F1, and IoU of MS-AGAN improve by 1.12%, 0.42%, and 0.25%, respectively. (2) On road connectivity, the Conn index of MS-AGAN from the Daxing dataset is 46.39%, with an improvement of 0.62% over the baselines, and the Conn index of MS-AGAN on DeepGlobe is 70.08%, holding an improvement of 1.73% over CoANet. The quantitative and qualitative analyses both demonstrate the superiority of MS-AGAN in preserving road connectivity. (3) In particular, the BER of MS-AGAN is 20.86% over the Daxing dataset with a 0.22% decrease compared to the best baselines and 11.77% on DeepGlobe with a 0.85% decrease compared to the best baselines. The proposed MS-AGAN provides an efficient, cost-effective, and reliable method for the dynamic updating of road networks via HRSIs.",
        "author_keywords": [
            "generative adversarial network",
            "remote sensing",
            "road extraction",
            "satellite image analysis"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Development of an AI advisor for conceptual land use planning",
        "authors": "Park C.",
        "journal": "Cities",
        "doi": "10.1016/j.cities.2023.104371",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159355666",
        "scopus_id": "85159355666",
        "abstract": "To efficiently manage a time-consuming and expensive process in traditional urban planning, we aim to develop an artificial intelligence (AI) advisor that assists nonprofessionals participating in the urban planning process by using a generative adversarial network (GAN). This study presents the process of developing the AI model, which suggests appropriate land use plans for user-targeted sites and urban density scenarios. We first create an image dataset that embeds land use, floor area ratio (FAR), and building cover ratio (BCR) information in the RGB channel. Then, an algorithm is developed for establishing an optimized training set with 1000 images and methods for validating the obtained results from both quantitative and visual perspectives. We set up a pilot test to generate three urban density scenarios in Sewoon-Sangga district by constructing urban data-encoded image datasets of Seoul. The pilot test results reveal that our proposed model successfully suggests appropriate land use plans according to the three scenarios. Based on the pilot test, the AI advisor improves its output, training performance, and usability by reflecting block morphology with the Hamming distance and accepting user-designed road patterns. We expect that the novel approach developed in our study will contribute to research on AI-based urban planning.",
        "author_keywords": [
            "Artificial intelligence",
            "Computer-aided design",
            "Generative adversarial network",
            "Geographical information system (GIS)",
            "Urban informatics",
            "Urban planning"
        ],
        "subject_areas": [
            "Development",
            "Sociology and Political Science",
            "Urban Studies",
            "Tourism, Leisure and Hospitality Management"
        ]
    },
    {
        "title": "Human-Instructed Deep Hierarchical Generative Learning for Automated Urban Planning",
        "authors": "Wang D.",
        "journal": "Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",
        "doi": "10.1609/aaai.v37i4.25589",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85167871952",
        "scopus_id": "85167871952",
        "abstract": "The essential task of urban planning is to generate the optimal land-use configuration of a target area. However, traditional urban planning is time-consuming and labor-intensive. Deep generative learning gives us hope that we can automate this planning process and come up with the ideal urban plans. While remarkable achievements have been obtained, they have exhibited limitations in lacking awareness of: 1) the hierarchical dependencies between functional zones and spatial grids; 2) the peer dependencies among functional zones; and 3) human regulations to ensure the usability of generated configurations. To address these limitations, we develop a novel human-instructed deep hierarchical generative model. We rethink the urban planning generative task from a unique functionality perspective, where we summarize planning requirements into different functionality projections for better urban plan generation. To this end, we develop a three-stage generation process from a target area to zones to grids. The first stage is to label the grids of a target area with latent functionalities to discover functional zones. The second stage is to perceive the planning requirements to form urban functionality projections. We propose a novel module: functionalizer to project the embedding of human instructions and geospatial contexts to the zone-level plan to obtain such projections. Each projection includes the information of land-use portfolios and the structural dependencies across spatial grids in terms of a specific urban function. The third stage is to leverage multi-attentions to model the zone-zone peer dependencies of the functionality projections to generate grid-level land-use configurations. Finally, we present extensive experiments to demonstrate the effectiveness of our framework.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Continuous Trajectory Generation Based on Two-Stage GAN",
        "authors": "Jiang W.",
        "journal": "Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",
        "doi": "10.1609/aaai.v37i4.25557",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85167871618",
        "scopus_id": "85167871618",
        "abstract": "Simulating the human mobility and generating large-scale trajectories are of great use in many real-world applications, such as urban planning, epidemic spreading analysis, and geographic privacy protect. Although many previous works have studied the problem of trajectory generation, the continuity of the generated trajectories has been neglected, which makes these methods useless for practical urban simulation scenarios. To solve this problem, we propose a novel two-stage generative adversarial framework to generate the continuous trajectory on the road network, namely TS-TrajGen, which efficiently integrates prior domain knowledge of human mobility with model-free learning paradigm. Specifically, we build the generator under the human mobility hypothesis of the A* algorithm to learn the human mobility behavior. For the discriminator, we combine the sequential reward with the mobility yaw reward to enhance the effectiveness of the generator. Finally, we propose a novel two-stage generation process to overcome the weak point of the existing stochastic generation process. Extensive experiments on two real-world datasets and two case studies demonstrate that our framework yields significant improvements over the state-of-the-art methods.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Enhancing haze removal and super-resolution in real-world images: A cycle generative adversarial network-based approach for synthesizing paired hazy and clear images",
        "authors": "Su X.",
        "journal": "Optical Engineering",
        "doi": "10.1117/1.OE.62.6.063101",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85164214820",
        "scopus_id": "85164214820",
        "abstract": "Haze significantly impacts various fields, such as autonomous driving, smart cities, and security monitoring. Deep learning has been proven effective in removing haze from images. However, obtaining pixel-aligned hazy and clear paired images in the real world can be challenging. Therefore, synthesized hazed images are often used for training deep networks. These images are typically generated based on parameters such as depth information and atmospheric scattering coefficient. However, this approach may cause the loss of important haze details, leading to color distortion or incomplete dehazed images. To address this problem, this paper proposes a method for synthesizing hazed images using a cycle generative adversarial network (CycleGAN). The CycleGAN is trained with unpaired hazy and clear images to learn the features of the hazy images. Then, the real haze features are added to clear images using the trained CycleGAN, resulting in well-pixel-aligned synthesized hazy and clear paired images that can be used for dehaze training. The results demonstrate that the dataset synthesized using this method efficiently solves the problem associated with traditional synthesized datasets. Furthermore, the dehazed images are restored using a super-resolution algorithm, enabling the obtainment of high-resolution clear images. This method has broadened the applications of deep learning in haze removal, particularly highlighting its potential in the fields of autonomous driving and smart cities.",
        "author_keywords": [
            "cycle generative adversarial network",
            "image dehazing",
            "image sharpness enhancement"
        ],
        "subject_areas": [
            "Atomic and Molecular Physics, and Optics",
            "Engineering (all)"
        ]
    },
    {
        "title": "Automatic Face Mask Identification in Saudi Smart Cities: Using Technology to Prevent the Spread of COVID-19",
        "authors": "Alsalamah M.S.I.",
        "journal": "Information Sciences Letters",
        "doi": "10.18576/isl/120617",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85160784106",
        "scopus_id": "85160784106",
        "abstract": "The novel coronavirus that triggered the COVID-19 outburst is still active around the globe. By now, COVID-19 has affected practically every facet of progress, most importantly, it has shaken the healthcare system like never before. At its peak, it forced Governments throughout the world into lockdowns to limit the reach of the epidemic. Based on early advisories of the World Health Organization (WHO), the only method of safeguarding oneself from being infected was to wear a face mask. Even today, with fewer cases being reported, masking oneself remains the single most effective and cheap means of prevention. As urban areas continue to grow, effective city management is essential for mitigating the increase of the deadly COVID-19 disease. The success of smart cities depends on significant upgrades to public transportation, highways, companies, homes, and municipal streets. There is room for improvement in the public bus transportation system now in place, and one of those improvements would be to use artificial intelligence. To determine if the person is wearing a face mask, you need an autonomous mask detection and alert system. Therefore, this study introduced a deep learning-based design that combines the attention-based generative adversarial network (ABGAN) with the multi-objective interactive honeybee mating optimization (MOIHBMO) approach to create an automated face mask recognition system. A set of 1386 images has been used to create a real-time dataset. This database contains 690 pictures without face masks and 686 images with them. The suggested algorithm ABGAN-MOIHBMO is compared to other traditional methods for detection of face masks, such as DL, AI, and DNN. The performance indicators used are error rate, inference speed, precision, recall, accuracy, and over fitting assessments. The results demonstrate that the proposed ABGAN-MOIHBMO outperforms the existing methodologies. It provides 96% of precision, 86% of recall, 93% for the f1 score, which are higher/better than the other, traditional methods. The error rate in ABGAN-MOIHBMO is a low 1.1%, which is lower other approaches. To predict and underline the significance of face mask use, the face mask detection technique may be employed in the future at Saudi airports, shopping centers, and other congested locations. On a larger platform, our research will be an effective instrument in helping many nations throughout the globe combat the rapid spread of this contagious illness.",
        "author_keywords": [
            "ABGAN",
            "COVID-19",
            "MOIHBMO algorithm",
            "smart cities",
            "transportation system"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Library and Information Sciences",
            "Applied Mathematics"
        ]
    },
    {
        "title": "Advancing justice in a city’s complex systems using designs enabled by space",
        "authors": "Mayrhofer-Hufnagl I.",
        "journal": "International Journal of Architectural Computing",
        "doi": "10.1177/14780771231168223",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85152386011",
        "scopus_id": "85152386011",
        "abstract": "Understanding the importance of data is crucial for realizing the full potential of AI in architectural design. Satellite images are extremely numerous, continuous, high resolution, and accessible, allowing nuanced experimentation through dataset curation. Combining deep learning with remote-sensing technologies, this study poses the following questions. Do newly available datasets uncover ideas about the city previously hidden because urban theory is predominantly Eurocentric? Do extensive and continuous datasets promise a more refined examination of datasets’ effects on outcomes? Generative adversarial networks can endlessly generate new designs based on a curated dataset, but architectural evaluation has been questionable. We employ quantitative and qualitative assessment metrics to investigate human collaboration with AI, producing results that contribute to understanding AI-based urban design models and the significance of dataset curation.",
        "author_keywords": [
            "feature visualization",
            "generative adversarial networks",
            "generative deep learning",
            "remote sensing",
            "urban design"
        ],
        "subject_areas": [
            "Building and Construction",
            "Computer Science Applications",
            "Computer Graphics and Computer-Aided Design"
        ]
    },
    {
        "title": "Spatial adoption forecast methodology for photovoltaic systems throughout a city",
        "authors": "Jones C.B.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2023.104430",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85150276115",
        "scopus_id": "85150276115",
        "abstract": "This work predicts future adoptions of distributed photovoltaic (PV) systems throughout an entire city using open-source geographic information system (GIS) data. The approach combines census income and building zoning data into a single geographic district map where adoptions are likely to be consistent from year to year. Existing PV system locations for each year are input into a data-driven model for each of the combined income and building type districts to predict future PV installations. In this work, two algorithms were tested as part of the methodology: linear least-squares regression and the Bass Diffusion model. Using a linear regression algorithm, in this paper's test city (Santa Fe, New Mexico, U.S.A), the percentage of loads with PV was predicted to increase from 5.2% in 2020 to 18% in 2050. In the same test city, the Bass Diffusion model predicted and increase in PV to be about 27% of the all the buildings by 2050. This simple but detailed approach provides electric utilities with a useful tool for planning assessments or municipalities can use the results to inform policy decisions. The approach differs from existing literature in that it offers a data-driven prediction methodology that is influenced by past trends and also consider local building types and economics.",
        "author_keywords": [
            "Adoptions",
            "Data-driven",
            "Forecast",
            "Geospatial analysis",
            "Integration",
            "Permits",
            "Photovoltaic",
            "Zoning districts"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Data generative machine learning model for the assessment of outdoor thermal and wind comfort in a northern urban environment",
        "authors": "Eslamirad N.",
        "journal": "Frontiers of Architectural Research",
        "doi": "10.1016/j.foar.2022.12.001",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85147377825",
        "scopus_id": "85147377825",
        "abstract": "Predicting comfort levels in cities is challenging due to the many metric assessment. To overcome these challenges, much research is being done in the computing community to develop methods capable of generating outdoor comfort data. Machine Learning (ML) provides many opportunities to discover patterns in large datasets such as urban data. This paper proposes a data-driven approach to build a predictive and data-generative model to assess outdoor thermal comfort. The model benefits from the results of a study, which analyses Computational Fluid Dynamics (CFD) urban simulation to determine the thermal and wind comfort in Tallinn, Estonia. The ML model was built based on classification, and it uses an opaque ML model. The results were evaluated by applying different metrics and show us that the approach allows the implementation of a data-generative ML model to generate reliable data on outdoor comfort that can be used by urban stakeholders, planners, and researchers.",
        "author_keywords": [
            "Data generative model",
            "Machine learning approach",
            "Outdoor thermal and wind comfort",
            "Predictive model",
            "Urban climate"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Archeology",
            "Urban Studies"
        ]
    },
    {
        "title": "A Novel Unsupervised Video Anomaly Detection Framework Based on Optical Flow Reconstruction and Erased Frame Prediction",
        "authors": "Huang H.",
        "journal": "Sensors",
        "doi": "10.3390/s23104828",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85160421980",
        "scopus_id": "85160421980",
        "abstract": "Reconstruction-based and prediction-based approaches are widely used for video anomaly detection (VAD) in smart city surveillance applications. However, neither of these approaches can effectively utilize the rich contextual information that exists in videos, which makes it difficult to accurately perceive anomalous activities. In this paper, we exploit the idea of a training model based on the “Cloze Test” strategy in natural language processing (NLP) and introduce a novel unsupervised learning framework to encode both motion and appearance information at an object level. Specifically, to store the normal modes of video activity reconstructions, we first design an optical stream memory network with skip connections. Secondly, we build a space–time cube (STC) for use as the basic processing unit of the model and erase a patch in the STC to form the frame to be reconstructed. This enables a so-called ”incomplete event (IE)” to be completed. On this basis, a conditional autoencoder is utilized to capture the high correspondence between optical flow and STC. The model predicts erased patches in IEs based on the context of the front and back frames. Finally, we employ a generating adversarial network (GAN)-based training method to improve the performance of VAD. By distinguishing the predicted erased optical flow and erased video frame, the anomaly detection results are shown to be more reliable with our proposed method which can help reconstruct the original video in IE. Comparative experiments conducted on the benchmark UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets demonstrate AUROC scores reaching 97.7%, 89.7%, and 75.8%, respectively.",
        "author_keywords": [
            "incomplete event",
            "optical flow",
            "video anomaly detection"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Information Systems",
            "Atomic and Molecular Physics, and Optics",
            "Biochemistry",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Review of Research on Vehicle Re-identification Methods with Unsupervised Learning",
        "authors": "Xu Y.",
        "journal": "Journal of Frontiers of Computer Science and Technology",
        "doi": "10.3778/j.issn.1673-9418.2209100",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85160315217",
        "scopus_id": "85160315217",
        "abstract": "As one of the key technologies of intelligent transportation systems, vehicle re-identification (Re-ID) aims to retrieve the same vehicle from different monitoring scenes and plays an important role in building a safe and smart city. With the continuous development of computer vision, the Re-ID method of using supervised learning suffers from the problems of strong reliance on manual annotation in the training process and weak scene generalization ability, so unsupervised learning of vehicle Re-ID gradually becomes the focus of research in recent years. Firstly, the present mainstream vehicle Re-ID datasets and the commonly used model evaluation metrics are introduced. Then, latest unsupervised learning-based vehicle Re-ID methods are grouped into two categories: generative adversarial networks and clustering algorithms according to the current research ideas. Starting from the problems of domain deviation, cross-view deviation and insufficient information of data samples, the former is further divided into three categories of style transfer, multi-view generation, and data augmentation. For the labeling pro-blem, the latter can be divided into two categories of pseudo-labeled unsupervised domain adaptation and no label information required. With problem solving as the starting point, the fundamentals, advantages and disadvantages, and performance results of each type of method on mainstream datasets are summarized. Finally, the challenges faced by the current unsupervised learning for vehicle Re-ID are analyzed, and the future work in this research direction is prospected.",
        "author_keywords": [
            "clustering",
            "generative adversarial networks",
            "intelligent transportation",
            "unsupervised learning",
            "vehicle re-identification"
        ],
        "subject_areas": [
            "Computer Science (all)"
        ]
    },
    {
        "title": "Market behavior-oriented deep learning-based secure data analysis in smart cities",
        "authors": "Lv Q.",
        "journal": "Computers and Electrical Engineering",
        "doi": "10.1016/j.compeleceng.2023.108722",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85152597464",
        "scopus_id": "85152597464",
        "abstract": "The construction of Smart Cities is inseparable from the healthy operation of markets. Reasonable data analysis can provide a crucial foundation for the development of market behavior by considering the enormous amount of data generated by a market economy. To this end, we propose enhanced cluster generative adversarial networks (eClusterGAN) to achieve latent space clustering. However, data storage security is crucial. Moreover, we suggest a GAN-based network intrusion detection system (GAN–NIDS) that uses adversarial learning to assist the generator in learning the spatial distribution of normal network flows. The simulation results showed that the proposed eClusterGAN and GAN–NIDS outperformed the benchmarks in terms of clustering accuracy, running time, precision, recall, and F1, which can support researchers in studying economic data trends. The construction of Smart Cities can effectively ensure healthy market development by discovering and disseminating the potential value of market economic data.",
        "author_keywords": [
            "Clustering",
            "Deep learning",
            "Market economy",
            "Secure data analysis",
            "Smart cities"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Computer Science (all)",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "CSCAD: Correlation Structure-Based Collective Anomaly Detection in Complex System",
        "authors": "Qin H.",
        "journal": "IEEE Transactions on Knowledge and Data Engineering",
        "doi": "10.1109/TKDE.2022.3154166",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127025695",
        "scopus_id": "85127025695",
        "abstract": "Detecting anomalies in large complex systems is a critical and challenging task. The difficulties arise from several aspects. First, collecting ground truth labels or prior knowledge for anomalies is hard in real-world systems, which often lead to limited or no anomaly labels in the dataset. Second, anomalies in large systems usually occur in a collective manner due to the underlying dependency structure among devices or sensors. Lastly, real-time anomaly detection for high-dimensional data requires efficient algorithms that are capable of handling different types of data (i.e. continuous and discrete). We propose a correlation structure-based collective anomaly detection (CSCAD) model for high-dimensional anomaly detection problem in large systems, which is also generalizable to semi-supervised or supervised settings. Our framework utilize graph convolutional network combining a variational autoencoder to jointly exploit the feature space correlation and reconstruction deficiency of samples to perform anomaly detection. We propose an extended mutual information (EMI) metric to mine the internal correlation structure among different data features, which enhances the data reconstruction capability of CSCAD. The reconstruction loss and latent standard deviation vector of a sample obtained from reconstruction network can be perceived as two natural anomalous degree measures. An anomaly discriminating network can then be trained using low anomalous degree samples as positive samples, and high anomalous degree samples as negative samples. Experimental results on five public datasets demonstrate that our approach consistently outperforms all the competing baselines.",
        "author_keywords": [
            "Anomaly detection",
            "complex system",
            "correlation mining",
            "unsupervised learning",
            "urban computing",
            "variational autoencoder"
        ],
        "subject_areas": [
            "Information Systems",
            "Computer Science Applications",
            "Computational Theory and Mathematics"
        ]
    },
    {
        "title": "Generative Adversarial Networks (GAN) and HDFS-Based Realtime Traffic Forecasting System Using CCTV Surveillance",
        "authors": "Devadhas Sujakumari P.",
        "journal": "Symmetry",
        "doi": "10.3390/sym15040779",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85156091015",
        "scopus_id": "85156091015",
        "abstract": "The most crucial component of any smart city traffic management system is traffic flow prediction. It can assist a driver in selecting the most efficient route to their destination. The digitalization of closed-circuit television (CCTV) systems has resulted in more effective and capable surveillance imaging systems for security applications. The number of automobiles on the world’s highways has steadily increased in recent decades. However, road capacity has not developed at the same rate, resulting in significantly increasing congestion. The model learning mechanism cannot be guided or improved by prior domain knowledge of real-world problems. In reality, symmetrical features are common in many real-world research objects. To mitigate this severe situation, the researchers chose adaptive traffic management to make intelligent and efficient use of the current infrastructure. Data grow exponentially and become a complex item that must be managed. Unstructured data are a subset of big data that are difficult to process and have volatile properties. CCTV cameras are used in traffic management to monitor a specific point on the roadway. CCTV generates unstructured data in the form of images and videos. Because of the data’s intricacy, these data are challenging to process. This study proposes using big data analytics to transform real-time unstructured data from CCTV into information that can be shown on a web dashboard. As a Hadoop-based architectural stack that can serve as the ICT backbone for managing unstructured data efficiently, the Hadoop Distributed File System (HDFS) stores several sorts of data using the Hadoop file storage system, a high-performance integrated virtual environment (HIVE) tables, and non-relational storage. Traditional computer vision algorithms are incapable of processing such massive amounts of visual data collected in real-time. However, the inferiority of traffic data and the quality of unit information are always symmetrical phenomena. As a result, there is a need for big data analytics with machine learning, which entails processing and analyzing vast amounts of visual data, such as photographs or videos, to uncover semantic patterns that may be interpreted. As a result, smart cities require a more accurate traffic flow prediction system. In comparison to other recent methods applied to the dataset, the proposed method achieved the highest accuracy of 98.21%. In this study, we look at the construction of a secure CCTV strategy that predicts traffic from CCTV surveillance using real-time traffic prediction analysis with generative adversarial networks (GAN) and HDFS.",
        "author_keywords": [
            "generative adversarial networks (GAN)",
            "Hadoop Distributed File System (HDFS)",
            "image synthesis",
            "Intelligent Transportation System (ITS)",
            "traffic management system"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Chemistry (miscellaneous)",
            "Mathematics (all)",
            "Physics and Astronomy (miscellaneous)"
        ]
    },
    {
        "title": "Semi-Supervised Land Cover Classification of Remote Sensing Imagery Using CycleGAN and EfficientNet",
        "authors": "Kwak T.",
        "journal": "KSCE Journal of Civil Engineering",
        "doi": "10.1007/s12205-023-2285-0",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85149238913",
        "scopus_id": "85149238913",
        "abstract": "Image classification of very high resolution (VHR) images is a fundamental task in the remote sensing domain for various applications, such as land cover mapping, vegetation mapping, and urban planning. Recently, deep learning-based semantic segmentation networks demonstrated the promising performance for pixel-level image classification. However, deep learning-based approaches are generally limited by the requirement of a sufficient amount of labeled data to obtain stable accuracy, and acquiring reference labels of remotely-sensed VHR images is very labor-extensive and expensive. Hence, this paper applied a semi-supervised learning-based CycleGAN and EfficientNet for VHR remote sensing image classification to overcome this problem. The proposed method achieved the highest accuracy than the other benchmarks. The largest increase in accuracy was observed in a test site containing complex objects due to the regularization effect of the semi-supervised method using unlabeled data. Moreover, results indicated that a relatively sufficient amount of unlabeled data compared with labeled data are required to increase the classification accuracy by controlling the amount of labeled and unlabeled data. Finally, we verified that the semi-supervised method returned significantly improved results irrespective of the three classification network structures, displaying the applicability of the method for semi-supervised image classification on remotely-sensed VHR images.",
        "author_keywords": [
            "CycleGAN",
            "EfficientNet",
            "Land cover classification",
            "Remote sensing",
            "Semi-supervised learning",
            "VHR image classification"
        ],
        "subject_areas": [
            "Civil and Structural Engineering"
        ]
    },
    {
        "title": "Data-driven distributionally robust scheduling of community integrated energy systems with uncertain renewable generations considering integrated demand response",
        "authors": "Li Y.",
        "journal": "Applied Energy",
        "doi": "10.1016/j.apenergy.2023.120749",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85147586430",
        "scopus_id": "85147586430",
        "abstract": "A community integrated energy system (CIES) is an important carrier of the energy internet and smart city in geographical and functional terms. Its emergence provides a new solution to the problems of energy utilization and environmental pollution. To coordinate the integrated demand response and uncertainty of renewable energy generation (RGs), a data-driven two-stage distributionally robust optimization (DRO) model is constructed. A comprehensive norm consisting of the 1-norm and ∞-norm is used as the uncertainty probability distribution information set, thereby avoiding complex probability density information. To address multiple uncertainties of RGs, a generative adversarial network based on the Wasserstein distance with gradient penalty is proposed to generate RG scenarios, which has wide applicability. To further tap the potential of the demand response, we take into account the ambiguity of human thermal comfort and the thermal inertia of buildings. Thus, an integrated demand response mechanism is developed that effectively promotes the consumption of renewable energy. The proposed method is simulated in an actual CIES in North China. In comparison with traditional stochastic programming and robust optimization, it is verified that the proposed DRO model properly balances the relationship between economical operation and robustness while exhibiting stronger adaptability. Furthermore, our approach outperforms other commonly used DRO methods with better operational economy, lower renewable power curtailment rate, and higher computational efficiency.",
        "author_keywords": [
            "Community integrated energy system",
            "Distributionally robust optimization",
            "Integrated demand response",
            "Renewable energy",
            "Scenario generation",
            "Uncertainty modeling"
        ],
        "subject_areas": [
            "Building and Construction",
            "Renewable Energy, Sustainability and the Environment",
            "Mechanical Engineering",
            "Energy (all)",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Automated urban planning aware spatial hierarchies and human instructions",
        "authors": "Wang D.",
        "journal": "Knowledge and Information Systems",
        "doi": "10.1007/s10115-022-01801-6",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85142934026",
        "scopus_id": "85142934026",
        "abstract": "Traditional urban planning demands urban experts to spend much time producing an optimal urban plan under many architectural constraints. The remarkable imaginative ability of deep generative learning provides hope for renovating this domain. Existing works are constrained by: (1) neglecting human requirements; (2) omitting spatial hierarchies, and (3) lacking urban plan samples. We propose a novel, deep human-instructed urban planner to fill these gaps and implement two practical frameworks. In the preliminary version, we formulate the task into an encoder–decoder paradigm. The encoder is to learn the information distribution of surrounding contexts, human instructions, and land-use configuration. The decoder is to reconstruct the land-use configuration and the associated urban functional zones. Although it has achieved good results, the generation performance is still unstable due to the complex optimization directions of the decoder. Thus, we propose a cascading deep generative adversarial network (GAN) in this paper, inspired by the workflow of urban experts. The first GAN is to build urban functional zones based on human instructions and surrounding contexts. The second GAN will produce the land-use configuration by considering the built urban functional zones. Finally, we conducted extensive experiments and case studies to validate the effectiveness and superiority of our work.",
        "author_keywords": [
            "Deep generative adversarial network",
            "Deep variational autoencoder",
            "Representation learning",
            "Urban planning"
        ],
        "subject_areas": [
            "Software",
            "Information Systems",
            "Human-Computer Interaction",
            "Hardware and Architecture",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Identifying correlations between depression and urban morphology through generative deep learning",
        "authors": "Newton D.W.",
        "journal": "International Journal of Architectural Computing",
        "doi": "10.1177/14780771221089885",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85130877160",
        "scopus_id": "85130877160",
        "abstract": "Mental health disorders, such as depression, have been estimated to account for the largest proportion of global disease burden. Existing research has established significant correlations between the built environment and mental health. This research, however, has relied on traditional statistical methods that are not amenable to working with large remote sensing image-based datasets. This research addresses this challenge and contributes new knowledge and a novel method for using generative deep learning for urban analysis and synthesis tasks involving mental health. The research specifically investigates three mental state measures: depression, anxiety, and the perception of safety. The experimental results demonstrate the efficacy of the process—providing a new method to find correlational signals, while providing insights on the correlation between specific urban design features and the incidence of depression.",
        "author_keywords": [
            "depression",
            "generative adversarial network",
            "generative deep learning",
            "urban planning"
        ],
        "subject_areas": [
            "Building and Construction",
            "Computer Science Applications",
            "Computer Graphics and Computer-Aided Design"
        ]
    },
    {
        "title": "Positivity and difference of influence of built environment around urban park on building energy consumption",
        "authors": "Wang P.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2022.104321",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85143155554",
        "scopus_id": "85143155554",
        "abstract": "Built environment can improve thermal comfort and reduce building energy consumption. Among these, urban parks are considered as a major strategy for reducing building energy consumption. Understanding the relationship of built environment around the urban park on building energy consumption is thus critical. This study established grid groups with different built environment layouts around urban park from the perspective of 3D building characteristics, land cover and road network. Then the correlation relationship between built environment and building energy consumption was examined by using the spatial regressive model, and the positivity and difference of building environment effect on building energy consumption were analyzed and compared emphatically. The results showed that water body and road intersection can weaken the positive effect of impervious surface area (ISA) in compact high-rise building area, and water body can promote the negative effect of form factor (S/V) in sparse high-rise building area. Additionally, we found that the sparse high-rise buildings were conducive to the spread of cold air in the park compared to compact high-rise, which promoted the negative effects of S/V. Therefore, the built environment should be incorporated into urban planning to reduce building energy consumption.",
        "author_keywords": [
            "Building energy consumption",
            "Spatial autoregressive model",
            "Surrounding built environment",
            "Urban park"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Automated Urban Planning for Reimagining City Configuration via Adversarial Learning: Quantification, Generation, and Evaluation",
        "authors": "Wang D.",
        "journal": "ACM Transactions on Spatial Algorithms and Systems",
        "doi": "10.1145/3524302",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85143601056",
        "scopus_id": "85143601056",
        "abstract": "Urban planning refers to the efforts of designing land-use configurations given a region. However, to obtain effective urban plans, urban experts have to spend much time and effort analyzing sophisticated planning constraints based on domain knowledge and personal experiences. To alleviate the heavy burden of them and produce consistent urban plans, we want to ask that can AI accelerate the urban planning process, so that human planners only adjust generated configurations for specific needs? The recent advance of deep generative models provides a possible answer, which inspires us to automate urban planning from an adversarial learning perspective. However, three major challenges arise: (1) how to define a quantitative land-use configuration? (2) how to automate configuration planning? (3) how to evaluate the quality of a generated configuration? In this article, we systematically address the three challenges. Specifically, (1) We define a land-use configuration as a longitude-latitude-channel tensor. (2) We formulate the automated urban planning problem into a task of deep generative learning. The objective is to generate a configuration tensor given the surrounding contexts of a target region. In particular, we first construct spatial graphs using geographic and human mobility data crawled from websites to learn graph representations. We then combine each target area and its surrounding context representations as a tuple, and categorize all tuples into positive (well-planned areas) and negative samples (poorly-planned areas). Next, we develop an adversarial learning framework, in which a generator takes the surrounding context representations as input to generate a land-use configuration, and a discriminator learns to distinguish between positive and negative samples. (3) We provide quantitative evaluation metrics and conduct extensive experiments to demonstrate the effectiveness of our framework.",
        "author_keywords": [
            "Generative adversarial networks",
            "Graph neural networks",
            "Representation learning",
            "Urban planning"
        ],
        "subject_areas": [
            "Signal Processing",
            "Information Systems",
            "Modeling and Simulation",
            "Computer Science Applications",
            "Geometry and Topology",
            "Discrete Mathematics and Combinatorics"
        ]
    },
    {
        "title": "PREDICTING AMENITIES DISTRIBUTIONS FOR WORKERS FROM THE BUILT ENVIRONMENT BASED ON MACHINE LEARNING",
        "authors": "Wan H.",
        "journal": "Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia",
        "doi": "10.52842/conf.caadria.2023.1.019",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85197164408",
        "scopus_id": "85197164408",
        "abstract": "The working population has increased in cities with urbanization. Providing a supportive built environment with reasonable amenities distribution for them is becoming more important. Previous GIS-based approaches to urban planning for this issue tend to be subjective with high labour costs. This paper uses the generative adversarial network (GAN) to explore the relationship between amenities distributions and urban morphology, thus effectively predicting and visualizing the ideal amenities distributions in fastgrowing cities based on the condition of well-developed megacities. In this research, we take Shanghai, one of the global cities in China with a big labour market, as the research sample. First, we use the Point of Interest (POI) data to draw the heatmap of urban amenities that support workers’ daily life and collect the corresponding city maps. Then, we cut them into hundreds of image pairs as the training set and train a GAN model for predicting the future amenities distributions in other cities. To implement the model, we further collect the city maps of Jiaxing, one of the second-tier cities near Shanghai, as the testing set. Results show that our trained model can accurately predict amenities distributions for its future. The GAN-based prediction could effectively support detailed urban planning.",
        "author_keywords": [
            "Amenities Distributions",
            "Big Data Analysis",
            "Machine Learning",
            "Point of interest",
            "Urban Planning"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Computer Graphics and Computer-Aided Design",
            "Materials Science (miscellaneous)",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Cloud Cover Removal from Remote Sensing Data using GANs Based on Attention Mechanism",
        "authors": "Siva Jyothi Natha Reddy B.",
        "journal": "Proceedings of the IEEE International Conference Image Information Processing",
        "doi": "10.1109/ICIIP61524.2023.10537777",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195239815",
        "scopus_id": "85195239815",
        "abstract": "Cloud interference is a significant challenge in remote sensing applications, impacting the quality and reliability of data used for environmental analysis, disaster monitoring, and urban planning. In this study, we present an innovative approach to remove clouds from remote sensing data by employing Generative Adversarial Networks (GANs) with an integrated attention mechanism. Our method is designed to effectively restore regions obscured by clouds while preserving the integrity of the remaining image. We introduce a specialized architecture called U-net based Attention GAN (UAGAN) to address cloud cover issues. In this architecture, the generator network utilizes attention mechanisms to identify and rectify cloud-affected areas. The attention mechanism dynamically emphasizes relevant spatial regions during cloud removal, enhancing the precision of the restoration process. To evaluate our approach, we conducted experiments using the RICE dataset and trained our UAGAN model. Our method's effectiveness was assessed using quantitative metrics, including the Structural Similarity Index (SSIM), Root Mean Squared Error (RMSE), and Peak Signal-to-Noise Ratio (PSNR). Comparative analysis of three different models, namely vanilla GAN, U-net GAN, and UAGAN, demonstrates that UAGAN outperforms the others with impressive results, achieving a PSNR of 29.901 dB, RMSE of 7.891, and SSIM of 0.971.This research contributes to the advancement of cloud removal techniques in remote sensing, offering a promising solution for improving data quality and enhancing the accuracy of downstream applications. The integration of GANs and attention mechanisms showcases the potential for innovative approaches to address complex challenges in remote sensing data analysis.",
        "author_keywords": [
            "Attention mechanism",
            "Cloud removal",
            "Data quality",
            "Generative Adversarial Networks (GANs)",
            "Remote sensing data"
        ],
        "subject_areas": [
            "Computer Graphics and Computer-Aided Design",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Health Informatics",
            "Radiology, Nuclear Medicine and Imaging"
        ]
    },
    {
        "title": "A Comparative Analysis of Satellite Image to Map Image Translation Using GANs",
        "authors": "Uma Maheshwari V.",
        "journal": "Proceedings of the IEEE International Conference Image Information Processing",
        "doi": "10.1109/ICIIP61524.2023.10537690",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85195239485",
        "scopus_id": "85195239485",
        "abstract": "Image-to-image translation is a challenging task that aims to convert an input image from one domain to another while preserving its semantic content. In this comparative study, we examine four state-of-the-art Generative Adversarial Network (GAN) architectures: Pix2Pix, CycleGAN, and DualGAN, for the specific task of translating satellite images to map types and examine how they are used in the classification of land cover, urban planning, disaster management, and environmental monitoring. Using several measures such as Inception score, Fréchet Inception Distance, Pixel Accuracy, and Structural Similarity, we assess how models are producing maps and compare their respective performances. This thorough comparative study aims to provide insights into the strengths and weaknesses of Pix2Pix, CycleGAN, and DualGAN in the context of satellite image-to-map translation. Our findings can aid researchers and practitioners in selecting the most appropriate GAN architecture for this task, ultimately advancing the field of image-to-image translation for satellite imagery applications.",
        "author_keywords": [
            "CycleGAN",
            "DualGAN",
            "Fréchet Inception Distance (FID)",
            "Generative Adversarial Network (GAN)",
            "Inception score (IS)",
            "Pix2Pix",
            "Pixel Accuracy",
            "Structural Similarity (SSIM)"
        ],
        "subject_areas": [
            "Computer Graphics and Computer-Aided Design",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Health Informatics",
            "Radiology, Nuclear Medicine and Imaging"
        ]
    },
    {
        "title": "Two-Stage Trajectory Generation Model for Realistic Human Mobility Simulation",
        "authors": "Gong H.",
        "journal": "Proceedings - 2023 IEEE International Conference on High Performance Computing and Communications, Data Science and Systems, Smart City and Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2023",
        "doi": "10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00135",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85189863195",
        "scopus_id": "85189863195",
        "abstract": "Human mobility data is crucial for understanding mobility patterns and provides valuable insights for fields like urban planning and tourism recommendation. To address limitations in trajectory generation methods that treat all points equally, this study proposes a two-stage trajectory simulation model that generates separate sequences for stopping points and moving points. By differentiating between these two types of points, the model can effectively capture mobility intentions and moving paths. The stopping point sequence generator utilizes a GAN-based approach to capture mobility intentions and patterns, while the moving point generator constructs a weighted directed road network graph to determine efficient paths between stopping points. Extensive experiments using a real-life mobility dataset demonstrate the effectiveness of the proposed model in generating realistic trajectories. Moreover, when used for next location prediction task, the synthetic trajectory data generated by our model produces results that closely resemble real-world situations.",
        "author_keywords": [
            "Data Augmentation",
            "GAN",
            "Trajectory Simulation"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Information Systems",
            "Information Systems and Management",
            "Energy Engineering and Power Technology",
            "Safety, Risk, Reliability and Quality",
            "Instrumentation",
            "Urban Studies"
        ]
    },
    {
        "title": "UrbanGenoGAN: pioneering urban spatial planning using the synergistic integration of GAN, GA, and GIS",
        "authors": "Cheng W.",
        "journal": "Frontiers in Environmental Science",
        "doi": "10.3389/fenvs.2023.1287858",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85188561539",
        "scopus_id": "85188561539",
        "abstract": "Introduction: Urban spatial planning is critical for the development of sustainable and livable cities. However, traditional planning methods often face challenges in handling complex planning scenarios and large-scale data. Methods: This paper introduces UrbanGenoGAN, a novel algorithm that integrates generative adversarial networks (GANs), genetic optimization algorithms (GOAs), and geographic information system (GIS) to address these challenges. Leveraging the generative power of GANs, the optimization capabilities of genetic algorithms, and the spatial analysis capabilities of GIS, UrbanGenoGAN is designed to generate optimized urban plans that cater to various urban planning challenges. Our methodology details the algorithm’s design and integration of its components, data collection and preprocessing, and the training and implementation processes. Results: Through rigorous evaluation metrics, comparative analysis with existing methodologies, and case studies, the proposed algorithm demonstrates significant improvement in urban planning outcomes. The research also explores the technical and practical considerations for implementing UrbanGenoGAN, including scalability, computational efficiency, data privacy, and ethical considerations. Discussion: The findings suggest that the integration of advanced machine learning and optimization techniques with spatial analysis offers a promising approach to enhancing decision-making in urban spatial planning. This work contributes to the growing field of AI applications in urban planning and paves the way for more efficient and sustainable urban development.",
        "author_keywords": [
            "data optimization",
            "machine learning",
            "sustainable urban development",
            "urban spatial planning",
            "UrbanGenoGAN"
        ],
        "subject_areas": [
            "Environmental Science (all)"
        ]
    },
    {
        "title": "TL-GAN: Transfer Learning with Generative Adversarial Network Model for Satellite Image Resolution Enhancement",
        "authors": "Islam R.",
        "journal": "2023 26th International Conference on Computer and Information Technology, ICCIT 2023",
        "doi": "10.1109/ICCIT60459.2023.10441504",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85187404958",
        "scopus_id": "85187404958",
        "abstract": "Satellite imagery is essential in many sectors, including remote sensing, environmental monitoring, and urban planning. However, the low-resolution of satellite images makes retrieving fine-grained features difficult and limits their usefulness. Several resolution enhancement methods, including iterative algorithms and deep network-based algorithms, were widely employed to overcome this problem. In this paper, a hybrid model based on a deep neural network is designed to overcome the problem of low-resolution satellite images. To improve resolution, the proposed hybrid network combines a Generative Adversarial Network (GAN) and a pre-trained DenseNet model. The leading benefit of the technique is that GAN learns to generate high-resolution images with realistic and visually appealing details through adversarial training, and the incorporated DenseNet model improves the accuracy of the generated GAN images. To validate the effectiveness of the suggested approach, experimental assessments are designed utilizing a variety of satellite image datasets. The proposed hybrid network produced significant improvements in visual quality and detail preservation in super-resolved satellite images. Finally, the algorithm was compared to the state-of-the-arts method for better evaluation, and the experimental findings demonstrated quantitative and qualitative improvements. Experimental result showed that in terms of peak signal to noise ratio and structure similarity index measurement, the proposed technique achieved 36.28 dB and 0.8304 accuracy, respectively.",
        "author_keywords": [
            "Deep Learning",
            "Generative Adversarial Network",
            "Satellite Imaging",
            "Single Image Super Resolution",
            "Transfer Learning"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Information Systems",
            "Signal Processing",
            "Communication"
        ]
    },
    {
        "title": "Deep Learning based Image Fusion Applied on Landsat-8 Archival Data using UVCGAN",
        "authors": "Kambham S.P.",
        "journal": "2023 Innovations in Power and Advanced Computing Technologies, i-PACT 2023",
        "doi": "10.1109/I-PACT58649.2023.10434448",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85186988004",
        "scopus_id": "85186988004",
        "abstract": "Image fusion is required to maximise the utilisation of the different satellite sensors and enhance the usage and quality of the images obtained from them. One can get over obstacles like varied geographical resolutions, spectral bands, and temporal coverage by fusing images from multiple satellites, such as Landsat8 and Sentinel 2. For various applications that involve observationof the Earth like land cover classification, monitoring of vegetation,disaster monitoring, and urban planning, the fusion process aims to produce composite images that integrate the spectral richness, spatial detail, and temporal frequency of the input images. The creation of Sentinel-like imagery from Landsat8 data enhances its potential for Earth observation applications, making the problem of Landsat 8 and Sentinel 2 imagery fusion very important to solve. A deep learning methodology is required to solve this problem because of its capacity to discover complex correlations and patterns within the data. In this paper, a U-Net Vision Transformer Cycle-consistent Generative Adversarial Network (UVCGAN) - based image fusion method that effectively transforms Landsat 8 images into Sentinel-like imagery is pro- posed. The results obtained from the experiments illustrate the efficiency and effectiveness of the proposed method in generating high-quality composite images with improved spectral and spatialcharacteristics.",
        "author_keywords": [
            "Deep Learning",
            "Image fusion",
            "Landsat-8",
            "Remote sensing",
            "Sentinel-2",
            "UVCGAN"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Energy Engineering and Power Technology",
            "Electrical and Electronic Engineering",
            "Safety, Risk, Reliability and Quality"
        ]
    },
    {
        "title": "Transformer-based Spatial-Temporal Graph Attention Network for Traffic Flow Prediction",
        "authors": "Yan F.",
        "journal": "Proceedings - 2023 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, CyberC 2023",
        "doi": "10.1109/CyberC58899.2023.00031",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85186769342",
        "scopus_id": "85186769342",
        "abstract": "Traffic flow prediction, which plays an important role in intelligent traffic systems, has become a pressing problem to be addressed with the continuous development of smart cities. Currently, the fundamental obstacle lies in effectively modelling the complex spatial-temporal dependencies present in traffic flow data. Deep learning models such as Graph Neural Network based models and Transformer based models have shown promising results in this field. However, methods founded on a single model or framework have one significant limitation: Such methods cannot adequately represent the spatial and temporal features of traffic flow data, restricting the model's ability to learn the dynamics of urban transportation. In this paper, we propose a transformer-based spatial-temporal graph attention network model called TSTGAT for traffic flow prediction, which integrates Transformer and Graph Attention Network. Experiments on two real-world traffic datasets from the Caltrans Performance Measurement System (PeMS) demonstrate that the proposed TSTGAT model outperforms well-known baselines.",
        "author_keywords": [
            "deep learning",
            "graph neural network",
            "Traffic flow prediction",
            "transformer"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "title": "Parallel Learning Based Foundation Model for Networked Traffic Signal Control",
        "authors": "Zhao C.",
        "journal": "IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC",
        "doi": "10.1109/ITSC57777.2023.10422161",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85186538554",
        "scopus_id": "85186538554",
        "abstract": "Networked Traffic Signal Control (NTSC) is a fundamental component of Intelligent Transportation Systems (ITS) and the broader vision of smart city development. While a plethora of intelligent strategies have been developed, the Sim2Real challenge often impedes their full realization. In response, this paper introduces the Parallel Learning-based Adaptive Network for Traffic Signal Control (PLANT) as a foundation model for NTSC. We employ the Wasserstein GAN with Gradient Penalty (WGAN-GP) to generate a wide range of artificial scenarios for robust PLANT training. Further, the Transformer-based Cooperation Mechanism (TCM) is integrated as the primary learner within PLANT, facilitating effective capture of traffic dynamics and knowledge accumulation. This knowledge is readily transferable to real-world applications through meticulous fine-tuning, equipping PLANT to adapt and evolve in alignment with shifting transportation paradigms. Our empirical study on the Hangzhou road network demonstrates PLANT's superiority over both traditional and emerging DRL-based approaches, emphasizing its viability as a potential foundation model for NTSC.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Generative Adversarial Network Style Transfer for Sustainable Urban Restoration Planning in Ukraine",
        "authors": "Shelestov A.",
        "journal": "2023 13th International Conference on Dependable Systems, Services and Technologies, DESSERT 2023",
        "doi": "10.1109/DESSERT61349.2023.10416492",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185825524",
        "scopus_id": "85185825524",
        "abstract": "Due to the ongoing Russian invasion in Ukraine, many Ukrainian cities received immense damage or were destroyed. Restoring these cities is set to become one of the main priorities of the Ukrainian government in the near future. Because of its importance and sensitivity, cutting-edge technology should be used at every step of the task. The restoration process should use best European experience and practices. Generative Adversarial Networks (GAN) style transfer can help with modelling how the city would look if restored using techniques from selected European cities. Moreover, it can model the properties of smart planning of city, for instance a green zones optimization. This paper presents a novel approach to urban restoration planning using GANs to capture and translate architectural and urban planning styles from European cities into the reconstruction of a Ukrainian city. The study focuses on the destroyed city of Mariupol and evaluates the impact of these stylistic influences on greenspace distribution in the restored urban environment. In our case study, we transferred architectural features of Polish and Italian urban project and determined that for this specific city, the Polish urban planning model would be more beneficiary. The total proportion of greenspaces in the area was shown to be 7.18% with Polish project, compared to 5.32% of the Italian model.",
        "author_keywords": [
            "Generative Adversarial Networks",
            "Remote Sensing",
            "Urban planning"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Information Systems",
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality"
        ]
    },
    {
        "title": "A Survey on the Applications of Frontier AI, Foundation Models, and Large Language Models to Intelligent Transportation Systems",
        "authors": "Shoaib M.R.",
        "journal": "ICCA 2023 - 2023 5th International Conference on Computer and Applications, Proceedings",
        "doi": "10.1109/ICCA59364.2023.10401518",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85185195047",
        "scopus_id": "85185195047",
        "abstract": "This survey paper explores the transformative influence of frontier AI, foundation models, and Large Language Models (LLMs) in the realm of Intelligent Transportation Systems (ITS), emphasizing their integral role in advancing transportation intelligence, optimizing traffic management, and contributing to the realization of smart cities. Frontier AI refers to the forefront of AI technology, encompassing the latest advancements, innovations, and experimental techniques in the field, especially AI foundation models and LLMs. Foundation models, like GPT-4, are large, general-purpose AI models that provide a base for a wide range of applications. They are characterized by their versatility and scalability. LLMs are obtained from fine-tuning foundation models with a specific focus on processing and generating natural language. They excel in tasks like language understanding, text generation, translation, and summarization. By leveraging vast textual data, including traffic reports and social media interactions, LLMs extract critical insights, fostering the evolution of ITS. The survey navigates the dynamic synergy between LLMs and ITS, delving into applications in traffic management, integration into autonomous vehicles, and their role in shaping smart cities. It provides insights into ongoing research, innovations, and emerging trends, aiming to inspire collaboration at the intersection of language, intelligence, and mobility for safer, more efficient, and sustainable transportation systems. The paper further surveys interactions between LLMs and various aspects of ITS, exploring roles in traffic management, facilitating autonomous vehicles, and contributing to smart city development, while addressing challenges brought by frontier AI and foundation models. This paper offers valuable inspiration for future research and innovation in the transformative domain of intelligent transportation.",
        "author_keywords": [
            "6G Wireless Communication",
            "Foundation Models",
            "Frontier AI",
            "Intelligent Transportation Systems (ITS)",
            "Internet of Vehicles (IoVs)",
            "Large Language Models (LLMs)",
            "Smart Cities",
            "Vehicular Technology"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Media Technology",
            "Modeling and Simulation",
            "Education"
        ]
    },
    {
        "title": "Vision transformers for dense prediction",
        "authors": "de Oliveira Souza R.S.",
        "journal": "2023 15th IEEE International Conference on Industry Applications, INDUSCON 2023 - Proceedings",
        "doi": "10.1109/INDUSCON58041.2023.10374648",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85183666511",
        "scopus_id": "85183666511",
        "abstract": "Resumo-In this review, we delve into the advancements and applications of monocular depth prediction, focusing on the intricacies of the protocol experiments, dataset transfer, and fine-tuning. We highlight the incorporation of gradient matching loss and the significance of employing a depth inverse representation. Furthermore, our study underscores the expansive utility of such predictive models, not only in surveillance within smart city paradigms and public security but also in diverse domains such as agribusiness, education, and biomedical engineering. Leveraging datasets like MIX 5, MIX 6, and ADE20K, we elucidate the performance enhancement achieved by Transformer-based Neural Networks in dense prediction tasks. Through these findings, the potential for Transformer-based models in practical applications, respecting data protection norms like LGPD, becomes evident. The collaborative efforts of academic and domestic partners in realizing this review are also acknowledged.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Counting People in Crowds Using Multiple Column Neural Networks",
        "authors": "Konishi C.M.",
        "journal": "Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",
        "doi": "10.5220/0011704000003417",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85183600194",
        "scopus_id": "85183600194",
        "abstract": "Crowd counting through images is a research field of great interest for its various applications, such as surveillance camera images monitoring, urban planning. In this work, a model (MCNN-U) based on Generative Adversarial Networks (GANs) with Wasserstein cost and Multiple Column Neural Networks (MCNNs) is proposed to obtain better estimates of the number of people. The model was evaluated using two crowd counting databases, UCF-CC-50 and ShanghaiTech. In the first database, the reduction in the mean absolute error was greater than 30%, whereas the gains in efficiency were smaller in the second database. An adaptation of the LayerCAM method was also proposed for the crowd counter network visualization.",
        "author_keywords": [
            "Activation Maps",
            "Crowd Counting",
            "Deep Learning",
            "Generative Adversarial Networks"
        ],
        "subject_areas": [
            "Computer Graphics and Computer-Aided Design",
            "Computer Vision and Pattern Recognition",
            "Human-Computer Interaction"
        ]
    },
    {
        "title": "A Comparative Study on Vision Transformers in Remote Sensing Building Extraction",
        "authors": "Angelis G.F.",
        "journal": "Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",
        "doi": "10.5220/0011787800003417",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85182781102",
        "scopus_id": "85182781102",
        "abstract": "Data visualization has received great attention in the last few years and gives valuable assets for better understanding and extracting information from data. More specifically, in Geospatial data, visualization includes information about the location, the geometric shape of elements, and the exact position of elements that can lead in enhances downstream applications such as damage detection, building energy consumption estimation, urban planning and change detection. Extracting building footprints from remote sensing (RS) imagery can help in visualizing damaged buildings and separate them form terrestrial objects. Considering this, the current manuscript provides a detailed comparison and a new benchmark for remote sensing building extraction. Experiments are conducted in three publicly available datasets aiming to evaluate accuracy and performance of the compared Transformer-based architectures. MiTNet and other five transformers architectures are introduced, namely DeepViTUNet, DeepViTUNet++, Coordformer, PoolFormer, EfficientFormer. In these choices we study design adjustments in order to obtain the best trade off between computational cost and performance. Experimental findings demonstrate that MitNet, which learns features in a hierarchical manner can be established as a new benchmark.",
        "author_keywords": [
            "Building",
            "Extraction",
            "Remote Sensing",
            "Segmentation",
            "Transformers"
        ],
        "subject_areas": [
            "Computer Graphics and Computer-Aided Design",
            "Computer Vision and Pattern Recognition",
            "Human-Computer Interaction"
        ]
    },
    {
        "title": "Estimating surface utilization factors for BIPV applications using pix2pix on street captured façade images",
        "authors": "Duran A.",
        "journal": "Journal of Physics: Conference Series",
        "doi": "10.1088/1742-6596/2600/4/042005",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85180149490",
        "scopus_id": "85180149490",
        "abstract": "While techniques for assessing solar potential, particularly on roofs, are well-established, estimating solar potential on building facades often requires more work due to the complexity of urban features and the elaborate design of building facades. Existing methods to assess the solar potential of building facades often neglect the characteristics of individual facades. This study presents an image-based method for a more accurate estimation of the PV potential of facades. The proposed method is composed of four steps: (1) data acquisition, preprocessing, and manual labeling, (2) training a pixel-wise semantic image segmentation model based on Generative Adversarial Networks (GANs), (3) color content analysis of segmented images, and (4) estimating the annual solar energy potential. We apply the proposed workflow to several buildings in Zurich, Switzerland, and evaluate segmentation quality and resulting changes in façade surface utilization factors. In a comparative analysis between the widely used web-based solar potential assessment tools, Sonnenfassade, Global Solar Atlas and the simulation software Climate Studio, we demonstrate the downstream impact of surface utilization factors on resulting solar potentials. Considerable deviations in façade availability for BIPV deployments among the various tools as compared to our segmentation approach indicate the potential impact of the proposed method on policy-making and the benefits for BIPV design and planning.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "A Web-Based Chatbot for Indian Cities: A Comparison of CNN, ANN, and LSTM Models",
        "authors": "Sai A.M.A.",
        "journal": "2023 14th International Conference on Computing Communication and Networking Technologies, ICCCNT 2023",
        "doi": "10.1109/ICCCNT56998.2023.10307912",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85179854515",
        "scopus_id": "85179854515",
        "abstract": "Digital transformation is necessary to bring an inclusive opportunity for technology and society to meet the needs brought by both environment, circumstances, and events. In this work, we explore the capability of Generative AI in the societal context of smart city resource management with a particular focus on tourist service management. This work attempts to collaborate many services and resources as an information service to cater to the needs of smart city tourism. We demonstrated the potential of AI in achieving this collaborative information service dissemination with the help of an AI-enabled chatbot Web-application. We also discuss the technical elements required for the real-time information management that we envision for future smart city tourism initiatives. Our experimentation shows that LSTM outperforms CNN and ANN in performance.",
        "author_keywords": [
            "Chatbots",
            "LSTM",
            "Neural Network",
            "Smart City",
            "Tourism"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Decision Sciences (miscellaneous)",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Evaluating an Auto Decoder-based Generative Model for the Infomorphism Urban Planning Framework",
        "authors": "Li F.",
        "journal": "Building Simulation Conference Proceedings",
        "doi": "10.26868/25222708.2023.1393",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85179500768",
        "scopus_id": "85179500768",
        "abstract": "In recent years, various modeling efforts have been undertaken to design and plan buildings for increasing local renewable energy production. To this end, advanced generative models have been developed to explore various urban forms that may provide better access to renewables. However, current approaches have failed to adequately evaluate the effectiveness of a design from a local energy network performance and a collective energy efficiency perspective. An auto-decoder model has been developed to generate planning envelopes, and configurations are evaluated based on integrated local energy networks. The optimal form is identified, which maximizes collective energy efficiency at the neighborhood level.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Proposal for the Implementation of Spatial Common Ground and Spatial AI using the SSCP (Spatial Simulation-based Cyber-Physical) Model",
        "authors": "Miyake Y.",
        "journal": "Proceedings of 2023 IEEE International Smart Cities Conference, ISC2 2023",
        "doi": "10.1109/ISC257844.2023.10293487",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85178345398",
        "scopus_id": "85178345398",
        "abstract": "This paper proposes an architecture for implementing 'Spatial AI' that enables autonomous agents to systematically imagine and navigate their environment. Spatial AI, when implemented, allows for the prediction of the state of the world and the generation of the behavior of the group of agents. A digital twin of a dynamic collective agent environment, including autonomous groups of agents, serves as a basis for simulating various situations and actions. As a means of implementing this architecture, the SSCP Model is proposed, which is a framework for artificial intelligence that can manage agents existing within an arbitrary space. By unifying the agents' communication style, spatial intelligence, spatial representation, and environmental knowledge, Spatial AI provides a Common Ground for controlling diverse groups of AI agents.",
        "author_keywords": [
            "artificial intelligence",
            "autonomous agent",
            "collective agent control",
            "Common Ground",
            "game AI",
            "game engine",
            "smart city",
            "spatial AI",
            "spatial intelligence",
            "spatial simulation",
            "SSCP model",
            "World Model",
            "world representation"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Energy Engineering and Power Technology",
            "Renewable Energy, Sustainability and the Environment",
            "Communication",
            "Urban Studies"
        ]
    },
    {
        "title": "Synthetic Electricity Consumption Data Generation Using Tabular Generative Adversarial Networks",
        "authors": "Tun T.P.",
        "journal": "58th International Universities Power Engineering Conference, UPEC 2023",
        "doi": "10.1109/UPEC57427.2023.10294666",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85178155880",
        "scopus_id": "85178155880",
        "abstract": "Generating synthetic electricity consumption data is crucial for developing efficient energy systems in smart cities. In this paper, we propose the use of Tabular Generative Adversarial Networks (Tabular GAN) for generating synthetic data for residential electricity consumption. Tabular GANs have been used in various domains and have shown promising results in generating high-quality synthetic data. The performance of our proposed method was evaluated by comparing the probability density, mean, standard deviation, and variances of the synthetic data with the original data. The results showed that the Tabular GAN method generated synthetic data that closely match the statistical characteristics of the original data and the simulation outcome indicated that the synthetic data generated by Tabular GAN could effectively simulate the patterns and behaviors observed in the original data. Overall, the proposed method demonstrates the effectiveness of using Tabular GANs for generating synthetic electricity consumption data.",
        "author_keywords": [
            "CTGAN",
            "electricity consumption",
            "GAN",
            "synthetic data",
            "Tabular GAN"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Energy Engineering and Power Technology",
            "Renewable Energy, Sustainability and the Environment",
            "Electrical and Electronic Engineering",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "TIGAN: Trajectory Imputation via Generative Adversarial Network",
        "authors": "Shi Y.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-46677-9_14",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85177421210",
        "scopus_id": "85177421210",
        "abstract": "GPS trajectories are crucial for urban planning, traffic prediction, and location-based services. These applications often require dense trajectories, which is often not the case due to power limitations and privacy concerns. To this end, we propose a novel generative adversarial network-based model, namely TIGAN, for trajectory imputation. TIGAN inserts artificial GPS points between real ones, resulting in imputed trajectories that closely resemble those collected at much higher sampling rates. Unlike existing works, TIGAN does not require prior knowledge such as underlying road networks. Moreover, TIGAN incorporates transportation modes into trajectory imputation, leading to much better performance. Evaluation in two real-world datasets demonstrates the superior performance of TIGAN over state-of-the-art methods.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "5GT-GAN: Enhancing Data Augmentation for 5G-Enabled Mobile Edge Computing in Smart Cities",
        "authors": "Pandey C.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2023.3328170",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85176788903",
        "scopus_id": "85176788903",
        "abstract": "This paper introduces 5GT-GAN, a novel approach leveraging generative adversarial networks (GANs) to create synthetic mobile Internet traffic data, particularly tailored to smart city applications. Given the challenges of data scarcity and privacy concerns in the context of 5G, generating synthetic data becomes a crucial aspect for effectively deploying AI-driven systems in real-world scenarios. 5GT-GAN integrates unsupervised GAN schemes with the ability to manage temporal dynamics through supervised autoregressive models, successfully generating large-scale synthetic mobile Internet traffic data. Our experimental results illustrate the superior performance of 5GT-GAN in terms of mean squared error (MSE) and mean absolute error (MAE) compared to traditional models. The use of 'Train Synthetic Test Real' (TSTR) and 'Train Real Test Synthetic' (TRTS) methodologies affirmed the model's effectiveness with (0.0023 MAE, 0.0074 MSE) and (0.0045 MAE, 0.0092 MSE) respectively. Moreover, the model's runtime complexity of O(n log n) emphasized its efficiency in handling larger datasets, an edge over traditional models. The study also identifies potential future work in augmenting data for traffic prediction and integrating self-attention mechanisms to enhance the capabilities of the model further.",
        "author_keywords": [
            "5GT-GAN",
            "generative adversarial networks",
            "Internet of Things (IoT)",
            "multi-access edge computing (MEC)",
            "smart city",
            "synthetic data"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "An Ensemble for Satellite Image to Map Layout Translation",
        "authors": "Wyawahare M.",
        "journal": "Lecture Notes in Networks and Systems",
        "doi": "10.1007/978-981-99-5166-6_69",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85174442678",
        "scopus_id": "85174442678",
        "abstract": "Mapping and updating maps tend to be a tedious and arduous job requiring human supervision. Accurate and up-to-date maps are necessary for the proper functioning of mobility services, urban planning, navigation, etc. Since generative adversarial networks (GANs) are a cutting-edge method to translate satellite-to-map images, streamlining is a forward-looking technique for satellite-to-map image translation. Furthermore, the introduced work utilizes generative adversarial networks to automatically update the map layout, which will ultimately facilitate the process of maintaining proper map layouts. To decrease the noisy patterns created during translation, a controller or manager that oversees the meaning and interpretation of information at a conceptual or abstract level is presented in the study. The cGAN converts the aerial and satellite images into broad map images without the help of any human annotated data. The paper proposes conditional GAN-based approach, an adversarial learning-based unsupervised domain mapping model with conditioning variable to create high-quality images.",
        "author_keywords": [
            "Conditional GAN",
            "Generative adversarial network",
            "Image translation",
            "Satellite images"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "TEFNEN: Transformer for Energy Forecasting in Natural Environment",
        "authors": "Domínguez-Cid S.",
        "journal": "International Conference on Electrical, Computer, Communications and Mechatronics Engineering, ICECCME 2023",
        "doi": "10.1109/ICECCME57830.2023.10253223",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85174074576",
        "scopus_id": "85174074576",
        "abstract": "Photovoltaic systems are being used in almost every field such as smart cities, Internet of Things paradigms or remote Wireless Sensor Networks. In Internet of things paradigms deployed in natural environments, energy harvesting technology is crucial to power the devices. For the energy management system, it is important to predict how much energy can be harvested from the environment. In this work we focus on creating a model for forecasting the total energy produced by a photovoltaic installation one day in advance. The model is based on the original Transformer architecture. This structure has minor modifications for time series applications. The dataset was created with weather forecasts and the energy and power production of a real photovoltaic installation. The model was trained and compared with state-of-art approaches. The results show that our approach could predict the total energy generated by the photovoltaic installation one day-ahead.",
        "author_keywords": [
            "Energy harvesting",
            "IoT",
            "PV",
            "Transformer"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Electrical and Electronic Engineering",
            "Mechanical Engineering",
            "Electronic, Optical and Magnetic Materials",
            "Instrumentation"
        ]
    },
    {
        "title": "Fed4ReID: Federated Learning with Data Augmentation for Person Re-identification Service in Edge Computing",
        "authors": "Zhang C.",
        "journal": "Proceedings - 2023 IEEE International Conference on Web Services, ICWS 2023",
        "doi": "10.1109/ICWS60048.2023.00021",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85173872534",
        "scopus_id": "85173872534",
        "abstract": "Federated learning is a new distributed privacy-preserving learning paradigm which perfectly meets the requirements of many large service systems such as banking, healthcare, and smart city. Meanwhile, person re-identification, as a technology to associate the images of the same person from different data sources, has been widely used in many smart services such as smart logistics, smart surveillance, and many public searching and rescue missions. Therefore, it is a promising solution to use federated learning for person re-identification to improve the model accuracy while protecting the data privacy. However, the common problem of non-independent and identically distributed (Non-IID) data with heterogeneous clients in federated learning often causes undesirable model accuracy. To address such a problem, in this paper, we propose a novel strategy named federated learning with data augmentation for person re-identification (Fed4ReID). Specifically, to alleviate the impact of Non-IID data, we utilise a pre-trained DCGAN (Deep Convolutional Generative Adversarial Network) model for data augmentation at each edge servers. Experiments on public datasets show that our proposed strategy can outperform baseline method in general accuracy.",
        "author_keywords": [
            "DCGAN",
            "Edge computing",
            "Federated learning",
            "Non-IID",
            "Person re-identification"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Information Systems and Management"
        ]
    },
    {
        "title": "Future Landscape Visualization by Generating Images Using a Diffusion Model and Instance Segmentation",
        "authors": "Mugita Y.",
        "journal": "Proceedings of the International Conference on Education and Research in Computer Aided Architectural Design in Europe",
        "doi": "10.52842/conf.ecaade.2023.2.549",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85172477583",
        "scopus_id": "85172477583",
        "abstract": "When designing a new landscape, such as when demolishing buildings and building new ones, visual methods are effective in sharing a common image. It is possible to visualize future landscapes by making sketches and models, but this requires a great deal of skill and effort on the part of the creator. One method for visualizing future landscapes without the need for specialized skills or labor is image generation using deep learning, and a method has been proposed of using deep learning to generate landscape images after demolishing current buildings. However, there are two problems: the inability to remove arbitrary buildings and the inability to generate a landscape after reconstruction. Therefore, this study proposes a future landscape visualization method that integrates instance segmentation and a diffusion model. The proposed method can generate both post-removal images of existing buildings and post-reconstruction images based on text input, without the need for specialized technology or labor. Verification results confirmed that the post-removal image was more than 90% accurate when the building was removed and replaced with the sky. And the post-reconstruction image matched the text content with a best accuracy of more than 90%. This research will contribute to the realization of urban planning in which all project stakeholders, both professionals and the public, can directly participate by visualizing their own design proposals for future landscapes.",
        "author_keywords": [
            "Deep Learning",
            "Diffusion Model",
            "Inpainting",
            "Instance Segmentation",
            "Landscape Visualization",
            "Text Input",
            "Text-to-image Model"
        ],
        "subject_areas": [
            "Architecture",
            "Education",
            "Computer Graphics and Computer-Aided Design"
        ]
    },
    {
        "title": "Identification of Anomalies in Urban Sound Data with Autoencoders",
        "authors": "Melgar-García L.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-40725-3_3",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85172271157",
        "scopus_id": "85172271157",
        "abstract": "The growing population in the metropolises is influencing the need to plan cities to be safer for people. Several Smart Cities initiatives are being implemented in the cities to achieve this goal. A network of acoustic sensors has been deployed in New York City thanks to the SONYC project. Sounds of the city are being collected and analyzed. In this research work, acoustic signal data are represented with Mel-spectrogram images with mel-scale frequency versus time on a decibel scale. Traditional autoencoders and variational autoencoder models are deployed to detect anomalies in the mel-spectrogram images. The obtained results demonstrate that the variational autoencoder model finds anomalies accurately in the acoustic records.",
        "author_keywords": [
            "Acoustic sensor network",
            "Anomaly detection",
            "Autoencoders",
            "Urban sound data"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Raindrop Removal using Image Inpainting",
        "authors": "Nithyashree M.",
        "journal": "Proceedings of the 5th International Conference on Inventive Research in Computing Applications, ICIRCA 2023",
        "doi": "10.1109/ICIRCA57980.2023.10220866",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85172229296",
        "scopus_id": "85172229296",
        "abstract": "Image Restoration under severe weather circumstances has drawn a lot of interest for many computer vision applications. In order to deliver accurate and high quality surveillance in the context of smart cities, image de-raining is a crucial subject that has been explored extensively in recent years. In order to handle the challenge of removing raindrops, two different strategies are adopted in this research study: The Diffusion model and the Generative adversarial network model. By considering the recent improvements in image deraining methods, this research study proposes a novel technique that makes use of conditional generative adversarial network with adversarial loss, which provides a factor to loss functions and regulates the output for achieving the improved results. In addition, diffusion modelling, a novel patch-based method is used to perform image restoration. Diffusion probabilistic frameworks are used for normalising noise over affected regions. This research study compares and evaluates how well these two techniques perform in eliminating the raindrops from images. This study demonstrates that the diffusion model outperforms the GAN technique in terms of qualitative assessments and visual appearance by conducting a comparative analysis on actual and synthetic data.",
        "author_keywords": [
            "Denoising diffusion model",
            "Generative adversarial networks",
            "Raindrop"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "title": "CSGAN: Modality-Aware Trajectory Generation via Clustering-based Sequence GAN",
        "authors": "Zhang M.",
        "journal": "Proceedings - IEEE International Conference on Mobile Data Management",
        "doi": "10.1109/MDM58254.2023.00032",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85171164846",
        "scopus_id": "85171164846",
        "abstract": "Human mobility data is useful for various applications in urban planning, transportation, and public health, but collecting and sharing real-world trajectories can be challenging due to privacy and data quality issues. To address these problems, recent research focuses on generating synthetic trajectories, mainly using generative adversarial networks (GANs) trained by real-world trajectories. In this paper, we hypothesize that by explicitly capturing the modality of transportation (e.g., walking, biking, driving), we can generate not only more diverse and representative trajectories for different modalities but also more realistic trajectories that preserve the geographical density, trajectory, and transition level properties by capturing both cross-modality and modality-specific patterns. Towards this end, we propose a Clustering-based Sequence Generative Adversarial Network (CSGAN)1 that simultaneously clusters the trajectories based on their modalities and learns the essential properties of real-world trajectories to generate realistic and representative synthetic trajectories. To measure the effectiveness of generated trajectories, in addition to typical density and trajectory level statistics, we define several new metrics for a comprehensive evaluation, including modality distribution and transition probabilities both globally and within each modality. Our extensive experiments with real-world datasets show the superiority of our model in various metrics over state-of-the-art models.",
        "author_keywords": [
            "Clustering",
            "Generative Adversarial Networks",
            "Reinforcement Learning",
            "Synthetic Trajectory Generation"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "DEMO: STM - A Privacy-Enhanced Solution for Spatio-Temporal Trajectory Management",
        "authors": "Yonekura H.",
        "journal": "Proceedings - IEEE International Conference on Mobile Data Management",
        "doi": "10.1109/MDM58254.2023.00034",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85171159600",
        "scopus_id": "85171159600",
        "abstract": "In this demonstration paper, we present STM: a new system for securing and management of vehicle trajectory data using a generative model that balances privacy and utility. For instance, traditional methods for taxi-demand prediction pose the risk of privacy breaches from both the data and the model. To address this challenge, we deploy Spatiotemporal-GAN to generate synthetic trajectories that meet privacy regulations such as GDPR. We assess the quality of the generated data by constructing several taxi-demand prediction models. Moreover, we evaluate the privacy risk by implementing trajectory user linking attacks against the generated data and membership inference attacks against the prediction model. Our system is designed with rich interactivity and visualization, enabling the audience to use these modules. Overall, our approach demonstrates the potential of generative models in preserving privacy while maintaining data utility in the context of taxi-demand prediction.",
        "author_keywords": [
            "Privacy-preservation",
            "Smart Transportation",
            "Taxi-demand Prediction",
            "Trajectory generation",
            "Urban Planning"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "A Privacy-Preserving and Research-Utilizable Trajectory Generator via Deep Generative Approach",
        "authors": "Sun X.",
        "journal": "2023 6th International Conference on Electronics Technology, ICET 2023",
        "doi": "10.1109/ICET58434.2023.10211675",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85169909478",
        "scopus_id": "85169909478",
        "abstract": "Large-scale trajectory data is critical for a smart city to improve the efficiency of a transportation system. However, the release of original trajectory data violates privacy protection principles if no privacy-preserving approach is adopted, that's why the public trajectory data for research is so limited. To enable extensive available trajectory data publishing, we propose a Privacy-Preserving and research-utilizable Trajectory Generator (PPTG), which uses a deep generative model to provide utilizable synthetic trajectories. Specifically, PPTG can not only extract the intrinsic and spatial features, but also get rid of possible privacy information from the real trajectories. In experiments, we show that the privacy-preserving trajectory data generated by PPTG can achieve superior performance in terms of privacy protection and data utility against the existing approaches.",
        "author_keywords": [
            "deep generative model",
            "privacy-preserving trajectory publishing",
            "Trajectory generator"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Information Systems",
            "Information Systems and Management",
            "Electrical and Electronic Engineering",
            "Safety, Risk, Reliability and Quality",
            "Instrumentation",
            "Atomic and Molecular Physics, and Optics"
        ]
    },
    {
        "title": "Enhanced Expectation-Maximization Algorithm for Smart Traffic IoT Systems using Deep Generative Adversarial Networks to Reduce waiting time",
        "authors": "Yamini B.",
        "journal": "2023 4th International Conference on Electronics and Sustainable Communication Systems, ICESC 2023 - Proceedings",
        "doi": "10.1109/ICESC57686.2023.10193089",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85168314714",
        "scopus_id": "85168314714",
        "abstract": "The main focus of the work is to improve the smart traffic systems for the Internet of Things (IoT) such as traditional signals and safe driving via tracking the congestion and monitoring traffic slowly. Depending on the circumstances, intersections between roads can sometimes lead to accidents, so this problem is considered part of the research. These limitations can be overcome by using modern sensors that can reduce the traffic signal waiting time and rash driving on the National Highway (NH) road. Urban countries make use of AI-based decisions performing smart control over managing vehicles. In the proposed model the novel combination of collecting road maps coordinating points that can connect the access movements. Also IoT devices such as mobile phones, unusual network failure, and peak time traffic control by preprocessing the collected traffic dataset. Based on the dataset the detection of coverage area can be extracted using Enhanced Expectation Maximization Algorithm for ranking the variables. Initially, the classification algorithms were used and grouped as accident months, non-accident months, hill stations, and highway NH Road delay time are some of categories. Using Deep Generative Adversarial Network (DGAN) data can be balanced and used to reduce the waiting time along with predicting the smart cities' transportation for reliable customers.",
        "author_keywords": [
            "Artificial Intelligence",
            "Deep Generative Adversarial Network",
            "Deep Learning",
            "Enhanced Expectation-Maximization Algorithm",
            "Internet of Things",
            "National Highway road"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Information Systems and Management",
            "Renewable Energy, Sustainability and the Environment",
            "Electrical and Electronic Engineering",
            "Information Systems",
            "Safety, Risk, Reliability and Quality"
        ]
    },
    {
        "title": "Rag-Pickers as Benefactors and Beneficiaries of the Sustainable Development Goals:A Brief Literature Review",
        "authors": "Venkatesh G.",
        "journal": "Studia Ecologiae et Bioethicae",
        "doi": "10.21697/seb.2023.10",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85167361013",
        "scopus_id": "85167361013",
        "abstract": "Ragpickers have long led a marginalised, subliminal and deprived existence, and have silently gone about contributing to ‘informal waste recycling’, diverting in many cities and towns, over half of the recyclable wastes from dumpsites to the technosphere. The reviewer has based this paper on 60 peer-reviewed publications spanning a time period of 28 years – from 1995 – 2022, originating from over a dozen different countries, and encompassing the social, economic and environmental dimensions of sustainability. The discussion has been structured around the six question words – Where/Wherefrom, When, How, What, Why and Who/Whom. While there is no claim of any addition per se being made to the extant body of knowledge, the reviewer would like to describe this as an attempt to simply collate exist-ing knowledge to serve the practical purpose of highlighting the plight of our impoverished, malnourished, oppressed brethren, to elicit appreciation, understanding and support for them, from policymakers in government, CSR personnel from the corporate world, journalists in the media, and most importantly, from the common urban denizens. All these entities can work shoulder to shoulder with the NGOs who have been relentlessly striving to help the rag-pickers to ‘stay afloat’. The reviewer fondly hopes that this will motivate more concerted transdisciplinary applied research, predicated on the Sustainable Development Goals – a collaboration among the disciplines of healthcare, sociology, psychology, urban planning, sustainable development, environmental engineering, and even art and poetry.",
        "author_keywords": [
            "environment",
            "rag-picker/ragpicker",
            "rag-picking/ragpicking",
            "urban metabolism",
            "waste management"
        ],
        "subject_areas": [
            "Arts and Humanities (miscellaneous)",
            "Philosophy",
            "Environmental Science (all)",
            "Health Policy"
        ]
    },
    {
        "title": "Smart City Facility Location Recommendation Algorithm Using Multimedia Data and Improved Generative Adversarial Networks",
        "authors": "Xie X.",
        "journal": "International Journal of Intelligent Systems",
        "doi": "10.1155/2023/6664219",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85165934599",
        "scopus_id": "85165934599",
        "abstract": "Internet of Things, low energy consumption, and intelligent and functionally integrated urban infrastructure construction are crucial elements in the development of smart cities. Distributed generation (DG) and electric vehicle charging infrastructure play a vital role in the planning and construction of smart cities. However, the uncertainty associated with the power output of distributed generation significantly impacts the planning of distribution networks. To address this issue, this paper proposes a site-selection recommendation algorithm that leverages urban multimedia data and improved generative adversarial networks. The proposed algorithm begins by modeling the uncertainty of wind power and photovoltaic (PV) generation using an enhanced conditional generative adversarial network model. To generate multimedia datasets with time-series characteristics for wind power and PV generation scenarios, monthly multimedia data labels are incorporated into the model. These multimedia datasets, representing a wide range of scenarios, are then clustered using the K-means clustering method. Furthermore, a distributed generation planning model is established, aiming to minimize the annual integrated cost. The planning problem is efficiently solved using CPLEX, a mathematical programming solver. In the simulation experiments, the proposed scheme is compared with alternative schemes. The results demonstrate that the proposed scheme achieves a significant total cost saving of 21.95% compared to the comparison scheme. Moreover, the experimental comparison reveals that the proposed scheme exhibits higher stability. Additionally, in terms of algorithm efficiency, the proposed algorithm outperforms the other three algorithms tested in terms of the number of iterations and speed. The experimental results highlight the effectiveness of the proposed planning model in improving the economy and stability of the distribution network. Furthermore, it enhances the computational efficiency of the planning problem associated with distributed power supply and electric vehicle charging stations. The findings of this research hold substantial research significance for the site selection planning of distributed power supply.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Cloth-changing person re-identification：a summary",
        "authors": "Zhang P.",
        "journal": "Journal of Image and Graphics",
        "doi": "10.11834/jig.220702",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85162873989",
        "scopus_id": "85162873989",
        "abstract": "Person re-identification（Re-ID）aims to build identity correspondence of the target pedestrian among multiple non-overlap monitoring areas，which has significant application value in the fields such as smart city，criminal investigation and forensics，and surveillance security. Conventional Re-ID methods are often focused on short-term scenarios，which aim to tackle some challenges in related to illumination difference，view-angle change and occlusion. In these methods，the target pedestrian of interest（TPoI）is assumed as unchangeable dressing status while he re-appears under the surveillance circustmances. Such methods are restricted by the homology of appearance across different cameras，such as the same color and texture of pedestrians’clothes. In contrast，cloth-changing person Re-ID aims at long-term scenarios，which determines that the TPoI re-appears after a long-time gap likes one week or more. In addition to the above challenges in classical person Re-ID，cloth-changing person Re-ID also suffers the difficulty of appearance difference caused by clothes changing. This makes it a research difficulty in recent years. Considering cloth-changing person Re-ID，this paper discusses its challenges and difficulties，and provides an indepth review on recent progress in terms of the analysis of datasets and methods. Based on the analysis，some potential research trends and solutions are proposed. First，we summary and compare the existing cloth-changing person Re-ID datasets in relevant to 1）RGBD-based pattern analysis and computer vision（PAVIS），BIWI，and IAS-Lab，2）radio frequency-based radio frequency re-identification dataset-campus（RRDCampus）and RRD-Home，3）RGB image-based Celeb-ReID，person Re-ID under moderate clothing change（PRCC），long-term cloth-changing（LTCC），and DeepChange and 4）video-based train station dataset（TSD），Motion-ReID and CVID-ReID（cloth-varing video Re-ID），which can be oriented to their difficulties and limitations on the aspects of collecting methods，number of identities and images. Additionally，some popular person Re-ID evaluation metrics are summarized in the context of cumulative match characteristics（CMC），mean average precision（mAP）and mean inverse negative penalty（mINP）. Second，we summary the existing cloth-changing person Re-ID methods and segment them into two major categories in terms of data collection：1）non-visual sensor-based and 2）visual camera-based methods. Non-visual sensor based methods are used to alleviate the influence of clothes from the perspective of data collection manner. In this paper，non-visual sensors are configured into two aspects，i. e. ，RGBD sensor and radio frequency（RF）. The RGBD sensor is used to produce depth information，which can boost the human shape information and eliminate the effect of cloth color. However，the depth information is still influenced by clothes’contour. The RF-based method can be used for overcoming the weakness further. The wireless devices-derived RF signal emittion can penetrate cloths and reflect the shape information of human body. Unfortunately，the non-visual sensor based methods heavily rely on expensive snesors. It is hard to be applied to the existing surveillance systems. In contrast，visual camera based methods can be used to RGB monitoring cameras directly，and its problem can be tackled through cloth-invariant feature learning and representation from RGB images/ videos. These methods can be divided into three categories：1）explicit feature learning and extraction（EFLE），2）feature decoupling（FD），and 3）implicit data adaption（IDA）. The EFLE can extract cloth-invariant identity-relevant biometric features explicitly，such as face，gait，and body shape. And，these methods consist of two aspects，i. e. ，hand-crafted and learning-based. The hand-crafted methods can be used to design feature representation，e. g. ，body measurement and analysis. The learning-based methods guide deep neural network models to learn biometric features using some localization or regularization modules. The FD is used to decouple identity information and cloth-related appearance feature and produce pure identity information，e. g. ，CESD，DG-Net，IS-GAN，AFD-Net，etc. Differently，IDA adopts a data-driven manner，which can adapt intra-class diversity automatically using large volume of data with abundant intra-class variance，e. g. ，ReIDCaps，RCSANet. On the basis，the cons of current cloth-changing person Re-ID methods are analyzed，e. g. ，lack of large-scale and multi-view dataset，feature alignment problem，occlusion，weak feature discriminability and generalization problem. Aiming to these drawbacks，this paper further looks forward to six promising research directions as mentioned below：1）to construct large-scale video-based datasets and explore spatio-temporal features from video clips or contexts. It is supposed that video footages include rich gait information and provide multi-view body characteristics for 3D human reconstruction；2）to utilize 3D human reconstruction for learning view-invariant human geometric features from 3D space. The 3D body is assumed to be robust to shape deformation which highlights body structure information；3）to weaken the effect of clothes-related attributes with the help of pedestrian attribute analysis. It is beneficial for the extraction of semantic-level cues；4）to mine and integrate multiple features using multi-feature co-learning simultaneously，such as gaits，face and shape. These multi-modality features can yield Re-ID models to pay attention on different views of a walking human and thus help investigate more discriminative representation；5）to overcome the limitation of limited labelled data with unsupervised learning. Notably，the integration of generative models and constrastive learning can be used to supervise the feature learning through minimizing the difference between raw image and synthesized image；and 6）multi-task learning pipeline can be as another feasible solution. It combines multiple correlated tasks，such as pedestrian attribute analysis，action analysis and body reconstruction. This resembles to the idea of recently popular universal models that regularizes the stem model to learn more generalized representations.",
        "author_keywords": [
            "biometric",
            "cloth-changing person re-identification",
            "data-driven learning",
            "deep learning",
            "feature decoupling",
            "feature learning and representation",
            "video surveillance"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Vision and Pattern Recognition",
            "Computer Graphics and Computer-Aided Design",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Balancing Privacy and Utility of Spatio-Temporal Data for Taxi-Demand Prediction",
        "authors": "Ozeki R.",
        "journal": "Proceedings - IEEE International Conference on Mobile Data Management",
        "doi": "10.1109/MDM58254.2023.00044",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85162118743",
        "scopus_id": "85162118743",
        "abstract": "The growing demand for ride-hailing services has led to an increasing need for accurate taxi demand prediction. However, the use of real passenger data to train predictive models raises serious privacy concerns. To address this challenge, we present a privacy-preserving taxi demand prediction system that employs a generative model to synthesize synthetic trajectory data, preserving privacy while retaining the statistical properties of the original data. The system also overcomes the challenge of location dependence of latitude-longitude values by encoding the representation into region-independent space, making it more general and applicable to different geographical areas. The system was evaluated on real-world data collected from a major taxi service provider in Japan over a period of six months. The results showed that the system can effectively defend against 98% of all attempted attacks on passenger data and against 60% of state-of-the-art attacks on the learning-based prediction models. Additionally, the proposed system ensures the prediction performance, with a barely noticeable decrease of 2.9% compared to using the original data.",
        "author_keywords": [
            "Privacy-preservation",
            "Smart Transportation",
            "Taxi-demand Prediction",
            "Trajectory generation",
            "Urban Planning"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Urban Protected Areas and Urban Biodiversity",
        "authors": "Ioja C.",
        "journal": "Cities and Nature",
        "doi": "10.1007/978-3-030-73089-5_20",
        "publication_date": "2023",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85161964668",
        "scopus_id": "85161964668",
        "abstract": "Protected areas become urban protected areas by their location. The International Union for Nature Conservation defines a protected area as: “Clearly defined geographical space, recognized, dedicated, and managed through legal or other effective means, to achieve the long-term conservation of nature with its associated ecosystem services and cultural values.” Different chapters in part IV aim to contribute to increase the understanding about the general concept of urban protected areas (Iojă), trade-offs and synergies of cultural ecosystem services of these areas (Badiu et al.), and perceptions and preferences to urban nature (Hayir-Kanat and Breuste). Likewise, chapters are also provided on social aspects of biodiversity (Dushkova et al.), urban land use aspects of biodiversity (Gan and Breuste), and strategies to increase urban biodiversity in urban parks (Borysiak et al.). The case studies cover a wide range of geographical backgrounds, going from Central Europe (Borysiak et al.) to South Eastern Europe (Iojă, Badiu et al.), and including Russia (Dushkova et al.), the biggest European city, i.e., Istanbul (Hayir-Kanat and Breuste), and one of the biggest Asian cities, i.e., Shanghai (Gan and Breuste). Part IV targets to improve the understanding of nature protection and biodiversity in cities under different natural and societal conditions.",
        "author_keywords": [
            "Nature conservation",
            "Protected areas",
            "Urban biodiversity",
            "Urban planning",
            "Wild animals",
            "Wild plants"
        ],
        "subject_areas": [
            "Food Science",
            "Renewable Energy, Sustainability and the Environment",
            "Geography, Planning and Development",
            "Urban Studies"
        ]
    },
    {
        "title": "Correction of Banding Errors in Satellite Images With Generative Adversarial Networks (GAN)",
        "authors": "Paola Z.L.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2023.3279265",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85161075955",
        "scopus_id": "85161075955",
        "abstract": "This research proposes an innovative method for correcting banding errors in satellite images based on Generative Adversarial Networks (GAN). Small satellites are frequently launched into space to obtain images that can be used in scientific or military research, commercial activities, and urban planning, among other applications. However, its small cameras are more susceptible to radiometric, geometric errors, and other distortions caused by atmospheric interference. The proposed method was compared to the conventional correction technique using experimental data, showing the similar performance (92.64% and 90.05% accuracy, respectively). These experimental results suggest that generative models utilizing Artificial Intelligence (AI) techniques, specifically Deep Learning, are getting closer to achieving automatic correction close to conventional methods. Advantages of the GAN models include automating the task of correcting banding in satellite images, reducing the required time, and facilitating the processing without requiring prior technical knowledge in handling Geographic Information Systems (GIS). Potentially, this technique could represent a valuable tool for satellite image processing, improving the accuracy of the results and making the process more efficient. The research is particularly relevant to the field of remote sensing and can have practical applications in various industries.",
        "author_keywords": [
            "Artificial neural network",
            "banding",
            "deep learning",
            "generative adversarial network",
            "radiometric error",
            "satellite images"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "Multispectral Remote Sensing Image Deblurring Using Auxiliary Band Gradient Information",
        "authors": "Liao Z.",
        "journal": "IEEE Transactions on Geoscience and Remote Sensing",
        "doi": "10.1109/TGRS.2023.3280647",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85161067692",
        "scopus_id": "85161067692",
        "abstract": "Multispectral remote sensing images (RSI), including hyperspectral and multispectral images, contain adequate information of ground objects and areas and play important roles in environmental monitoring, weather forecasting, urban planning, and so on. However, due to many inevitable external effects on the remote sensing pathway, RSIs are often degraded by blur. The fields of multispectral RSI deblurring have witnessed great improvements in recent years, including both optimization-based and deep-learning-based methods. However, issues are to be addressed in the RSI deblurring field, such as the incompatibility of general regularizations, lack of spectral correlations for multispectral RSIs, demands of blind deblurring for real-world applications, and high costs of computation. To address these problems, we incorporate a novel prior exploiting gradient information similarity between different spectral bands, and we name it auxiliary band gradient information (ABGI) prior. We show that the ABGI prior is applicable to all gradient sparsity regularizations by a simple subtract-then-add step. Specifically, we apply ABGI prior to the patchwise minimal pixel (PMP) prior-based deblurring method, and we also prove that the PMP prior exhibits sparsity for clear natural RSIs. We estimate our method on RSI datasets of different spectral types and geographic resolutions. Compared with other state-of-the-art deblurring methods, our method shows superior performance on both simulated and real-world blur.",
        "author_keywords": [
            "Auxiliary band gradient information (ABGI)",
            "blind deblurring",
            "remote sensing image (RSI)"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Remote sensing image analysis and prediction based on improved Pix2Pix model for water environment protection of smart cities",
        "authors": "Wang L.",
        "journal": "PeerJ Computer Science",
        "doi": "10.7717/PEERJ-CS.1292",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159778284",
        "scopus_id": "85159778284",
        "abstract": "Background. As an important part of smart cities, smart water environmental protection has become an important way to solve water environmental pollution problems. It is proposed in this article to develop a water quality remote sensing image analysis and prediction method based on the improved Pix2Pix (3D-GAN) model to overcome the problems associated with water environment prediction of smart cities based on remote sensing image data having low accuracy in predicting image information, as well as being difficult to train. Methods. Firstly, due to inversion differences and weather conditions, water quality remote sensing images are not perfect, which leads to the creation of time series data that cannot be used directly in prediction modeling. Therefore, a method for preprocessing time series of remote sensing images has been proposed in this article. The original remote sensing image was unified by pixel substitution, the image was repaired by spatial weight matrix, and the time series data was supplemented by linear interpolation. Secondly, in order to enhance the ability of the prediction model to process spatial-temporal data and improve the prediction accuracy of remote sensing images, the convolutional gated recurrent unit network is concatenated with the Unet network as the generator of the improved Pix2Pix model. At the same time, the channel attention mechanism is introduced into the convolutional gated recurrent unit network to enhance the ability of extracting image time series information, and the residual structure is introduced into the downsampling of the U-net network to avoid gradient explosion or disappearance. After that, the remote sensing images of historical moments are superimposed on the channels as labels and sent to the discriminator for adversarial training. The improved Pix2Pix model no longer translates images, but can predict two dimensions of space and one dimension of time, so it is actually a 3D-GAN model. Third, remote sensing image inversion data of chlorophyll-a concentrations in the Taihu Lake basin are used to verify and predict the water environment at future moments. Results. The results show that the mean value of structural similarity, peak signal-tonoise ratio, cosine similarity, and mutual information between the predicted value of the proposed method and the real remote sensing image is higher than that of existing methods, which indicates that the proposed method is effective in predicting water environment of smart cities",
        "author_keywords": [
            "Artificial intelligence",
            "Deep learning",
            "Image analysis",
            "Neural network",
            "Pix2Pix model",
            "Prediction",
            "Remote sensing",
            "Smart cities",
            "Spatial-temporal data",
            "Water environment"
        ],
        "subject_areas": [
            "Computer Science (all)"
        ]
    },
    {
        "title": "3D Visualization System for Urban Buildings Based on Deep Learning",
        "authors": "Nie S.",
        "journal": "Proceedings of SPIE - The International Society for Optical Engineering",
        "doi": "10.1117/12.2669825",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159696098",
        "scopus_id": "85159696098",
        "abstract": "With the continuous development of the construction of digital communities, digital cities and digital earth, 3D model visualization technology has become a more important development direction. This paper took deep learning as the basic premise to design the 3D visualization model based on StyleGAN2 algorithm. That is, firstly, StyleGAN2 algorithm was used to segment the image, and Three JS was selected as the Web 3D visualization framework for the model; then the 3D visualization model based on StyleGAN2 algorithm was constructed. After testing and training the model for many times, the corresponding modeling image was acquired. After aligning this image and positioning coordinates, it was substituted in the suitable modeling scene, and finally the fast modeling of buildings was realized. The results show that StyleGAN2 algorithm has superior performance and high modeling efficiency, which can lead to lower modeling cost and thus promote the improvement of 3D visualization of urban buildings.",
        "author_keywords": [
            "Indoor scenes",
            "Intelligent city",
            "StyleGAN2 algorithm",
            "Three JS framework",
            "Visualization"
        ],
        "subject_areas": [
            "Electronic, Optical and Magnetic Materials",
            "Condensed Matter Physics",
            "Computer Science Applications",
            "Applied Mathematics",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Machine Learning for Relaying Topology: Optimization of IoT Networks with Energy Harvesting",
        "authors": "Chung K.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2023.3270631",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159658842",
        "scopus_id": "85159658842",
        "abstract": "In this paper, we examine Internet of Things (IoT) systems related to smart cities, smart factories, connected cars, etc. To support such systems in a wide area with low power consumption, energy harvesting technology utilizing wireless charging infrastructure is necessary for the longevity of networks. Considering that the position and amount of energy charged for each device could be unbalanced according to the distribution of nodes and energy sources, maximizing the minimum throughput among all nodes has become an NP-hard challenging issue. To overcome this challenge, we propose a machine learning based relaying topology algorithm with a novel backward-pass rate assessment method to present proper learning direction and an iterative balancing time slot allocation algorithm which can utilize a node with sufficient energy as the relay. To validate our proposed scheme, we conducted simulations on our established system model; thus, we confirm that the proposed scheme is stable and superior to conventional schemes.",
        "author_keywords": [
            "energy harvesting",
            "IoT network",
            "relay",
            "TDMA system",
            "Unsupervised learning",
            "variational autoencoder"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "A Survey on Mapping of Urban Green Spaces within Remote Sensing Data Using Machine Learning & Deep Learning Techniques",
        "authors": "Burrewar S.S.",
        "journal": "2023 15th International Conference on Computer and Automation Engineering, ICCAE 2023",
        "doi": "10.1109/ICCAE56788.2023.10111467",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159640282",
        "scopus_id": "85159640282",
        "abstract": "For environmental protection, urban planning, monitoring, and management of the urban ecosystem, mapping urban green spaces is a crucial undertaking. A vital source of information for United Nations Sustainable Development Goal 11.7 could come from urban green space mapping. The standard method of mapping urban green spaces requires field measurements and takes a lot of time. It is also important to update urban green space maps periodically because urban green spaces can change quickly over time due to development. With the advent of high-resolution satellite sensors like Sentinel-1 and Sentinel-2, a large number of remote sensing images may be gathered, providing quick and precise information over urban areas. This work intends to offer a new perspective on how crowd sourced geospatial big data and remote sensing may be combined to enhance the mapping of urban green spaces, including time optimization and accurate information through machine learning and deep learning. For the revitalization of cities, this data will be valuable. Remote sensing imagery data can be classified using machine learning techniques like Support vector machines (SVM), Random forests (RF), and Naive Bayes (NB). In deep learning techniques such as Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN), K Nearest Neighbor (KNN), Generative Adversarial Networks (GAN), and Recurrent Neural Networks (RNN) can be used to classify remote sensing images.",
        "author_keywords": [
            "deep learning",
            "machine learning",
            "mapping",
            "remote sensing data",
            "urban green spaces"
        ],
        "subject_areas": [
            "Statistics, Probability and Uncertainty",
            "Artificial Intelligence",
            "Computer Science Applications",
            "Information Systems and Management",
            "Control and Systems Engineering",
            "Control and Optimization"
        ]
    },
    {
        "title": "Physics-Informed AI Surrogates for Day-Ahead Wind Power Probabilistic Forecasting with Incomplete Data for Smart Grid in Smart Cities",
        "authors": "Wu Z.",
        "journal": "CMES - Computer Modeling in Engineering and Sciences",
        "doi": "10.32604/cmes.2023.027124",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159229566",
        "scopus_id": "85159229566",
        "abstract": "Due to the high inherent uncertainty of renewable energy, probabilistic day-ahead wind power forecasting is crucial for modeling and controlling the uncertainty of renewable energy smart grids in smart cities. However, the accuracy and reliability of high-resolution day-ahead wind power forecasting are constrained by unreliable local weather prediction and incomplete power generation data. This article proposes a physics-informed artificial intelligence (AI) surrogates method to augment the incomplete dataset and quantify its uncertainty to improve wind power forecasting performance. The incomplete dataset, built with numerical weather prediction data, historical wind power generation, and weather factors data, is augmented based on generative adversarial networks. After augmentation, the enriched data is then fed into a multiple AI surrogates model constructed by two extreme learning machine networks to train the forecasting model for wind power. Therefore, the forecasting models’ accuracy and generalization ability are improved by mining the implicit physics information from the incomplete dataset. An incomplete dataset gathered from a wind farm in North China, containing only 15 days of weather and wind power generation data with missing points caused by occasional shutdowns, is utilized to verify the proposed method’s performance. Compared with other probabilistic forecasting methods, the proposed method shows better accuracy and probabilistic performance on the same incomplete dataset, which highlights its potential for more flexible and sensitive maintenance of smart grids in smart cities.",
        "author_keywords": [
            "day-ahead forecasting",
            "extreme learning machine",
            "generative adversarial network",
            "incomplete data",
            "Physics-informed method",
            "probabilistic forecasting",
            "smart grids",
            "wind power"
        ],
        "subject_areas": [
            "Software",
            "Modeling and Simulation",
            "Computer Science Applications"
        ]
    },
    {
        "title": "Network Intrusion Detection in Internet of Blended Environment Using Ensemble of Heterogeneous Autoencoders (E-HAE)",
        "authors": "Jilcha L.A.",
        "journal": "Computer Systems Science and Engineering",
        "doi": "10.32604/csse.2023.037615",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85158885805",
        "scopus_id": "85158885805",
        "abstract": "Contemporary attackers, mainly motivated by financial gain, consistently devise sophisticated penetration techniques to access important information or data. The growing use of Internet of Things (IoT) technology in the contemporary convergence environment to connect to corporate networks and cloud-based applications only worsens this situation, as it facilitates multiple new attack vectors to emerge effortlessly. As such, existing intrusion detection systems suffer from performance degradation mainly because of insufficient considerations and poorly modeled detection systems. To address this problem, we designed a blended threat detection approach, considering the possible impact and dimensionality of new attack surfaces due to the aforementioned convergence.We collectively refer to the convergence of different technology sectors as the internet of blended environment. The proposed approach encompasses an ensemble of heterogeneous probabilistic autoencoders that leverage the corresponding advantages of a convolutional variational autoencoder and long short-term memory variational autoencoder. An extensive experimental analysis conducted on the TON_IoT dataset demonstrated 96.02% detection accuracy.Furthermore, performance of the proposed approach was compared with various single model (autoencoder)-based network intrusion detection approaches: autoencoder, variational autoencoder, convolutional variational autoencoder, and long short-term memory variational autoencoder. The proposed model outperformed all compared models, demonstrating F1-score improvements of 4.99%, 2.25%, 1.92%, and 3.69%, respectively.",
        "author_keywords": [
            "anomaly detection",
            "autoencoder",
            "convolutional variational autoencoder",
            "digital healthcare",
            "ensemble learning",
            "LSTM",
            "Network intrusion detection",
            "smart city",
            "smart factory",
            "smart grid",
            "TON_IoT dataset",
            "variational autoencoder"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Synthetic Dataset of Electroluminescence Images of Photovoltaic Cells by Deep Convolutional Generative Adversarial Networks",
        "authors": "Romero H.F.M.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-3-031-28454-0_1",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85152541506",
        "scopus_id": "85152541506",
        "abstract": "This article presents a different way of obtaining images of solar cells using Artificial Intelligence techniques such as Generative Adversarial Neural Networks (GANs). This will improve the maintenance of Photovoltaic Systems in different places like Smart Cities. The original data has been obtained manually and preprocessed to create better images. The GAN architecture used is known as Deep Convolutional GAN since it performs better than other GANs. The synthetic images were labeled and analyzed to ensure their quality.",
        "author_keywords": [
            "Artificial Intelligence",
            "Electroluminescence",
            "Generative Adversarial Neural Networks",
            "Photovoltaics",
            "Synthetic Data"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "GANs for Privacy-Aware Mobility Modeling",
        "authors": "Fontana I.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2023.3260981",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85151511728",
        "scopus_id": "85151511728",
        "abstract": "Human mobility modeling is crucial for many facets of our society, including disease transmission modeling and urban planning. The explosion of mobility data prompted the application of deep learning to human mobility. Along with the growth of research interest, there is also increasing privacy concern. This study first examines the cutting-edge approaches for trajectory generation, classification, and next-location prediction. Second, we propose a novel privacy-aware approach for predicting next-week trajectories. The approach is based on two modules, a Generative Adversarial Network used for generating synthetic trajectories and a deep learning model for user identification which safeguards privacy. These two modules are combined with a next-week trajectory predictor that uses privacy-aware synthetic data. The experiments on two real-life datasets show that the generator creates trajectories similar to the real ones yet different enough to safeguard privacy. The low user-recognition recognition accuracy of models trained on the generated data demonstrates privacy awareness. Statistical tests confirm no significant difference between the original and the generated trajectories. We further demonstrate the utility of the synthetic data by predicting week-ahead trajectories based on the synthetic trajectories. Our study shows how privacy and utility can be managed jointly using the proposed privacy-aware approach.",
        "author_keywords": [
            "Deep learning",
            "generative adversarial networks",
            "location data",
            "machine learning",
            "mobility modeling",
            "privacy"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "Fine-Grained Urban Flow Inferring via Conditional Generative Adversarial Networks",
        "authors": "Zhang X.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-25201-3_32",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85151059930",
        "scopus_id": "85151059930",
        "abstract": "Urban flow super-resolution (UFSR) can deduce fine-grained urban flow heatmap (UFH) based on coarse-grained observations and plays an essential role in urban planning (traffic prediction, public facility deployment, for instance). However, existing methods fail to capture the internal structural features of sparse UFHs and the external factors that lead to a significant waste of urban resources. To this end, we propose an enhanced super-resolution framework (Urban Flow-aware Super Resolution - Generative Adversarial Network, UrbanSG) to deduce fine-grained UFH for urban resource allocation. Specifically, we employ a conditional-GAN as the backbone, considering external factors as the specified condition. To capture the implicit urban structural correlation, we integrate the flow self-attention mechanism into our model, which focuses on urban grids with active traffic volumes. The evaluations of extensive experiments on two real-world datasets demonstrate the superiority of our framework. Especially when dealing with a sparse dataset, our method reduces error by 15.02% to the state-of-the-art baselines.",
        "author_keywords": [
            "Attention mechanism",
            "Deep learning",
            "Super resolution",
            "Urban computing"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Abnormal human behavior detection based on VAE-LSTM hybrid model in WiFi CSI with PCA",
        "authors": "Kim Y.",
        "journal": "International Conference on Information Networking",
        "doi": "10.1109/ICOIN56518.2023.10048984",
        "publication_date": "2023",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85149180796",
        "scopus_id": "85149180796",
        "abstract": "Recently, It is easy to find network access points(APs), which can be used for more than simply connecting devices to the Internet. For example, the waveform of a WiFi signal changes when a human action is performed between the two APs. In previous research, we demonstrated how changes in an electric wave affect the channel state information of a signal and how deep learning can utilize this information to detect and predict human behavior. In this paper, we proposed a method to detect human behavior. The proposed method improves the performance of detection of human behavior and effective in a changing environment. We found that using a VAE-LSTM hybrid model with PCA is useful in terms of detecting abnormal human behavior Experimental results demonstrate that the proposed method can detect general abnormal behavior with >-79% overall precision in a changing environment.",
        "author_keywords": [
            "autoencoder",
            "CNN",
            "CSI",
            "IOT",
            "LSTM",
            "PCA",
            "RNN",
            "Smart City",
            "VAE"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Information Systems"
        ]
    },
    {
        "title": "An Individual Tree Segmentation Method From Mobile Mapping Point Clouds Based on Improved 3-D Morphological Analysis",
        "authors": "Wang W.",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "doi": "10.1109/JSTARS.2023.3243283",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85148465406",
        "scopus_id": "85148465406",
        "abstract": "Street tree extraction based on the 3-D mobile mapping point cloud plays an important role in building smart cities and creating highly accurate urban street maps. Existing methods are often over- or under-segmented when segmenting overlapping street tree canopies and extracting geometrically complex trees. To address this problem, we propose a method based on improved 3-D morphological analysis for extracting street trees from mobile laser scanner (MLS) point clouds. First, the 3-D semantic point cloud segmentation framework based on deep learning is used for preclassification of the original point cloud to obtain the vegetation point cloud in the scene. Considering the influence of terrain unevenness, the vegetation point cloud is deterraformed and slice point cloud containing tree trunks is obtained through spatial filtering on height. On this basis, a voxel-based region growing method constrained with the changing rate of convex area is used to locate the stree trees. Then we propose a progressive tree crown segmentation method, which first completed the preliminary individual segmentation of the tree crown point cloud based on the voxel-based region growth constrained by the minimum increment rule, and then optimizes the crown edges by 'valley' structure-based clustering. In this article, the proposed method is validated and the accuracy is evaluated using three sets of MLS datasets collected from different scenarios. The experimental results show that the method can effectively identify and localize street trees with different geometries and has a good segmentation effect for street trees with large adhesion between canopies. The accuracy and recall of tree localization are higher than 96.08% and 95.83%, respectively, and the average precision and recall of instance segmentation in three datasets are higher than 93.23% and 95.41%, respectively.",
        "author_keywords": [
            "Aquaculture ponds extraction",
            "diffusion model",
            "hyperspectral image",
            "image superresolution",
            "remote sensing",
            "unsupervised classification"
        ],
        "subject_areas": [
            "Computers in Earth Sciences",
            "Atmospheric Science"
        ]
    },
    {
        "title": "A novel machine learning-based framework for mapping outdoor thermal comfort",
        "authors": "Shahrestani S.S.",
        "journal": "Advances in Building Energy Research",
        "doi": "10.1080/17512549.2022.2152865",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85144026059",
        "scopus_id": "85144026059",
        "abstract": "Rapid urbanization and global warming have increased heat stress in urban areas. This in turn makes using indoor space more compelling and leads to more energy consumption. Therefore, paying attention to outdoor spaces design with thermal comfort in mind becomes more important since outdoor spaces can host a variety of activities. This research aims to introduce a machine learning-based framework to predict the effects of different urban configurations (i.e. different greening configurations and types, different façade materials, and different urban geometry) on outdoor thermal comfort through training a pix2pix Convolutional generative adversarial network (cGAN) model. For the training of the machine learning model, a dataset consisting of 208 coupled pictures of input and output has been created. The simulation of this data has been carried out by ENVI-met. The resulting machine learning model had a Structural Similarity Index (SSIM) of 96% on the test dataset with the highest SSIM of 97.08 and lowest of 94.43 which shows the high accuracy of the model and it could have reached an answer in 3 s compared to the 30-min average time for ENVI-met simulation. The resulting model shows great promise for assisting researchers and urban designers in studying existing urban contexts or planning new developments. HIGHLIGHTS Machine learning use in outdoor thermal comfort assessment has been investigated. Vegetation, urban geometry, surface albedo, and water bodies have been studied parameters. Vegetation and street orientation have the highest and water bodies have the least impact on outdoor thermal comfort. Pix2pix algorithm implementation could create thermal comfort maps with 96% SSIM.",
        "author_keywords": [
            "generative adversarial network",
            "Outdoor thermal comfort assessment",
            "pix2pix",
            "public space design",
            "thermal comfort map"
        ],
        "subject_areas": [
            "Building and Construction"
        ]
    },
    {
        "title": "Effects of urban form on sea cooling capacity under the heatwave",
        "authors": "Guo F.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2022.104271",
        "publication_date": "2023",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85141235791",
        "scopus_id": "85141235791",
        "abstract": "The sea is considered an important factor for ameliorating urban heat island effects in coastal cities, especially during heatwaves. Nevertheless, the mechanisms for urban form factors and sea cooling are poorly understood. To fill this gap, under the heatwave, coastline urban heat island intensity (CUI) was proposed to evaluate the cooling effect of the sea in Dalian (a coastal city in China), and combined with spatial autoregressive models to explore the impact of urban form factors on CUI. Results were as follows: 1) the sea showed the greatest cooling potential within a distance of 2.5 km, with a maximum cooling range of 9.2 km; 2) land cover factors had the strongest influence on CUI; 3) building average height and sky view factor in the offshore area had a prominent influence on CUI than inland; 4) distance to the coastline had obvious effect on CUI. Urban form affects the cooling capacity of the sea by affecting the surface temperature and the fluidity of the wind, which showed spatial heterogeneity. Above all, mitigation strategies were proposed, such as control of the underlying surface material, and the urban form should be dominated by low-density multistory/high-rise in the offshore.",
        "author_keywords": [
            "Heatwave",
            "Land Surface temperature",
            "Sea",
            "Spatial autoregressive model",
            "Urban form factors"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Embedded Vision Intelligence for the Safety of Smart Cities",
        "authors": "Martin J.",
        "journal": "Journal of Imaging",
        "doi": "10.3390/jimaging8120326",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85144591572",
        "scopus_id": "85144591572",
        "abstract": "Advances in Artificial intelligence (AI) and embedded systems have resulted on a recent increase in use of image processing applications for smart cities’ safety. This enables a cost-adequate scale of automated video surveillance, increasing the data available and releasing human intervention. At the same time, although deep learning is a very intensive task in terms of computing resources, hardware and software improvements have emerged, allowing embedded systems to implement sophisticated machine learning algorithms at the edge. Additionally, new lightweight open-source middleware for constrained resource devices, such as EdgeX Foundry, have appeared to facilitate the collection and processing of data at sensor level, with communication capabilities to exchange data with a cloud enterprise application. The objective of this work is to show and describe the development of two Edge Smart Camera Systems for safety of Smart cities within S4AllCities H2020 project. Hence, the work presents hardware and software modules developed within the project, including a custom hardware platform specifically developed for the deployment of deep learning models based on the I.MX8 Plus from NXP, which considerably reduces processing and inference times; a custom Video Analytics Edge Computing (VAEC) system deployed on a commercial NVIDIA Jetson TX2 platform, which provides high level results on person detection processes; and an edge computing framework for the management of those two edge devices, namely Distributed Edge Computing framework, DECIoT. To verify the utility and functionality of the systems, extended experiments were performed. The results highlight their potential to provide enhanced situational awareness and demonstrate the suitability for edge machine vision applications for safety in smart cities.",
        "author_keywords": [
            "artificial intelligence",
            "deep learning",
            "edge",
            "EdgeX Foundry",
            "embedded machine vision",
            "smart cities"
        ],
        "subject_areas": [
            "Radiology, Nuclear Medicine and Imaging",
            "Computer Vision and Pattern Recognition",
            "Computer Graphics and Computer-Aided Design",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Deep Learning-Based Path Loss Model in Urban Environments Using Image-to-Image Translation",
        "authors": "Juang R.T.",
        "journal": "IEEE Transactions on Antennas and Propagation",
        "doi": "10.1109/TAP.2022.3209229",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85139420453",
        "scopus_id": "85139420453",
        "abstract": "Ray-tracing techniques offer accurate predictions on path loss but suffer from high computational complexity. To have a fast and accurate path loss prediction, this article applies a deep learning-based image-to-image translation technique to construct a path loss model in urban environments. The proposed method combines a variational autoencoder with a generative adversarial network to translate images from the domain of street maps to the domain of path loss. It is trained in a supervised manner using paired samples, where the input is the street map with 3-D building information and the output is the path loss in the area obtained from the ray-tracing model. Based on a realistic digital map of urban Taipei city, simulation results show that the proposed model outperforms conventional ones when operating at the 3.5 GHz frequency band. The standard deviation of prediction error is reduced by over 62%. Besides prediction accuracy, the proposed model has the advantage of low computational complexity over ray-tracing techniques. Hence, it has great potential for the deployment of unmanned aerial vehicle-mounted base stations (UAV-BSs) for future communication systems. In this future work, the optimal UAV mobility can be determined upon the rapid evaluation of the UAV-BS coverage using the proposed model.",
        "author_keywords": [
            "Generative adversarial network (GAN)",
            "image-to-image translation",
            "path loss model",
            "variational autoencoder (VAE)"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Scaling of urban amenities: generative statistics and implications for urban planning",
        "authors": "Kaufmann T.",
        "journal": "EPJ Data Science",
        "doi": "10.1140/epjds/s13688-022-00362-6",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85137574296",
        "scopus_id": "85137574296",
        "abstract": "Cities have been extensively studied as complex adaptive systems over the last 50 years. Recently, several empirical studies and emerging theory provided support for the fact that many different urban indicators follow general consistent statistical patterns across countries, cultures and times. In particular, total personal income, measures of innovation, crime rates, characteristics of the built environment and other indicators have been shown to exhibit non-linear power-law scaling with the population size of functional cities. Here, we show how to apply this type of analysis inside cities to establish universal patterns in the quantity and distribution of urban amenities such as restaurants, parks, and universities. Using a unique data set containing millions of amenities in the 50 largest US metropolitan areas, we establish general non-linear scaling patterns between each city’s population and many different amenities types, the small-area statistics of their spatial abundance, and the characteristics of their mean distance to each other. We use these size-specific statistical findings to produce generative models for the expected amenity abundances of any US city. We then compute the deviations observed in given cities from this statistical many-amenity model to build a characteristic signature for each urban area. Finally, we show how urban planning can be guided by these systemic quantitative expectations in the context of new city design or the identification of local deficits in service provision in existing cities.",
        "author_keywords": [
            "Land use",
            "Planning support systems",
            "Service provision",
            "Spatial statistics",
            "Urban analytics"
        ],
        "subject_areas": [
            "Modeling and Simulation",
            "Computer Science Applications",
            "Computational Mathematics"
        ]
    },
    {
        "title": "GOF-TTE: Generative Online Federated Learning Framework for Travel Time Estimation",
        "authors": "Zhang Z.",
        "journal": "IEEE Internet of Things Journal",
        "doi": "10.1109/JIOT.2022.3190864",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85135216943",
        "scopus_id": "85135216943",
        "abstract": "Estimating the travel time of a path is an essential topic for the intelligent transportation system. It serves as the foundation for real-world applications, such as traffic monitoring, route planning, and taxi dispatching. However, building a model for such a data-driven task requires a large amount of users' travel information, which closely relates to their privacy and, thus, is less likely to be shared. The not independent and identically distributed (Non-IID) trajectory data across data owners also make a predictive model extremely challenging to be personalized if we directly apply federated learning. Finally, previous work on travel time estimation (TTE) does not consider the real-time traffic state of roads, which we argue, can significantly influence the prediction. To address the above challenges, we introduce GOF-TTE for the mobile user group, generative online federated learning framework for TTE, which 1) utilizes the federated learning approach, allowing private data to be kept on client devices while training, and designs the global model as an online generative model shared by all clients to infer the real-time road traffic state and 2) apart from sharing a base model at the server, adapts a fine-tuned personalized model for every client to study their personal driving habits, making up for the residual error made by localized global model prediction. We also employ a simple privacy attack to our framework and implement the differential privacy mechanism to guarantee privacy safety further. Finally, we conduct experiments on two real-world public taxi data sets of DiDi Chengdu and Xi'an. The experimental results demonstrate the effectiveness of our proposed framework.",
        "author_keywords": [
            "Federated learning",
            "travel time estimation (TTE)",
            "ubiquitous",
            "urban computing"
        ],
        "subject_areas": [
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Generative Personalized Federated Learning Framework for Travel Time Estimation",
        "authors": "Fan Z.",
        "journal": "SenSys 2022 - Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems",
        "doi": "10.1145/3560905.3568083",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85147544057",
        "scopus_id": "85147544057",
        "abstract": "Estimating the travel time of a given path is an important topic for the intelligent transportation system and serves as the foundation for various real-world applications. However, building an estimation model for such a data-driven task requires a large amount of mobile users' trajectory data which directly relates to their privacy and thus is less likely to be shared. Therefore, we propose GPF-TTE, Generative Personalized Federated Learning Framework for Travel Time Estimation (poster version of our previous work [1]) based on the issue of privacy protection for the mobile user group, in which 1) utilizes the federated learning approach, allowing private data to be kept on client devices while training, 2) apart from sharing a base model, we also adapt a fine-tuned personalized model for each client to study their personal driving habits, making up for the residual error caused by the prediction of the localized global model (the base model in local device), and 3) the cloud server aggregates localized models into the global model as a generative model to infer the future road traffic state.",
        "author_keywords": [
            "federated learning",
            "ubiquitous",
            "urban computing"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Control and Systems Engineering",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Factorized deep generative models for end-to-end trajectory generation with spatiotemporal validity constraints",
        "authors": "Zhang L.",
        "journal": "GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems",
        "doi": "10.1145/3557915.3560994",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85143617334",
        "scopus_id": "85143617334",
        "abstract": "A growing number of research areas such as location-based social networks, intelligent transportation systems, and urban computing utilize large amounts of trajectory data for benchmarking data management approaches and analysis methods. Given the general lackness of available large datasets, realistic synthetic trajectory datasets become important. This work proposes deep generative models for trajectory data that can learn disentangled models for sophisticated latent patterns. Existing methods rely on predefined heuristics and cannot learn the unknown underlying generative mechanisms. The proposed novel deep generative VAE-like models factorize global and local semantics (habits vs. random routing change). We further develop new inference strategies based on variational inference and constrained optimization to encapsulate spatiotemporal validity. New deep neural network architectures are developed to implement generative and inference models with dynamic latent priors. The proposed methods represent significant quantitative and qualitative improvements over existing approaches as demonstrated by extensive experiments. The software is made publicly available 1.",
        "author_keywords": [
            "deep generative models",
            "end-to-end trajectory generation",
            "spatiotemporal-validity constraint",
            "variational autoencoders"
        ],
        "subject_areas": [
            "Earth-Surface Processes",
            "Computer Science Applications",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Information Systems"
        ]
    },
    {
        "title": "Revealing the Impact of Urban Form on COVID-19 Based on Machine Learning: Taking Macau as an Example",
        "authors": "Chen Y.",
        "journal": "Sustainability (Switzerland)",
        "doi": "10.3390/su142114341",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85141877058",
        "scopus_id": "85141877058",
        "abstract": "The COVID-19 pandemic has led to a re-examination of the urban space, and the field of planning and architecture is no exception. In this study, a conditional generative adversarial network (CGAN) is used to construct a method for deriving the distribution of urban texture through the distribution hotspots of the COVID-19 epidemic. At the same time, the relationship between urban form and the COVID-19 epidemic is established, so that the machine can automatically deduce and calculate the appearance of urban forms that are prone to epidemics and may have high risks, which has application value and potential in the field of planning and design. In this study, taking Macau as an example, this method was used to conduct model training, image generation, and comparison of the derivation results of different assumed epidemic distribution degrees. The implications of this study for urban planning are as follows: (1) there is a correlation between different urban forms and the distribution of epidemics, and CGAN can be used to predict urban forms with high epidemic risk; (2) large-scale buildings and high-density buildings can promote the distribution of the COVID-19 epidemic; (3) green public open spaces and squares have an inhibitory effect on the distribution of the COVID-19 epidemic; and (4) reducing the volume and density of buildings and increasing the area of green public open spaces and squares can help reduce the distribution of the COVID-19 epidemic.",
        "author_keywords": [
            "CGAN",
            "influencing factors",
            "Macau",
            "machine learning",
            "urban form"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Building and Construction",
            "Environmental Science (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Block chain fostered cycle-consistent generative adversarial network framework espoused intrusion detection for protecting IoT network",
        "authors": "Sugitha G.",
        "journal": "Transactions on Emerging Telecommunications Technologies",
        "doi": "10.1002/ett.4578",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85132891049",
        "scopus_id": "85132891049",
        "abstract": "In smart city infrastructure, IoT networks contain intelligent devices for collecting and processing data using open channel internet. Some challenges have occurred in the existing methods while transferring the data, like centralism, safety, secrecy (data destroying, inference attacks), transparency, scalability, verification, and controlling the rapid adaptation of smart cities. To overcome these challenges, a machine learning based block chain method is proposed in this manuscript. The machine learning strategies can process massive datasets. Furthermore, they contain adequate generalization to identify various attack vectors. Here, the block chain fostered cycle-consistent generative adversarial network (CCGAN) framework espoused intrusion detection is proposed for protecting the IoT network. Also, a 3 level privacy model is introduced for protecting the IoT devices. The first level is block chain based privacy detection and the second level is CCGAN and the third level is classification. In first level, ToN-IoT, BoT-IoT datasets are taken to detect the IoT intrusion, these data's are given to the block chain to authenticate and to collect the data in the IoT devices in the smart cities and stored in the blocks present in the block chain. In second level, the feature mapping and feature selection are done. The normal and attacked instances are classified in level 3. The performance of the proposed method shows higher accuracy 25.37%, 29.57%, and 18.67%, higher recall 23.75%, 17.58%, and 14.68% better than the existing methods, like block chain and machine learning method based privacy protection in IoT using optimized gradient tree boosting system (IOT-BC-XGBoost), and block chain and machine learning method based privacy protection in IoT using deep gated recurrent neural network (IOT-BC-DGRNN), respectively.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Foreseeing private car transfer between urban regions with multiple graph-based generative adversarial networks",
        "authors": "Liu C.",
        "journal": "World Wide Web",
        "doi": "10.1007/s11280-021-00995-z",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85125564759",
        "scopus_id": "85125564759",
        "abstract": "Private car transfer indicates that people drive private cars and travel between urban regions to perform daily activities. Foreseeing private car transfer between urban regions can facilitate a broad scope of applications ranging from route planning, hot region discovery to urban computing. However, three challenges remain. i) Private car transfer between regions is affected by multiple spatio-temporal correlations. ii) Transfer records are highly sparse and imbalanced. iii) Modeling the stay duration of private cars. In this paper, we model private cars’ travel in urban regions as the spatio-temporal graph and formulate private car transfer foreseeing as the time-evolving adjacency matrix prediction of the graph. To specify, we propose MG-GAN (Multiple Graph-based Generative Adversarial Network) to predict private car transfer. For one thing, we design multi-graph dense convolutions with gated recurrent networks as the generative network to capture multiple spatio-temporal correlations. For another, the attentive multi-graph convolutional network is designed as the discriminative network to learn the stay duration correlations of private cars in each region. The iterative adversarial processes between generating and discriminating networks enhance the MG-GAN’s ability to tackle the sparse data problem. Besides, a topic clustering algorithm based on multi-source data fusion is proposed to balance the fused data. Extensive experiments on the real-world private car and taxi trip datasets demonstrate that MG-GAN performs better than the state-of-the-art baselines.",
        "author_keywords": [
            "Generative adversarial networks",
            "Mulitple graph",
            "Private car",
            "Spatio-temporal prediction",
            "Transfer flow"
        ],
        "subject_areas": [
            "Software",
            "Hardware and Architecture",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "3D building fabrication with geometry and texture coordination via hybrid GAN",
        "authors": "Du Z.",
        "journal": "Journal of Ambient Intelligence and Humanized Computing",
        "doi": "10.1007/s12652-020-02488-9",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85089864134",
        "scopus_id": "85089864134",
        "abstract": "3D building plays the essential role in digital city construction, city augmented reality and smart urban planning & design. Conventional building construction is accomplished by modeling software which requires significant human intervention. In this paper, a method of 3D building fabrication via Hybrid generative adversarial network (GAN) is proposed, in which a loss function with the introduction of cycle consistency loss and perceptual loss is given, a multi-properties GAN chain is built to create the building with complex architectures. Additionally, a mixed GAN network to generate the geometry and texture coordination is put forward. The discussed method can refine rough architectural models for outputting realistic buildings. Experiments show that generated 3D buildings utilizing the presented method are realistic, with geometry and textural consistency, which improves performance by 20% over traditional methods.",
        "author_keywords": [
            "3D building generation",
            "GAN chain",
            "Hybrid GAN",
            "multi-properties generation"
        ],
        "subject_areas": [
            "Computer Science (all)"
        ]
    },
    {
        "title": "TrajFormer: Efficient Trajectory Classification with Transformers",
        "authors": "Liang Y.",
        "journal": "International Conference on Information and Knowledge Management, Proceedings",
        "doi": "10.1145/3511808.3557481",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85140921372",
        "scopus_id": "85140921372",
        "abstract": "Transformers have been an efficient alternative to recurrent neural networks in many sequential learning tasks. When adapting transformers to modeling trajectories, we encounter two major issues. First, being originally designed for language modeling, transformers assume regular intervals between input tokens, which contradicts the irregularity of trajectories. Second, transformers often suffer high computational costs, especially for long trajectories. In this paper, we address these challenges by presenting a novel transformer architecture entitled TrajFormer. Our model first generates continuous point embeddings by jointly considering the input features and the information of spatio-temporal intervals, and then adopts a squeeze function to speed up the representation learning. Moreover, we introduce an auxiliary loss to ease the training of transformers using the supervision signals provided by all output tokens. Extensive experiments verify that our TrajFormer achieves a preferable speed-accuracy balance compared to existing approaches.",
        "author_keywords": [
            "trajectory classification",
            "transformer",
            "urban computing"
        ],
        "subject_areas": [
            "Business, Management and Accounting (all)",
            "Decision Sciences (all)"
        ]
    },
    {
        "title": "Accelerated environmental performance-driven urban design with generative adversarial network",
        "authors": "Huang C.",
        "journal": "Building and Environment",
        "doi": "10.1016/j.buildenv.2022.109575",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85143054602",
        "scopus_id": "85143054602",
        "abstract": "The morphological design of urban blocks greatly affects the outdoor environment. Currently, performance-based urban and building design relies on a time-consuming numerical simulation process, hindering performance optimization early in the design process. This paper proposes an automated design process that applies generative adversarial network (GAN) as a surrogate model to accelerate environmental performance-driven urban design. Parameterized urban blocks are designed for random sampling and constructing a numerical simulation database. The GAN model was trained to predict pedestrian level wind (PLW), annual cumulative solar radiation (Radiation) and Universal Thermal Climate Index (UTCI) in real-time. The GAN-based surrogate model is combined with a multi-objective genetic algorithm to achieve real-time optimization of urban morphology. The results show that on the test set, the pix2pix model using a specific encoding method predicts the R2 of 0.70, 0.86 and 0.80 for PLW, Radiation and UTCI, respectively, while the method can speed up 120–240 times compared to the numerical simulation method. The optimization results show that NSGA-II combined with global averaging pooling achieves the best optimization results. When the number of optimized samples exceeds 174, the proposed method has a time advantage over traditional methods for outdoor environment optimization in urban design.",
        "author_keywords": [
            "Generative adversarial network",
            "Genetic optimization",
            "Performance-driven design",
            "Surrogate model",
            "Urban block"
        ],
        "subject_areas": [
            "Environmental Engineering",
            "Civil and Structural Engineering",
            "Geography, Planning and Development",
            "Building and Construction"
        ]
    },
    {
        "title": "Coupling Coordination and Interactive Response Analysis of Ecological Environment and Urban Resilience in the Yangtze River Economic Belt",
        "authors": "Yang M.",
        "journal": "International Journal of Environmental Research and Public Health",
        "doi": "10.3390/ijerph191911988",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85139811592",
        "scopus_id": "85139811592",
        "abstract": "There is a complex dynamic coupling interaction process between the ecological environment and urban resilience. It is important to clarify the coordination relationship and interactive response mechanism between them for sustainable development construction of the Yangtze River Economic Belt. The coupling coordination degree model and the panel vector autoregressive model (PVAR) were adopted to quantitatively examine the dynamic coordination and interactive response of the ecological environment and urban resilience in the Yangtze River Economic Belt from 2000 to 2019. Our study’s results are the following: (1) The ecological environment index and urban resilience index have a generally positive trend of fluctuation and increase during the study period but show significant regional differentiation. (2) The coupling coordination degree of ecological environment and urban resilience in the Yangtze River Economic Belt increased steadily, forming a spatial distribution pattern of “strong in the east and weak in the west”, with cities in the region mainly at the basic coordination level and generally lagging behind in development. (3) Both the ecological environment and urban resilience systems in the Yangtze River Economic Belt have significant self-reinforcing mechanisms, but the reinforcing effect is gradually decreasing, and the two positively promote each other, with urban resilience showing a more obvious promoting effect on the ecological environment.",
        "author_keywords": [
            "coupling coordination",
            "ecological environment",
            "interactive response",
            "the Yangtze River Economic Belt",
            "urban resilience"
        ],
        "subject_areas": [
            "Pollution",
            "Public Health, Environmental and Occupational Health",
            "Health, Toxicology and Mutagenesis"
        ]
    },
    {
        "title": "Peer effects in local government decision-making: Evidence from urban environmental regulation",
        "authors": "Xu J.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2022.104066",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85134722932",
        "scopus_id": "85134722932",
        "abstract": "This paper is the first to introduce the theory of peer effects to explain the interactive behavior of urban environmental regulation (UER). We construct a spatial autoregressive (SAR) model including lagged terms of the dependent variable using panel data of 284 cities in China from 2003 to 2019. The results show that: (1) there are significant peer effects of UER among geographically, economically, and administratively related cities, and the highest peer effects is found among geographically adjacent cities. (2) Cities with higher intensity of environmental regulation have larger peer effects and are more likely to be imitated. (3) The internal learning effect of cities weakens the peer effects of UER, while the external learning effect and competition mechanism strengthen it. Exogenous shocks such as the new environmental regulation standard policy, innovation-oriented city pilot work, and the opening of high-speed rail all have a significant impact on the peer effects of UER. The study suggests the central government guides the positive interaction of local governments’ environmental regulations to promote regional pollution control.",
        "author_keywords": [
            "Competition effect",
            "Exogenous shocks",
            "Learning effect",
            "Peer effects",
            "Spatial autoregressive model",
            "Urban environmental regulation"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "An edge detection–based eGAN model for connectivity in ambient intelligence environments",
        "authors": "Lee C.Y.",
        "journal": "Journal of Ambient Intelligence and Humanized Computing",
        "doi": "10.1007/s12652-021-03261-2",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85104124304",
        "scopus_id": "85104124304",
        "abstract": "In generative adversarial networks (GANs), a generator network and discriminator network compete in deep learning tasks to generate real images. To reduce the difference between the generated image and actual image, an edge GAN (eGAN) model using edge detection was proposed. This eGAN model can utilize ambient intelligence, a human-centered technology that includes IoT, smart cities, and autonomous driving. Ambient intelligence is essential for the interconnection between humans and objects. The eGAN model was used to make this connectivity more accurate and reliable. Edge detection is an edge feature that extracts the boundaries of an image and generate images in a fast manner; however, because its threshold is arbitrarily set, the connectivity may be unstable. To solve this problem and improve the performance of the eGAN model, we analyzed various GAN models and edge detection methods and proposed a new edge detection technology using threshold settings. This edge detection method sets the threshold value for images, thereby increasing the accuracy of edge connection and reducing the loss error between the image generated by the eGAN model and actual image. To evaluate the performance of the eGAN model, the error between the generated image and actual image was compared by applying the GAN and eGAN models to the same image dataset. Consequently, it was found that the performance of the eGAN model improved by 21% in comparison to the existing GAN model.",
        "author_keywords": [
            "Ambient intelligence",
            "Edge detection",
            "EGAN",
            "Generative adversarial networks",
            "Smart cities",
            "Threshold"
        ],
        "subject_areas": [
            "Computer Science (all)"
        ]
    },
    {
        "title": "Understanding land take in small and medium-sized cities through scenarios of shrinkage and growth using autoregressive models",
        "authors": "Jaoude G.A.",
        "journal": "Frontiers in Built Environment",
        "doi": "10.3389/fbuil.2022.908698",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85139462696",
        "scopus_id": "85139462696",
        "abstract": "Rapid transitions induced by migration flows and socio-economic developments brought about massive changes in urbanization processes and resulted in increasingly uncertain futures. The implications and complexities of the ensuing urbanization patterns are difficult to predict and project into the future. While most studies are focused on large cities and major urban centers, urbanization processes in small and medium-sized cities have garnered little scholarly and political attention. To understand future urbanization patterns, we used the TOPOI method, a novel approach for classifying territorial settlements, and spatial autoregressive models to examine contrasting futures of population growth and shrinkage in one small and one medium-sized city in Lower Saxony, Germany. Results revealed that despite planning frameworks, high population density and functional mix, respectively, were insufficient mechanisms to reduce land take. Contrary to current assumptions on the functional mix of small and medium-sized towns, our findings showed that more than half of the settlements across the study area accommodated three or more functions. Since the share of residential buildings and functional mix strongly influenced land take, further research is needed to understand their implications on sustainable urban planning. Shrinking towns in Lower Saxony continue to present multidimensional challenges and emphasize the need for transforming local planning cultures and institutional frameworks to sustainably manage and repurpose these potentially vacant areas.",
        "author_keywords": [
            "demographic change",
            "Germany",
            "spatial regression models",
            "TOPOI method",
            "urbanization patterns"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Building and Construction",
            "Urban Studies"
        ]
    },
    {
        "title": "Forecasting fine-grained city-scale cellular traffic with sparse crowdsourced measurements",
        "authors": "Duan J.H.",
        "journal": "Computer Networks",
        "doi": "10.1016/j.comnet.2022.109156",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85134563079",
        "scopus_id": "85134563079",
        "abstract": "With the rapid development of wireless technology and the edge computing applications, an increasing number of 4G/5G infrastructure are densely deployed to meet the booming cellular traffic demands. Monitoring and forecasting urban cellular traffic is fundamental for urban planning, network resources allocation, traffic engineering, etc. In this paper, we address the crowdsourcing-based urban cellular traffic prediction problem, i.e., to predict the city-scale fine-grained cellular traffic patterns based on partial user-generated measurements. We propose a novel deep generative adversarial network (GAN) model called CrowdGAN to solve the problem. Specifically, CrowdGAN employs a convolutional Long Short-Term Memory (LSTM) network to extract spatio-temporal features from sparse traffic maps, and adopts a novel design of co-training a generator and a discriminator under the supervision of an accuracy assurance network to generate a high-resolution cellular traffic map for prediction. We implement the proposed CrowdGAN in TensorFlow and evaluate its performance using two real-world cellular traffic datasets. Extensive experiments show that CrowdGAN significantly outperforms the baselines on a variety of performance metrics, and achieves at least 47% reduction in root-mean-squared error compared to the state-of-the-art.",
        "author_keywords": [
            "Cellular traffic prediction",
            "Crowdsourcing-based measurement",
            "Deep learning",
            "Generative adversarial network (GAN)"
        ],
        "subject_areas": [
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "An Integrated Spatial Autoregressive Model for Analyzing and Simulating Urban Spatial Growth in a Garden City, China",
        "authors": "Qiu B.",
        "journal": "International Journal of Environmental Research and Public Health",
        "doi": "10.3390/ijerph191811732",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85138440415",
        "scopus_id": "85138440415",
        "abstract": "In the past, the research on models related to urban land-use change and prediction was greatly complicated by the high precision of models. When planning some garden cities, we should explore a more applicable, specific, and effective macro approach than the community-level one. In this study, a model consisting of spatial autoregressive (SAR), cellular automata (CA), and Markov chains is constructed. One It can well-consider the spatial autocorrelation and integrate the advantages of CA into a geographical simulation to find the driving forces behind the expansion of a garden city. This framework has been applied to the urban planning and development of Chengdu, China. The research results show that the application of the SAR model shows the development trend in the southeast region and the needs to optimize the central region and protect the western region as an ecological reserve. The descriptive statistics and the spatial autocorrelation of the residuals are reliable. The influence of spatial variables from strong to weak is distance to water, slope, population density, GDP, distance to main roads, distance to railways, and distance to the center of the county (district). Taking 2005 as the initial year, the land-use situation in 2015 was simulated and compared with the actual land-use situation. It seems that the Kappa coefficient of the construction-land simulation is 0.7634, with high accuracy. Therefore, the land use in 2025 and 2035 is further simulated, which provides a reference for garden cities to formulate a reasonable urban space development strategy.",
        "author_keywords": [
            "cellular automata",
            "Chengdu",
            "GIS",
            "spatial autoregressive",
            "urban spatial growth simulation"
        ],
        "subject_areas": [
            "Pollution",
            "Public Health, Environmental and Occupational Health",
            "Health, Toxicology and Mutagenesis"
        ]
    },
    {
        "title": "Generative Adversarial Networks in the built environment: A comprehensive review of the application of GANs across data types and scales",
        "authors": "Wu A.N.",
        "journal": "Building and Environment",
        "doi": "10.1016/j.buildenv.2022.109477",
        "publication_date": "2022",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85136502357",
        "scopus_id": "85136502357",
        "abstract": "Generative Adversarial Networks (GANs) are a type of deep neural network that have achieved many state-of-the-art results for generative tasks. GANs can be useful in the built environment, from processing large-scale urban mobility data and remote sensing images at the regional level, to performance analysis and design generation at the building level. We analyzed 100 articles to provide a comprehensive state-of-the-art review on how GANs are currently applied to solve challenging tasks in the built environment. Our results show that: (i) GANs are replacing older methods in some problems and setting state-of-the-art performances; (ii) GANs are opening new frontiers in previously overlooked problems, such as automatically generating spatially accurate floorplan layouts; (iii) GANs can be applied to different scales in the built environment, from entire cities to neighborhoods and buildings; and (iv) GANs are being used in a variety of problems and data types, from remote sensing data augmentation, vector data generation, spatio-temporal data privacy protection, to building design generation. In total, there are 26 unique application domains enabled by GANs; (v) however, one common challenge in this field currently is the lack of high-quality datasets curated specifically for problems in the built environment. With more data in the future, GANs could potentially produce even better results than today.",
        "author_keywords": [
            "Generative design",
            "GeoAI",
            "Machine learning",
            "Urban AI",
            "Urban planning"
        ],
        "subject_areas": [
            "Environmental Engineering",
            "Civil and Structural Engineering",
            "Geography, Planning and Development",
            "Building and Construction"
        ]
    },
    {
        "title": "A framework for human-computer interactive street network design based on a multi-stage deep learning approach",
        "authors": "Fang Z.",
        "journal": "Computers, Environment and Urban Systems",
        "doi": "10.1016/j.compenvurbsys.2022.101853",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85134359698",
        "scopus_id": "85134359698",
        "abstract": "Limited attention has been given to human-computer interactions in the plan-making process to capitalize on the relative strengths of both. This paper proposes a methodological framework for an interactive street network design that complements user-driven (i.e., procedural-based tools) and example-driven (i.e., learning-based tools) approaches in urban planning and design. The proposed framework consists of three components: (1) a data preparation module to link open-source road networks with human-labeled planning guidance, (2) a multi-stage deep learning (MSDL) model to reinforce the user-defined guidance in the automatic generation of street networks, and (3) a human-computer interaction (HCI) interface to enable the progressive design process. The performance and the working mechanism of the proposed framework were examined through experiments in four European cities (i.e., Amsterdam, Barcelona, Berlin, and Prague). The experiments demonstrate that the proposed MSDL model can achieve a better predictive performance compared to benchmark models, particularly when limited planning guidance is given. These finding are revealed using either computer vision- or street network-related metrics. With less than 40% of the ground truth planning guidance used as an input, the MSDL model can perform as well as other models using 100% of the information. Furthermore, when embedded within an HCI system for user trials, the model can facilitate a human-computer collaborative design process. This advantage is derived from the model's ability to provide initial prototypes, timely responses to changed guidance, and quantifiable evaluations of the generated proposals. Suitable for professionals and laypersons, the proposed tool can inform plan-making and public engagement by offering realistic, enriched, and human-centered spatial proposal alternatives for comparison.",
        "author_keywords": [
            "Computer vision",
            "Generative adversarial network",
            "Human-computer interaction",
            "Planning support systems",
            "Street network generation"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Ecological Modeling",
            "Environmental Science (all)",
            "Urban Studies"
        ]
    },
    {
        "title": "Generative population synthesis for joint household and individual characteristics",
        "authors": "Aemmer Z.",
        "journal": "Computers, Environment and Urban Systems",
        "doi": "10.1016/j.compenvurbsys.2022.101852",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85133765463",
        "scopus_id": "85133765463",
        "abstract": "Household surveys provide immense value in the fields of transportation and urban planning. However, even the most well-funded surveying agencies rely on sampling methods to estimate the nature of the true population, and the collected microdata is frequently aggregated, or limited in volume and detail to protect the privacy of respondents. Population synthesis provides a means to scale this microdata to represent larger regions for use in microsimulation. Despite their accuracy and widespread adoption, traditional synthesis algorithms for reweighting microdata samples scale poorly with the number of variables and geographic regions being modeled, and can suffer from non-convergence with smaller sample sizes. Several generative models have been proposed to address these shortcomings, but lack features such as sub-region modeling, and the ability to simultaneously generate both individuals and households. This work proposes an extension to recent generative approaches capable of generating synthetic populations consisting of both individual and household-level variables, that uses a two-part Variational Autoencoder (VAE) and Conditional-VAE (CVAE) to learn a distribution of latent variables in the general population, and use them to generate new samples. This can help in synthesizing smaller, traditionally under-sampled groups. This approach is benchmarked against a state of the art open source population synthesizer. In addition, the VAE/CVAE model is tested under increasingly minimal training data. Findings indicate the VAE/CVAE model creates more accurate populations, using less time than the traditional synthesizer under small to medium dimensional datasets (4–16 variables). The VAE/CVAE also performs well with few (n = 100) training samples, with diminishing returns for additional training samples.",
        "author_keywords": [
            "Conditional variational autoencoder",
            "Generative",
            "Machine learning",
            "Population synthesis"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Ecological Modeling",
            "Environmental Science (all)",
            "Urban Studies"
        ]
    },
    {
        "title": "MetroGAN: Simulating Urban Morphology with Generative Adversarial Network",
        "authors": "Zhang W.",
        "journal": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "doi": "10.1145/3534678.3539239",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85137144337",
        "scopus_id": "85137144337",
        "abstract": "Simulating urban morphology with location attributes is a challenging task in urban science. Recent studies have shown that Generative Adversarial Networks (GANs) have the potential to shed light on this task. However, existing GAN-based models are limited by the sparsity of urban data and instability in model training, hampering their applications. Here, we propose a GAN framework with geographical knowledge, namely Metropolitan GAN (MetroGAN), for urban morphology simulation. We incorporate a progressive growing structure to learn hierarchical features and design a geographical loss to impose the constraints of water areas. Besides, we propose a comprehensive evaluation framework for the complex structure of urban systems. Results show that MetroGAN outperforms the state-of-the-art urban simulation methods by over 20% in all metrics. Inspiringly, using physical geography features singly, MetroGAN can still generate shapes of the cities. These results demonstrate that MetroGAN solves the instability problem of previous urban simulation GANs and is generalizable to deal with various urban attributes.",
        "author_keywords": [
            "generative adversarial networks",
            "urban morphology simulation"
        ],
        "subject_areas": [
            "Software",
            "Information Systems"
        ]
    },
    {
        "title": "FEDGAN-IDS: Privacy-preserving IDS using GAN and Federated Learning",
        "authors": "Tabassum A.",
        "journal": "Computer Communications",
        "doi": "10.1016/j.comcom.2022.06.015",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85132917957",
        "scopus_id": "85132917957",
        "abstract": "Federated Learning (FL) is a promising distributed training model that aims to minimize the data sharing to enhance privacy and performance. FL requires sufficient and diverse training data to build efficient models. Lack of data balance as seen in rare classes affects the model accuracy. Generative Adversarial Networks (GAN) are remarkable in data augmentation to balance the available training data. In this article, we propose a novel Federated Deep Learning (DL) Intrusion Detection System (IDS) using GAN, named FEDGAN-IDS, to detect cyber threats in smart Internet of Things (IoT) systems; smarthomes, smart e-healthcare systems and smart cities. We distribute the GAN network over IoT devices to act as a classifier and train using augmented local data. We compare the convergence and accuracy of our model with other federated intrusion detection models. Extensive experiments with multiple datasets demonstrates the effectiveness of the proposed FEDGAN-IDS. The model performs better and converges earlier than the state-of-the-art standalone IDS.",
        "author_keywords": [
            "Deep Learning (DL)",
            "Federated Learning (FL)",
            "Generative Adversarial Network (GAN)",
            "Internet of Things (IoT)",
            "Intrusion Detection System (IDS)"
        ],
        "subject_areas": [
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "High-resolution spatial analysis for the air quality regulation service from urban vegetation: A case study of Taipei City",
        "authors": "Chen H.S.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2022.103976",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85131958822",
        "scopus_id": "85131958822",
        "abstract": "Rapid economic growth has caused air pollution, particularly in city areas. Removing air pollutants generated by various emission sources is crucial to control PM2.5, improve air quality, and maintain human health in high-density urban areas. In response to air pollution, urban vegetation plays an essential role in providing air quality regulation service. To estimate the air quality regulation service provided by urban vegetation, this study integrated spatial analysis, a dry deposition model, and an atmospheric diffusion model to spatially quantify the air quality regulation service of PM2.5 in Taipei City on a high-resolution scale (30 m × 30 m per spatial unit). The results show that in 2016, total PM2.5 emissions in Taipei City were 1,400.88 tonnes and that urban vegetation removed 18.31 tonnes of PM2.5, with an average PM2.5 removal rate of 0.16 g/m2, and the corresponding PM2.5 concentration improvement value of 0.0136 μg/m3. This finding revealed a significant gap between the amounts of emissions and purifications of PM2.5, the air quality regulation service provided by the urban vegetation in Taipei City remains insufficient. The results of this study not only point out the spatial differences of regulation services and propose a new research framework for quantifying the natural benefits, but also as a guideline for governments to form the auxiliary policies of the urban ecosystem service and facilitate the urban green infrastructure planning.",
        "author_keywords": [
            "Air quality regulation service",
            "GIS",
            "PM2.5",
            "Taipei City",
            "Urban vegetation"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Off-Deployment Traffic Estimation-A Traffic Generative Adversarial Networks Approach",
        "authors": "Zhang Y.",
        "journal": "IEEE Transactions on Big Data",
        "doi": "10.1109/TBDATA.2020.3014511",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85089397725",
        "scopus_id": "85089397725",
        "abstract": "The rapid progress of urbanization has expedited the process of urban planning, e.g., new residential, commercial areas, which in turn boosts the local travel demand. We propose a novel 'off-deployment traffic estimation problem', namely, to foresee the traffic condition changes of a region prior to the deployment of a construction plan. This problem is important to city planners to evaluate and develop urban deployment plans. However, this task is challenging. Traditional traffic estimation approaches lack the ability to solve this problem, since no data about the impact can be collected before the deployment and old data fails to capture the traffic pattern changes. In this paper, we define the off-deployment traffic estimation problem as a traffic generation problem, and develop a novel deep generative model TrafficGAN that captures the shared patterns across spatial regions of how traffic conditions evolve according to travel demand changes and underlying road network structures. In particular, TrafficGAN captures the road network structures through a dynamic filter in the dynamic convolutional layer. We evaluate our TrafficGAN using a large-scale traffic data collected from Shenzhen, China. Results show that TrafficGAN can more accurately estimate the traffic conditions compared with all baselines. We also showcase that TrafficGAN can identify potential traffic issues in some regions and suggest possible reasons.",
        "author_keywords": [
            "Generative model",
            "Traffic estimation",
            "TrafficGAN"
        ],
        "subject_areas": [
            "Information Systems",
            "Information Systems and Management"
        ]
    },
    {
        "title": "Towards a sustainable monitoring: A self-powered smart transportation infrastructure skin",
        "authors": "Zheng Q.",
        "journal": "Nano Energy",
        "doi": "10.1016/j.nanoen.2022.107245",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85129566278",
        "scopus_id": "85129566278",
        "abstract": "Sustainable monitoring of traffic using clean energy supply has always been a significant problem for engineers. In this study, we proposed a self-powered smart transportation infrastructure skin (SSTIS) as an innovative and bionic system for the traffic classification of a smart city. This system incorporated the self-powered flexible sensors with net-zero power consumption based on the Triboelectric Nanogenerator (TENG) and an intelligent analysis system based on artificial intelligence (AI). The feasibility of the SSTIS was tested using the full-scale accelerated pavement tests (APT) and the long-short term memory (LSTM) deep learning model with a vehicle axle load classification accuracy up to 89.06%. This robust SSTIS was later tested on highway and collected around 869,600 pieces of signals data. The generative adversarial networks (GAN) WGAN-GP (Wasserstein GAN - Gradient Penalty) was used for data augmentation, due to the imbalanced data of different vehicle types in actual traffic. The overall accuracy for on-road vehicle type classification improved to 81.06% using the convolutional neural network ResNet. Finally, we developed a mobile traffic signal information monitoring system based on cloud platform and Android framework, which enabled engineers to obtain the vehicle axle-load information mobilely. This study is the emerging design and engineering application of the self-powered flexible sensors for smart traffic monitoring, which provides a significant advance for intelligent transportation and smart cities in future.",
        "author_keywords": [
            "Bionic",
            "Flexible sensor",
            "Smart cities",
            "Smart transportation infrastructure skin",
            "TENG"
        ],
        "subject_areas": [
            "Renewable Energy, Sustainability and the Environment",
            "Materials Science (all)",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Spatiotemporal Tensor Completion for Improved Urban Traffic Imputation",
        "authors": "Ben Said A.",
        "journal": "IEEE Transactions on Intelligent Transportation Systems",
        "doi": "10.1109/TITS.2021.3062999",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85102709133",
        "scopus_id": "85102709133",
        "abstract": "Effective management of urban traffic is important for any smart city initiative. Therefore, the quality of the sensory traffic data is of paramount importance. However, like any sensory data, urban traffic data are prone to imperfections leading to missing measurements. In this paper, we focus on inter-region traffic data completion. We model the inter-region traffic as a spatiotemporal tensor that suffers from missing measurements. To recover the missing data, we propose an enhanced CANDECOMP/PARAFAC (CP) completion approach that considers the urban and temporal aspects of the traffic. To derive the urban characteristics, we divide the area of study into regions. Then, for each region, we compute urban feature vectors inspired from biodiversity which are used to compute the urban similarity matrix. To mine the temporal aspect, we first conduct an entropy analysis to determine the most regular time-series. Then, we conduct a joint Fourier and correlation analysis to compute its periodicity and construct the temporal matrix. Both urban and temporal matrices are fed into a modified CP-completion objective function. To solve this objective, we propose an alternating least square approach that operates on the vectorized version of the inputs. We conduct comprehensive comparative study with two evaluation scenarios. In the first one, we simulate random missing values. In the second scenario, we simulate missing values at a given area and time duration. Our results demonstrate that our approach provides effective recovering performance reaching 26% improvement compared to state-of-art CP approaches and 35% compared to state-of-art generative model-based approaches.",
        "author_keywords": [
            "CANDECOMP/PARAFAC",
            "tensor completion",
            "Traffic tensor"
        ],
        "subject_areas": [
            "Automotive Engineering",
            "Mechanical Engineering",
            "Computer Science Applications"
        ]
    },
    {
        "title": "Trajectory Prediction in Complex Scenes Based on Multi-Head Attention Adversarial Mechanism",
        "authors": "Yu L.",
        "journal": "Jisuanji Xuebao/Chinese Journal of Computers",
        "doi": "10.11897/SP.J.1016.2022.01133",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85132321130",
        "scopus_id": "85132321130",
        "abstract": "Pedestrian trajectory prediction plays a vital role in intelligent city construction and public crisis management. Distinct from the single trajectory prediction which rely on strong temporal correlation, in the complex scenes, the trajectory reflects not only the temporal characteristics of a single person, but the interactive features between human and other moving objects nearby. Therefore, how to deeply describe such temporality and interactivity, and then to generate accurate trajectory prediction results according to the change of the scene has become a major problem in the field of trajectory prediction today. In recent years, deep learning has attracted great attention and achieved success in the trajectory prediction tasks. However, most of these methods capture the influence between pedestrians from a single view, and they fail to consider the multiple factors which have an effect on the decision of pedestrians, such as going straight or turning. To this end, in this paper, we propose a multi-head attention generative adversarial model (MAGAM) which combines the multi-head attention mechanism and the generative adversarial network to model the pedestrian trajectory in the complex scenes. Specifically, the MAGAM model employs multi-head attention mechanism with relative displacement information to learn the attentive weight of subspace features in the whole trajectory feature space on different aspects, to realize the characterization of the interactive trajectory features that resulting from mutual influence between pedestrians. Moreover, the adversarial generation strategy and multi-trajectory generation strategy are used to achieve the reasonable generation of individual moving trajectory in the complex scenes. During the training process, the generator firstly extracts the personalized temporal features of pedestrians from historical observation sequences with long short-term memory (LSTM) based encoders. Secondly, the locations of pedestrians and temporal features are integrated into the multi-head attention model to learn the different weights and output the interactive state of the pedestrians. Thirdly, the interactive states and the Gaussian noise are fed into the LSTM-based decoders to generate multiple prediction trajectories. Then the discriminators are employed to judge whether the input trajectory belongs to the truth trajectory or generated trajectory as much as possible. By training with the adversarial mechanism, we could obtain the approximate truth results when modeling convergences. Finally, in order to estimate the performance of the proposed model, we conduct the experiments on two public datasets (ETH and UCY) which are widely used in the trajectory prediction tasks. We evaluate the prediction results based on three evaluation indicators: the average displacement error, the final displacement error, and the average no-linear displacement error. Compared with the existing trajectory prediction methods, the three metrics of the MAGAM model on all the datasets reduced by 26.90%, 21.02% and 24.06% on average. And the prediction results and the interactive scenes among pedestrians are visualized and analyzed which demonstrates the rationality of the results. Additionally, the performance of the MAGAM model including the average convergence accuracy, the average convergence time and the average prediction time is verified through related experiments, compared with the baselines, the MAGAM model gets the longest convergence time and prediction time.",
        "author_keywords": [
            "Adversarial generation",
            "Complex scenes",
            "Multi-head attention",
            "Positional encoding",
            "Trajectory prediction"
        ],
        "subject_areas": [
            "Software",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Computer Graphics and Computer-Aided Design"
        ]
    },
    {
        "title": "Deep Transfer Learning Across Cities for Mobile Traffic Prediction",
        "authors": "Wu Q.",
        "journal": "IEEE/ACM Transactions on Networking",
        "doi": "10.1109/TNET.2021.3136707",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85122085786",
        "scopus_id": "85122085786",
        "abstract": "Precise citywide mobile traffic prediction is of great significance for intelligent network planning and proactive service provisioning. Current traffic prediction approaches mainly focus on training a well-performed model for the cities with a large amount of mobile traffic data. However, for the cities with scarce data, the prediction performance will be greatly limited. To tackle this problem, in this paper we propose a novel cross-city deep transfer learning framework named CCTP for citywide mobile traffic prediction in cities with data scarcity. Specifically, we first present a novel spatial-temporal learning model and pre-train the model by abundant data of a source city to obtain prior knowledge of mobile traffic dynamics. We then devise an efficient generative adversarial network (GAN) based cross-domain adapter for distribution alignment between target data and source data. To deal with data scarcity issue in some clusters of target city, we further design an inter-cluster transfer learning strategy for performance enhancement. Extensive experiments conducted on real-world mobile traffic datasets demonstrate that our proposed CCTP framework can achieve superior performance in citywide mobile traffic prediction with data scarcity.",
        "author_keywords": [
            "Citywide mobile traffic prediction",
            "cross-city learning",
            "data scarcity",
            "domain adaptation",
            "transfer learning"
        ],
        "subject_areas": [
            "Software",
            "Computer Science Applications",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Internet of things-based deeply proficient monitoring and protection system for crop field",
        "authors": "Prabu A.V.",
        "journal": "Expert Systems",
        "doi": "10.1111/exsy.12876",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85119273476",
        "scopus_id": "85119273476",
        "abstract": "The production rate of crops is significantly declining due to natural disasters, animal interventions and plant diseases. Internet of things (IoT) and wireless sensor networks are widely applied in crop field monitoring systems to observe the quality of each plant and the field. This work proposes IoT based crop field protection system (ICFPS) that monitors and protects the crop fields from animal intrusions. This proposed system uses ultrasonic sensors, hyperspectral cameras, voice recorded buzzers and other agriculture sensors to protect the entire crop field. This system uses numerous sensor nodes and cameras for gathering field objects (images and environmental objects). The proposed ICFPS creates deep learning techniques such as recurrent convolutional neural networks (RCNN) and recurrent generative adversarial neural networks (RGAN) for feature extraction, disease detection and field data monitoring practices. This proposed work develops a smart city-based agriculture system using cognitive learning approaches. This proposed system analyses crop field data and provide automatic alerts regarding animal interferences and crop diseases. Moreover, the cognitive smart crop field system observes various field conditions which support for good production rate. In this system, sensors and camera-enabled agriculture drones are coordinated with each other to collect the field data regularly. At the same time, the proposed work trains the RCNN and RGAN units using effective crop field datasets to attain realistic decisions within minimal time intervals. The experiment details and results show the proposed ICFPS works with 8%–10% of more classification accuracy than existing systems.",
        "author_keywords": [
            "cognitive smart systems",
            "crop field",
            "deep learning and data analysis",
            "internet of things",
            "smart cities",
            "wireless sensor networks"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Theoretical Computer Science",
            "Computational Theory and Mathematics",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "A survey of person re-identification based on deep learning",
        "authors": "Li Q.",
        "journal": "Gongcheng Kexue Xuebao/Chinese Journal of Engineering",
        "doi": "10.13374/j.issn2095-9389.2020.12.22.004",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127765392",
        "scopus_id": "85127765392",
        "abstract": "Person re-identification is an important part of multi-target tracking across cameras; its aim is to identify the same person across different cameras. Given a query image, the purpose of person re-identification is to find the best match for the query image in an image set. Person re-identification is a key component in an intelligent security system; it is beneficial for building a smart bank or smart factory and plays a crucial role in the construction of a smart city. Nowadays, with the development of artificial intelligence and increasing demand for precise identification in practical scenarios, deep learning-based person re-identification technology has become a popular research topic; this technology has achieved state-of-the-art results in comparison with conventional approaches. Although there are many recently proposed networks with stronger representation ability and a high level of accuracy for person re-identification, there also exist some problems that should be considered and solved. These include the insufficient generalization ability of various poses, the inability to fully utilize the temporal information, and the ineffective identification of occluded objects. As a result, many scholars have researched this field and have pointed out some promising solutions to cope with the aforementioned problems. This paper aims to summarize the application of deep learning in the field of person re-identification along with its advantages and shortcomings. First, the background of person re-identification is introduced, including the application scenarios, datasets, and evaluation indicators. Additionally, some basic methods of person re-identification based on deep learning are summarized. According to the existing research on person re-identification, the main approaches proposed by scholars worldwide can be summarized into four aspects, which are based on local features, generative adversarial networks, video data, and re-ranking. A detailed comparative study of these four methods is then conducted. Finally, the existing problems and future studies that can be done in the field of person re-identification are analyzed and discussed.",
        "author_keywords": [
            "Deep learning",
            "Generating adversarial networks",
            "Local feature",
            "Person re-identification",
            "Reranking",
            "Video data"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Super-resolution research on remote sensing images in the megacity based on improved srgan",
        "authors": "Xin L.",
        "journal": "ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",
        "doi": "10.5194/isprs-Annals-V-3-2022-603-2022",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85132009410",
        "scopus_id": "85132009410",
        "abstract": "Remote sensing images of Earth observation with high spatial resolution and high temporal resolution are critical for the application of remote sensing technology in Megacities.With the development of Smart City,more demands which are still difficult to be perfectly satisfied on the spatial resolution and temporal resolution of remote sensing images have been put forward.This paper studies the use of SRGAN which means Super-Resolution using a Generative Adversarial Network (a network structure that uses the loss function considering the perceptual loss and the adversarial loss to improve the spatial resolution of remote sensing images) for super-resolution reconstruction of single remote sensing image.It is able to enhance the spatial resolution of remote sensing images and improve the depth and breadth of remote sensing images.We adjust the reasonable parameters and network structure for our research by analysing the SRGAN in the network architecture, the perceptual loss and the adversarial loss.A super-resolution model is obtained by training with aerial photogrammetry images whose spatial resolution are 0.1 meter in Shanghai.We find the improved SRGAN has a good performance in in remote sensing image super-resolution by comparing the super-resoved images with real high-resolution images in visual perception, spatial position mapping accuracy and chromaticity spatial information. In addition, it is proved that the trained model is also effective to deal with Worldview-2 and SuperView-1 satellite images whose spatial resolution are 0.5 m. Our research shows that our method which can effectively realize the super-resolution of remote sensing images has great potential in the application of remote sensing technology such as urban mapping and changes monitoring.",
        "author_keywords": [
            "Deeplearning",
            "High resolution satellite imagery",
            "SRGAN",
            "Super resolution",
            "Urban Remote Sensing"
        ],
        "subject_areas": [
            "Instrumentation",
            "Environmental Science (miscellaneous)",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Traffic Request Generation through a Variational Auto Encoder Approach",
        "authors": "Chiesa S.",
        "journal": "Computers",
        "doi": "10.3390/computers11050071",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85129992088",
        "scopus_id": "85129992088",
        "abstract": "Traffic and transportation forecasting is a key issue in urban planning aimed to provide a greener and more sustainable environment to residents. Their privacy is a second key issue that requires synthetic travel data. A possible solution is offered by generative models. Here, a variational autoencoder architecture has been trained on a floating car dataset in order to grasp the statistical features of the traffic demand in the city of Rome. The architecture is based on multilayer dense neural networks for encoding and decoding parts. A brief analysis of parameter influence is conducted. The generated trajectories are compared with those in the dataset. The resulting reconstructed synthetic data are employed to compute the traffic fluxes and geographic distribution of parked cars. Further work directions are provided.",
        "author_keywords": [
            "generative models",
            "traffic model",
            "urban mobility",
            "variational autoencoder"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Development of a Face Prediction System for Missing Children in a Smart City Safety Network",
        "authors": "Wang D.C.",
        "journal": "Electronics (Switzerland)",
        "doi": "10.3390/electronics11091440",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85129212618",
        "scopus_id": "85129212618",
        "abstract": "Cases of missing children not being found are rare, but they continue to occur. If the child is not found immediately, the parents may not be able to identify the child’s appearance because they have not seen their child for a long time. Therefore, our purpose is to predict children’s faces when they grow up and help parents search for missing children. DNA paternity testing is the most accurate way to detect whether two people have a blood relation. However, DNA paternity testing for every unidentified child would be costly. Therefore, we propose the development of the Face Prediction System for Missing Children in a Smart City Safety Network. It can predict the faces of missing children at their current age, and parents can quickly confirm the possibility of blood relations with any unidentified child. The advantage is that it can eliminate incorrect matches and narrow down the search at a low cost. Our system combines StyleGAN2 and FaceNet methods to achieve prediction. StyleGAN2 is used to style mix two face images. FaceNet is used to compare the similarity of two face images. Experiments show that the similarity between predicted and expected results is more than 75%. This means that the system can well predict children’s faces when they grow up. Our system has more natural and higher similarity comparison results than Conditional Adversarial Autoencoder (CAAE), High Resolution Face Age Editing (HRFAE) and Identity-Preserved Conditional Generative Adversarial Networks (IPCGAN).",
        "author_keywords": [
            "face aging",
            "FaceNet",
            "generative adversarial network",
            "missing child",
            "StyleGAN2"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Signal Processing",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "When Robots Dream: In Conversation with Alexandra Carlson",
        "authors": "del Campo M.",
        "journal": "Architectural Design",
        "doi": "10.1002/ad.2812",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127676027",
        "scopus_id": "85127676027",
        "abstract": "Matias del Campo interviews Alexandra Carlson who had a key role in founding the pioneering Architecture and Artificial Intelligence Laboratory (AR2IL) at the University of Michigan's Robotics Department and Taubman College of Architecture and Urban Planning. The synthesis of the architectural and dataset sharing adds another dimension to design possibilities.",
        "author_keywords": [
            "AR2IL",
            "Architecture and Artificial Intelligence Laboratory (AR2IL)",
            "artificial neural networks (ANNs)",
            "biological neural networks (BNNs)",
            "convolutional neural networks (CNNs)",
            "data sharing.",
            "Deep neural networks (DNNs)",
            "dendrites",
            "Ford Motor Company Robotics Building",
            "generative adversarial networks (GANs)",
            "image datasets",
            "Matias del Campo",
            "Robot Garden",
            "Sandra Manninger",
            "SPAN",
            "University of Michigan"
        ],
        "subject_areas": [
            "Architecture",
            "Visual Arts and Performing Arts"
        ]
    },
    {
        "title": "Sequential Masterplanning: Using Urban-GANs",
        "authors": "He W.",
        "journal": "Architectural Design",
        "doi": "10.1002/ad.2820",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127563333",
        "scopus_id": "85127563333",
        "abstract": "AI, and particularly the use of generative adversarial networks (GANs), can provide a more dynamic urban-planning visual tool allowing the development potential of specific sites to be explored. Wanyu He – founder and CEO of XKool Technology, co-founder of Future Architecture Lab and University of Hong Kong academic – explains how.",
        "author_keywords": [
            "AI-based probabilistic modelling",
            "Convoluted neural networks (CNNs)",
            "generative adversarial network (GAN)",
            "identification model",
            "Michel Foucault",
            "Urban- GAN model",
            "‘semantic’ data",
            "‘time series’"
        ],
        "subject_areas": [
            "Architecture",
            "Visual Arts and Performing Arts"
        ]
    },
    {
        "title": "Applying Artificial Intelligence and Deep Belief Network to predict traffic congestion evacuation performance in smart cities",
        "authors": "Chen G.",
        "journal": "Applied Soft Computing",
        "doi": "10.1016/j.asoc.2022.108692",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127469082",
        "scopus_id": "85127469082",
        "abstract": "This work is developed to discuss the feasibility and efficiency of adopting Artificial Intelligence (AI) Deep Learning in smart city scenarios. A traffic flow prediction model is constructed based on the Deep Belief Network (DBN) algorithm. The target road section and its historical traffic flow data in Tianjin are collected and pre-processed. Then, several Restricted Boltzmann Machines (RBM) are stacked together to form a DBN, which is trained as a generative model. Finally, its performance is analyzed by the simulation experiment. The algorithm model proposed is compared with Neuro Fuzzy C-Means (FCM) model, Deep Learning Architecture (DLA), and Convolutional Neural Network (CNN) model. The results show that the Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) of the algorithm model proposed are 4.42%, 6.21%, and 8.03%, respectively. Its prediction accuracy is significantly higher than that of the other three algorithms. In addition, the algorithm can effectively suppress the spread of congestion in the smart city, achieving timely evacuation of traffic congestion. In short, the constructed Deep Learning-based traffic flow prediction model has a high-precision prediction effect and traffic congestion evacuation performance, which can provide experimental references for the later construction of smart cities.",
        "author_keywords": [
            "Artificial Intelligence",
            "Deep Belief Network",
            "Smart cities, Deep Learning",
            "Traffic flow prediction"
        ],
        "subject_areas": [
            "Software"
        ]
    },
    {
        "title": "AP-GAN: Adversarial patch attack on content-based image retrieval systems",
        "authors": "Zhao G.",
        "journal": "GeoInformatica",
        "doi": "10.1007/s10707-020-00418-7",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85088833795",
        "scopus_id": "85088833795",
        "abstract": "Key Smart City applications such as traffic management and public security rely heavily on the intelligent processing of video and image data, often in the form of visual retrieval tasks, such as person Re-IDentification (ReID) and vehicle re-identification. For these tasks, Deep Neural Networks (DNNs) have been the dominant solution for the past decade, for their remarkable ability in learning discriminative features from images to boost retrieval performance. However, it is been discovered that DNNs are broadly vulnerable to maliciously constructed adversarial examples. By adding small perturbations to a query image, the returned retrieval results will be completely dissimilar from the query image. This poses serious challenges to vital systems in Smart City applications that depend on the DNN-based visual retrieval technology, as in the physical world, simple camouflage can be added on the subject (a few patches on the body or car), and turn the subject completely untrackable by person or vehicle Re-ID systems. To demonstrate the potential of such threats, this paper proposes a novel adversarial patch generative adversarial network (AP-GAN) to generate adversarial patches instead of modifying the entire image, which also causes the DNNs-based image retrieval models to return incorrect results. AP-GAN is trained in an unsupervised way that requires only a small amount of unlabeled data for training. Once trained, it produces query-specific perturbations for query images to form adversarial queries. Extensive experiments show that the AP-GAN achieves excellent attacking performance with various application scenarios that are based on deep features, including image retrieval, person ReID and vehicle ReID. The results of this study provide a warning that when deploying a DNNs-based image retrieval system, its security and robustness needs to be thoroughly considered.",
        "author_keywords": [
            "Adversarial attack",
            "Adversarial patch",
            "GAN",
            "Image retrieval"
        ],
        "subject_areas": [
            "Information Systems",
            "Geography, Planning and Development"
        ]
    },
    {
        "title": "Semi-supervised Scene Classification of Remote Sensing Images Based on GAN",
        "authors": "Xia Y.",
        "journal": "Guangzi Xuebao/Acta Photonica Sinica",
        "doi": "10.3788/gzxb20225103.0310003",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127232288",
        "scopus_id": "85127232288",
        "abstract": "Remote sensing image scene classification is an important and challenging problem of remote sensing image interpretation. With the generation of a large number of scene-rich high-resolution remote sensing images, scene classification of remote sensing images is widely used in many fields such as smart city construction, natural disaster monitoring and land resource utilization. Due to the advancement of deep learning techniques and the establishment of large-scale scene classification datasets, scene classification methods have been significantly improved. Although the classification methods based on deep learning have achieved high classification accuracy, the supervised methods require a large number of training samples, while the unsupervised classification methods are difficult to meet the practical needs and have low classification accuracy. Meanwhile, the annotation of remote sensing images requires rich engineering skills and expert knowledge, and in remote sensing applications, only a small amount of labeled remote sensing images exist for supervised training in most cases, and a large amount of unlabeled images cannot be fully utilized. Therefore, a semi-supervised learning method that extracts effective features from a large amount of unlabeled data by learning a small amount of labeled data becomes a potential way to solve such problems. To address the problems of complex background of remote sensing images and the inability of supervised scene classification algorithms to utilize unlabeled data, a semi-supervised remote sensing image scene classification method based on generative adversarial networks, namely, residual attention generative adversarial networks, is proposed. First, to enhance the stability of training, the residual blocks with jump structure are introduced in the deep neural network. At the same time, the spectral normalization constrains the spectral norm of the weight matrix in each convolutional layer of the residual block to ensure that the input and output of each batch of data satisfy the 1-Lipschitz continuity, which makes the generative adversarial training always smooth, not only improves the training stability, but also avoids network degradation. Secondly, since the shallow features extracted by the bottom convolution contain mostly local information and low semantics, while the deep features extracted by the top convolution contain more global information but lose part of the detail information. Therefore, the shallow features are fused with the deep features extracted from the multi-layer spectral normalized residual blocks to reduce the loss of features and allow the model to learn the complementary relationships between different features, thus improving the model's representational ability. Finally, to guide the model to focus more purposefully on important features and suppress unnecessary features, an attention module that mimics the signal processing of the human brain is used. Meanwhile, in order to obtain stronger feature representation ability and capture the dependency relationship between features, a gating mechanism is introduced to form an attention module combined with gating. To verify the superiority of the method, experiments were conducted on two high-resolution remote sensing image datasets, EuroSAT and UC Merced. In the EuroSAT dataset, the highest classification accuracy reached 93.3% and 97.4% when the number of labeled features was 2 000 and 21 600, respectively. In the UC Merced dataset, the classification accuracies reached 85.7% and 91.0% when the number of labeled was 400 and 1 680, respectively. To further validate the degree of contribution of each module, ablation experiments were also conducted in the EuroSAT and UCM public datasets, and it can be concluded from the validation that the spectral normalization residual module has the largest contribution, with improvement for different number of labeled samples. The reason is that the spectral normalization ensures that the gradient of the network is limited to a certain range during backpropagation, improving the stability of the generative adversarial network, and also does not destroy the network structure in the process. The next is the attention module combined with gating, especially when the labeled sample size is greater than 10%, the classification effect is improved more because the sample size is sufficient to learn more comprehensive features. The smallest contribution is the feature fusion module, because when the sample size is very small, the network is not sufficiently trained and learned, and a part of redundant or invalid features are extracted, resulting in lower classification accuracy. The above experimental results show that the proposed residual attention generation adversarial network classification method can effectively extract more discriminative features and improve the semi-supervised classification performance for the problem of small sample size of labeled high-resolution remote sensing images, which makes it difficult to extract discriminative features.",
        "author_keywords": [
            "Attention mechanism",
            "Generative Adversarial network",
            "Remote sensing image",
            "Scene classification",
            "Semi-supervised"
        ],
        "subject_areas": [
            "Atomic and Molecular Physics, and Optics"
        ]
    },
    {
        "title": "A Video Analytics System for Person Detection Combined with Edge Computing",
        "authors": "Maltezos E.",
        "journal": "Computation",
        "doi": "10.3390/computation10030035",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85128187774",
        "scopus_id": "85128187774",
        "abstract": "Ensuring citizens' safety and security has been identified as the number one priority for city authorities when it comes to the use of smart city technologies. Automatic understanding of the scene, and the associated provision of situational awareness for emergency situations, are able to efficiently contribute to such domains. In this study, a Video Analytics Edge Computing (VAEC) system is presented that performs real-time enhanced situation awareness for person detection in a video surveillance manner that is also able to share geolocated person detection alerts and other accompanied crucial information. The VAEC system adopts state-of-the-art object detection and tracking algorithms, and it is integrated with the proposed Distribute Edge Computing Internet of Things (DECIoT) platform. The aforementioned alerts and information are able to be shared, though the DECIoT, to smart city platforms utilizing proper middleware. To verify the utility and functionality of the VAEC system, extended experiments were performed (i) in several light conditions, (ii) using several camera sensors, and (iii) in several use cases, such as installed in fixed position of a building or mounted to a car. The results highlight the potential of VAEC system to be exploited by decision-makers or city authorities, providing enhanced situational awareness.",
        "author_keywords": [
            "Computer vision",
            "Edge computing",
            "Object detection",
            "Object tracking",
            "Person detection",
            "Situational awareness",
            "Smart cities",
            "Terrestrial",
            "Vehicle",
            "YOLOv5"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)",
            "Modeling and Simulation",
            "Applied Mathematics"
        ]
    },
    {
        "title": "Understanding and Modeling Urban Mobility Dynamics via Disentangled Representation Learning",
        "authors": "Zhang H.",
        "journal": "IEEE Transactions on Intelligent Transportation Systems",
        "doi": "10.1109/TITS.2020.3030259",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127835972",
        "scopus_id": "85127835972",
        "abstract": "Understanding the underlying patterns of the urban mobility dynamics is essential for both the traffic state estimation and management of urban facilities and services. Due to the coupling relationship of generative factors in spatial-temporal domain, it is challenging to model the citywide traffic dynamics under a structural pattern of critical features such as hours of days, days of weeks and weather conditions. To address this challenge, this article develops a disentangled representation learning framework to learn an interpretable factorized representation of the independent data generative factors. In order to make full use of the knowledge on generative factors, this article proposes spatial-temporal generative adversarial network (ST-GAN) to assign the generative factors of traffic flow to the feature vector in latent space and reconstructs the high-dimensional citywide traffic flow from the given factors. With the help of the disentangled representations, the decomposed feature vector in latent space discloses the relationship between underlying patterns and citywide traffic dynamics. Several comprehensively experiments show that ST-GAN not only effectively improves the prediction accuracy but also promisingly characterize structural properties of the traffic evolution process.",
        "author_keywords": [
            "big data",
            "deep learning",
            "disentangled representation",
            "generative adversary networks",
            "Urban computing"
        ],
        "subject_areas": [
            "Automotive Engineering",
            "Mechanical Engineering",
            "Computer Science Applications"
        ]
    },
    {
        "title": "The Geographical Distribution and Influencing Factors of COVID-19 in China",
        "authors": "Li W.",
        "journal": "Tropical Medicine and Infectious Disease",
        "doi": "10.3390/tropicalmed7030045",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85126719151",
        "scopus_id": "85126719151",
        "abstract": "The study of the spatial differentiation of COVID-19 in cities and its driving mechanism is helpful to reveal the spatial distribution pattern, transmission mechanism and diffusion model, and evolution mechanism of the epidemic and can lay the foundation for constructing the spatial dynamics model of the epidemic and provide theoretical basis for the policy design, spatial planning and implementation of epidemic prevention and control and social governance. Geodetector(Origin version,Beijing,PR China) is a great tool for analysis of spatial differentiation and its influencing factors, and it provides decision support for differentiated policy design and its implementation in executing the city-specific policies. Using factor detection and interaction analysis of Geodetector, 15 indicators of economic, social, ecological, and environmental dimensions were integrated, and 143 cities were selected for the empirical research in China. The research shows that, first of all, risks of both infection and death show positive spatial autocorrelation, but the geographical distribution of local spatial autocorrelation differs significantly between the two. Secondly, the inequalities in urban economic, social, and residential environments interact with COVID-19 spatial heterogeneity, with stronger explanatory power especially when multidimensional inequalities are superimposed. Thirdly, the spatial distribution and spread of COVID-19 are highly spatially heterogeneous and correlated due to the complex influence of multiple factors, with factors such as Area of Urban Construction Land, GDP, Industrial Smoke and Dust Emission, and Expenditure having the strongest influence, the factors such as Area of Green, Number of Hospital Beds and Parks, and Industrial NOx Emissions having unignorable influence, while the factors such as Number of Free Parks and Industrial Enterprises, Per-GDP, and Population Density play an indirect role mainly by means of interaction. Fourthly, the factor interaction effect from the infected person’s perspective mainly shows a nonlinear enhancement effect, that is, the joint influence of the two factors is greater than the sum of their direct influences; but from the perspective of the dead, it mainly shows a two-factor enhancement effect, that is, the joint influence of the two factors is greater than the maximum of their direct influences but less than their sum. Fifthly, some suggestions are put forward from the perspectives of building a healthy, resilient, safe, and smart city, providing valuable reference and decision basis for city governments to carry out differentiated policy design.",
        "author_keywords": [
            "China",
            "COVID-19",
            "Infectious diseases",
            "Spatial distribution",
            "Urban inequalities"
        ],
        "subject_areas": [
            "Immunology and Microbiology (all)",
            "Public Health, Environmental and Occupational Health",
            "Infectious Diseases"
        ]
    },
    {
        "title": "Generative Adversarial Network Approach to Future Sermonizing of Housing Dispersal in Emerging Cities",
        "authors": "Ibrahim H.",
        "journal": "Journal of Urban Planning and Development",
        "doi": "10.1061/(ASCE)UP.1943-5444.0000783",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85120371400",
        "scopus_id": "85120371400",
        "abstract": "This study aims to visualize the future housing dispersal of expatriates, based on the predicted urban growth in emerging cities. Generalized adversarial networks (GANs) will be utilized to predict the future urban growth of Doha Metropolitan emerging city. The housing dispersal of expatriates will be visualized on the predicted urban growth map to investigate housing preferences, which will be based on Gordon's theory. This study will prove the feasibility of a process approach when practicing the management of urban growth in emerging cities worldwide. It could be a robust solution for the worsening imbalance in the urban morphology of metropolitan cities. The findings of the broad-spectrum housing dispersal guidelines could benefit the policymakers and planners for the realities of spatial patterns and future urban growth.",
        "author_keywords": [
            "Emerging cities",
            "Generative adversarial network",
            "Housing dispersal",
            "Machine learning",
            "Urban growth"
        ],
        "subject_areas": [
            "Civil and Structural Engineering",
            "Geography, Planning and Development",
            "Development",
            "Urban Studies"
        ]
    },
    {
        "title": "MasterplanGAN: Facilitating the smart rendering of urban master plans via generative adversarial networks",
        "authors": "Ye X.",
        "journal": "Environment and Planning B: Urban Analytics and City Science",
        "doi": "10.1177/23998083211023516",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85109015192",
        "scopus_id": "85109015192",
        "abstract": "This study proposes a prototype for the smart rendering of urban master plans via artificial intelligence algorithms, a process which is time-consuming and relies on professionals’ experience. With the help of crowdsourced data and generative adversarial networks (GAN), a generation model was trained to provide colorful rendering of master plans similar to those produced by experienced urban designers. Approximately 5000 master plans from Pinterest were processed and CycleGAN was applied as the core algorithm to build this model, the so-called MasterplanGAN. Using the uncolored input design files in an AutoCAD format, the MasterplanGAN can provide master plan renderings within a few seconds. The validation of the generated results was achieved using quantitative and qualitative judgments. The achievements of this study contribute to the development of automatic generation of previously subjective and experience-oriented processes, which can serve as a useful tool for urban designers and planners to save time in real projects. It also contributes to push the methodological boundaries of urban design by addressing urban design requirements with new urban data and new techniques. This initial exploration indicates that a large but clear picture of computational urban design can be presented, integrating scientific thinking, design, and computer techniques.",
        "author_keywords": [
            "crowdsourced data",
            "Deep learning",
            "generative adversarial networks",
            "MasterplanGAN",
            "urban design"
        ],
        "subject_areas": [
            "Architecture",
            "Geography, Planning and Development",
            "Urban Studies",
            "Nature and Landscape Conservation",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "A MACHINE-LEARNING APPROACH TO URBAN DESIGN INTERVENTIONS IN NON-PLANNED SETTLEMENTS",
        "authors": "Boim A.",
        "journal": "Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia",
        "doi": "10.52842/conf.caadria.2022.1.223",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85183103719",
        "scopus_id": "85183103719",
        "abstract": "This study presents generative adversarial networks (GANs), a machine-learning technique that can be used as an urban design tool capable of learning and reproducing complex patterns that express the unique spatial qualities of non-planned settlements. We report preliminary experimental results of training and testing GAN models on different datasets of urban patterns. The results reveal that machine learning models can generate development alternatives with high morphological resemblance to the original urban fabric based on the suggested training process. This study contributes a methodological framework that has the potential to generate development alternatives sensitive to the local practices, thereby promoting preservation of traditional knowledge and cultural sustainability.",
        "author_keywords": [
            "Cultural Sustainability",
            "Generative Adversarial Networks",
            "Machine Learning",
            "Non-planned Settlements",
            "SDG 11"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Computer Graphics and Computer-Aided Design",
            "Materials Science (miscellaneous)",
            "Modeling and Simulation"
        ]
    },
    {
        "title": "Generation of High Quality Density Map Using USkipGAN",
        "authors": "Ganga B.",
        "journal": "2022 IEEE International Conference for Women in Innovation, Technology and Entrepreneurship, ICWITE 2022 - Proceedings",
        "doi": "10.1109/ICWITE57052.2022.10334424",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85179891013",
        "scopus_id": "85179891013",
        "abstract": "In intelligence video surveillance, crowd analysis tasks like counting are gaining much importance. It is applied in urban planning, traffic management, and avoiding untoward situations due to overcrowding. The main challenge lies in considering varying crowd sizes, distances, and features while precisely counting and building a high caliber density map. Considering the above challenges in the crowd, this paper presented UskipGAN architecture comprising Unet skip connection, Unet generator, and discriminator to construct a good quality density map. The Unet skip connection fabricated as an encoder-decoder structure executes semantic segmentation by including global and local spatial features. The unet generator concatenates input from the Unet skip connection to its varying kernel size to detect finer and more diverse details of the people. The resulting density maps are refined in the discriminator by deploying a binary entropy loss function. The observation is evaluated on the datasets of ShanghaiTech A, B, and UCFF-CC-50, having varied scenes and densities deploying mean square error (MSE) and mean absolute error (MAE) as metrics. The preliminary test proves the recommended model's effectiveness on the MSE metric on the above three datasets, and it outperforms on UCFF-CC-50 datasets.",
        "author_keywords": [
            "Generative Adversarial Network(GAN)",
            "Skip connection"
        ],
        "subject_areas": [
            "Business, Management and Accounting (miscellaneous)",
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Information Systems",
            "Psychology (miscellaneous)",
            "Gender Studies"
        ]
    },
    {
        "title": "Anomaly Detection Methods in Surveillance Videos: A Survey",
        "authors": "Borawar L.",
        "journal": "2022 International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2022",
        "doi": "10.1109/SMARTGENCON56628.2022.10084028",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85153678075",
        "scopus_id": "85153678075",
        "abstract": "Surveillance system continuously generates massive amount of video data in the newest technological era, analysing these data is a tedious task for security specialists. With the popularization of surveillance monitoring system and the evolution of information technology, how to immediately and without human interaction detect unusual behaviours in surveillance footage is becoming more and more crucial for smart cities and public safety. Finding of abnormal footage physically in these massive video recordings is a laborious work, as they do not happen often in the real world. This clearly shows the necessity of automated anomaly detection, afterward that can detect crimes and aid investigations. The progress of anomaly detection has substantially benefited from deep learning, and much outstanding work has been published on this subject. This survey paper provides a comprehensive review of various anomaly detection and recognition methods. Researchers will get a better perspective of anomaly detection task with GAN approach, fine-tuned approach, and keyframes extraction plus shallow network approach and also their issues as well.",
        "author_keywords": [
            "3DConvNets",
            "anomaly detection",
            "intelligent surveillance net-works",
            "keyframe extraction",
            "spatial augmentation",
            "U-Net"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Information Systems and Management",
            "Electrical and Electronic Engineering",
            "Control and Optimization"
        ]
    },
    {
        "title": "FastFlow: AI for Fast Urban Wind Velocity Prediction",
        "authors": "Low S.J.",
        "journal": "IEEE International Conference on Data Mining Workshops, ICDMW",
        "doi": "10.1109/ICDMW58026.2022.00028",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85148421795",
        "scopus_id": "85148421795",
        "abstract": "Data-driven approaches, including deep learning, have shown great promise as surrogate models across many domains, including computer vision and natural language pro-cessing. These extend to various areas in sustainability, including for satellite image analysis to obtain information such as land usage and extent of development. An interesting direction for which data-driven methods have not been applied much yet is in the quick quantitative evaluation of urban layouts for planning and design. In particular, urban designs typically involve complex trade-offs between multiple objectives, including limits on urban build-up and/or consideration of urban heat island effect. Hence, it can be beneficial to urban planners to have a fast surrogate model to predict urban characteristics of a hypothetical layout, e.g. pedestrian-level wind velocity, without having to run compu-tationally expensive and time-consuming high-fidelity numerical simulations each time. This fast surrogate can then be potentially integrated into other design optimization frameworks, including generative models or other gradient-based methods. Here we present an investigation into the use of convolutional neural networks as a surrogate for urban layout characterization that is typically done via high-fidelity numerical simulation. We then further apply this model towards a first demonstration of its utility for data-driven pedestrian-level wind velocity prediction. The data set in this work comprises results from high-fidelity numerical simulations of wind velocities for a diverse set of realistic urban layouts, based on randomized samples from a real-world, highly built-up urban city. We then provide prediction results obtained from the neural network trained on this data-set, demonstrating test errors of under 0.1 m/s for previously unseen novel urban layouts. We further illustrate how this can be useful for purposes such as rapid evaluation of pedestrian wind velocity for a potential new layout. In addition, it is hoped that this data set will further inspire, facilitate and accelerate research in data-driven urban AI, even as our baseline model facilitates quantitative comparison to future, more innovative methods.",
        "author_keywords": [
            "Computational Fluid Dynamics (CFD)",
            "Convolutional Neural Network (CNN)",
            "Pedestrian Wind Velocity",
            "U-Net",
            "Urban Planning",
            "Urban Wind Flow"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Software"
        ]
    },
    {
        "title": "Generation of Synthetic Urban Vehicle Trajectories",
        "authors": "Anastasiou C.",
        "journal": "Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022",
        "doi": "10.1109/BigData55660.2022.10020237",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85147931629",
        "scopus_id": "85147931629",
        "abstract": "The analysis of trajectory datasets has numerous applications ranging from urban planning to human mobility understanding, but to protect the privacy of individuals trajectory datasets are rarely released to researchers. And even when they are, they are limited in size and spatio-temporal coverage. To address these issues a number of methods for generating synthetic yet realistic trajectory datasets have been proposed. These existing methods either require a lot of complex parameters to be calibrated (simulators) or rely on existing trajectory datasets (generative models). In this paper, we propose Data-Driven Trajectory Generator, dubbed DDTG, a data-driven, model-free, and parameter-less algorithm for generating realistic synthetic vehicle trajectory datasets. Unlike existing approaches, DDTG relies on aggregate origin-destination and traffic data, both of which are publicly available and free of privacy concerns. Furthermore, we show that our method is orthogonal to the existing approaches with which DDTG can be combined to generate synthetic datasets of higher quality. Our experiments with real-world trajectory and traffic data show that the datasets generated by DDTG follow distributions that are very close to the distributions of real trajectory datasets.",
        "author_keywords": [
            "synthetic datasets",
            "synthetic vehicle trajectory"
        ],
        "subject_areas": [
            "Modeling and Simulation",
            "Computer Networks and Communications",
            "Information Systems",
            "Information Systems and Management",
            "Safety, Risk, Reliability and Quality",
            "Control and Optimization"
        ]
    },
    {
        "title": "Mest-GAN: Cross-City Urban Traffic Estimation with Me ta S patial-T emporal G enerative A dversarial N etworks",
        "authors": "Zhang Y.",
        "journal": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "doi": "10.1109/ICDM54844.2022.00084",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85147733808",
        "scopus_id": "85147733808",
        "abstract": "The conditional urban traffic estimation problem aims to accurately estimate the future traffic status based on the changing local travel demands, which has long been an important issue in urban planning. However, most existing methods require the target city to provide a large amount of traffic data. Once traffic estimation is performed in a 'new' city where many urban services and transportation infrastructures are not built and thus no prior data is available, those works would fail due to the lack of data. In this paper, we aim to solve the conditional urban traffic estimation problem in case of data scarcity (i.e., the target city cannot provide any prior data) and tackle the main challenges including (1) knowledge learning from the source and (2) knowledge adaptation without prior traffic data. We propose a novel generative adversarial network - Meta Spatial-Temporal Generative Adversarial Network (Mest-GAN), which can successfully estimate traffic in the target city based on local travel demands without the access to any prior traffic data. To address the first challenge, we learn the latent distribution of travel demands with the inference network, the latent distribution also indicates the diverse spatial-temporal traffic patterns. To solve the second challenge, we use the travel demand data in the target city for adaptation, where the inference network infers a latent code guiding the generator to produce accurate traffic estimations. Extensive experiments on real-world multiple-city datasets demonstrate that our Mest-GAN produces high-quality traffic estimations and outperforms state-of-the-art baseline methods.",
        "author_keywords": [
            "generative adversarial networks",
            "urban traffic estimation"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "STrans-GAN: Spatially-Transferable Generative Adversarial Networks for Urban Traffic Estimation",
        "authors": "Zhang Y.",
        "journal": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "doi": "10.1109/ICDM54844.2022.00085",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85147730403",
        "scopus_id": "85147730403",
        "abstract": "Conditional traffic estimation is a vital problem in urban plan deployment, which can help evaluate urban construction plans and improve transportation efficiency. Conventional methods for conditional traffic estimation usually focus on supervised settings, which require a large amount of labeled training data. However, in many urban planning applications, the large amount of traffic data in a new city can be hard or impossible to acquire. To tackle the conditional traffic estimation problem in data scarcity situations, we formulate the problem as a spatial transfer generative learning problem. Compared to prior spatial transfer learning frameworks with only single source city, we propose to extracts knowledge from multiple source cities to improve the estimation accuracy and transfer stability, which is a technically more challenging task. As a solution, we propose a new cross-city conditional traffic estimation method - Spatially-Transferable Generative Adversarial Networks (STrans-GAN) with novel pre-training and fine-tuning algorithms. STransGAN preserves diverse traffic patterns from multiple source cities through traffic clustering, and incorporates meta-learning idea into the pre-training process to learn a well-generalized model. During fine-tuning, we propose to add a cluster matching regularizer to realize the flexible adaptation in different scenarios. Through extensive experiments on multiple-city datasets, the effectiveness of STrans-GAN is proved.",
        "author_keywords": [
            "Generative adversarial networks",
            "meta learning",
            "urban traffic estimation"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Pix2Pix GAN Image Synthesis To Detect Electric Vehicle License Plate",
        "authors": "Kalpana A.",
        "journal": "Proceedings of 4th International Conference on Cybernetics, Cognition and Machine Learning Applications, ICCCMLA 2022",
        "doi": "10.1109/ICCCMLA56841.2022.9989063",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85146339089",
        "scopus_id": "85146339089",
        "abstract": "The area of image processing is more intensive in development and research activities for decades. The role of image processing is huge in modeling, analytics, communication, computation, information security, information forensics and smart city application. Images are ubiquitous in day to day life and images or videos play dominant role in monitoring applications. But when it comes to development of specific application, collection of data is a very challenging task. Nowadays deep learning plays a significant role for generation of data. Robust technologies like Generative Adversarial Network (GAN) and Cycle GAN play a crucial role for generating realistic images with super resolution. GAN and its associated methods used for image synthesis improve the accuracy of deep learning models. In this paper, we analyze challenges of license plate recognition in realistic situation and experiments demonstrate that GAN can generate realistic images to improve the accuracy of license plate recognition.",
        "author_keywords": [
            "Deep Learning",
            "Generative Adversarial Network",
            "Generator",
            "Image synthesis",
            "License Plate Recognition"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Safety, Risk, Reliability and Quality",
            "Cognitive Neuroscience"
        ]
    },
    {
        "title": "Dalle-Urban: Capturing the Urban Design Expertise of Large Text to Image Transformers",
        "authors": NaN,
        "journal": "2022 International Conference on Digital Image Computing: Techniques and Applications, DICTA 2022",
        "doi": "10.1109/DICTA56598.2022.10034603",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85144859479",
        "scopus_id": "85144859479",
        "abstract": "Automatically converting text descriptions into images using transformer architectures has recently received considerable attention. Such advances have implications for many applied design disciplines across fashion, art, architecture, urban planning, landscape design and the future tools available to such disciplines. However, a detailed analysis capturing the capabilities of such models, specifically with a focus on the built environment, has not been performed to date. In this work, we investigate the capabilities and biases of such text-to-image methods as it applies to the built environment in detail. We use a systematic grammar to generate queries related to the built environment and evaluate resulting generated images. We generate 1020 different images and find that text to image transformers are robust at generating realistic images across different domains for this use-case. Generated imagery can be found at the github: REMOVED FOR REVIEW.",
        "author_keywords": [
            "built environment",
            "computer vision",
            "dataset",
            "deep learning",
            "image generation",
            "natural language processing",
            "urban design",
            "urban planning"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Signal Processing",
            "Radiology, Nuclear Medicine and Imaging"
        ]
    },
    {
        "title": "Hybrid Deep-Generative Adversarial Network Based Intrusion Detection Model for Internet of Things Using Binary Particle Swarm Optimization",
        "authors": "Balaji S.",
        "journal": "International Journal of Electrical and Electronics Research",
        "doi": "10.37391/ijeer.100432",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85143542429",
        "scopus_id": "85143542429",
        "abstract": "The applications of internet of things networks extensively increasing which provide ease of data communication among interconnected smart devices. IoT connected with smart devices diverse in a range of fields associated with smart cities, smart-transportation, smart-industrial, healthcare, hospitality etc. The smart devices lack with computational power, energy and inconsistent topology. Due to these factors these are most vulnerable to security attacks which affect the transmission reliability of data between nodes. An IoT network connects heterogeneous devices together and generates high volume of data. To provide security against intrusion attacks, deep neural network (DNN) techniques are adopted to detect malicious attacks. We have proposed on an anomaly Hybrid based deep learning-based approach which is Generative Adversarial Network in accordance with detecting malicious intruders. We designed a distributed IDS controller validated over dataset of NSL-KDD and proven with higher performance in detecting the DDOS Distributed-Denial-of service-attacks. Thus, Experimental Results are calculated with predefined threshold values to detect DDoS-attacks and the resultant proves that HD-GAN model offers better intrusion detection with respect to higher accuracy, recall, precision, f-measure, and lower FPR (False-Positive-Rate).",
        "author_keywords": [
            "Distributed Deep Neural Network",
            "Distributed Denial of Service (DDoS)",
            "Generative Adversarial Network (GAN)"
        ],
        "subject_areas": [
            "Engineering (miscellaneous)",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Preliminary Study for Impact of Social Media Networks on Traffic Prediction",
        "authors": "Laynes Fiascunari V.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-3-031-19647-8_15",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85142749467",
        "scopus_id": "85142749467",
        "abstract": "While smart cities have the required infrastructure for traffic prediction, underdeveloped cities lack the budget and technology to perform an accurate model. Current research uses data mining of tweets and specific posts to provide population trends, but there is no work done in social network analysis for the same end. This paper proposes an applied informatics application with social network usage to aid in the lack of data due to nonexistent traffic sensors. The Twitter API was used to download a network of users that follows traffic updates accounts and then, use a model of information diffusion (independent cascade model) to retrieve a variable that holds a metric of how the information regarding current traffic has traveled through the network. Finally, an updated traffic dataset with the new social network variable is used to train and validate an LSTM neural network to show if the new variable can be a predictor for traffic. Results show that a deterministic independent cascade model ran on a New York City-based 2-tier social network marginally improved the prediction by 0.4%. This proposal can be replicated in other information diffusion models.",
        "author_keywords": [
            "Applied informatics",
            "Deep learning",
            "Social network",
            "Traffic prediction"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "Future of Artificial Intelligence in Libraries",
        "authors": "Pence H.E.",
        "journal": "Reference Librarian",
        "doi": "10.1080/02763877.2022.2140741",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85142539359",
        "scopus_id": "85142539359",
        "abstract": "Commercial and research applications of artificial Intelligence (AI) are becoming increasingly important. AI is used to improve products, predict customer behavior, keep track of inventory, and analyze Big Data. AI agents are also employed to improve the performance of search engines and smartphones. There are a number of ways that AI is being considered for applications in the library, especially data analysis, supporting remote access to library services, and making the library a center for research using Big Data. AI has the potential to perform routine tasks that now require a human being, which will free up librarians to offer the in-depth expertise that is essential for advanced research.",
        "author_keywords": [
            "Artificial intelligence",
            "big data",
            "library of the future",
            "mobile internet",
            "remote services",
            "search",
            "smart cities",
            "virtual personal assistant"
        ],
        "subject_areas": [
            "Library and Information Sciences"
        ]
    },
    {
        "title": "Multiple Pedestrian Tracking Framework using Deep Learning-based Multiscale Image Analysis for Stationary-camera Video Surveillance",
        "authors": "Barbu T.",
        "journal": "ISC2 2022 - 8th IEEE International Smart Cities Conference",
        "doi": "10.1109/ISC255366.2022.9922217",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85142035613",
        "scopus_id": "85142035613",
        "abstract": "A novel single static-camera multiple pedestrian detection and tracking system, which could be succesfully used by the Smart City technologies, is introduced in this article. The moving person detection process is performed by applying a combination of advanced computer vision and machine learning solutions, such as Gaussian Mixture Models (GMM), Histogram of Oriented Gradients (HOG), Support Vector Machines (SVM) and Aggregate Channel Features (ACF), to each frame of the color video sequence. An instance matching-based tracking technique that uses a deep learning-based multiscale analysis of the subimages of the detected pedestrians is then proposed. Its scale-space is created by applying the numerical approximation algorithm of a well-posed nonlinear anisotropic diffusion-based model that is introduced here. The results of the pedestrian detection and tracking experiments are described in the end.",
        "author_keywords": [
            "ACF detector",
            "convolutional neural networks",
            "Gaussian Mixture Models",
            "HOG + SVM detector",
            "multi-scale analysis",
            "nonlinear anisotropic diffusion model",
            "Pedestrian detection and tracking",
            "Smart City"
        ],
        "subject_areas": [
            "Instrumentation",
            "Transportation",
            "Urban Studies",
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Energy Engineering and Power Technology"
        ]
    },
    {
        "title": "iPLAN: Interactive and Procedural Layout Planning",
        "authors": "He F.",
        "journal": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
        "doi": "10.1109/CVPR52688.2022.00764",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85140444212",
        "scopus_id": "85140444212",
        "abstract": "Layout design is ubiquitous in many applications, e.g. architecture/urban planning, etc, which involves a lengthy iterative design process. Recently, deep learning has been leveraged to automatically generate layouts via image generation, showing a huge potential to free designers from laborious routines. While automatic generation can greatly boost productivity, designer input is undoubtedly crucial. An ideal AI-aided design tool should automate repetitive routines, and meanwhile accept human guidance and provide smart/proactive suggestions. However, the capability of involving humans into the loop has been largely ignored in existing methods which are mostly end-to-end approaches. To this end, we propose a new human-in-the-loop generative model, iPLAN, which is capable of automatically generating layouts, but also interacting with designers throughout the whole procedure, enabling humans and AI to co-evolve a sketchy idea gradually into the final design. iPLAN is evaluated on diverse datasets and compared with existing methods. The results show that iPLAN has high fidelity in producing similar layouts to those from human designers, great flexibility in accepting designer inputs and providing design suggestions accordingly, and strong generalizability when facing unseen design tasks and limited training data.",
        "author_keywords": [
            "Image and video synthesis and generation"
        ],
        "subject_areas": [
            "Software",
            "Computer Vision and Pattern Recognition"
        ]
    },
    {
        "title": "Epistemic Uncertainty Quantification in Human Trajectory Prediction",
        "authors": "Canche M.",
        "journal": "Intelligent Systems Reference Library",
        "doi": "10.1007/978-3-031-06307-7_3",
        "publication_date": "2022",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85138132919",
        "scopus_id": "85138132919",
        "abstract": "Human Trajectory Prediction (HTP) is a critical technology in several areas related to the development of smart cities, such as video monitoring or autonomous driving. In the last years, there has been a leap forward in the state of the art of HTP, with great improvements observed in most of the classical benchmarks used in the related literature. This has been possible through the use of powerful data-driven deep learning techniques, coupled with probabilistic generative models and methodologies to cope with contextual information and social interactions between agents. In this chapter, we first show how incorporating Bayesian Deep Learning (BDL) techniques in Human Trajectory Prediction allows to provide realistic estimates of the epistemic and aleatoric uncertainties on the computed predictions. In addition, we also present an original methodology to assess the quality of the produced uncertainties (through BDL or other probabilistic approach).",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Spatial-Temporal Semantic Generative Adversarial Networks for Flexible Multi-step Urban Flow Prediction",
        "authors": "Li L.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-15934-3_63",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85137982345",
        "scopus_id": "85137982345",
        "abstract": "Accurate multi-step citywide urban flow prediction plays a critical role in traffic management and future smart city. However, it is very challenging since urban flow is affected by complex semantic factors and has multi-scale dependencies on both spatial and temporal dimensional features. Moreover, it’s difficult for most existing one-step urban flow prediction models to predict several future time steps in a short time accurately. Inspired by the success of Generative Adversarial Networks (GAN) in video prediction and image generation, in this paper we propose a Seq2Seq Spatial-Temporal Semantic Generative Adversarial Networks named STS-GAN for multi-step urban flow prediction. We regard citywide urban flow data in successive time steps as image frames of a video. Specifically, we first design a Spatial-Temporal Semantic Encoder (STSE) to capture relative semantic factors and spatial-temporal dependencies simultaneously at each time step, which consists of Residual Convolution units. Then a Seq2Seq GAN model is proposed to generate a sequence of future urban flow predictions based on historical data. Furthermore, by integrating GAN’s adversarial loss with prediction error, our STS-GAN can effectively address the blurry prediction issue. Extensive experiments are conducted on two large-scale urban flow datasets in Beijing and Guangzhou, which demonstrate STS-GAN achieves state-of-the-art performance compared with existing methods.",
        "author_keywords": [
            "Generative Adversarial Networks",
            "Neural network models",
            "Spatial-temporal data mining",
            "Urban flow prediction"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "SASAKI: Filling the design gap—Urban impressions with AI",
        "authors": "Raman T.A.",
        "journal": "Artificial Intelligence in Urban Planning and Design: Technologies, Implementation, and Impacts",
        "doi": "10.1016/B978-0-12-823941-4.00002-0",
        "publication_date": "2022",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85137427984",
        "scopus_id": "85137427984",
        "abstract": "Planning and design project scopes have been expanding due to the increasing complexity of work in urban environments which have added pressure on limited firm resources. As design and planning functions increasingly overlap, it is the hope that technologies like machine learning and other digital tools will evolve and proliferate to enable designers to employ data-driven analyses in informing a wider range of design decisions. This chapter proposes a potential use case for generative adversarial networks (GANs) in the planning and design process. GANs are used to develop novel impressionistic aerial imagery—or urban impressions—based on a variety of inputs common to practice such as variations of land use and/or land cover. The GANs make extensive use of readily-available, tiled, web-format maps in both their training and prediction. The generated urban impressions were evaluated based on a range of qualitative criteria, including their ability to foster increased dialogue between parties. Additionally, this research included the development of a prototype tool that creates urban impressions based on selected inputs early on in the predesign phase. Ultimately, it is the hope that this prototype “sketch tool” will allow practitioners to use GANs to test out initial “sketched” approaches in planning and design and communicate them to the client for early feedback.",
        "author_keywords": [
            "Artificial intelligence",
            "Urban design",
            "Urban impressions",
            "Urban planning",
            "Urban sketching"
        ],
        "subject_areas": [
            "Social Sciences (all)"
        ]
    },
    {
        "title": "Generative Modeling of Pedestrian Behavior: A Receding Horizon Optimization-Based Trajectory Planning Approach",
        "authors": "Gupta S.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2022.3193671",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85135736222",
        "scopus_id": "85135736222",
        "abstract": "Urbanization is bringing together various modes of transport, and with that, there are challenges to maintaining the safety of all road users, especially vulnerable road users (VRUs). There is a need for street designs that encourages cooperation between road users. Shared space is a street design approach that softens the demarcation of vehicles and pedestrian traffic by reducing traffic rules, traffic signals, road marking, and regulations. Understanding the interactions and trajectory formations of various VRUs will facilitate the design of safer shared spaces. In line with this goal, this paper aims to develop a methodology for generating VRUs trajectories that accounts for behaviors and social interactions. We develop a receding horizon optimization-based pedestrian trajectory planning algorithm capable of modeling pedestrian trajectories in a variety of shared space scenarios. Focusing on three scenarios-group interactions, unidirectional interaction, and fixed obstacle interaction-case studies are performed to demonstrate the strengths of the resulting generative model. Additionally, generated trajectories are validated using two benchmark datasets - DUT and TrajNet++. The three case studies are shown to yield low or near-zero Mean Euclidean Distance and Final Displacement Error values supporting the performance validity of the models. We also analyze gait parameters (step length and step frequency) to further demonstrate the model's capability at generating realistic pedestrian trajectories.",
        "author_keywords": [
            "mixed integer linear programming",
            "Optimization",
            "shared space",
            "social interaction rules",
            "trajectory-planning",
            "urban design and planning",
            "vulnerable road users"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "Contemporary Advertising Text Art Design and Effect Evaluation by IoT Deep Learning under the Smart City",
        "authors": "Zhang L.",
        "journal": "Security and Communication Networks",
        "doi": "10.1155/2022/5161398",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85135435647",
        "scopus_id": "85135435647",
        "abstract": "This work intends to solve the problem that the current artistic typeface generation methods rely too much on manual intervention, lack novelty, and the single font local feature and the global feature extraction method cannot fully describe the font features. Firstly, it proposes a handwritten word recognition model based on generalized search trees (GIST) and the pyramid histogram of oriented gradient (PHOG). The local features and global features of the font are fused. Secondly, a model of automatic artistic typeface generation based on generative adversarial networks (GAN) is constructed, which can use hand-drawn fonts to automatically generate artistic typefaces in the desired style through training as needed. Finally, the generation of the huaniao typeface is used as an example. By constructing the dataset, the effectiveness of the two models is verified. The experimental results show the following: (1) The proposed handwritten character recognition model based on GIST and PHOG has a higher recognition rate of different fonts than the single GIST and PHOG features by more than 5.8%. The total recognition time is reduced by more than 49.4%, and the performance is improved significantly. (2) Compared with other popular algorithms, the constructed GAN-based automatic artistic typeface generation model has the best quality of the generation of huaniao on both the pencil sketch and the calligraphy character image dataset. Models have broad application prospects in contemporary advertising text art design. This study aims to provide important technical support for the automation of contemporary advertising text art design and the improvement of overall efficiency.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Post-analysis of OSM-GAN Spatial Change Detection",
        "authors": "Niroshan L.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-031-06245-2_3",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85131141206",
        "scopus_id": "85131141206",
        "abstract": "Keeping crowdsourced maps up-to-date is important for a wide range of location-based applications (route planning, urban planning, navigation, tourism, etc.). We propose a novel map updating mechanism that combines the latest freely available remote sensing data with the current state of online vector map data to train a Deep Learning (DL) neural network. It uses a Generative Adversarial Network (GAN) to perform image-to-image translation, followed by segmentation and raster-vector comparison processes to identify changes to map features (e.g. buildings, roads, etc.) when compared to existing map data. This paper evaluates various GAN models trained with sixteen different datasets designed for use by our change detection/map updating procedure. Each GAN model is evaluated quantitatively and qualitatively to select the most accurate DL model for use in future spatial change detection applications.",
        "author_keywords": [
            "Generative Adversarial Networks",
            "OpenStreetMap",
            "Remote sensing",
            "Spatial change detection"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Generating Dynamic Urban Traffic Based on Stochastic Origin-Destination Matrix",
        "authors": "Wang Z.",
        "journal": "2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2022",
        "doi": "10.1109/CSCWD54268.2022.9776297",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85130785220",
        "scopus_id": "85130785220",
        "abstract": "Urban traffic data plays an important role in urban transportation planning. Due to the scarcity of real-life urban traffic data, many transportation planning applications need to generate synthesized traffic flows based on the real-life trajectory datasets. However, those synthesized traffic flows can only fit the input trajectories, which are static and does not reflect the real traffic distributions. In this paper, we use a stochastic origin-destination (OD) matrix to represent the density of the dynamic traffic flows and then develop a dynamic traffic flow generator. We extract the stochastic OD matrix from the trajectory data, design an efficient neural network to the predict successive stochastic OD matrices, and deploy our model on a real-world road network. The proposed model surpasses the existing generative model in RMSE, MAE, VAR, KL indicators, and is significantly better than the existing model in the MAE indicator. Our traffic generator is able to dynamically adjust urban traffics to generate different simulation environments.",
        "author_keywords": [
            "OD Matrix",
            "Traffic Generation",
            "Traffic Simulation System"
        ],
        "subject_areas": [
            "Computer Graphics and Computer-Aided Design",
            "Computer Science Applications"
        ]
    },
    {
        "title": "Urban building extraction from high-resolution remote sensing imagery based on multi-scale recurrent conditional generative adversarial network",
        "authors": "Wang Z.",
        "journal": "GIScience and Remote Sensing",
        "doi": "10.1080/15481603.2022.2076382",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85130721135",
        "scopus_id": "85130721135",
        "abstract": "Urban building extraction from high-resolution remote sensing imagery is important for urban planning, population statistics, and disaster assessment. However, the high density and slight boundary differences of urban building regions pose a great challenge for accurate building extraction. Although existing building extraction methods have achieved better results in urban building extraction, there are still some problems, such as boundary information loss, poor extraction effect for dense regions, and serious interference by building shadows. To accurately extract building regions from high-resolution remote sensing images, in this study, we propose a practical method for building extraction based on convolution neural networks (CNNs). Firstly, the multi-scale recurrent residual convolution is introduced into the generative network to extract the multi-scale and multi-resolution features of remote sensing images. Secondly, the attention gates skip connection (AGs) is used to enhance the information interaction between different scale features. Finally, the adversarial network with parallel architecture is used to decrease the difference between the extracted results and the ground truths. Moreover, the conditional information constraint is introduced in the training process to improve robustness and generalization ability of the proposed method. The qualitative and quantitative analyses are performed on IAILD and Massachusetts datasets. The experimental results show that the proposed method can accurately and effectively extract building regions from remote sensing images.",
        "author_keywords": [
            "conditional information constraint",
            "convolutional neural network (CNN)",
            "generative adversarial network (GAN)",
            "Remote sensing imagery",
            "urban building extraction"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Environmental Economic Decision Support Information System Based on GIS",
        "authors": "Wang Y.",
        "journal": "Lecture Notes on Data Engineering and Communications Technologies",
        "doi": "10.1007/978-3-030-96908-0_23",
        "publication_date": "2022",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85126266060",
        "scopus_id": "85126266060",
        "abstract": "Environmental and development issues are the focus of attention in the world today. The analysis of the impact of projects on the environment is included in the evaluation of investment projects, and sustainable development, not just economic benefits, is used as the evaluation criteria for investment projects, which is important for improving and promoting human society Comprehensive progress is of great significance. The purpose of this paper is to study the environmental economic decision support information system based on GIS. Firstly, it introduces the feasibility analysis, demand analysis project and the implementation of key GIS technology based on the theory of environmental economics. Secondly, it introduces the data collection and design of GIS environmental economic decision support information system, including data collection, data processing, and data organization and management mode. It is the realization of the auxiliary decision support system for city M urban planning based on GIS, including the introduction of the system and the operation of the system interface. Analyzing the Gaussian atmospheric diffusion model module and the statistical calculation module in the decision support system, the green volume of the E and F areas both reached 55%, which provides better data support for the planning and design of the city.",
        "author_keywords": [
            "Decision support",
            "Environmental economy",
            "GIS technology",
            "Information system"
        ],
        "subject_areas": [
            "Information Systems",
            "Media Technology",
            "Computer Science Applications",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "A contingent diffusion model of local climate change policy adoption: Evidence from Southern California cities",
        "authors": "An B.Y.",
        "journal": "Cities",
        "doi": "10.1016/j.cities.2021.103418",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85120471410",
        "scopus_id": "85120471410",
        "abstract": "Climate change policy is an essential driver of urban sustainability, yet minimal research has examined how they emerge and spread across cities in shared metropolitan areas. While policy diffusion or policy mobility theories could explain the aforesaid, much of the international scholarship have not utilized an amalgamation of these two complementary theoretical perspectives. As a result, we lack a comprehensive understanding of the regional dynamics and spillover effects local governments can generate for urban sustainability. This article proposes a contingent diffusion model to examine the intra-regional adoption of local climate action plans within Southern California from 2000 to 2018. We find that neighboring jurisdictions that adopt climate policy increase the likelihood of a home city's adoption. Yet, neighboring effect is contingent on the home city's existing pro-environmental policy propensity. However, in contrast to conventional wisdom, this study finds no evidence that local environmental advocacy groups play a crucial role in the diffusion of municipal climate initiatives. Altogether, the results suggest that a regional diffusion model of policy innovations is more likely successful when adaptive capacity is in place to facilitate green infrastructure. These findings provide implications for policymakers and planners who want to achieve successful spillovers of urban climate policies across local governments.",
        "author_keywords": [
            "Climate policy",
            "Local government",
            "Policy mobility",
            "Regional diffusion",
            "Spillover",
            "Urban planning"
        ],
        "subject_areas": [
            "Development",
            "Sociology and Political Science",
            "Urban Studies",
            "Tourism, Leisure and Hospitality Management"
        ]
    },
    {
        "title": "The effect of intra-urban mobility flows on the spatial heterogeneity of social media activity: investigating the response to rainfall events",
        "authors": "de Andrade S.C.",
        "journal": "International Journal of Geographical Information Science",
        "doi": "10.1080/13658816.2021.1957898",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85111863180",
        "scopus_id": "85111863180",
        "abstract": "Although it is acknowledged that urban inequalities can lead to biases in the production of social media data, there is a lack of studies which make an assessment of the effects of intra-urban movements in real-world urban analytics applications, based on social media. This study investigates the spatial heterogeneity of social media with regard to the regular intra-urban movements of residents by means of a case study of rainfall-related Twitter activity in São Paulo, Brazil. We apply a spatial autoregressive model that uses population and income as covariates and intra-urban mobility flows as spatial weights to explain the spatial distribution of the social response to rainfall events in Twitter vis-à-vis rainfall radar data. Results show high spatial heterogeneity in the response of social media to rainfall events, which is linked to intra-urban inequalities. Our model performance ((Formula presented.)) provides evidence that urban mobility flows and socio-economic indicators are significant factors to explain the spatial heterogeneity of thematic spatiotemporal patterns extracted from social media. Therefore, urban analytics research and practice should consider not only the influence of socio-economic profile of neighborhoods but also the spatial interaction introduced by intra-urban mobility flows to account for spatial heterogeneity when using social media data.",
        "author_keywords": [
            "mobility flows",
            "rainfall data",
            "social media",
            "spatial autoregressive model",
            "Spatial heterogeneity"
        ],
        "subject_areas": [
            "Information Systems",
            "Geography, Planning and Development",
            "Library and Information Sciences"
        ]
    },
    {
        "title": "ST-FVGAN: filling series traffic missing values with generative adversarial network",
        "authors": "Yang B.",
        "journal": "Transportation Letters",
        "doi": "10.1080/19427867.2021.1879624",
        "publication_date": "2022",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100352993",
        "scopus_id": "85100352993",
        "abstract": "The imputation of time series traffic flow data is of great significance to the intelligent transportation, urban planning, and road emergency handling. This paper proposes a filling missing time series traffic data with Generative Adversarial Network (ST-FVGAN), which not only considers the spatio-temporal correlation and utilizes the idea of data generating of the Generative Adversarial Network, but also considers the external factors and introduces a more comprehensive loss function. Specifically, the model firstly constructs a Generator network which is composed of convolutional layer, residual block, and pixelshuffle block for the better potential distribution of the existing data, and then use the Discriminator network for the input judging. Experiments are conducted on the open-source TaxiBJ GPS dataset, and evaluated by the root mean square error (RMSE) index. The experimental results show that our model has the better accurate and reasonable performance than the traditional imputation methods.",
        "author_keywords": [
            "Generative adversarial networks (GAN)",
            "spatio-temporal features processing",
            "traffic data imputation",
            "urban computing"
        ],
        "subject_areas": [
            "Transportation"
        ]
    },
    {
        "title": "Automatic generation of urban road planning network under deep learning",
        "authors": "Zhong Q.",
        "journal": "Journal of Physics: Conference Series",
        "doi": "10.1088/1742-6596/2074/1/012088",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85121440091",
        "scopus_id": "85121440091",
        "abstract": "With the rapid advancement of China's urbanization process and the rapid increase of the number of motor vehicles, now the vast majority of cities in China are faced with traffic congestion, environmental pollution, noise pollution and other problems. Facing these problems, a road network with reasonable structure, proper layout and sufficient capacity has become an important basic condition for the sustainable development of urban traffic system. This paper mainly studies the automatic generation method of urban road planning network based on deep learning. In this paper, a model based on deep neural network is proposed, which integrates the knowledge of road planning domain and generative adversarial network, and can realize the generation of road network simply and quickly.",
        "author_keywords": [
            "Adversarial Networks",
            "Deep Learning",
            "Road Planning",
            "Urban Roads"
        ],
        "subject_areas": [
            "Physics and Astronomy (all)"
        ]
    },
    {
        "title": "FedDPGAN: Federated Differentially Private Generative Adversarial Networks Framework for the Detection of COVID-19 Pneumonia",
        "authors": "Zhang L.",
        "journal": "Information Systems Frontiers",
        "doi": "10.1007/s10796-021-10144-6",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85107977450",
        "scopus_id": "85107977450",
        "abstract": "Existing deep learning technologies generally learn the features of chest X-ray data generated by Generative Adversarial Networks (GAN) to diagnose COVID-19 pneumonia. However, the above methods have a critical challenge: data privacy. GAN will leak the semantic information of the training data which can be used to reconstruct the training samples by attackers, thereby this method will leak the privacy of the patient. Furthermore, for this reason, that is the limitation of the training data sample, different hospitals jointly train the model through data sharing, which will also cause privacy leakage. To solve this problem, we adopt the Federated Learning (FL) framework, a new technique being used to protect data privacy. Under the FL framework and Differentially Private thinking, we propose a Federated Differentially Private Generative Adversarial Network (FedDPGAN) to detect COVID-19 pneumonia for sustainable smart cities. Specifically, we use DP-GAN to privately generate diverse patient data in which differential privacy technology is introduced to make sure the privacy protection of the semantic information of the training dataset. Furthermore, we leverage FL to allow hospitals to collaboratively train COVID-19 models without sharing the original data. Under Independent and Identically Distributed (IID) and non-IID settings, the evaluation of the proposed model is on three types of chest X-ray (CXR)images dataset (COVID-19, normal, and normal pneumonia). A large number of truthful reports make the verification of our model can effectively diagnose COVID-19 without compromising privacy.",
        "author_keywords": [
            "COVID-19",
            "Differential privacy",
            "Federated learning",
            "Generative adversarial networks",
            "Privacy protection"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Software",
            "Information Systems",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "GAN-Based Semisupervised Scene Classification of Remote Sensing Image",
        "authors": "Guo D.",
        "journal": "IEEE Geoscience and Remote Sensing Letters",
        "doi": "10.1109/LGRS.2020.3014108",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85101788817",
        "scopus_id": "85101788817",
        "abstract": "With the advent of a large number of remote sensing images (RSIs), scene classification of RSI is widely applied to many fields such as urban planning, natural disaster detection, and environmental monitoring. Compared with the natural image field, the lack of labeled RSI is a bottleneck of supervised scene classification methods based on deep learning. Meanwhile, unsupervised scene classification is difficult to meet actual needs. To this end, we propose a novel semisupervised scene classification method for RSI using generative adversarial nets (GANs), in which a gating unit, a self-attention gating (SAG) module, and a pretrained Inception V3 branch are introduced into discriminative network to enhance the feature representation capability for facilitating semisupervised classification. To be specific, the gating unit aims to learn the weights of each feature map and capture the dependence relationship between features. The SAG module aims to capture a long-range dependence for adaptively focusing on important scene regions. The Inception V3 branch aims to extract the high-level semantic representation of input images and further enhance the discriminant ability by gating unit and SAG module. Furthermore, a new optimization term is incorporated into the generator loss to indirectly drive discriminator to correctly classify scene images. To verify the effectiveness of the proposed method, extensive experimental results on UC Merced and EuroSAT data sets demonstrate that the method surpasses most of the state-of-the-art semisupervised image classification methods significantly, especially when only few samples are tagged.",
        "author_keywords": [
            "Gating unit",
            "generative adversarial nets (GANs)",
            "remote sensing image (RSI)",
            "self-attention gating (SAG) module",
            "semisupervised image classification"
        ],
        "subject_areas": [
            "Geotechnical Engineering and Engineering Geology",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Artificial Intelligence Acquisition and Response of Disaster Information Using Smart City High-Rise Wide-Angle CCTV",
        "authors": "Lim D.H.",
        "journal": "Journal of Korean Institute of Communications and Information Sciences",
        "doi": "10.7840/kics.2021.46.11.2023",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85190685396",
        "scopus_id": "85190685396",
        "abstract": "The timing of a disaster cannot be predicted. In particular, fires, floods, power outages, building collapses, and major accidents in local governments occur quickly and in a short time. An instantaneous fire spreads to the entire building, causing property damage as well as personal injury. From the point of view of smart city operation, one administrative goal will be achieved if the safety of citizens is maintained by using the 4th industrial technology's artificial intelligence and wired and wireless communication. In order to quickly respond to disasters in smart cities, high-rise wide-angle CCTVs that enable control from a new perspective must be able to collect image information, and continuous control using LSTM-based edge computing should be operated to quickly detect disasters and effectively respond to disasters. In this study, we discuss the disaster information acquisition design of smart city high-rise wide-angle CCTV. We explain detailed design of high-rise wide-angle CCTV installation conditions analysis, high-rise wide-angle CCTV camera selection criteria, video information network connection plan, and high-rise wide-angle CCTV installation structure construction plan. Finally, we study artificial intelligence disaster information acquisition and artificial intelligence disaster response algorithms based on GAN and LSTM, and study real-time disaster response using TensorFlow.",
        "author_keywords": [
            "AI",
            "Algorithm",
            "Disaster Information",
            "Generative Adversarial Network",
            "High-rise CCTV",
            "Long Short Term Memory",
            "Smart City",
            "Wide-angle CCTV"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Information Systems and Management",
            "Computer Science (miscellaneous)"
        ]
    },
    {
        "title": "One-shot Transfer Learning for Population Mapping",
        "authors": "Shao E.",
        "journal": "International Conference on Information and Knowledge Management, Proceedings",
        "doi": "10.1145/3459637.3482460",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85119203097",
        "scopus_id": "85119203097",
        "abstract": "Fine-grained population distribution data is of great importance for many applications, e.g., urban planning, traffic scheduling, epidemic modeling, and risk control. However, due to the limitations of data collection, including infrastructure density, user privacy, and business security, such fine-grained data is hard to collect and usually, only coarse-grained data is available. Thus, obtaining fine-grained population distribution from coarse-grained distribution becomes an important problem. To tackle this problem, existing methods mainly rely on sufficient fine-grained ground truth for training, which is not often available for the majority of cities. That limits the applications of these methods and brings the necessity to transfer knowledge between data-sufficient source cities to data-scarce target cities. In knowledge transfer scenario, we employ single reference fine-grained ground truth in target city, which is easy to obtain via remote sensing or questionnaire, as the ground truth to inform the large-scale urban structure and support the knowledge transfer in target city. By this approach, we transform the fine-grained population mapping problem into a one-shot transfer learning problem. In this paper, we propose a novel one-shot transfer learning framework PSRNet to transfer spatialoral knowledge across cities from three views. From the view of network structure, we build a dense connection-based population mapping network with temporal feature enhancement to capture the complicated spatialoral correlation between population distributions of different granularities. From the view of data, we design a generative model to synthesize fine-grained population samples with POI distribution and the single fine-grained ground truth in data-scarce target city. From the view of optimization, after combining above structure and data, we propose a pixel-level adversarial domain adaption mechanism for universal feature extraction and knowledge transfer during training with scarce ground truth for supervision. Experiments on real-life datasets of 4 cities demonstrate that PSRNet has significant advantages over 8 state-of-the-art baselines by reducing RMSE and MAE by more than 25%. Our code and datasets are released in Github (https://github.com/erzhuoshao/PSRNet-CIKM).",
        "author_keywords": [
            "population distribution",
            "super-resolution",
            "transfer learning"
        ],
        "subject_areas": [
            "Business, Management and Accounting (all)",
            "Decision Sciences (all)"
        ]
    },
    {
        "title": "An enhanced 3D model and generative adversarial network for automated generation of horizontal building mask images and cloudless aerial photographs",
        "authors": "Ikeno K.",
        "journal": "Advanced Engineering Informatics",
        "doi": "10.1016/j.aei.2021.101380",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85112398164",
        "scopus_id": "85112398164",
        "abstract": "Information extracted from aerial photographs is widely used in the fields of urban planning and design. An effective method for detecting buildings in aerial photographs is to use deep learning to understand the current state of a target region. However, the building mask images used to train the deep learning model must be manually generated in many cases. To overcome this challenge, a method has been proposed for automatically generating mask images by using textured three-dimensional (3D) virtual models with aerial photographs. Some aerial photographs include clouds, which degrade image quality. These clouds can be removed by using a generative adversarial network (GAN), which leads to improvements in training quality. Therefore, the objective of this research was to propose a method for automatically generating building mask images by using 3D virtual models with textured aerial photographs. In this study, using GAN to remove clouds in aerial photographs improved training quality. A model trained on datasets generated by the proposed method was able to detect buildings in aerial photographs with IoU = 0.651.",
        "author_keywords": [
            "Deep learning",
            "Generative adversarial network",
            "Mask image",
            "Semantic segmentation",
            "Training data",
            "Urban planning and design"
        ],
        "subject_areas": [
            "Information Systems",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "A mechanistic data-driven approach to synthesize human mobility considering the spatial, temporal, and social dimensions together",
        "authors": "Cornacchia G.",
        "journal": "ISPRS International Journal of Geo-Information",
        "doi": "10.3390/ijgi10090599",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85116960421",
        "scopus_id": "85116960421",
        "abstract": "Modelling human mobility is crucial in several areas, from urban planning to epidemic modelling, traffic forecasting, and what-if analysis. Existing generative models focus mainly on reproducing the spatial and temporal dimensions of human mobility, while the social aspect, though it influences human movements significantly, is often neglected. Those models that capture some social perspectives of human mobility utilize trivial and unrealistic spatial and temporal mechanisms. In this paper, we propose the Spatial, Temporal and Social Exploration and Preferential Return model (STS-EPR), which embeds mechanisms to capture the spatial, temporal, and social aspects together. We compare the trajectories produced by STS-EPR with respect to real-world trajectories and synthetic trajectories generated by two state-of-the-art generative models on a set of standard mobility measures. Our experiments conducted on an open dataset show that STS-EPR, overall, outperforms existing spatial-temporal or social models demonstrating the importance of modelling adequately the sociality to capture precisely all the other dimensions of human mobility. We further investigate the impact of the tile shape of the spatial tessellation on the performance of our model. STS-EPR, which is open-source and tested on open data, represents a step towards the design of a mechanistic data-driven model that captures all the aspects of human mobility comprehensively.",
        "author_keywords": [
            "Data science",
            "Generative models",
            "Human mobility",
            "Mathematical modelling",
            "Mechanistic models",
            "Social network",
            "Synthetic trajectories"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Patterns of the expanding city: An algorithmic interpretation of otto wagner’s work",
        "authors": "Bereczki Z.",
        "journal": "Heritage",
        "doi": "10.3390/heritage4030059",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85109378307",
        "scopus_id": "85109378307",
        "abstract": "Central Europe witnessed an urban boom at the beginning of the 20th century. By that time, the leading state of the area was Austria-Hungary, with Vienna as its capital. Before the First World War, even larger expansion of the cities was predictable. Otto Wagner, a leading architect of the empire and an expert in urban planning and architectural theory, published his vision about the future of the evolution of cities in 1911. In this book, he formulates clear rules about how a city should sustainably expand in a controlled manner. In this article, these rules of the inherited patterns are systematised and turned into recursive algorithms to simulate the urban growth controlled by them and the resulting patterns. The algorithms are tested on 1911 Vienna and, as comparison, on 2021 Miskolc, a medium-sized city in Hungary with different geographic surroundings. In the article, the resulting patterns are presented in 2D and 3D.",
        "author_keywords": [
            "Austria-Hungary",
            "Generative modelling",
            "Pattern language",
            "Urban planning",
            "Vienna"
        ],
        "subject_areas": [
            "Conservation",
            "Archeology (arts and humanities)",
            "Materials Science (miscellaneous)"
        ]
    },
    {
        "title": "The impact of land urbanization on carbon dioxide emissions in the Yangtze River Delta, China: A multiscale perspective",
        "authors": "Li J.",
        "journal": "Cities",
        "doi": "10.1016/j.cities.2021.103275",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85107707581",
        "scopus_id": "85107707581",
        "abstract": "Urban areas have become one of the main sources of CO2 emissions. Considering the spatial interactions between county scale and prefectural scale divisions and spatial spillover effects, this study employed a hierarchical spatial autoregressive model to investigate the impact of land urbanization on CO2 emissions in the Yangtze River Delta (YRD) during 1995–2015. The results showed that CO2 emissions exhibited spatial clustering across the counties and prefectural cities in the YRD region. The prefectural cities with the High-High type were mainly concentrated in Shanghai, Suzhou and Nantong during 1995–2015, indicating that they were the main areas that required CO2 emissions reduction. Land urbanization has a positive effect on CO2 emissions; there is an inverse U-shaped relationship between land urbanization and CO2 emissions. CO2 emissions presented spatiotemporal variations between the county and prefectural scales in the YRD region. The spatial interactions between county scale and prefectural scale suggest that local governments should integrate their neighboring governments (higher and lower governments) to reduce CO2 emissions in the YRD. The population, GDP per capita, carbon intensity, and spatial factor also played a significant role in reducing CO2 emissions. The results provide useful information for low-carbon urbanization development in the YRD.",
        "author_keywords": [
            "Carbon dioxide emissions",
            "Hierarchical spatial autoregressive model",
            "Land urbanization",
            "Multiscale perspective",
            "Yangtze River Delta"
        ],
        "subject_areas": [
            "Development",
            "Sociology and Political Science",
            "Urban Studies",
            "Tourism, Leisure and Hospitality Management"
        ]
    },
    {
        "title": "Multi-modal generative adversarial networks for traffic event detection in smart cities",
        "authors": "Chen Q.",
        "journal": "Expert Systems with Applications",
        "doi": "10.1016/j.eswa.2021.114939",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85103950278",
        "scopus_id": "85103950278",
        "abstract": "Advances in the Internet of Things have enabled the development of many smart city applications and expert systems that help citizens and authorities better understand the dynamics of the cities, and make better planning and utilisation of city resources. Smart cities are composed of complex systems that usually process and analyse big data from the Cyber, Physical, and Social worlds. Traffic event detection is an important and complex task in smart transportation modelling and management. We address this problem using semi-supervised deep learning with data of different modalities, e.g., physical sensor observations and social media data. Unlike most existing studies focusing on data of single modality, the proposed method makes use of data of multiple modalities that appear to complement and reinforce each other. Meanwhile, as the amount of labelled data in big data applications is usually extremely limited, we extend the multi-modal Generative Adversarial Network model to a semi-supervised architecture to characterise traffic events. We evaluate the model with a large, real-world dataset consisting of traffic sensor observations and social media data collected from the San Francisco Bay Area over a period of four months. The evaluation results clearly demonstrate the advantages of the proposed model in extracting and classifying traffic events.",
        "author_keywords": [
            "Deep learning",
            "Generative adversarial network",
            "Multi-modal learning",
            "Semi-supervised learning",
            "Smart transportation",
            "Traffic event detection"
        ],
        "subject_areas": [
            "Engineering (all)",
            "Computer Science Applications",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Climate Adaptation as a Racial Project: An Analysis of Color-Blind Flood Resilience Efforts in Austin, Texas",
        "authors": "Zoll D.",
        "journal": "Environmental Justice",
        "doi": "10.1089/env.2021.0034",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85112795790",
        "scopus_id": "85112795790",
        "abstract": "As awareness of climate change increases, U.S. cities are beginning to implement climate mitigation and adaptation initiatives to reduce population vulnerabilities to climate risks. This study contributes to a growing literature that quantitatively describes the relationships between sociodemographic variables and climate adaptation interventions in U.S. cities. Ordinary linear and simultaneous autoregressive models are used to evaluate early flood adaptation actions in Austin, Texas, to assess relationships between flood risk, green infrastructure, and measures of race and income. Findings of unequal exposure to flood risk and uneven access to flood resilience initiatives contribute to our understanding of color-blind urban planning responses to climate change and their potential to amplify inequitable protection from climate risks.",
        "author_keywords": [
            "climate adaptation",
            "climate justice",
            "color-blind adaptation",
            "urban planning"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Management, Monitoring, Policy and Law",
            "Health, Toxicology and Mutagenesis"
        ]
    },
    {
        "title": "Cost-Effective Active Sparse Urban Sensing: Adversarial Autoencoder Approach",
        "authors": "Zhu K.",
        "journal": "IEEE Internet of Things Journal",
        "doi": "10.1109/JIOT.2021.3060815",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85101751341",
        "scopus_id": "85101751341",
        "abstract": "The ever-expanding applications of mobile crowdsensing have made scalable environment sensing possible by exploiting the power of ubiquitous smart devices. Nevertheless, the implementation of sensing applications in urban scale meets serious challenges in terms of sensing costs and quality. For example, data sparsity will arise due to sensing ability and cost, and the measurements could contain noise or errors. Therefore, missing data inference with low-quality measurements is critical. To tackle these challenges, we design a low-cost crowdsensing system by missing data inference incorporating with active sensing grids selection. Specifically, an adversarial autoencoder (AAE)-based scheme is proposed for missing data inference. This model applies VAE to learn latent variables and generates full data and further utilizes the adversarial nets to play a min-max game with the autoencoder. Furthermore, an active learning-based method is designed to iteratively select sensing grids to further reduce the cost. The proposed scheme can handle large missing rate, both random and block missing patterns, and is robust against measurement noise. Comprehensive experiments based on three data sets are conducted to evaluate the effectiveness of the proposed system.",
        "author_keywords": [
            "Active learning (AL)",
            "adversarial autoencoder (AAE)",
            "mobile crowdsensing (MCS)",
            "smart city"
        ],
        "subject_areas": [
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "TSA-GAN: A Robust Generative Adversarial Networks for Time Series Augmentation",
        "authors": "Li Z.",
        "journal": "Proceedings of the International Joint Conference on Neural Networks",
        "doi": "10.1109/IJCNN52387.2021.9534001",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85116450057",
        "scopus_id": "85116450057",
        "abstract": "Time series classification (TSC) is widely used in various real-world applications such as human activity recognition, smart city governance, etc. Unfortunately, due to different reasons, only part of time series could be collected which may obviously degrade the performance of time series classifiers. To alleviate this problem, time series augmentation aims to generate synthetic time series by learning useful features from collected time series. As the popular generative model, generative adversarial networks (GAN) is regarded as a promising model for time series augmentation. However, applying GAN to the time series data suffers from a challenge in which the generated instances hold low quality but the model has gotten saturation. In this paper, for time series augmentation, we proposed TSA-GAN which is a robust GAN model with a self-adaptive recovering strategy to solve this problem. On 85 datasets of the UCR 2015 archive, our proposed TSA-GAN helps time series classifiers achieve performance improvements ranging from 8.3% to 12.5%, which is far better than the baseline.",
        "author_keywords": [
            "GANs",
            "time series augmentation",
            "training saturation"
        ],
        "subject_areas": [
            "Software",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Information diffusion across cyber-physical-social systems in smart city: A survey",
        "authors": "Zhou X.",
        "journal": "Neurocomputing",
        "doi": "10.1016/j.neucom.2020.08.089",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85102430887",
        "scopus_id": "85102430887",
        "abstract": "The smart city makes use of information technology to integrate city systems and functions to optimize city management and services. In this paper, we treat the smart city as a Cyber-Physical-Social System (CPSS), which is a kind of heterogeneous complex network system. Since information diffusion is fundamental to complex network analysis, we would like to summarize information diffusion in CPSS, including features of information diffusion, its application in the field of smart city, and critical technologies of information diffusion modeling and analysis. Finally, we point out open research issues, challenges, and put forward the possible future direction for research of information diffusion in smart city CPSS.",
        "author_keywords": [
            "CPSS",
            "Information diffusion",
            "Smart city"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Cognitive Neuroscience",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Designing Intelligent Agents for the Management of Complex Data Communication Networks in Smart Cities",
        "authors": "Minea M.",
        "journal": "Proceedings of the 13th International Conference on Electronics, Computers and Artificial Intelligence, ECAI 2021",
        "doi": "10.1109/ECAI52376.2021.9515055",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85115081774",
        "scopus_id": "85115081774",
        "abstract": "The paper focuses on the design of future complex networks, in the perspective of smart cities, where many sensors and data flows are expected to arise. The research proposes the use of multiple intelligent agents to monitor critical features of the communication network, including hardware and applications/software components, in a tree architecture, with a top-supervisor agent, also used as human-machine interface for the Fault Management System operators. A study case is also included, along with recommendations for the best artificial intelligence components to be used in such an architecture.",
        "author_keywords": [
            "AI agent",
            "AI assistance",
            "applications and microservices",
            "automation",
            "infrastructure monitoring"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Information Systems",
            "Information Systems and Management",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Vehicle trajectory prediction and generation using LSTM models and GANs",
        "authors": "Rossi L.",
        "journal": "PLoS ONE",
        "doi": "10.1371/journal.pone.0253868",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85110379757",
        "scopus_id": "85110379757",
        "abstract": "Vehicles' trajectory prediction is a topic with growing interest in recent years, as there are applications in several domains ranging from autonomous driving to traffic congestion prediction and urban planning. Predicting trajectories starting from Floating Car Data (FCD) is a complex task that comes with different challenges, namely Vehicle to Infrastructure (V2I) interaction, Vehicle to Vehicle (V2V) interaction, multimodality, and generalizability. These challenges, especially, have not been completely explored by state-of-the-art works. In particular, multimodality and generalizability have been neglected the most, and this work attempts to fill this gap by proposing and defining new datasets, metrics, and methods to help understand and predict vehicle trajectories. We propose and compare Deep Learning models based on Long Short-Term Memory and Generative Adversarial Network architectures; in particular, our GAN-3 model can be used to generate multiple predictions in multimodal scenarios. These approaches are evaluated with our newly proposed error metrics N-ADE and N-FDE, which normalize some biases in the standard Average Displacement Error (ADE) and Final Displacement Error (FDE) metrics. Experiments have been conducted using newly collected datasets in four large Italian cities (Rome, Milan, Naples, and Turin), considering different trajectory lengths to analyze error growth over a larger number of time-steps. The results prove that, although LSTM-based models are superior in unimodal scenarios, generative models perform best in those where the effects of multimodality are higher. Space-time and geographical analysis are performed, to prove the suitability of the proposed methodology for real cases and management services.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Recent progress in 3D vision",
        "authors": "Long X.",
        "journal": "Journal of Image and Graphics",
        "doi": "10.11834/jig.210043",
        "publication_date": "2021",
        "document_type": "Review",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85108987358",
        "scopus_id": "85108987358",
        "abstract": "3D vision has numerous applications in various areas, such as autonomous vehicles, robotics, digital city, virtual/mixed reality, human-machine interaction, entertainment, and sports. It covers a broad variety of research topics, ranging from 3D data acquisition, 3D modeling, shape analysis, rendering, to interaction. With the rapid development of 3D acquisition sensors (such as low-cost LiDARs, depth cameras, and 3D scanners), 3D data become even more accessible and available. Moreover, the advances in deep learning techniques further boost the development of 3D vision, with a large number of algorithms being proposed recently. We provide a comprehensive review on progress of 3D vision algorithms in recent few years, mostly in the last year. This survey covers seven different topics, including stereo matching, monocular depth estimation, visual localization in large-scale scenes, simultaneous localization and mapping (SLAM), 3D geometric modeling, dynamic human modeling, and point cloud understanding. Although several surveys are now available in the area of 3D vision, this survey is different from few aspects. First, this study covers a wide range of topics in 3D vision and can therefore benefit a broad research community. On the contrary, most existing works mainly focus on a specific topic, such as depth estimation or point cloud learning. Second, this study mainly focuses on the progress in very recent years. Therefore, it can provide the readers with up-to-date information. Third, this paper presents a direct comparison between the progresses in China and abroad. The recent progress in depth image acquisition, including stereo matching and monocular depth estimation, is initially reviewed. The stereo matching algorithms are divided into non-end-to-end stereo matching, end-to-end stereo matching, and unsupervised stereo matching algorithms. The monocular depth estimation algorithms are categorized into depth regression networks and depth completion networks. The depth regression networks are further divided into encoder-decoder networks and composite networks. Then, the recent progress in visual localization, including visual localization in large-scale scenes and SLAM is reviewed. The visual localization algorithms for large-scale scenes are divided into end-to-end and non-end-to-end algorithms, and these non-end-to-end algorithms are further categorized into deep learning-based feature description algorithms, 2D image retrieval-based visual localization algorithms, 2D-3D matching-based visual localization algorithms, and visual localization algorithms based on the fusion of 2D image retrieval and 2D-3D matching. SLAM algorithms are divided into visual SLAM algorithms and multisensor fusion based SLAM algorithms. The recent progress in 3D modeling and understanding, including 3D geometric modeling, dynamic human modeling, and point cloud understanding is further reviewed. 3D geometric modeling algorithms consist of several components, including deep 3D representation learning, deep 3D generative models, structured representation learning and generative models, and deep learning-based 3D modeling. Dynamic human modeling algorithms are divided into multiview RGB modeling algorithms, single-depth camera-based and multiple-depth camera-based algorithms, and single-view RGB modeling methods. Point cloud understanding algorithms are further categorized into semantic segmentation methods and instance segmentation methods for point clouds. The paper is organized as follows. In Section 1, we present the progress in 3D vision outside China. In Section 2, we introduce the progress of 3D vision in China. In Section 3, the 3D vision techniques developed in China and abroad are compared and analyzed. In Section 4, we point out several future research directions in the area.",
        "author_keywords": [
            "3D geometry modeling",
            "Dynamic human reconstruction",
            "Monocular depth estimation",
            "Point cloud understanding",
            "Simultaneous localization and mapping(SLAM)",
            "Stereo matching",
            "Visual localization"
        ],
        "subject_areas": [
            "Human-Computer Interaction",
            "Computer Vision and Pattern Recognition",
            "Computer Graphics and Computer-Aided Design",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "TIED: A cycle consistent encoder-decoder model for text-to-image retrieval",
        "authors": "Sebastian C.",
        "journal": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",
        "doi": "10.1109/CVPRW53098.2021.00467",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85116004712",
        "scopus_id": "85116004712",
        "abstract": "Retrieving specific vehicle tracks by Natural Language (NL)-based descriptions is a convenient way to monitor vehicle movement patterns and traffic-related events. NL-based image retrieval has several applications in smart cities, traffic control, etc. In this work, we propose TIED, a text-to-image encoder-decoder model for the simultaneous extraction of visual and textual information for vehicle track retrieval. The model consists of an encoder network that enforces the two modalities into a common latent space and a decoder network that performs an inverse mapping to the text descriptions. The method exploits visual semantic attributes of a target vehicle along with a cycle-consistency loss. The proposed method employs both intra-modal and inter-modal relationships to improve retrieval performance. Our system yields competitive performance achieving the 7th position in the Natural Language-Based Vehicle Retrieval public track of the 2021 NVIDIA AI City Challenge. We demonstrate that the proposed TIED model obtains six times higher Mean Reciprocal Rank (MRR) than the baseline, achieving an MRR of 15.48. The code and models will be made publicly available.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Business location planning based on a novel geo-social influence diffusion model",
        "authors": "Zeng Q.",
        "journal": "Information Sciences",
        "doi": "10.1016/j.ins.2021.01.047",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85114703167",
        "scopus_id": "85114703167",
        "abstract": "In modern smart cities, an increasing number of businesses rely on social network marketing to capture potential customers and third-party delivery systems to serve them; this system is called “online to offline”. Consequently, the well-known business location planning problem, which is used to attract nearby offline users, must be redefined. Thus, we propose a novel influence diffusion model to simulate the spread of advertisements for a given location within the geo-social networks; this model considers the distance from the social network users to the location and other existing competitors. We present an approximation algorithm to evaluate the maximum influence that can be achieved for a location based on the diffusion model. Moreover, to efficiently select the optimal location (with the largest maximum influence spread) from multiple candidates, a clustering-based pruning strategy is proposed. Our experimental results demonstrated the effectiveness and efficiency of our approach.",
        "author_keywords": [
            "Business location planning",
            "Diffusion model",
            "Geo-social networks",
            "Influence maximization"
        ],
        "subject_areas": [
            "Software",
            "Control and Systems Engineering",
            "Theoretical Computer Science",
            "Computer Science Applications",
            "Information Systems and Management",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "GAN Based Noise Generation to Aid Activity Recognition when Augmenting Measured WiFi Radar Data with Simulations",
        "authors": "Vishwakarma S.",
        "journal": "2021 IEEE International Conference on Communications Workshops, ICC Workshops 2021 - Proceedings",
        "doi": "10.1109/ICCWorkshops50388.2021.9473900",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85110935862",
        "scopus_id": "85110935862",
        "abstract": "This work considers the use of a passive WiFi radar (PWR) to monitor human activities. Real-time uncooperative monitoring of people has numerous applications ranging from smart cities and transport to IoT and security. In e-healthcare, PWR technology could be used for ambient assisted living and early detection of chronic health conditions. Large training datasets could drive forward machine-learning-focused research in the above applications. However, generating and labeling large volumes of high-quality, diverse radar datasets is an onerous task. Therefore, we present an open-source motion capture data-driven simulation tool, SimHumalator, that can generate large volumes of human micro-Doppler radar data at multiple IEEE WiFi standards(IEEE 802.11g, n, and ad). We qualitatively compare the micro-Doppler signatures generated through SimHumalator with the measured signatures. To create a more realistic training dataset, we artificially add noise to our clean simulated spectrograms. A noise distribution is directly learned from real radar measurements using a Generative Adversarial Network (GAN). We observe improvements in the classification performances between 3 to 8%. Our results suggest that simulation data can be used to make adequate training data when the available measurement training support is low.",
        "author_keywords": [
            "activity recognition",
            "generative adversarial networks",
            "micro-Doppler",
            "Passive WiFi Sensing"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Hardware and Architecture",
            "Information Systems and Management"
        ]
    },
    {
        "title": "Data-Augmentation-Based Cellular Traffic Prediction in Edge-Computing-Enabled Smart City",
        "authors": "Wang Z.",
        "journal": "IEEE Transactions on Industrial Informatics",
        "doi": "10.1109/TII.2020.3009159",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85102367109",
        "scopus_id": "85102367109",
        "abstract": "With the massive deployment of 5G cellular infrastructures, traffic prediction has become an indispensable part of the cellular resource management system in order to provide reliable and fast communication services that can meet the increasing quality-of-service requirements of smart city. A promising approach for handling this problem is to introduce intelligent methods to implement a highly effective and efficient cellular traffic prediction model. Meanwhile, integrating the multiaccess edge computing framework in 5G cellular networks facilitates the application of intelligent traffic prediction models by enabling their implementation at the network edge. However, the data shortage and privacy issues may still be obstacles for training a robust and accurate prediction model at the edge. To address these issues, we propose a data-augmentation-based cellular traffic prediction model (ctGAN-S2S), where an effective data augmentation submodel based on generative adversarial networks is proposed to improve the prediction performance while protecting data privacy, and a long-short-term-memory-based sequence-to-sequence submodel is used to achieve the flexible multistep cellular traffic prediction. The experimental results on a real-world city-scale cellular traffic dataset reveal that our ctGAN-S2S model achieves up to 48.49% improvement of the prediction accuracy compared to four typical reference models.",
        "author_keywords": [
            "Cellular networks",
            "data augmentation",
            "neural networks",
            "smart city",
            "time-series prediction"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Information Systems",
            "Computer Science Applications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Synthetic Ride-Requests Generation using WGAN with Location Embeddings",
        "authors": "Nookala U.",
        "journal": "2021 Smart City Symposium Prague, SCSP 2021",
        "doi": "10.1109/SCSP52043.2021.9447372",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85111602939",
        "scopus_id": "85111602939",
        "abstract": "Ride-hailing services have gained tremendous importance in social life today, and the amount of resources involved have been hiking up. Ride-request data has been crucial in the research of improving ride-hailing efficiency and minimizing the cost. This work aims to model human mobility patterns to generate realistic ride-requests, addressing the prevailing problem of lack of historical training data and realistic synthetic data for different hypothetical scenarios. Synthetic generation also inherently carries anonymity. In particular, our work focuses on modeling both spatial and temporal distributions jointly for ride-hailing services. A Ride-Request Wasserstein Generative Adversarial Network (RR-WGAN) is proposed to generate plausible pick-up and drop-off geolocations. The generated ride-requests are extensively evaluated under a wide range of criteria we design, giving a comprehensive understanding of how the model performs. The proposed approach has achieved better performance than state-of-the-art methods in most scenarios. We believe this approach could provide value for ride-hailing service providers, research communities, and policy-makers.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Atmospheric environmental impact and communication signal processing optimization in coastal areas",
        "authors": "Li L.",
        "journal": "Arabian Journal of Geosciences",
        "doi": "10.1007/s12517-021-07206-z",
        "publication_date": "2021",
        "document_type": "Retracted",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85106221753",
        "scopus_id": "85106221753",
        "abstract": "The degree of air pollution in an area depends on the initial parameters of pollutant emissions, meteorological conditions, and the state of the ground surface. Meteorology and potential surface conditions determine the rate of dissolution and diffusion, as well as the pathways for the migration and transformation of pollutants in the atmosphere. In this work, the researchers created a Lagrangian smoke diffusion model based on pollution levels, meteorological conditions, and initial parameters of the lower surface of the near-surface layer. The calculation uses the method of superposition of the diffusion concentration of the ground source and the ground source, and the Lagrangian coordinate system is determined by the cumulative map of the wind rose. When calculating the long-term average atmospheric concentration, a correction factor is introduced to correct for the effects of near-surface and underlying ground conditions. With the rapid development of China’s economy, communication between people anytime and anywhere has become very important, and people’s demand for and reliance on mobile communication is also increasing. The constant changes in social life mean that urban planning changes every day, and the solutions and facilities introduced by the existing mobile companies cannot meet the needs of mobile phone users. With the continuous emergence of a large number of blind spots and new problems, we find new practical solutions for mobile communications to adapt to new needs. According to the actual situation of mobile communication, combined with the theory of wireless signal propagation, this article discusses the project of in-depth optimization of the mobile coverage area, discusses according to the characteristics of the communication project and the actual situation of different regions, and finally realizes the project plan of optimized coverage in practice.",
        "author_keywords": [
            "Atmospheric environment",
            "Coastal area",
            "Communication signal",
            "Processing optimization"
        ],
        "subject_areas": [
            "Environmental Science (all)",
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "GAN based efficient foreground extraction and HGWOSA based optimization for video synopsis generation",
        "authors": "Ghatak S.",
        "journal": "Digital Signal Processing: A Review Journal",
        "doi": "10.1016/j.dsp.2021.102988",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100487128",
        "scopus_id": "85100487128",
        "abstract": "Video Synopsis is a smart and efficient solution to summarize a long duration of surveillance video into short. Most of the video synopsis techniques are not suitable to address complex situations like changes in illumination, dynamic background, camera jitter, etc. These techniques firmly depend on the preprocessing results of foreground extraction and multiple objects tracking. Further, the optimization process is a vital phase for the decrement of collision rate among moving objects, where the widely used Simulated Annealing (SA) usually suffers from the issue of slow convergence rate with a high computational overhead. Taking these aforementioned facts into account for feature extraction, we formulate a foreground extraction scheme exploring the concept of multi-frame and multi-scale in Generative Adversarial Network (mFS-GANs). Further, an optimization algorithm is proposed through the hybridization of SA and Grey Wolf Optimizer (GWO), named as, HGWOSA to ensure global optimal result with a low computing overhead. The performance of the proposed scheme is evaluated through extensive simulations and compared with that of the benchmark schemes. The experiments are carried out using some standard surveillance video dataset (ChangeDetection.Net, MIT Surveillance Dataset, and UMN Dataset) and one self-generated surveillance video at IIIT Bhubaneswar. Overall analysis and experimental evaluations demonstrate that our proposed scheme outperforms the other competing schemes in terms of both the quantitative and qualitative measures. Finally, the proposed model can be substantially employed in the generation of off-line video synopsis, which is potentially applicable to video surveillance applications for smart cities.",
        "author_keywords": [
            "Deep learning",
            "Generative adversarial networks (GANs)",
            "Grey wolf optimizer (GWO)",
            "Simulated annealing (SA)",
            "Video synopsis"
        ],
        "subject_areas": [
            "Signal Processing",
            "Computer Vision and Pattern Recognition",
            "Statistics, Probability and Uncertainty",
            "Computational Theory and Mathematics",
            "Electrical and Electronic Engineering",
            "Artificial Intelligence",
            "Applied Mathematics"
        ]
    },
    {
        "title": "Remote sensing building segmentation by CGAN with multilevel channel attention mechanism",
        "authors": "Yu S.",
        "journal": "Journal of Image and Graphics",
        "doi": "10.11834/jig.200059",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85104624477",
        "scopus_id": "85104624477",
        "abstract": "Objective: Remote sensing building object segmentation is one of the important applications in image processing, which plays a vital role in smart city planning and urban change detection. However, building objects in remote sensing images have many complex characteristics, such as variable sizes, dense distributions, diverse topological shapes, complex backgrounds, and presence of occlusions and shadows. Traditional building segmentation algorithms are mainly based on manually designed features such as shapes, edges, and shadow features. These features are shallow features of the building target and cannot well express high-level semantic information, resulting in low recognition accuracy. By contrast, deep convolutional networks show excellent performance in pixel-level classification of natural images. Various fully convolutional network based image segmentation models have been continuously proposed. Most of these models use deconvolution or bilinear interpolation after feature extraction. Feature upsampling and pixel-by-pixel classification are used to segment the input image. The deep features of the building are extracted using highly nonlinear mapping and a large amount of data training, which overcomes the shortcomings of traditional algorithms. However, upsampling cannot completely compensate the information loss caused by repeated convolution and pooling operations in the deep convolutional network model. Therefore, the prediction results are relatively rough, such as small target misclassification, inaccurate boundaries, and other issues. In the field of remote sensing, public data sets are few. Training excellent deep convolutional networks is difficult, and the robustness of the network needs to be further improved. Aiming at the above problems, this paper proposes a conditional generative adversarial network (Ra-CGAN) with multilevel channel attention mechanism to segment remote sensing building objects. Method: A generative model with a multilevel channel attention mechanism is first built. The model is based on a coding and decoding structure that solves small target misses by fusing deep semantics and shallow details with attention. Second, a discriminative network is built and used to distinguish whether the input comes from the real label map or the segmentation map generated by the model. The segmentation result (accuracy and smoothness) is improved by correcting the difference between the two maps. The downsampling method without pooling is used in the discriminator to enhance the propagation of the gradient. Finally, the generated model and the discriminant model are alternately confronted for training through the constraint of the conditional variable of the labelled image. Learning the higher-order data distribution characteristics results in more continuity for the target space. The loss function uses a hybrid loss function, which comes from the cross-entropy loss function brought by the generated map and the real label map in the generation mode. The discriminator predicts the generated image as the loss value brought by the real label image. Experiments are performed on the WHU Building Dataset and Satellite Dataset II datasets. The first dataset has a dense building with many types and accurate labels, and can provide comprehensive, representative evaluation capabilities for the model. Another dataset with a higher segmentation difficulty is used to verify the robustness and scalability of the model. The lighting information and background information of the building are more complex than those of the first dataset. The experiment uses the PyTorch deep learning framework. The size of original image and the label image are unified to 512 × 512 pixels for training, the learning rate of Adam is set to 0.000 2, the momentum parameter is 0.5, the batch-size is 12, and the epoch is 200 times. Acceleration is performed using NVIDIA GTX TITAN Xp. Evaluation indicators include intersection over union (IOU), precision, recall, and F1-score. Result: Experiments are performed on the WHU Building Dataset and Satellite Dataset II datasets, and the methods are compared with the latest literature. Experimental results show that in the WHU dataset, the segmentation performance of the Ra-CGAN model is substantially improved compared with models without attention mechanism and adversarial training. Space continuity and integrity of the complex building and small building, and smoothness of building edges are considerably improved. Compared with U-Net, IOU value is increased by 3.75%, and F1-score is increased by 2.52%. Compared with the second-performance model, IOU value is increased by 1.1%, and F1-score is increased by 1.1%. In the Satellite Dataset II, Ra-CGAN obtains more ideal results in terms of target integrity and smoothness than other models, especially in the case of insufficient data samples. Compared with U-Net, IOU value is increased by 7.26%, and F1-score is increased by 6.68%. Compared with the second-placed model, IOU value is increased by 1.7% and F1-score is increased by 1.6%. Conclusion: A CGAN remote sensing building object segmentation model with multilevel channel attention mechanism, which combines the advantages of multilevel channel attention mechanism generation model and conditional generative adversarial networks, is proposed. Experimental results show that our model is superior to several state-of-the-art segmentation methods. Much more accurate remote sensing building object segmentation results are obtained on different datasets, proving that the model exhibits better robustness and scalability.",
        "author_keywords": [
            "Attention mechanism",
            "Conditional generative adversarial network (CGAN)",
            "Deep convolutional neural network",
            "Multi-scale feature fusion",
            "Remote sensing image segmentation"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Graphics and Computer-Aided Design",
            "Computer Vision and Pattern Recognition",
            "Human-Computer Interaction"
        ]
    },
    {
        "title": "Rain streak removal for single images using conditional generative adversarial networks",
        "authors": "Hettiarachchi P.",
        "journal": "Applied Sciences (Switzerland)",
        "doi": "10.3390/app11052214",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85102509189",
        "scopus_id": "85102509189",
        "abstract": "Rapid developments in urbanization and smart city environments have accelerated the need to deliver safe, sustainable, and effective resource utilization and service provision and have thereby enhanced the need for intelligent, real-time video surveillance. Recent advances in machine learning and deep learning have the capability to detect and localize salient objects in surveillance video streams; however, several practical issues remain unaddressed, such as diverse weather conditions, recording conditions, and motion blur. In this context, image de-raining is an important issue that has been investigated extensively in recent years to provide accurate and quality surveillance in the smart city domain. Existing deep convolutional neural networks have obtained great success in image translation and other computer vision tasks; however, image de-raining is ill posed and has not been addressed in real-time, intelligent video surveillance systems. In this work, we propose to utilize the generative capabilities of recently introduced conditional generative adversarial networks (cGANs) as an image de-raining approach. We utilize the adversarial loss in GANs that provides an additional component to the loss function, which in turn regulates the final output and helps to yield better results. Experiments on both real and synthetic data show that the proposed method outperforms most of the existing state-of-the-art models in terms of quantitative evaluations and visual appearance.",
        "author_keywords": [
            "Deep learning",
            "Generative adversarial networks",
            "Image de-raining",
            "Traffic surveillance image processing"
        ],
        "subject_areas": [
            "Materials Science (all)",
            "Instrumentation",
            "Engineering (all)",
            "Process Chemistry and Technology",
            "Computer Science Applications",
            "Fluid Flow and Transfer Processes"
        ]
    },
    {
        "title": "Cyber security in smart cities: A review of deep learning-based applications and case studies",
        "authors": "Chen D.",
        "journal": "Sustainable Cities and Society",
        "doi": "10.1016/j.scs.2020.102655",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85098718110",
        "scopus_id": "85098718110",
        "abstract": "On the one hand, smart cities have brought about various changes, aiming to revolutionize people's lives. On the other hand, while smart cities bring better life experiences and great convenience to people's lives, there are more hidden dangers of cyber security, including information leakage and malicious cyber attacks. The current cyber security development cannot keep up with the eager adoption of global smart city technologies so correct design based on deep learning methods is essential to protect smart city cyber. This paper summarizes the knowledge and interpretation of Smart Cities (SC), Cyber Security (CS), and Deep Learning (DL) concepts as well as discussed existing related work on IoT security in smart cities. Specifically, we briefly reviewed several deep learning models, including Boltzmann machines, restricted Boltzmann machines, deep belief networks, recurrent neural networks, convolutional neural networks, and generative adversarial networks. Then we introduced cyber security applications and use cases based on deep learning technology in smart cities. Finally, we describe the future development trend of smart city cyber security.",
        "author_keywords": [
            "A review",
            "Cyber security",
            "Deep learning",
            "Smart cities"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Civil and Structural Engineering",
            "Renewable Energy, Sustainability and the Environment",
            "Transportation"
        ]
    },
    {
        "title": "Cascading Scene and Viewpoint Feature Learning for Pedestrian Gender Recognition",
        "authors": "Cai L.",
        "journal": "IEEE Internet of Things Journal",
        "doi": "10.1109/JIOT.2020.3021763",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100731226",
        "scopus_id": "85100731226",
        "abstract": "Pedestrian gender recognition plays an important role in smart city. To effectively improve the pedestrian gender recognition performance, a new method, called cascading scene and viewpoint feature learning (CSVFL), is proposed in this article. The novelty of the proposed CSVFL lies on the joint consideration of two crucial challenges in pedestrian gender recognition, namely, scene and viewpoint variation. For that, the proposed CSVFL starts with the scene transfer (ST) scheme, followed by the viewpoint adaptation (VA) scheme in a cascading manner. Specifically, the ST scheme exploits the key pedestrian segmentation network to extract the key pedestrian masks for the subsequent key pedestrian transfer generative adversarial network, with the goal of encouraging the input pedestrian image to have the similar style to the target scene while preserving the image details of the key pedestrian as much as possible. Afterward, the obtained scene-transferred pedestrian images are fed to train the deep feature learning network with the VA scheme, in which each neuron will be enabled/disabled for different viewpoints depending on whether it has contribution on the corresponding viewpoint. Extensive experiments conducted on the commonly used pedestrian attribute data sets have demonstrated that the proposed CSVFL approach outperforms multiple recently reported pedestrian gender recognition methods.",
        "author_keywords": [
            "Cascading feature learning",
            "pedestrian gender recognition",
            "scene variation",
            "viewpoint variation"
        ],
        "subject_areas": [
            "Signal Processing",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Human mesh reconstruction with generative adversarial networks from single rgb images",
        "authors": "Gao R.",
        "journal": "Sensors (Switzerland)",
        "doi": "10.3390/s21041350",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100784196",
        "scopus_id": "85100784196",
        "abstract": "Applications related to smart cities require virtual cities in the experimental development stage. To build a virtual city that are close to a real city, a large number of various types of human models need to be created. To reduce the cost of acquiring models, this paper proposes a method to reconstruct 3D human meshes from single images captured using a normal camera. It presents a method for reconstructing the complete mesh of the human body from a single RGB image and a generative adversarial network consisting of a newly designed shape–pose-based generator (based on deep convolutional neural networks) and an enhanced multi-source discriminator. Using a machine learning approach, the reliance on multiple sensors is reduced and 3D human meshes can be recovered using a single camera, thereby reducing the cost of building smart cities. The proposed method achieves an accuracy of 92.1% in body shape recovery; it can also process 34 images per second. The method proposed in this paper approach significantly improves the performance compared with previous state-of-the-art approaches. Given a single view image of various humans, our results can be used to generate various 3D human models, which can facilitate 3D human modeling work to simulate virtual cities. Since our method can also restore the poses of the humans in the image, it is possible to create various human poses by given corresponding images with specific human poses.",
        "author_keywords": [
            "3D human model",
            "Artificial intelligence",
            "Deep learning",
            "GAN",
            "Image processing",
            "Smart cities"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Information Systems",
            "Atomic and Molecular Physics, and Optics",
            "Biochemistry",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Advanced driving assistance based on the fusion of infrared and visible images",
        "authors": "Gu Y.",
        "journal": "Entropy",
        "doi": "10.3390/e23020239",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85111271042",
        "scopus_id": "85111271042",
        "abstract": "Obtaining key and rich visual information under sophisticated road conditions is one of the key requirements for advanced driving assistance. In this paper, a newfangled end-to-end model is proposed for advanced driving assistance based on the fusion of infrared and visible images, termed as FusionADA. In our model, we are committed to extracting and fusing the optimal texture details and salient thermal targets from the source images. To achieve this goal, our model constitutes an adversarial framework between the generator and the discriminator. Specifically, the generator aims to generate a fused image with basic intensity information together with the optimal texture details from source images, while the discriminator aims to force the fused image to restore the salient thermal targets from the source infrared image. In addition, our FusionADA is a fully end-to-end model, solving the issues of manually designing complicated activity level measurements and fusion rules existing in traditional methods. Qualitative and quantitative experiments on publicly available datasets RoadScene and TNO demonstrate the superiority of our FusionADA over the state-of-the-art approaches.",
        "author_keywords": [
            "Advanced driving assistance",
            "Generative adversarial network",
            "Infrared and visible image fusion",
            "Smart city"
        ],
        "subject_areas": [
            "Information Systems",
            "Mathematical Physics",
            "Physics and Astronomy (miscellaneous)",
            "Physics and Astronomy (all)",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Corrigendum to “Impacts of urban landscapes on students’ academic performance” [Landsc. Urban Plan. 201 (2020) 103840] (Landscape and Urban Planning (2020) 201, (S0169204619317116), (10.1016/j.landurbplan.2020.103840))",
        "authors": "Lin M.",
        "journal": "Landscape and Urban Planning",
        "doi": "10.1016/j.landurbplan.2020.103982",
        "publication_date": "2021",
        "document_type": "Erratum",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85094908727",
        "scopus_id": "85094908727",
        "abstract": "The authors regret that the abstract and key words for this article were not included in the final publication—despite these having been included in the manuscript submission throughout the peer review process. The abstract and key words are obviously important components of a publication, especially in the digital age where they are (1) the only piece of the publication to appear in indexing databases and (2) the primary tools to guide indexers and search-engines. Therefore, the abstract and key words are provided here. Abstract: Contact with nature has long been associated with human health benefits, such as improved vitality and productivity, as well as reduced stress and anxiety. It also appears to impact educational outcomes; however, previous studies have reported mixed conclusions. These contradictory findings indicate that the underlying mechanism of this relationship is still unclear. This study examines the association between urban landscapes and school-level academic performance using data from 470 third-grade schools in the Atlanta Metropolitan Area, Georgia. Measures of urban landscapes in each school attendance area (SAA) include tree canopy cover (%), grass (%), shrub (%), water (%), and impervious surface (%). Standardized test scores on English Language Arts (ELA), Mathematics, Science, and Social Studies were measures for academic performance. Spatial lag simultaneous autoregressive (SAR) models were applied to determine associations between SAA vegetation and water and school-level academic achievement after accounting for demographic (e.g., percent Hispanic) and socioeconomic (e.g., percent students that are certified by National School Lunch Program) factors related to achievement. Tree canopy cover was significantly and positively related to academic performance, while percent grass and shrub covers had no significant associations. Percent water in SAA showed statistically significant and positive correlation with the mean science and social science scores, as well as students’ proficiency level in social science. Findings from this study can help better plan urban environments. Keywords: Green space; Blue space; Academic performance; Simultaneous autoregressive model The authors would like to apologise for any inconvenience caused.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "BlockPlanner: City Block Generation with Vectorized Graph Representation",
        "authors": "Xu L.",
        "journal": "Proceedings of the IEEE International Conference on Computer Vision",
        "doi": "10.1109/ICCV48922.2021.00503",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127823568",
        "scopus_id": "85127823568",
        "abstract": "City modeling is the foundation for computational urban planning, navigation, and entertainment. In this work, we present the first generative model of city blocks named BlockPlanner, and showcase its ability to synthesize valid city blocks with varying land lots configurations. We propose a novel vectorized city block representation utilizing a ring topology and a two-tier graph to capture the global and local structures of a city block. Each land lot is abstracted into a vector representation covering both its 3D geometry and land use semantics. Such vectorized representation enables us to deploy a lightweight network to capture the underlying distribution of land lots configurations in a city block. To enforce intrinsic spatial constraints of a valid city block, a set of effective loss functions are imposed to shape rational results. We contribute a pilot city block dataset to demonstrate the effectiveness and efficiency of our representation and framework over the state-of-the-art. Notably, our BlockPlanner is also able to edit and manipulate city blocks, enabling several useful applications, e.g., topology refinement and footprint generation.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "A modified Generative Adversarial Network (GAN) architecture for land use classification",
        "authors": "Ansith S.",
        "journal": "Proceedings of the IEEE Madras Section International Conference 2021, MASCON 2021",
        "doi": "10.1109/MASCON51689.2021.9563609",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85126241210",
        "scopus_id": "85126241210",
        "abstract": "Land cover and usage classification with satellite images plays an important role in many applications such as land resource management, urban planning, precision agriculture and environmental protection. Faster and easier land cover and usage classification without the prior knowledge of the terrain and training sample assignment can be done using deep learning algorithms. Early works in land use classification are mainly focused on machine learning algorithms. In the past few years some deep learning (DL) architectures are also used in the land cover and usage classification purposes. But these DL architectures need large amounts of training samples to get higher accuracy. In this paper, a modified Generative Adversarial Network (GAN) architecture has been proposed for land use classification. This deep learning model performs physical atmospheric corrections as a pre-processing step. Moreover, the model has shown to perform an efficient classification based on the statistical qualifications performed herein with a limited training dataset acquired from UC Merced land use dataset.",
        "author_keywords": [
            "Deep learning algorithm",
            "GAN",
            "land use classification",
            "Remote sensing",
            "UC Merced land use dataset"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "C 3 -GAN: Complex-Condition-Controlled Urban Traffic Estimation through Generative Adversarial Networks",
        "authors": "Zhang Y.",
        "journal": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "doi": "10.1109/ICDM51629.2021.00196",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85125176893",
        "scopus_id": "85125176893",
        "abstract": "Given historical traffic distributions and associated urban conditions observed in a city, the conditional urban traffic estimation problem aims at estimating realistic future projections of the traffic under a set of new urban conditions, e.g., new bus routes, rainfall intensity and travel demands. The problem is important in reducing traffic congestion, improving public transportation efficiency, and facilitating urban planning. However, solving this problem is challenging due to the strong spatial dependencies of traffic patterns and the complex relations between the traffic and urban conditions. In this paper, we tackle the challenges by proposing a novel Complex-Condition-Controlled Urban Traffic Estimation through Generative Adversarial Networks (C3-GAN) for urban traffic estimation of a region under various complex conditions. C3-GAN features the following three novel designs on top of standard cGAN model: (1) an embedding network mapping the complex conditions to a latent space to find representations of the urban conditions; (2) an inference network to enhance the relations between the embedded latent vectors and the traffic data. Extensive experiments on real-world datasets demonstrate that our C3-GAN produces high-quality traffic estimations and outperforms state-of-the-art baseline methods.",
        "author_keywords": [
            "generative adversarial networks",
            "urban traffic estimation"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "GAN-based Intrusion Detection Data Enhancement",
        "authors": "Fu W.",
        "journal": "Proceedings of the 33rd Chinese Control and Decision Conference, CCDC 2021",
        "doi": "10.1109/CCDC52312.2021.9602568",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85125174885",
        "scopus_id": "85125174885",
        "abstract": "In view of the lack of intrusion detection data and the slow update of mainstream detection methods, an intrusion detection data generation method based on a generative adversarial network is proposed. First, the overall data is digitized and normalized to maintain the integrity of the data; Then use the ACGAN model to learn the hidden features of the data and generate new data; Finally, evaluate the similarity and validity of the generated data from multiple perspectives. Experimental results show that the data generated by this method has similar characteristics to the original data, and can be used to enhance the original data set to meet the needs of intrusion detection systems.",
        "author_keywords": [
            "Cyber Security",
            "Generative Adversarial Network",
            "Intrusion Detection Data",
            "Smart City"
        ],
        "subject_areas": [
            "Control and Optimization",
            "Artificial Intelligence",
            "Decision Sciences (miscellaneous)",
            "Control and Systems Engineering",
            "Safety, Risk, Reliability and Quality"
        ]
    },
    {
        "title": "Deep Human-guided Conditional Variational Generative Modeling for Automated Urban Planning",
        "authors": "Wang D.",
        "journal": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "doi": "10.1109/ICDM51629.2021.00079",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85125168031",
        "scopus_id": "85125168031",
        "abstract": "Urban planning designs land-use configurations and can benefit building livable, sustainable, safe communities. Inspired by image generation, deep urban planning aims to leverage deep learning to generate land-use configurations. However, urban planning is a complex process. Existing studies usually ignore the need of personalized human guidance in planning, and spatial hierarchical structure in planning generation. Moreover, the lack of large-scale land-use configuration samples poses a data sparsity challenge. This paper studies a novel deep human guided urban planning method to jointly solve the above challenges. Specifically, we formulate the problem into a deep conditional variational autoencoder based framework. In this framework, we exploit the deep encoder-decoder design to generate land-use configurations. To capture the spatial hierarchy structure of land uses, we enforce the decoder to generate both the coarse-grained layer of functional zones, and the fine-grained layer of POI distributions. To integrate human guidance, we allow humans to describe what they need as texts and use these texts as a model condition input. To mitigate training data sparsity and improve model robustness, we introduce a variational Gaussian embedding mechanism. It not just allows us to better approximate the embedding space distribution of training data and sample a larger population to overcome sparsity, but also adds more probabilistic randomness into the urban planning generation to improve embedding diversity so as to improve robustness. Finally, we present extensive experiments to validate the enhanced performances of our method.",
        "author_keywords": [
            "Automated Urban Planning",
            "Conditional Variational Generative Model",
            "Human Guided",
            "Spatial Data Mining"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Multi-Modal Visibility Improvement under Abnormal Weather Conditions using Contextual Conditional GAN",
        "authors": "Siddiqua M.",
        "journal": "2021 International Conference on Robotics and Automation in Industry, ICRAI 2021",
        "doi": "10.1109/ICRAI54018.2021.9651370",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85124271616",
        "scopus_id": "85124271616",
        "abstract": "Removal of multiple weather-induced effects in a single image remains an open problem, although several methods addressing single effect removal have been proposed. We present a single method for removing multiple weather-induced effects that are fog, haze, rain streaks, and snowflakes. The proposed method is a unified model, based on context encoder and conditional generative adversarial network, with a single set of parameters. We demonstrate that our model is effective at improving visibility in weather degraded images. Though the training is done on synthetic data the model generalizes on real images during testing.",
        "author_keywords": [
            "Conditional adversarial network",
            "Context encoders",
            "Smart cities",
            "Street views",
            "Visibility improvement",
            "Weather effects"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Industrial and Manufacturing Engineering",
            "Mechanical Engineering",
            "Control and Optimization"
        ]
    },
    {
        "title": "Strengthening IDS against Evasion Attacks with GAN-based Adversarial Samples in SDN-enabled network",
        "authors": "Xuan Qui C.P.",
        "journal": "Proceedings - 2021 RIVF International Conference on Computing and Communication Technologies, RIVF 2021",
        "doi": "10.1109/RIVF51545.2021.9642111",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85124100033",
        "scopus_id": "85124100033",
        "abstract": "With the spread of the number of smart devices in the context of Smart City, Software Defined Networking (SDN) is considered as a vital principle to manage a large-scale heterogeneous network within centralized controller. To deal with cyberattacks against such networks, intrusion detection system (IDS) is built to recognize and alert to the system administrator for further appropriate response. Currently, machine learning-based IDS (ML-IDS) has been explored and is still being developed. However, these systems give a high rate of false alert and are easily deceived by sophisticated attacks such as variants of attacks containing perturbation. Therefore, it is necessary to continuously evaluate and improve these systems by simulating mutation of real-world network attack. Relied on the Generative Discriminative Networks (GANs), we introduce DIGFuPAS, a framework that generates data flow of cyberattacks capable of bypassing ML-IDS. It can generate malicious data streams that mutate from real attack traffic making the IDS undetectable. The generated traffic flow is used to retrain ML-IDS, for improving the robustness of IDS in detecting sophisticated attacks. The experiments are performed and evaluated through 2 criteria: Detection rate (DR) and F1 Score (F1) on the public dataset, named CICIDS2017. DIGFuPAS can be used for continuously pentesting and evaluating IDS's capability once integrated as an automated sustainability test pipeline for SDN-enabled networks.",
        "author_keywords": [
            "Adversarial Attacks",
            "Generative Adversarial Networks",
            "IDS",
            "Machine Learning IDS"
        ],
        "subject_areas": [
            "Computer Vision and Pattern Recognition",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Detection of Deep-Morphed Deepfake Images to Make Robust Automatic Facial Recognition Systems",
        "authors": "Mitra A.",
        "journal": "Proceedings - 2021 19th OITS International Conference on Information Technology, OCIT 2021",
        "doi": "10.1109/OCIT53463.2021.00039",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85123339993",
        "scopus_id": "85123339993",
        "abstract": "Face Morphing has emerged as a pervasive attack of Facial Recognition Systems. The rapid growth of Generative Adversarial Networks takes it to a complete new level. Deepfake or deep neural network based face morphing, a.k.a deep-morph attack, presents a significant threat to Facial Recognition System. In this paper, we propose a novel Convolutional Neural Network based detection method of deep morphed deepfake images which is suitable for IoT environments in smart cities. A high accuracy of 94.83% has been achieved for the DeepfakeTIMIT HQ dataset. This lightweight and fast network is a natural choice for IoT environments.",
        "author_keywords": [
            "Convolutional Neural Network",
            "Deep Learning",
            "Deep-fake",
            "Deep-Morph",
            "Facial recognition System",
            "Smart City"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Science Applications",
            "Information Systems",
            "Software"
        ]
    },
    {
        "title": "Noise Generation GAN Based Identity Privacy Protection for Smart City",
        "authors": "Yang J.",
        "journal": "Proceedings - 2021 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Internet of People, and Smart City Innovations, SmartWorld/ScalCom/UIC/ATC/IoP/SCI 2021",
        "doi": "10.1109/SWC50871.2021.00053",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85123315691",
        "scopus_id": "85123315691",
        "abstract": "The development of Internet of Things (IoT) infrastructure in the city leads to the emergence of the concept of smart city, an integrated solution to provide convenience for various applications in our daily life by understanding and analyzing the collected data from multi-sources. However, the collection of facial images collected from various IoT devices such as surveillance cameras, wearable, and mobile devices increases the risk of an individual's privacy leak. The facial recognition models augment this risk. These models retrieve facial data collected from IoT devices stored in smart city databases to get personal identity information. With extensive utilization of such IoT devices, which serve as a visual data collector, we compromise the person's identity. Therefore, to protect the privacy of image data from a database, we propose a Sensitivity Map Noise-Adding model based on generative adversarial networks to provide privacy for facial images against the malicious use of the face recognition models. The proposed models work as a black-box model that does not require any architectural information or the parameters of the target model. Additionally, the model runs at a real-time speed and the average run time for one operation is less than 12 milliseconds. The protection can be deployed for both local images and streaming videos. The data privacy protection is based on our proposed concept of the Sensitivity Maps, which summarizes the effectiveness and efficiency of adding noises on each pixel on the original image to interfere with the target model's performance. We have built a new dataset of facial images containing 102 celebrities for the proposed model to be trained and evaluated. The experimental results prove the advantage of the proposed method against protecting the identity information in facial images.",
        "author_keywords": [
            "Face Recognition",
            "GAN",
            "Privacy"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Computer Vision and Pattern Recognition",
            "Safety, Risk, Reliability and Quality",
            "Energy Engineering and Power Technology",
            "Control and Optimization",
            "Communication"
        ]
    },
    {
        "title": "AirGen: GAN-based synthetic data generator for air monitoring in Smart City",
        "authors": "Le Minh K.H.",
        "journal": "6th International Forum on Research and Technology for Society and Industry, RTSI 2021 - Proceedings",
        "doi": "10.1109/RTSI50628.2021.9597364",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85123177659",
        "scopus_id": "85123177659",
        "abstract": "The past decade has seen a notable increase in air pollution that directly damages health, animals, and plants worldwide. To mitigate such negative effects, several research groups have been working on predicting air quality using deep learning. However, the lack of high-quality air quality datasets is a major obstacle encountered to achieve high accuracy prediction. In this paper, we introduce an air monitoring data generator powered by learning distributed real sequences using the generative adversarial network (GAN), namely AirGen. An unsupervised adversarial loss is also employed in the network to minimize the difference between generated synthetic and original data in the training process. Experiments on real datasets indicate that the data generated by Airgen could significantly increase the prediction accuracy performed by deep learning models. The mean square error (MSE) is remarkably reduced from 0.024 to 0.015.",
        "author_keywords": [
            "air pollution data",
            "IoT",
            "smart city",
            "synthetic data generation"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Energy Engineering and Power Technology",
            "Industrial and Manufacturing Engineering",
            "Social Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Decision Behavior Based Private Vehicle Trajectory Generation Towards Smart Cities",
        "authors": "Chen Q.",
        "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "doi": "10.1007/978-3-030-87571-8_10",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85115830327",
        "scopus_id": "85115830327",
        "abstract": "In contrast with the condition that the trajectory dataset of floating cars (taxis) can be easily obtained from the Internet, it is hard to get the trajectory data of social vehicles (private vehicles) because of personal privacy and government policies. This paper absorbs the idea of game theory, considers the influence of individuals in the group, and proposes a decision behavior based dataset generation (DBDG) model of vehicles to predict future inter-regional traffic. In addition, we adopt simulation tools and generative adversarial networks to train the trajectory prediction model so that the private vehicle trajectory dataset conforming to social rules (e.g., collisionless) is generated. Finally, we construct from macroscopic and microscopic perspectives to verify dataset generation methods proposed in this paper. The results show that the generated data not only has high accuracy and is valuable but can provide strong data support for the Internet of Vehicles and transportation research work.",
        "author_keywords": [
            "Dataset generation",
            "Generative adversarial networks",
            "Smart cities",
            "Spatial-temporal interaction"
        ],
        "subject_areas": [
            "Theoretical Computer Science",
            "Computer Science (all)"
        ]
    },
    {
        "title": "GAN-Based LUCC Prediction via the Combination of Prior City Planning Information and Land-Use Probability",
        "authors": "Sun S.",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "doi": "10.1109/JSTARS.2021.3106481",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85113297577",
        "scopus_id": "85113297577",
        "abstract": "Currently, the world is in a period of urbanization that will accelerate the processes of land-use cover and ecological change. Thus, establishing a land-use and land-cover change (LUCC) prediction and simulation model is of great significance for understanding the process of urban change and assessing its ecological impact. In previous studies, LUCC prediction models have been mainly based on cellular automata structures that calculate a future state pixel by pixel through transition rules. Because these transition rules are usually based on the global state and each pixel is calculated according to these fixed rules, the results of these methods have room for improvement in terms of generating details and heterogeneity. In this article, a generative adversarial network (GAN)-based LUCC prediction model using multiscale local spatial information is proposed. The model is based on a pix2pix GAN and an attention structure that predicts future land use through multiscale local spatial information. To validate our model, Shenzhen, a region that is experiencing rapid urbanization, was chosen as the source of the experimental data. The results indicate that the proposed method achieved the highest accuracy in both short-time interval and long-time interval scenarios. In addition, the results of the proposed method were also closest to the ground truth from the perspective of the landscape pattern.",
        "author_keywords": [
            "Deep learning",
            "Generative adversarial network (GAN)",
            "LUCC simulation",
            "Remote sensing",
            "Smart city"
        ],
        "subject_areas": [
            "Computers in Earth Sciences",
            "Atmospheric Science"
        ]
    },
    {
        "title": "Experimenting the Impact of Pedestrianisation on Urban Pollution Using Tangible Agent-Based Simulations: Application to Hoan Kiem District, Hanoi, Vietnam",
        "authors": "Brugière A.",
        "journal": "Springer Proceedings in Mathematics and Statistics",
        "doi": "10.1007/978-981-16-2629-6_4",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85111447392",
        "scopus_id": "85111447392",
        "abstract": "The development of permanent or temporary pedestrian areas, whether for leisure or to decrease air pollution, has become an integral part of urban planning in numerous cities around the world. Hanoi, the capital of Vietnam, began to implement its first area, around the iconic Hoan Kiem lake, a few years ago. In most of cases, however, road closure is likely to deport traffic to nearby neighbourhoods with the consequences of intensifying congestion and, possibly, increasing air pollution in these areas. Because this outcome might appear counter-intuitive to most stakeholders, it is becoming more and more necessary to analyse, assess and share the impacts of these developments in terms of traffic and pollution shifts before implementing them. In this project, we used the GAMA platform to build an agent-based model that simulates the traffic, its emissions of air pollutants, and the diffusion of these pollutants in the district of Hoan Kiem. This simulation has been designed so as to serve either as a decision support tool for local authorities or as an awareness-raising tool for the general public: thanks to its display on a physical 3D model of the district, people can effectively and naturally interact with it at public venues. Although more accurate data and more realistic diffusion models are necessary and will need further research in the future, the simulation is already able to reflect traffic and air pollution peaks during rush hours, allowing residents and developers to understand the impact of pedestrianization on air quality in different scenarios.",
        "author_keywords": [
            "Agent-based model",
            "Air pollution",
            "GAMA platform",
            "Interactive simulation",
            "Urban traffic"
        ],
        "subject_areas": [
            "Mathematics (all)"
        ]
    },
    {
        "title": "STS-EPR: Modelling individual mobility considering the spatial, temporal, and social dimensions together",
        "authors": "Cornacchia G.",
        "journal": "Procedia Computer Science",
        "doi": "10.1016/j.procs.2021.03.035",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85106732245",
        "scopus_id": "85106732245",
        "abstract": "Modelling human mobility is crucial in several scientific areas, from urban planning to epidemic modeling, traffic forecasting, and what-if analysis. On the one hand, existing models focus on the spatial and temporal dimensions of mobility only, while the social dimension is often neglected. On other hand, models that embed a social mechanism have trivial or unrealistic spatial and temporal mechanisms. We propose STS-EPR, a mechanistic model that captures the spatial, temporal, and social dimensions of human mobility together. Our results show that STS-EPR generates realistic trajectories, making it better than models that lack either in the social, the spatial, or the temporal mechanisms. STS-EPR is a step towards the design of mechanistic models that can capture all the aspects of human mobility in a comprehensive way.",
        "author_keywords": [
            "Data science",
            "Generative models",
            "Human mobility",
            "Mechanistic models",
            "Social network",
            "Synthetic trajectories"
        ],
        "subject_areas": [
            "Computer Science (all)"
        ]
    },
    {
        "title": "Can a generative adversarial network remove thin clouds in aerial photographs?: Toward improving the accuracy of generating horizontal building mask images for deep learning in urban planning and design",
        "authors": "Ikeno K.",
        "journal": "Projections - Proceedings of the 26th International Conference of the Association for Computer-Aided Architectural Design Research in Asia, CAADRIA 2021",
        "doi": "10.52842/conf.caadria.2021.2.377",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85104895101",
        "scopus_id": "85104895101",
        "abstract": "Information extracted from aerial photographs is widely used in the fields of urban planning and architecture. An effective method for detecting buildings in aerial photographs is to use deep learning to understand the current state of a target region. However, the building mask images used to train the deep learning model must be manually generated in many cases. To overcome this challenge, a method has been proposed for automatically generating mask images by using textured 3D virtual models with aerial photographs. Some aerial photographs include thin clouds, which degrade image quality. In this research, the thin clouds in these aerial photographs are removed by using a generative adversarial network, which leads to improvements in training accuracy. Therefore, the objective of this research is to propose a method for automatically generating building mask images by using 3D virtual models with textured aerial photographs to enable the removable of thin clouds so that the image can be used for deep learning. A model trained on datasets generated by the proposed method was able to detect buildings in aerial photographs with an accuracy of IoU = 0.651.",
        "author_keywords": [
            "Deep learning",
            "Generative adversarial network (GAN)",
            "Mask image",
            "Semantic segmentation",
            "Urban planning and design"
        ],
        "subject_areas": [
            "Computer Graphics and Computer-Aided Design",
            "Building and Construction"
        ]
    },
    {
        "title": "Neurocognitive–Inspired Approach for Visual Perception in Autonomous Driving",
        "authors": "Plebe A.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-3-030-68028-2_6",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85101586763",
        "scopus_id": "85101586763",
        "abstract": "Since the last decades, deep neural models have been pushing forward the frontiers of artificial intelligence. Applications that in the recent past were considered no more than utopian dreams, now appear to be feasible. The best example is autonomous driving. Despite the growing research aimed at implementing autonomous driving, no artificial intelligence can claim to have reached or closely approached the driving performance of humans, yet. While the early forms of artificial neural networks were aimed at simulating and understanding human cognition, contemporary deep neural networks are totally indifferent to cognitive studies, they are designed with pure engineering goals in mind. Several scholars, we included, argue that it urges to reconnect artificial modeling with an updated knowledge of how complex tasks are realized by the human mind and brain. In this paper, we will first try to distill concepts within neuroscience and cognitive science relevant for the driving behavior. Then, we will identify possible algorithmic counterparts of such concepts, and finally build an artificial neural model exploiting these components for the visual perception task of an autonomous vehicle. More specifically, we will point to four neurocognitive theories: the simulation theory of cognition; the Convergence–divergence Zones hypothesis; the transformational abstraction hypothesis; the free–energy predictive theory. Our proposed model tries to combine a number of existing algorithms that most closely resonate with the assumptions of these four neurocognitive theories.",
        "author_keywords": [
            "Autonomous driving",
            "Convergence–divergence Zones",
            "Deep learning",
            "Free energy",
            "Variational autoencoder"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "Towards Sustainable Energy Efficiency with Intelligent Electricity Theft Detection in Smart Grids Emphasising Enhanced Neural Networks",
        "authors": "Aldegheishem A.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2021.3056566",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100761076",
        "scopus_id": "85100761076",
        "abstract": "In smart grids, electricity theft is the most significant challenge. It cannot be identified easily since existing methods are dependent on specific devices. Also, the methods lack in extracting meaningful information from high-dimensional electricity consumption data and increase the false positive rate that limit their performance. Moreover, imbalanced data is a hurdle in accurate electricity theft detection (ETD) using data driven methods. To address this problem, sampling techniques are used in the literature. However, the traditional sampling techniques generate insufficient and unrealistic data that degrade the ETD rate. In this work, two novel ETD models are developed. A hybrid sampling approach, i.e., synthetic minority oversampling technique with edited nearest neighbor, is introduced in the first model. Furthermore, AlexNet is used for dimensionality reduction and extracting useful information from electricity consumption data. Finally, a light gradient boosting model is used for classification purpose. In the second model, conditional wasserstein generative adversarial network with gradient penalty is used to capture the real distribution of the electricity consumption data. It is constructed by adding auxiliary provisional information to generate more realistic data for the minority class. Moreover, GoogLeNet architecture is employed to reduce the dataset's dimensionality. Finally, adaptive boosting is used for classification of honest and suspicious consumers. Both models are trained and tested using real power consumption data provided by state grid corporation of China. The proposed models' performance is evaluated using different performance metrics like precision, recall, accuracy, F1-score, etc. The simulation results prove that the proposed models outperform the existing techniques, such as support vector machine, extreme gradient boosting, convolution neural network, etc., in terms of efficient ETD.",
        "author_keywords": [
            "Electricity theft detection",
            "generative adversarial network",
            "GoogLeNet",
            "imbalanced data",
            "SMOTEENN",
            "Urban planning"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Unsupervised domain adaptation in activity recognition: A gan-based approach",
        "authors": "Sanabria A.R.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2021.3053704",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100471007",
        "scopus_id": "85100471007",
        "abstract": "Sensor-based human activity recognition (HAR) is having a significant impact in a wide range of applications in smart city, smart home, and personal healthcare. Such wide deployment of HAR systems often faces the annotation-scarcity challenge; that is, most of the HAR techniques, especially the deep learning techniques, require a large number of training data while annotating sensor data is very time- and effort-consuming. Unsupervised domain adaptation has been successfully applied to tackle this challenge, where the activity knowledge from a well-annotated domain can be transferred to a new, unlabelled domain. However, these existing techniques do not perform well on highly heterogeneous domains. This article proposes shift-GAN that integrate bidirectional generative adversarial networks (Bi-GAN) and kernel mean matching (KMM) in an innovative way to learn intrinsic, robust feature transfer between two heterogeneous domains. Bi-GAN consists of two GANs that are bound by a cyclic constraint, which enables more effective feature transfer than a classic, single GAN model. KMM is a powerful non-parametric technique to correct covariate shift, which further improves feature space alignment. Through a series of comprehensive, empirical evaluations, shift-GAN has not only achieved its superior performance over 10 state-of-the-art domain adaptation techniques but also demonstrated its effectiveness in learning activity-independent, intrinsic feature mappings between two domains, robustness to sensor noise, and less sensitivity to training data.",
        "author_keywords": [
            "covariate shift",
            "domain adaptation",
            "ensemble learning",
            "generative adversarial networks",
            "Human activity recognition",
            "kernel mean matching"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "Semantic segmentation for buildings of large intra-class variation in remote sensing images with o-gan",
        "authors": "Sun S.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs13030475",
        "publication_date": "2021",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100278627",
        "scopus_id": "85100278627",
        "abstract": "Remote sensing building extraction is of great importance to many applications, such as urban planning and economic status assessment. Deep learning with deep network structures and back-propagation optimization can automatically learn features of targets in high-resolution remote sensing images. However, it is also obvious that the generalizability of deep networks is almost entirely dependent on the quality and quantity of the labels. Therefore, building extraction perfor-mances will be greatly affected if there is a large intra-class variation among samples of one class target. To solve the problem, a subdivision method for reducing intra-class differences is proposed to enhance semantic segmentation. We proposed that backgrounds and targets be separately generated by two orthogonal generative adversarial networks (O-GAN). The two O-GANs are connected by adding the new loss function to their discriminators. To better extract building features, drawing on the idea of fine-grained image classification, feature vectors for a target are obtained through an intermediate convolution layer of O-GAN with selective convolutional descriptor aggregation (SCDA). Subsequently, feature vectors are clustered into new, different subdivisions to train semantic segmentation networks. In the prediction stages, the subdivisions will be merged into one class. Experiments were conducted with remote sensing images of the Tibet area, where there are both tall buildings and herdsmen’s tents. The results indicate that, compared with direct semantic segmenta-tion, the proposed subdivision method can make an improvement on accuracy of about 4%. Besides, statistics and visualizing building features validated the rationality of features and subdivisions.",
        "author_keywords": [
            "Building extraction",
            "GF-2",
            "Orthogonal generative adversarial networks",
            "Subdivision"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Image Enhancement of Face Recognition Based on GAN",
        "authors": "Zhang Z.",
        "journal": "Advances in Intelligent Systems and Computing",
        "doi": "10.1007/978-981-33-4572-0_72",
        "publication_date": "2021",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85098253505",
        "scopus_id": "85098253505",
        "abstract": "Face recognition technology has attracted attention as people pay more and more attention to facial information, and has become a hot research topic. In this experiment, the training learning rate is set to 0.0004, 64 images are randomly loaded in a single loop, and then noise is added to start training. The cyclic process can be described as: First, the generator G generates output, and then the discriminator D performs the discrimination, and the generation loss and the discrimination loss are calculated by the output of the generator G and the discriminator D. Experimental data shows that a face database is formed through feature extraction and training of the face database. Then, randomly extract images for detection and recognition, and finally match the features in the feature library. The experimental results show that the accuracy of face recognition is 88.11% when the original data is used for 1000 iterations. The data filled with samples generated by GAN is used for training, and the accuracy of face recognition is 93.76%. There is a significant increase. At present, face verification and recognition still have difficulties in the application of computer science, and the generative confrontation network has made certain breakthroughs in the description of image generation.",
        "author_keywords": [
            "Dual-path confrontation generation network",
            "Face recognition image",
            "GAN technology"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Air pollution prediction with multi-modal data and deep neural networks",
        "authors": "Kalajdjieski J.",
        "journal": "Remote Sensing",
        "doi": "10.3390/rs12244142",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85098245118",
        "scopus_id": "85098245118",
        "abstract": "Air pollution is becoming a rising and serious environmental problem, especially in urban areas affected by an increasing migration rate. The large availability of sensor data enables the adoption of analytical tools to provide decision support capabilities. Employing sensors facilitates air pollution monitoring, but the lack of predictive capability limits such systems’ potential in practical scenarios. On the other hand, forecasting methods offer the opportunity to predict the future pollution in specific areas, potentially suggesting useful preventive measures. To date, many works tackled the problem of air pollution forecasting, most of which are based on sequence models. These models are trained with raw pollution data and are subsequently utilized to make predictions. This paper proposes a novel approach evaluating four different architectures that utilize camera images to estimate the air pollution in those areas. These images are further enhanced with weather data to boost the classification accuracy. The proposed approach exploits generative adversarial networks combined with data augmentation techniques to mitigate the class imbalance problem. The experiments show that the proposed method achieves robust accuracy of up to 0.88, which is comparable to sequence models and conventional models that utilize air pollution data. This is a remarkable result considering that the historic air pollution data is directly related to the output—future air pollution data, whereas the proposed architecture uses camera images to recognize the air pollution—which is an inherently much more difficult problem.",
        "author_keywords": [
            "Air pollution prediction",
            "Convolutional neural networks",
            "Deep learning",
            "Generative adversarial networks",
            "Smart city"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "A Multi-Objective Genetic GAN Oversampling: Application to Intelligent Transport Anomaly Detection\\",
        "authors": "Bouzeraib W.",
        "journal": "Proceedings - 2020 IEEE 22nd International Conference on High Performance Computing and Communications, IEEE 18th International Conference on Smart City and IEEE 6th International Conference on Data Science and Systems, HPCC-SmartCity-DSS 2020",
        "doi": "10.1109/HPCC-SmartCity-DSS50907.2020.00148",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85105338082",
        "scopus_id": "85105338082",
        "abstract": "The Internet of Things (IoT) enables the automation of data collection and processing functions but exposes a huge amount of data to the cyberattacks risk. To tackle this issue, anomaly detection allows to identify data points, events, and/or observations that deviate from a dataset's normal behaviour indicating eventual critical incidents. In this paper, we focus on the imbalance data and the minority classes problem where the number of abnormal samples is much less than normal (secure) samples. In particular, this paper presents a new equilibrium model based on a Genetic Algorithm to improve Generative Adversarial networks (GANs). This model addresses the problem of class imbalance to anomaly detection system performance. The proposed approach use is illustrated by a case study: An intelligent transport system-based scenario.",
        "author_keywords": [
            "Anomaly detection",
            "Generative Adversarial Network (GAN)",
            "Genetic Algorithm",
            "Machine Learning",
            "Multi-Objective algorithms"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Hardware and Architecture",
            "Information Systems",
            "Information Systems and Management",
            "Urban Studies"
        ]
    },
    {
        "title": "Newspaper article-based agent control in smart city simulations",
        "authors": "Kim E.",
        "journal": "Human-centric Computing and Information Sciences",
        "doi": "10.1186/s13673-020-00252-8",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85094973716",
        "scopus_id": "85094973716",
        "abstract": "The latest research on smart city technologies mainly focuses on utilizing cities’ resources to improve the quality of the lives of citizens. Diverse kinds of control signals from massive systems and devices such as adaptive traffic light systems in smart cities can be collected and utilized. Unfortunately, it is difficult to collect a massive dataset of control signals as doing so in the real-world requires significant effort and time. This paper proposes a deep generative model which integrates a long short-term memory model with generative adversarial network (LSTM-GAN) to generate agent control signals based on the words extracted from newspaper articles to solve the problem of collecting massive signals. The discriminatory network in the LSTM-GAN takes continuous word embedding vectors as inputs generated by a pre-trained Word2Vec model. The agent control signals of sequential actions are simultaneously predicted by the LSTM-GAN in real time. Specifically, to collect the training data of smart city simulations, the LSTM-GAN is trained based on the Corpus of Contemporary American English (COCA) newspaper dataset, which contains 5,317,731 sentences, for a total of 93,626,203 word tokens, from written texts. To verify the proposed method, agent control signals were generated and validated. In the training of the LSTM-GAN, the accuracy of the discriminator converged to 50%. In addition, the losses of the discriminator and the generator converged from 4527.04 and 4527.94 to 2.97 and 1.87, respectively.",
        "author_keywords": [
            "Control signal",
            "LSTM-GAN",
            "Simulation",
            "Smart city",
            "Word2Vec"
        ],
        "subject_areas": [
            "Computer Science (all)"
        ]
    },
    {
        "title": "Reimagining City Configuration: Automated Urban Planning via Adversarial Learning",
        "authors": "Wang D.",
        "journal": "GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems",
        "doi": "10.1145/3397536.3422268",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097296062",
        "scopus_id": "85097296062",
        "abstract": "Urban planning refers to the efforts of designing land-use configurations. Effective urban planning can help to mitigate the operational and social vulnerability of a urban system, such as high tax, crimes, traffic congestion and accidents, pollution, depression, and anxiety. Due to the high complexity of urban systems, such tasks are mostly completed by professional planners. But, human planners take longer time. The recent advance of deep learning motivates us to ask: can machines learn at a human capability to automatically and quickly calculate land-use configuration, so human planners can finally adjust machine-generated plans for specific needs? To this end, we formulate the automated urban planning problem into a task of learning to configure land-uses, given the surrounding spatial contexts. To set up the task, we define a land-use configuration as a longitude-latitude-channel tensor, where each channel is a category of POIs and the value of an entry is the number of POIs. The objective is then to propose an adversarial learning framework that can automatically generate such tensor for an unplanned area. In particular, we first characterize the contexts of surrounding areas of an unplanned area by learning representations from spatial graphs using geographic and human mobility data. Second, we combine each unplanned area and its surrounding context representation as a tuple, and categorize all the tuples into positive (well-planned areas) and negative samples (poorly-planned areas). Third, we develop an adversarial land-use configuration approach, where the surrounding context representation is fed into a generator to generate a land-use configuration, and a discriminator learns to distinguish among positive and negative samples. Finally, we devise two new measurements to evaluate the quality of land-use configurations and present extensive experiment and visualization results to demonstrate the effectiveness of our method.",
        "author_keywords": [
            "generative adversarial networks",
            "graph neural networks",
            "representation learning",
            "urban planning"
        ],
        "subject_areas": [
            "Earth-Surface Processes",
            "Computer Science Applications",
            "Modeling and Simulation",
            "Computer Graphics and Computer-Aided Design",
            "Information Systems"
        ]
    },
    {
        "title": "Multi-temporal remote sensing imagery semantic segmentation color consistency adversarial network",
        "authors": "Li X.",
        "journal": "Cehui Xuebao/Acta Geodaetica et Cartographica Sinica",
        "doi": "10.11947/j.AGCS.2020.20190439",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097042530",
        "scopus_id": "85097042530",
        "abstract": "Using deep convolutional neural network (CNN) to intelligently extract buildings from remote sensing images is of great significance for digital city construction, disaster detection and land management. The color difference between multi-temporal remote sensing images will lead to the decrease of generalization ability of building semantic segmentation model. In view of this, this paper proposes the attention-guided color consistency adversarial network (ACGAN). The algorithm takes the reference color style images and the images to be corrected in the same area and different phases as the training set and adopts the consistency adversarial network with the U-shaped attention mechanism to train the color consistency model. In the prediction stage, this model converts the hue of the images to that of the reference color style image, which is based on the reasoning ability of the deep learning model, instead of the corresponding reference color style image. This model transforms the hue of the images to be corrected into that of the reference color style images. This stage is based on the reasoning ability of the deep learning model, and the corresponding reference color style image is no longer needed. In order to verify the effectiveness of the algorithm, firstly, we compare the algorithm of this paper with the traditional image processing algorithm and other consistency adversarial network. The results show that the images after ACGAN color consistency processing are more similar to that of the reference color style images. Secondly, we carried out the building semantic segmentation experiment on the images processed by the above different color consistency algorithms, which proved that the method in this paper is more conducive to the impro-vement of the generalization ability of multi-temporal remote sensing image semantic segmentation model.",
        "author_keywords": [
            "Attention mechanism",
            "Color consistency",
            "Generative adversarial networks",
            "Multi-temporal remote sensing imagery",
            "Semantic segmentation"
        ],
        "subject_areas": [
            "Earth and Planetary Sciences (all)"
        ]
    },
    {
        "title": "Unsupervised Anomaly Detection in IoT Systems for Smart Cities",
        "authors": "Guo Y.",
        "journal": "IEEE Transactions on Network Science and Engineering",
        "doi": "10.1109/TNSE.2020.3027543",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85098876884",
        "scopus_id": "85098876884",
        "abstract": "Anomaly detection is critical in the Internet of Things (IoT) systems due to its wide applications for building smart cities, such as quality control in manufacturing, intrusion detection in system security, fault detection in system monitoring. Many existing schemes are problem specific and supervised approaches, which require domain knowledge and tremendous data labeling efforts. In this paper, we investigate unsupervised anomaly detection on multidimensional time series data in IoT systems, and develops a GRU-based Gaussian Mixture VAE scheme, called GGM-VAE. In particular, we employ Gated Recurrent Unit (GRU) cells to discover the correlations among time series data, and use Gaussian Mixture priors in the latent space to characterize the multimodal data. Several previous works assume simple distributions for Gaussian Mixture priors, resulting in insufficient ability to fully capture the data patterns. To overcome this issue, we design a model selection mechanism during the training process under the guidance of Bayesian Inference Criterion (BIC) to find the model which can well estimate the distribution in the Gaussian Mixture latent space. We conduct extensive simulations on four datasets and observe that our proposed scheme outperforms the state-of-the-art anomaly detection schemes and achieves up to 47.88% improvement in F1 scores on average.",
        "author_keywords": [
            "Gated Recurrent Unit (GRU)",
            "Gaussian Mixture Model (GMM)",
            "iot",
            "smart cities.",
            "unsupervised anomaly detection",
            "Variational Autoencoder(VAE)"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Location Semantics Inference with Graph Convolutional Networks",
        "authors": "Wu R.Z.",
        "journal": "Dianzi Keji Daxue Xuebao/Journal of the University of Electronic Science and Technology of China",
        "doi": "10.12178/1001-0548.2020152",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85092921544",
        "scopus_id": "85092921544",
        "abstract": "Data mining on check-in data inlocation based social networks (LBSNs) is an important research direction of urban computing and smart city, and a critical task is to infer location semantic. The study of location semantics has attracted increasing attention in diverse fields due to its wide applications such as location retrieval, location recommendation, data preprocessing and so on. Established inference approaches tend to manually discover the spatiotemporal pattern of unique location as features for training classifiers. However, extracting valuable spatiotemporal patterns or features is a non-trivial task. In this paper, we propose a novel location semantic inference with graph convolutional networks (SI-GCN). We introduce node2vec and variational autoencoder to learn spatial and temporal features of location, respectively. Furthermore, we leverage graph convolutional networks to capture high order relations in user's check-in activity with building a user-location bipartite network. And leveraging self-attention mechanism is allowed to distinguish contributions of the different nodes. Extensive experiments on several real-world check-in data sets show that our proposed framework outperforms than three state-of-art algorithms.",
        "author_keywords": [
            "Data mining",
            "GCN",
            "LBSNs",
            "Self-attention mechanism",
            "Semantics inference"
        ],
        "subject_areas": [
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Precise object detection using adversarially augmented local/global feature fusion",
        "authors": "Han X.",
        "journal": "Engineering Applications of Artificial Intelligence",
        "doi": "10.1016/j.engappai.2020.103710",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85088228053",
        "scopus_id": "85088228053",
        "abstract": "Object detection, which aims at recognizing or locating the objects of interest in remote sensing imagery with high spatial resolutions (HSR), plays a significant role in many real-world scenarios, e.g., environment monitoring, urban planning, civil infrastructure construction, disaster rescuing, and geographic image retrieval. As a long-lasting challenging problem in both machine learning and geoinformatics communities, many approaches have been proposed to tackle it. However, previous methods always overlook the abundant information embedded in the HSR remote sensing images. The effectiveness of these methods, e.g., accuracy of detection, is therefore limited to some extent. To overcome the mentioned challenge, in this paper, we propose a novel two-phase deep framework, dubbed GLGOD-Net, to effectively detect meaningful objects in HSR images. GLGOD-Net firstly attempts to learn the enhanced deep representations from super-resolution image data. Fully utilizing the augmented image representations, GLGOD-Net then learns the fused representations into which both local and global latent features are implanted. Such fused representations learned by GLGOD-Net can be used to precisely detect different objects in remote sensing images. The proposed framework has been extensively tested on a real-world HSR image dataset for object detection and has been compared with several strong baselines. The remarkable experimental results validate the effectiveness of GLGOD-Net. The success of GLGOD-Net not only advances the cutting-edge of image data analytics, but also promotes the corresponding applicability of deep learning in remote sensing imagery.",
        "author_keywords": [
            "Data augmentation",
            "Geospatial object detection",
            "High spatial resolution (HSR) remote sensing imagery",
            "Local/global feature fusion",
            "Super resolution generative adversarial network"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Artificial Intelligence",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "LONG-SHORT SKIP CONNECTIONS in DEEP NEURAL NETWORKS for DSM REFINEMENT",
        "authors": "Bittner K.",
        "journal": "International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",
        "doi": "10.5194/isprs-archives-XLIII-B2-2020-383-2020",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85091111762",
        "scopus_id": "85091111762",
        "abstract": "Detailed digital surface models (DSMs) from space-borne sensors are the key to successful solutions for many remote sensing problems, like environmental disaster simulations, change detection in rural and urban areas, 3D urban modeling for city planning and management, etc. Traditional methodologies, e.g., stereo matching, used to generate photogrammetric DSMs from stereo imagery, usually deliver low-quality results due to the matching errors in homogeneous areas or the lack of information when observing the scene under different viewing angles. This makes the tasks related to building reconstruction very challenging since in most cases it is difficult to recognize the type of roofs, especially if overlaid with trees. This work represents a continuation of research regarding the automatic optimization of building geometries in photogrammetric DSMs with half-meter resolution and introduces an improved generative adversarial network (GAN) architecture which allows to reconstruct complete and detailed building structures without neglecting even low-rise urban constructions. The generative part of the network is constructed in a way that it simultaneously processes height and intensity information, and combines short and long skip connections within one architecture. To improve different aspects of the surface, several loss terms are used, the contributions of which are automatically balanced during training. The obtained results demonstrate that the proposed methodology can achieve two goals without any manual intervention: improve the roof surfaces by making them more planar and also recognize and optimize even small residential buildings which are hard to detect.",
        "author_keywords": [
            "3D scene refinement",
            "balancing hyper-parameters",
            "building geometry",
            "Conditional generative adversarial networks (cGANs)",
            "long-short skip connections"
        ],
        "subject_areas": [
            "Information Systems",
            "Geography, Planning and Development"
        ]
    },
    {
        "title": "Precipitation is the dominant driver for bird species richness, phylogenetic and functional structure in university campuses in northern China",
        "authors": "Liang C.",
        "journal": "Avian Research",
        "doi": "10.1186/s40657-020-00212-x",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85089083459",
        "scopus_id": "85089083459",
        "abstract": "Background: Although urbanization is threatening biodiversity worldwide, the increasing green urban spaces could harbor relatively high biodiversity. Therefore, how to maintain the biodiversity in urban ecosystem is crucial for sustainable urban planning and management, especially in arid and semiarid regions with relatively fragile environment and low biodiversity. Here, for the first time we linked species richness, phylogenetic and functional structure of bird assemblages in university campuses in northern China with plant species richness, glacial-interglacial climate change, contemporary climate, and anthropogenic factors to compare their relative roles in shaping urban bird diversity. Methods: Bird surveys were conducted in 20 university campuses across Inner Mongolia, China. Ordinary least squares models and simultaneous autoregressive models were used to assess the relationships between bird species richness, phylogenetic and functional structure with environmental factors. Structural equation models were used to capture the direct and indirect effects of these factors on the three components of bird diversity. Results: Single-variable simultaneous autoregressive models showed that mean annual precipitation was consistently a significant driver for bird species richness, phylogenetic and functional structure. Meanwhile, mean annual temperature and plant species richness were also significant predictors for bird species richness. Conclusions: This study suggests that campuses with warmer and wetter climate as well as more woody plant species could harbor more bird species. In addition, wetter campuses tended to sustain over-dispersed phylogenetic and functional structure. Our findings emphasize the dominant effect of precipitation on bird diversity distribution in this arid and semiarid region, even in the urban ecosystem.",
        "author_keywords": [
            "Climate",
            "Functional structure",
            "Human factors",
            "Phylogenetic structure",
            "Urban bird diversity",
            "Woody plant diversity"
        ],
        "subject_areas": [
            "Ecology, Evolution, Behavior and Systematics",
            "Animal Science and Zoology"
        ]
    },
    {
        "title": "Systematizing heterogeneous expert knowledge, scenarios and goals via a goal-reasoning artificial intelligence agent for democratic urban land use planning",
        "authors": "Chen W.",
        "journal": "Cities",
        "doi": "10.1016/j.cities.2020.102703",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85082191847",
        "scopus_id": "85082191847",
        "abstract": "The tasks of democratic urban land use planning, as subjective-objective combined decision-making efforts that require considerable time and energy, have heretofore been accomplished mainly through deep human thought or by voting. In this paper, we introduce a goal-reasoning artificial intelligence (AI) agent that can assist with these tasks by combining traditional scenario planning, multicriteria decision analysis (MCDA) with a novel goal-oriented Monte Carlo tree search (G-MCTS) method. G-MCTS conducts goal-oriented searches to meet the needs of heterogeneous goals and provide the best land use solutions. We evaluated this method on a real-world planning case, and the results show that 1) the goal-reasoning AI agent is good at performing complex goal reasoning tasks with many heterogeneous expert knowledge; 2) different human planning manuscripts could be integrated into a better solution via a goal-reasoning AI agent; and 3) the goal-reasoning AI agent has the potential to make comprehensive decisions during a democratic political agenda. We conclude that the goal-reasoning AI agent, via an improved reinforcement learning (RL) method of G-MCTS, provides vast potential for assisting in subjective-objective combined urban land use planning and many other similar fields by weighing heterogeneous goals, reproducing human inspiration, and acting as a reflexive sociotechnical system.",
        "author_keywords": [
            "Artificial intelligence",
            "Goal reasoning",
            "Land use planning",
            "Markov decision processes",
            "Multicriteria decision analysis",
            "Reinforcement learning"
        ],
        "subject_areas": [
            "Development",
            "Sociology and Political Science",
            "Urban Studies",
            "Tourism, Leisure and Hospitality Management"
        ]
    },
    {
        "title": "Urban Experiment: Taking Off on the Wind of Al",
        "authors": "He W.",
        "journal": "Architectural Design",
        "doi": "10.1002/ad.2574",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85082727380",
        "scopus_id": "85082727380",
        "abstract": "Abstract. What will be the impact of Artificial Intelligence (AI) on our urban futures? It is clear is that a symbiosis between human designer and AI assistant is swiftly evolving. Wanyu He, CEO of XKool Technology and co-founder of Future Architecture Lab, leads us through some of the advantages of this new alliance, featuring some examples of XKool's AI- empowered insights.",
        "author_keywords": [
            "2017 Shenzhen-HongKong Bi-City Biennale of Urbanism\\Architecture",
            "big data",
            "Christie's auction house",
            "College of Architecture and Urban Planning, Tongji University",
            "convolutional neural networks (CNNs)",
            "DigitalFUTURE summer workshop",
            "generative adversarial networks (GANs)",
            "Grasshopper",
            "Intelligent Dynamic Urban Planning and Decision-Making Platform",
            "K-Means algorithm model",
            "Multi-dimensional Urban Digital Platform",
            "Nantou",
            "New York",
            "Shanghai",
            "XKool",
            "XKool AI Design Cloud Platform",
            "‘Non-existing Architectures’",
            "‘This Person Does Not Exist’"
        ],
        "subject_areas": [
            "Architecture",
            "Visual Arts and Performing Arts"
        ]
    },
    {
        "title": "Big data analytics: Computational intelligence techniques and application areas",
        "authors": "Iqbal R.",
        "journal": "Technological Forecasting and Social Change",
        "doi": "10.1016/j.techfore.2018.03.024",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85044950715",
        "scopus_id": "85044950715",
        "abstract": "Big Data has significant impact in developing functional smart cities and supporting modern societies. In this paper, we investigate the importance of Big Data in modern life and economy, and discuss challenges arising from Big Data utilization. Different computational intelligence techniques have been considered as tools for Big Data analytics. We also explore the powerful combination of Big Data and Computational Intelligence (CI) and identify a number of areas, where novel applications in real world smart city problems can be developed by utilizing these powerful tools and techniques. We present a case study for intelligent transportation in the context of a smart city, and a novel data modelling methodology based on a biologically inspired universal generative modelling approach called Hierarchical Spatial-Temporal State Machine (HSTSM). We further discuss various implications of policy, protection, valuation and commercialization related to Big Data, its applications and deployment.",
        "author_keywords": [
            "Big data",
            "Big data analytics",
            "CI applications",
            "Computational intelligence",
            "Smart city"
        ],
        "subject_areas": [
            "Business and International Management",
            "Applied Psychology",
            "Management of Technology and Innovation"
        ]
    },
    {
        "title": "Showcasing relationships between neighborhood design and wellbeing Toronto indicators",
        "authors": "Shaker R.R.",
        "journal": "Sustainability (Switzerland)",
        "doi": "10.3390/su12030997",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85081220429",
        "scopus_id": "85081220429",
        "abstract": "Cities are the keystone landscape features for achieving sustainability locally, regionally, and globally. With the increasing impacts of urban expansion eminent, policymakers have encouraged researchers to advance or invent methods for managing coupled human-environmental systems associated with local and regional sustainable development planning. Although progress has been made, there remains no universal instrument for attaining sustainability on neither regional nor local planning scales. Previous sustainable urbanization studies have revealed that landscape configuration metrics can supplement other measures of urbanwell-being, yet few have been included in public data dashboards or contrasted against local well-being indicators. To advance this sector of sustainable development planning, this study had three main intentions: (1) to produce a foundational suite of landscape ecology metrics from the 2007 land cover dataset for the City of Toronto; (2) to visualize and interpret spatial patterns of neighborhood streetscape patch cohesion index (COHESION), Shannon's diversity index (SHDI), and four Wellbeing Toronto indicators across the 140 Toronto neighborhoods; (3) to quantitatively assess the global collinearity and local explanatory power of the well-being and landscape measures showcased in this study. One-hundred-and-thirty landscape ecology metrics were computed: 18 class configuration metrics across seven land cover categories and four landscape diversity metrics. Anselin Moran's I-test was used to illustrate significant spatial patterns of well-being and landscape indicators; Pearson's correlation and conditional autoregressive (CAR) statistics were used to evaluate relationships between them. Spatial \"hot-spots\" and/or \"cold-spots\" were found in all streetscape variables. Among other interesting results, Walk Score® was negatively related to both tree canopy and grass/shrub connectedness, signifying its lack of consideration for the quality of ecosystem services and environmental public health-and subsequently happiness-during its proximity assessment of socioeconomic amenities. In sum, landscape ecology metrics can provide cost-effective ecological integrity addendum to existing and future urban resilience, sustainable development, and well-being monitoring programs.",
        "author_keywords": [
            "Crime",
            "Data dashboard",
            "Landscape indicators",
            "Premature mortality",
            "Spatial autoregressive modeling",
            "Streetscapes",
            "Sustainable urbanization",
            "Toronto",
            "Urban design",
            "Urban landscape",
            "Urban planning",
            "Walk score"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Building and Construction",
            "Environmental Science (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Learning with small data",
        "authors": "Li Z.",
        "journal": "WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining",
        "doi": "10.1145/3336191.3371874",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85079533847",
        "scopus_id": "85079533847",
        "abstract": "In the era of big data, it is easy for us collect a huge number of image and text data. However, we frequently face the real-world problems with only small (labeled) data in some domains, such as healthcare and urban computing. The challenge is how to make machine learn algorithms still work well with small data? To solve this challenge, in this tutorial, we will cover the state-of-the-art machine learning techniques to handle small data issue. In particular, we focus on the following three aspects: (1) Providing a comprehensive review of recent advances in exploring the power of knowledge transfer, especially focusing on meta-learning; (2) introducing the cutting-edge techniques of incorporating human/expert knowledge into machine learning models; and (3) identifying the open challenges to data augmentation techniques, such as generative adversarial networks. We believe this is an emerging and potentially high-impact topic in computational data science, which will attract both researchers and practitioners from academia and industry.",
        "author_keywords": [
            "Generative models",
            "Knowledge regularization",
            "Meta-learning",
            "Transfer learning"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Software",
            "Computer Science Applications"
        ]
    },
    {
        "title": "The modified smart city concept for Russian municipalities in the context of change management",
        "authors": "Komarevtseva O.O.",
        "journal": "R-Economy",
        "doi": "10.15826/recon.2020.6.4.026",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85147666454",
        "scopus_id": "85147666454",
        "abstract": "Relevance. Outdated tools and instruments for development and governance prevent the effective use of data and digital platforms in Russian cities, thus creating obstacles for the implementation of smart new solutions. Moreover, the established system of smart city evaluation is ‘overloaded’ with indicators. For these reasons, the smart city concept is inadequate for today’s reality of most Russian municipalities, making it difficult for them to meet the national goals for the digitalization of the country’s economy. The relevance of this study is determined by the need to adjust the smart city concept for municipal economy in Russia and to propose a modified version of this concept. Research objective. This study aims at creating a modified smart city concept by changing evaluation criteria and using a simulation model of municipal economy. Results. The study found that the established smart city concept is not entirely suitable for implementation in Russian municipalities. The lack of adequate methodology of smart city evaluation impedes efficient economic development of municipalities. Data and methods. The study applies a simulation model of municipal economy, which is built by using simulation modelling methods and the Bass diffusion model. Conclusions. The proposed modifications of the smart city concept can provide a springboard for economic development of Russian municipalities to achieve the goals of national digital strategies.",
        "author_keywords": [
            "change management",
            "digitalization",
            "municipal economy",
            "risk",
            "simulation",
            "smart city concept"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Public Administration",
            "Economics, Econometrics and Finance (all)"
        ]
    },
    {
        "title": "Building Footprint Extraction from High Resolution Aerial Images Using Generative Adversarial Network (GAN) Architecture",
        "authors": "Abdollahi A.",
        "journal": "IEEE Access",
        "doi": "10.1109/ACCESS.2020.3038225",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097646944",
        "scopus_id": "85097646944",
        "abstract": "Building extraction with high accuracy using semantic segmentation from high-resolution remotely sensed imagery has a wide range of applications like urban planning, updating of geospatial database, and disaster management. However, automatic building extraction with non-noisy segmentation map and obtaining accurate boundary information is a big challenge for most of the popular deep learning methods due to the existence of some barriers like cars, vegetation cover and shadow of trees in the high-resolution remote sensing imagery. Thus, we introduce an end-to-end convolutional neural network called Generative Adversarial Network (GAN) in this study to tackle these issues. In the generative model, we utilized SegNet model with Bi-directional Convolutional LSTM (BConvLSTM) to generate the segmentation map from Massachusetts building dataset containing high-resolution aerial imagery. BConvLSTM combines encoded features (containing of more local information) and decoded features (containing of more semantic information) to improve the performance of the model even with the presence of complex backgrounds and barriers. The adversarial training method enforces long-range spatial label vicinity to tackle with the issue of covering building objects with the existing occlusions such as trees, cars and shadows and achieve high-quality building segmentation outcomes under the complex areas. The quantitative results obtained by the proposed technique with an average F1-score of 96.81% show that the suggested approach could achieve better results through detecting and adjusting the difference between the segmentation model output and the reference map compared to other state-of-the-art approaches such as autoencoder method with 91.36%, SegNet+BConvLSTM with 95.96%, FCN-CRFs with 95.36%% SegNet with 94.77%, and GAN-SCA model with 96.36% accuracy.",
        "author_keywords": [
            "Building extraction",
            "GAN",
            "remote sensing",
            "SegNet"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Materials Science (all)",
            "Engineering (all)"
        ]
    },
    {
        "title": "RoadNetGAN: Generating Road Networks in Planar Graph Representation",
        "authors": "Owaki T.",
        "journal": "Communications in Computer and Information Science",
        "doi": "10.1007/978-3-030-63820-7_61",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097282301",
        "scopus_id": "85097282301",
        "abstract": "We propose RoadNetGAN, a road network generation method as an extension to NetGAN, a generative model that can generate graphs similar to real-world networks with the acquisition of similarity measure through learning. Our main contribution is twofold. Firstly, we added displacement attributes to the random walks to generate not only the sequence but also the spatial position of nodes as intersections within a road network to be generated, which increases the diversity of generated road network patterns including the shape of the city blocks. Secondly, we make the generator and discriminator neural networks conditional. This allows for learning of the specification of the initial node of random walks over a graph, which is especially important for interactive road network generation that is mostly used in the applications for urban planning of road networks. We demonstrate that the proposed method can generate road networks that mimic the real road networks with the desired similarity.",
        "author_keywords": [
            "Deep learning",
            "Generative adversarial networks",
            "Urban planning"
        ],
        "subject_areas": [
            "Computer Science (all)",
            "Mathematics (all)"
        ]
    },
    {
        "title": "Machine learning parameter estimation in a smart-city paradigm for the medical field",
        "authors": "Bhuvaneswari M.",
        "journal": "EAI/Springer Innovations in Communication and Computing",
        "doi": "10.1007/978-3-030-14718-1_7",
        "publication_date": "2020",
        "document_type": "Book Chapter",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85089525409",
        "scopus_id": "85089525409",
        "abstract": "Machine learning (ML)-based parameter estimation and classification have been receiving great attention in data modelling and processing. The Gaussian mixture model (GMM) is a probabilistic model that represents the presence of subpopulations, which works well with a parameter estimation strategy. In this chapter, maximum likelihood estimation based on expectation maximization is used for the parameter estimation approach; the estimated parameters are used for the training and testing of medical images for normality and abnormality. The mean and the covariance, considered to be the parameters, are used in GMM-based training for the classifier. Support vector machine (SVM), a discriminative classifier, and the GMM, a generative model classifier, are the two most popular techniques. The classification strategy performances of both classifiers have better proficiency than other classifiers. By combining the SVM and GMM, it is possible to improve classification because estimating the parameters through GMM has very limited features; hence, there is no need to use any feature reduction techniques. The features extracted were used for the training of the classifiers. The testing of medical images for normality was performed with respect to the features that were trained.",
        "author_keywords": [
            "Expected maximization (EM)",
            "Gaussian mixture model (GMM)",
            "Maximum likelihood estimation (MLE)",
            "Support vector machine (SVM)"
        ],
        "subject_areas": [
            "Information Systems",
            "Health Informatics",
            "Computer Networks and Communications",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Capsules TCN Network for Urban Computing and Intelligence in Urban Traffic Prediction",
        "authors": "Li D.",
        "journal": "Wireless Communications and Mobile Computing",
        "doi": "10.1155/2020/6896579",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85086803574",
        "scopus_id": "85086803574",
        "abstract": "Predicting urban traffic is of great importance to smart city systems and public security; however, it is a very challenging task because of several dynamic and complex factors, such as patterns of urban geographical location, weather, seasons, and holidays. To tackle these challenges, we are stimulated by the deep-learning method proposed to unlock the power of knowledge from urban computing and proposed a deep-learning model based on neural network, entitled Capsules TCN Network, to predict the traffic flow in local areas of the city at once. Capsules TCN Network employs a Capsules Network and Temporal Convolutional Network as the basic unit to learn the spatial dependence, time dependence, and external factors of traffic flow prediction. In specific, we consider some particular scenarios that require accurate traffic flow prediction (e.g., smart transportation, business circle analysis, and traffic flow assessment) and propose a GAN-based superresolution reconstruction model. Extensive experiments were conducted based on real-world datasets to demonstrate the superiority of Capsules TCN Network beyond several state-of-the-art methods. Compared with HA, ARIMA, RNN, and LSTM classic methods, respectively, the method proposed in the paper achieved better results in the experimental verification.",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Facelift: A transparent deep learning framework to beautify urban scenes",
        "authors": "Joglekar S.",
        "journal": "Royal Society Open Science",
        "doi": "10.1098/rsos.190987",
        "publication_date": "2020",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85079594079",
        "scopus_id": "85079594079",
        "abstract": "In the area of computer vision, deep learning techniques have recently been used to predict whether urban scenes are likely to be considered beautiful: it turns out that these techniques are able to make accurate predictions. Yet they fall short when it comes to generating actionable insights for urban design. To support urban interventions, one needs to go beyond predicting beauty, and tackle the challenge of recreating beauty. Unfortunately, deep learning techniques have not been designed with that challenge in mind. Given their 'black-box nature', these models cannot be directly used to explain why a particular urban scene is deemed to be beautiful. To partly fix that, we propose a deep learning framework (which we name FaceLift1) that is able to both beautify existing urban scenes (Google Street Views) and explain which urban elements make those transformed scenes beautiful. To quantitatively evaluate our framework, we cannot resort to any existing metric (as the research problem at hand has never been tackled before) and need to formulate new ones. These new metrics should ideally capture the presence (or absence) of elements that make urban spaces great. Upon a review of the urban planning literature, we identify five main metrics: walkability, green spaces, openness, landmarks and visual complexity. We find that, across all the five metrics, the beautified scenes meet the expectations set by the literature on what great spaces tend to be made of. This result is further confirmed by a 20-participant expert survey in which FaceLift has been found to be effective in promoting citizen participation. All this suggests that, in the future, as our framework's components are further researched and become better and more sophisticated, it is not hard to imagine technologies that will be able to accurately and efficiently support architects and planners in the design of the spaces we intuitively love.",
        "author_keywords": [
            "Deep learning",
            "Explainable models",
            "Generative models",
            "Urban beauty",
            "Urban design"
        ],
        "subject_areas": [
            "Multidisciplinary"
        ]
    },
    {
        "title": "RMB exchange rate prediction based on bayesian",
        "authors": "Hu W.",
        "journal": "Advances in Intelligent Systems and Computing",
        "doi": "10.1007/978-981-15-2568-1_133",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85079526331",
        "scopus_id": "85079526331",
        "abstract": "The traditional time series analysis and prediction methods do not take into account the prior information of samples and parameters, resulting in a large deviation between the prediction results and the actual data, and the Bayesian parameter estimation method can make full use of the prior information of the parameters. The variance of the estimated parameters is smaller, the estimated results are more accurate, and the predicted results are more real. In order to correctly analyze and predict the changing trend of RMB exchange rate, this paper selects exchange rate data of 995 working days from August 1, 2015 to August 30, 2019 to model the exchange rate of RMB against US dollar in time series autoregressive model. By using the MCMC method, I carry out the model parameters with Gibbs sampling estimation, which makes the prediction of the model more accurate.",
        "author_keywords": [
            "Autoregressive model",
            "Bayesian parameter estimation",
            "Gibbs sampling",
            "MCMC method"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Market Diffusion Model of Electric Vehicles for Planning Charging Infrastructure in India",
        "authors": "Ramchandran N.",
        "journal": "Lecture Notes in Electrical Engineering",
        "doi": "10.1007/978-981-32-9119-5_32",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85077777585",
        "scopus_id": "85077777585",
        "abstract": "The Indian government has set an ambitious goal of having an all-electric vehicle fleet by 2030. However, limiting factors related to technology, market and policy could impede their adoption. The objective of this research is to forecast how the diffusion of electric vehicles (EVs) will happen in India and the crucial elements that would influence adoption. The research outcomes are expected to help policy makers to optimally phase investments and incentives earmarked for public charging infrastructure. ‘Bass diffusion model’ has been used as the base for preparing a system dynamics model using Vensim software to forecast the diffusion of EV’s from 2017 to 2030. Consumer willingness to purchase EV’s has been elicited through a survey conducted among 50 respondents, who drive 4-wheelers. Adoption has been modeled considering the effect of 4 parameters on consumer willingness to purchase EV, namely- price differential between EV’s and ICE vehicles, range, recharge time and charging infrastructure density. The model output indicates an S-shaped diffusion curve with saturation near the 50th month. Out of the four parameters, adoption is found to be highly sensitive to charging infrastructure density. The paper concludes that there is a high scope of optimizing government investment in charging infrastructure which would require a detailed view of technical, policy and market related aspects.",
        "author_keywords": [
            "Consumer willingness",
            "Diffusion",
            "Electric vehicle",
            "Price differential",
            "Recharge time"
        ],
        "subject_areas": [
            "Industrial and Manufacturing Engineering"
        ]
    },
    {
        "title": "Deep learning based pedestrian detection at distance in smart cities",
        "authors": "Dinakaran R.K.",
        "journal": "Advances in Intelligent Systems and Computing",
        "doi": "10.1007/978-3-030-29513-4_43",
        "publication_date": "2020",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85072835032",
        "scopus_id": "85072835032",
        "abstract": "Generative adversarial networks (GANs) have been promising for many computer vision problems due to their powerful capabilities to enhance the data for training and test. In this paper, we leveraged GANs and proposed a new architecture with a cascaded Single Shot Detector (SSD) for pedestrian detection at distance, which is yet a challenge due to the varied sizes of pedestrians in videos at distance. To overcome the low-resolution issues in pedestrian detection at distance, DCGAN is employed to improve the resolution first to reconstruct more discriminative features for a SSD to detect objects in images or videos. A crucial advantage of our method is that it learns a multi-scale metric to distinguish multiple objects at different distances under one image, while DCGAN serves as an encoder-decoder platform to generate parts of an image that contain better discriminative information. To measure the effectiveness of our proposed method, experiments were carried out on the Canadian Institute for Advanced Research (CIFAR) dataset, and it was demonstrated that the proposed new architecture achieved a much better detection rate, particularly on vehicles and pedestrians at distance, making it highly suitable for smart cities applications that need to discover key objects or pedestrians at distance.",
        "author_keywords": [
            "Deep neural networks",
            "Object detection",
            "Smart cities",
            "Smart homecare"
        ],
        "subject_areas": [
            "Control and Systems Engineering",
            "Computer Science (all)"
        ]
    },
    {
        "title": "Demonstration of Electrically Injected Semipolar Laser Diodes Grown on Low-Cost and Scalable Sapphire Substrates",
        "authors": "Khoury M.",
        "journal": "ACS Applied Materials and Interfaces",
        "doi": "10.1021/acsami.9b17525",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85076790759",
        "scopus_id": "85076790759",
        "abstract": "The last two decades have shown an increasing need for GaN-based laser diodes (LDs), which are currently only grown on bulk GaN substrates, which remain to date very expensive and/or only available in small sizes. The ever growing laser market will expand in the coming years, thanks to the development of automotive laser lighting, high-speed Li-Fi optical data transmission, LiDAR sensing for autonomous vehicles and smart cities, head-up displays, and AR/VR systems, in addition to biomedical and further industrial applications. These emerging technologies demand for mass-production of GaN-based lasers to be produced on large-size, low-cost, and industrially compatible substrates. To address this issue, we demonstrate the first electrically injected semipolar 440 nm LD on high-quality and low-defect-density (11-22) GaN templates grown on scalable and low-cost sapphire substrates. The LDs exhibit a threshold current density of 17 kA/cm2, a single facet output power of more than 200 mW at 2 A with a slope efficiency of 0.85 W/A, and a TE polarization having a ratio of 97.6%. These results enable the advancement of ultra-low-cost LDs while benefiting from the inherent advantages of semipolar GaN properties.",
        "author_keywords": [
            "GaN",
            "laser diodes",
            "scalable",
            "semipolar",
            "templates"
        ],
        "subject_areas": [
            "Materials Science (all)"
        ]
    },
    {
        "title": "Spatial modeling of trends in crime over time in Philadelphia",
        "authors": "Balocchi C.",
        "journal": "Annals of Applied Statistics",
        "doi": "10.1214/19-AOAS1280",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85076494039",
        "scopus_id": "85076494039",
        "abstract": "Understanding the relationship between change in crime over time and the geography of urban areas is an important problem for urban planning. Accurate estimation of changing crime rates throughout a city would aid law enforcement as well as enable studies of the association between crime and the built environment. Bayesian modeling is a promising direction since areal data require principled sharing of information to address spatial autocorrelation between proximal neighborhoods. We develop several Bayesian approaches to spatial sharing of information between neighborhoods while modeling trends in crime counts over time. We apply our methodology to estimate changes in crime throughout Philadelphia over the 2006-15 period while also incorporating spatially-varying economic and demographic predictors. We find that the local shrinkage imposed by a conditional autoregressive model has substantial benefits in terms of out-of-sample predictive accuracy of crime. We also explore the possibility of spatial discontinuities between neighborhoods that could represent natural barriers or aspects of the built environment.",
        "author_keywords": [
            "Crime",
            "Spatial",
            "Time trends",
            "Urbanism"
        ],
        "subject_areas": [
            "Statistics and Probability",
            "Modeling and Simulation",
            "Statistics, Probability and Uncertainty"
        ]
    },
    {
        "title": "Privacy-aware synthesis of sensing data based on learning model at metropolitan scale: Poster abstract",
        "authors": "Zhang F.",
        "journal": "SenSys 2019 - Proceedings of the 17th Conference on Embedded Networked Sensor Systems",
        "doi": "10.1145/3356250.3361957",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85076590353",
        "scopus_id": "85076590353",
        "abstract": "With development of ubiquitous urban sensory infrastructures, large scale human mobility data have various applications and benefits in mobile networking and urban planning. Demands for sharing these sensing data to research communities have proliferated causing concerns over privacy. Traditional privacy solution is to apply comprehensive perturbation at feature level, which may results in significant utility loss. In this paper, we propose a learning-based generative model with designed classifiers to generate realistic synthetic mobility data with privacy protection at label/system property level. With two plug-in classifiers, i.e., privacy classifier and utility classifier, the trade-off between sensitive and non-sensitive mobility properties would be balanced with customization. To validate the performance, we implement our model based on the urban-scale cellphone data from the Shenzhen city as a case study. The resilience of smart attacks is tested and potential applications are pictured for this semi-supervised learning-based model.",
        "author_keywords": [
            "Data synthesis",
            "Human Mobility",
            "Privacy"
        ],
        "subject_areas": [
            "Computer Networks and Communications",
            "Control and Systems Engineering",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "TrafficGAN: Off-deployment traffic estimation with traffic generative adversarial networks",
        "authors": "Zhang Y.",
        "journal": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "doi": "10.1109/ICDM.2019.00193",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85078910602",
        "scopus_id": "85078910602",
        "abstract": "The rapid progress of urbanization has expedited the process of urban planning, e.g., new residential, commercial areas, which in turn boosts the local travel demand. We propose a novel 'off-deployment traffic estimation problem', namely, to foresee the traffic condition changes of a region prior to the deployment of a construction plan. This problem is important to city planners to evaluate and develop urban deployment plans. However, this task is challenging. Traditional traffic estimation approaches lack the ability to solve this problem, since no data about the impact can be collected before the deployment and old data fails to capture the traffic pattern changes. In this paper, we define the off-deployment traffic estimation problem as a traffic generation problem, and develop a novel deep generative model TrafficGAN that captures the shared patterns across spatial regions of how traffic conditions evolve according to travel demand changes and underlying road network structures. In particular, TrafficGAN captures the road network structures through a dynamic filter in the dynamic convolutional layer. We evaluate our TrafficGAN using a large-scale traffic data collected from Shenzhen, China. Results show that TrafficGAN can more accurately estimate the traffic conditions compared with all baselines.",
        "author_keywords": [
            "Generative Model",
            "Traffic estimation",
            "TrafficGAN"
        ],
        "subject_areas": [
            "Engineering (all)"
        ]
    },
    {
        "title": "Study on the diffusion model of urban atmospheric pollutants based on GIS technology",
        "authors": "Lü N.",
        "journal": "Xi'an Jianzhu Keji Daxue Xuebao/Journal of Xi'an University of Architecture and Technology",
        "doi": "10.15986/j.1006-7930.2019.05.017",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85076279742",
        "scopus_id": "85076279742",
        "abstract": "GIS has superior spatial analytical and data management functions. The article builds a diffusion model of urban atmospheric pollutant based on GIS technology, provides intuitive, scientific and effective data for assisting atmospheric pollution emergency work, and analyzes the atmospheric pollution diffusion simulation in Lanzhou City. At the same time, the calculation results are combined with urban planning to provide a theoretical basis for urban land layout. Results show that GIS has a wide range of applications in reaearch of the atmospheic pollutant, including data preprocessing, secondary development of models, and in displaying the output of computing results. MapObjects is introduced to confirm the feasibility of integrating atmospheric pollution diffusion research with GIS. The simulation study on the expansion of atmospheric pollutant in Lanzhou has found that the characteristics of atmospheric pollution are closely related to the distribution of pollution sources and topographical features.",
        "author_keywords": [
            "Atmospheric pollutant",
            "Chemical production",
            "Diffusion model",
            "GIS technology"
        ],
        "subject_areas": [
            "Architecture",
            "Building and Construction",
            "Arts and Humanities (miscellaneous)"
        ]
    },
    {
        "title": "Dynamic spatial cluster process model of geo-tagged tweets in London",
        "authors": "Mazzamurro M.",
        "journal": "5th IEEE International Smart Cities Conference, ISC2 2019",
        "doi": "10.1109/ISC246665.2019.9071657",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85084656296",
        "scopus_id": "85084656296",
        "abstract": "Geo-tagged social media data is a key input to many smart city application areas, ranging from mapping consumer demand to understanding location dependent well-being. The sparsity in geo-tagged data, especially in certain cities, means that there is a lack of dynamic spatial point process models for social media data. Having statistically representative spatial models can enable proxy models that improve our understanding of human patterns in urban and suburban areas. Here, we analyse a data set of more than 400, 000 Tweets in London to create a spatial point process model of Tweet clusters. We model Tweet clusters as a Poisson Cluster Process. We then track how the point process parameter and spatial entropy evolve over time to create a generative model usable for others, as well as discuss its relevance to urban dynamics and smart city applications.",
        "author_keywords": [
            "data analysis",
            "GIS",
            "point process",
            "social media"
        ],
        "subject_areas": [
            "Computer Science Applications",
            "Urban Studies",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "GaN-based Room Temperature Spintronics for Next Generation Low Power Consumption Electronic Devices",
        "authors": "Saravade V.",
        "journal": "HONET-ICT 2019 - IEEE 16th International Conference on Smart Cities: Improving Quality of Life using ICT, IoT and AI",
        "doi": "10.1109/HONET.2019.8908100",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85076357519",
        "scopus_id": "85076357519",
        "abstract": "There has been an exponential growth in the microelectronics industry over the last 70 years with a consistent miniaturization of transistors' size and increase in the speed and on-chip transistors density with reasonable power consumption, as seen in Figure 1 [1]. This trend will saturate soon especially due to the unintended thermal noise that is dissipated, as the density of transistors on the chips increase and as the corresponding electronics approach their physical limits. There is a need to implement new processing and computing techniques [2] with more compact size, lower power consumption and enhanced performance. Neuromorphic computing mimics the parallel processing of the mammalian brain and the quantum decoherence within the neurons, and seems to be promising for future applications and needs high speed electronics [3]. Quantum computing could enhance the functionalities, storage capabilities, and data manipulation and transmission, for the next generation of devices. Spintronics is an enabling technology to meet the speed, power, and scalability requirements for quantum information and neuromorphic computing [4 , 5]. The non-volatile nature of spintronic memory could help to tackle power efficiency challenges of microelectronics. Spin of a material is directly related with magnetic, electrical, and optical properties. It is necessary to investigate materials and understand their properties to control and manipulate their spin and use for spintronic applications. However, most materials show conducive properties for spintronics at cryogenic temperatures, which limits their practical applications. There is a need to investigate spintronic materials for quantum applications at room temperature (RT).",
        "author_keywords": NaN,
        "subject_areas": NaN
    },
    {
        "title": "Phytogan: Unpaired dead-to-live phytoplankton translation",
        "authors": "Han S.",
        "journal": "Proceedings - 2019 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Internet of People and Smart City Innovation, SmartWorld/UIC/ATC/SCALCOM/IOP/SCI 2019",
        "doi": "10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00109",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85083593256",
        "scopus_id": "85083593256",
        "abstract": "Detecting phytoplankton that causes red tide is an urgent task. However, the live phytoplankton images are scarce and difficult to obtain. This paper aims to discover a mapping between live and dead phytoplankton. We propose PhytoGAN, a Generative Adversarial Network for the unpaired dead-tolive phytoplankton translation. We design a new PCALoss by extracting the principal component of the image to enhance the contour of the generated image. The addition of PCALoss can significantly improve the integrity of images. The experiments are carried out on the existing phytoplankton dataset. A series of experiments are discussed in the paper to demonstrate the performance of the domain transformation and the proposed loss functions. The experimental results indicate that PhytoGAN can produce more integral images of phytoplankton while completing the domain transformation compared with the existing methods.",
        "author_keywords": [
            "Contour",
            "PCALoss",
            "PhytoGAN",
            "Phytoplankton"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Information Systems and Management",
            "Energy Engineering and Power Technology",
            "Electrical and Electronic Engineering",
            "Urban Studies"
        ]
    },
    {
        "title": "Improved procedures for training primal wasserstein gans",
        "authors": "Zhang T.",
        "journal": "Proceedings - 2019 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Internet of People and Smart City Innovation, SmartWorld/UIC/ATC/SCALCOM/IOP/SCI 2019",
        "doi": "10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00286",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85083558455",
        "scopus_id": "85083558455",
        "abstract": "Primal Wasserstein GANs are a variant of Generative Adversarial Networks (i.e., GANs), which optimize the primal form of empirical Wasserstein distance directly. However, the high computational complexity and training instability are the main challenges of this framework. Accordingly, to address these problems, we propose several procedures for improving the training of Primal Wasserstein GANs. We test the effectiveness of our proposed procedures on MNIST, CIFAR-10, LSUN-Bedroom and ImageNet-Dog category datasets, and the extensive experimental results confirm that our method is capable of generating high-quality images and obtaining high inception score. Importantly, we demonstrate that our method is more time efficient compared with other generative model techniques.",
        "author_keywords": [
            "Computational complexity",
            "Empirical wasserstein distance",
            "Primal GANS",
            "Training instability"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Information Systems",
            "Information Systems and Management",
            "Energy Engineering and Power Technology",
            "Electrical and Electronic Engineering",
            "Urban Studies"
        ]
    },
    {
        "title": "Swarm intelligence optimized generative model for network performance prediction",
        "authors": "Jiang C.",
        "journal": "Proceedings - 21st IEEE International Conference on High Performance Computing and Communications, 17th IEEE International Conference on Smart City and 5th IEEE International Conference on Data Science and Systems, HPCC/SmartCity/DSS 2019",
        "doi": "10.1109/HPCC/SmartCity/DSS.2019.00183",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85073561283",
        "scopus_id": "85073561283",
        "abstract": "Network state prediction methods are widely used currently to evaluate network performance instead of monitors or detectors because of its low-cost and timeliness. However, existing prediction methods are generally based on historical time-series data and insensitive to changes of external conditions. In this paper, based on the state-of-the-art deep generative model Conditional Variational Auto-Encoder, we propose a Network Performance Prediction method using Generative Model (NPGM). This method builds the distribution of network latency features according to historical data with traffic taken as condition. Generative model can deal with hidden variables when building the model which traditional methods cannot handle. Following the ideology of phase space reconstruction, we conceal the numerous factors and map the inherent properties of network into a hidden vector. In order to speed up training process, we optimize parameters of neural networks with our Self-adaptive Stochastic Particle Swarm Optimization (SPSO) instead of Gradient Descent (GD) algorithms. This approach applies self-adaptive coefficients and mutation operation, which improves training efficiency and searching accuracy. We propose a new criterion called Weighted Matrix Mean Absolute Percentage Error (WM-MAPE) to evaluate the predicting accuracy of latency matrices. We use real commercial backbone traffic data from the Center for Applied Internet Data Analysis database. Results on validation sets show that inference error of our approach is less than 50% of time-series-based methods and SPSO has a significantly better efficiency and convergence compared with GD and PSO algorithms.",
        "author_keywords": [
            "generative model",
            "hidden vector",
            "latency inference",
            "mutation",
            "self-adaptive coefficients"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Information Systems",
            "Information Systems and Management",
            "Energy Engineering and Power Technology"
        ]
    },
    {
        "title": "Generative adversarial networks based on denoising and reconstruction regularization",
        "authors": "Yanchun L.",
        "journal": "Proceedings - 21st IEEE International Conference on High Performance Computing and Communications, 17th IEEE International Conference on Smart City and 5th IEEE International Conference on Data Science and Systems, HPCC/SmartCity/DSS 2019",
        "doi": "10.1109/HPCC/SmartCity/DSS.2019.00299",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85073518865",
        "scopus_id": "85073518865",
        "abstract": "In this paper, a fast and easy implementation method is proposed, which adopts the denoising loss of real data and the reconstruction loss of latent codes to deal with the training instability and mode collapse of generative adversarial networks (GAN). The features learned from the corrupted real data by the discriminator are used by the generator to recover real data. Since the denoising loss can estimate the local properties of data generation density, adding denoising loss to the GAN objective functions can improve the quality and diversity of generated samples. Adding reconstruction loss of latent codes to the generator further improves the performance of GAN. Therefore, the optimizing signal of the generator comes from three aspects: the adversarial loss like in standard GAN, the denoising loss of real data and the reconstruction loss of latent codes, which help to prevent the no gradient problem. We evaluate the quality and diversity of generated samples with the robust metric Fréchet Inception Distance, a measure that can detect the intra-class mode dropping and is consistent with human assessment. In addition, we conduct a battery of experiments with the widely used architecture DCGAN and the complex architecture ResNet to demonstrate the effectiveness and robustness of the proposed method.",
        "author_keywords": [
            "deep generative model",
            "generative adversarial networks (gan)",
            "image generation"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Computer Networks and Communications",
            "Computer Science Applications",
            "Hardware and Architecture",
            "Information Systems",
            "Information Systems and Management",
            "Energy Engineering and Power Technology"
        ]
    },
    {
        "title": "A GAN-based active terrain mapping for collaborative air-ground robotic system",
        "authors": "Chen J.",
        "journal": "2019 4th IEEE International Conference on Advanced Robotics and Mechatronics, ICARM 2019",
        "doi": "10.1109/ICARM.2019.8833919",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85073261923",
        "scopus_id": "85073261923",
        "abstract": "Collaborative air-ground robotic system has recently emerged as an important research area and shown great potential in many practical applications of smart cities. This work aims to use such system to transform the aerial images from UAVs into terrain map exploited by UGVs to perform ground path planning or navigation tasks. We propose a novel GAN-based active terrain mapping (GAN-ATM) algorithm which integrates Active Learning (AL) strategy into Generative Adversarial Network (GAN) framework to build the terrain map efficiently with a very limited number of labeled data. The empirical results show that the proposed algorithm achieves the highest predictive accuracy of 90.35%. Due to a more accurate terrain map, the UAV using GAN-ATM can plan the shortest trajectory among all existing counterparts.",
        "author_keywords": [
            "Active Learning",
            "Collaborative Air-Ground Robotic System",
            "Convolutional Neural Networks (CNN)",
            "Generative Adversarial Networks (GAN)"
        ],
        "subject_areas": [
            "Artificial Intelligence",
            "Control and Systems Engineering",
            "Mechanical Engineering",
            "Control and Optimization"
        ]
    },
    {
        "title": "Distant Pedestrian Detection in the Wild using Single Shot Detector with Deep Convolutional Generative Adversarial Networks",
        "authors": "DInakaran R.",
        "journal": "Proceedings of the International Joint Conference on Neural Networks",
        "doi": "10.1109/IJCNN.2019.8851859",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85073247319",
        "scopus_id": "85073247319",
        "abstract": "In this work, we examine the feasibility of applying Deep Convolutional Generative Adversarial Networks (DCGANs) with Single Shot Detector (SSD) as data-processing technique to handle with the challenge of pedestrian detection in the wild. Specifically, we attempted to use in-fill completion to generate random transformations of images with missing pixels to expand existing labelled datasets. In our work, GAN's been trained intensively on low resolution images, in order to neutralize the challenges of the pedestrian detection in the wild, and considered humans, and few other classes for detection in smart cities. The object detector experiment performed by training GAN model along with SSD provided a substantial improvement in the results. This approach presents a very interesting overview in the current state of art on GAN networks for object detection. We used Canadian Institute for Advanced Research (CIFAR), Caltech, KITTI data set for training and testing the network under different resolutions and the experimental results with comparison been showed between DCGAN cascaded with SSD and SSD itself.",
        "author_keywords": [
            "Deep Convolutional Generative Adversarial Networks",
            "Pedestrian Detection",
            "Single Shot Detector",
            "Smart Cities",
            "Surveillance in the Wild."
        ],
        "subject_areas": [
            "Software",
            "Artificial Intelligence"
        ]
    },
    {
        "title": "Effects of urban form on air quality in China: An analysis based on the spatial autoregressive model",
        "authors": "Li F.",
        "journal": "Cities",
        "doi": "10.1016/j.cities.2019.01.025",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85060533490",
        "scopus_id": "85060533490",
        "abstract": "Understanding how urban air quality depends on urban form can have important implications for improving urban air quality by optimizing urban planning and management policies. This study employed the spatial autoregressive model to explore the effect of urban form on urban air quality in 288 prefecture-level cities in China. Information on the air quality (AQI) and six criteria pollutants (PM 2.5 , PM 10 , CO, SO 2 , NO 2 , O 3 ) were obtained from the hourly observation data of 1333 in-situ air monitoring stations throughout 2015. Urban form is characterized by five metrics, including urban size, shape, sprawl, fragmentation and traffic accessibility, and it is calculated based on land cover data. Results show that urban shape complexity and population density have a significant negative impact on urban air quality. Large city size is strongly related to comparatively poor air quality for cities in Southern China and only shows a slight association with emissions in Northern China. In general, lower-sized, scattered, polycentric cities provide better air quality in China. It is suggested that higher air quality and fewer pollutant emissions can be achieved through urban form planning and management policies, which aim to restrict the blind expansion of urban land and encourage moderately scattered, polycentric urban development.",
        "author_keywords": [
            "Air quality",
            "Prefecture-level cities in China",
            "Spatial autoregressive model",
            "Urban form"
        ],
        "subject_areas": [
            "Development",
            "Sociology and Political Science",
            "Urban Studies",
            "Tourism, Leisure and Hospitality Management"
        ]
    },
    {
        "title": "Depth map upsampling via multi-modal generative adversarial network",
        "authors": "Tan D.S.",
        "journal": "Sensors (Switzerland)",
        "doi": "10.3390/s19071587",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85064819646",
        "scopus_id": "85064819646",
        "abstract": "Autonomous robots for smart homes and smart cities mostly require depth perception in order to interact with their environments. However, depth maps are usually captured in a lower resolution as compared to RGB color images due to the inherent limitations of the sensors. Naively increasing its resolution often leads to loss of sharpness and incorrect estimates, especially in the regions with depth discontinuities or depth boundaries. In this paper, we propose a novel Generative Adversarial Network (GAN)-based framework for depth map super-resolution that is able to preserve the smooth areas, as well as the sharp edges at the boundaries of the depth map. Our proposed model is trained on two different modalities, namely color images and depth maps. However, at test time, our model only requires the depth map in order to produce a higher resolution version. We evaluated our model both quantitatively and qualitatively, and our experiments show that our method performs better than existing state-of-the-art models.",
        "author_keywords": [
            "Depth upsampling",
            "Encoder-decoder networks",
            "Generative adversarial networks"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Biochemistry",
            "Atomic and Molecular Physics, and Optics",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Single-image depth inference using generative adversarial networks",
        "authors": "Tan D.S.",
        "journal": "Sensors (Switzerland)",
        "doi": "10.3390/s19071708",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85064772576",
        "scopus_id": "85064772576",
        "abstract": "Depth has been a valuable piece of information for perception tasks such as robot grasping, obstacle avoidance, and navigation, which are essential tasks for developing smart homes and smart cities. However, not all applications have the luxury of using depth sensors or multiple cameras to obtain depth information. In this paper, we tackle the problem of estimating the per-pixel depths from a single image. Inspired by the recent works on generative neural network models, we formulate the task of depth estimation as a generative task where we synthesize an image of the depth map from a single Red, Green, and Blue (RGB) input image. We propose a novel generative adversarial network that has an encoder-decoder type generator with residual transposed convolution blocks trained with an adversarial loss. Quantitative and qualitative experimental results demonstrate the effectiveness of our approach over several depth estimation works.",
        "author_keywords": [
            "Depth estimation",
            "Encoder-decoder networks",
            "Generative adversarial networks"
        ],
        "subject_areas": [
            "Analytical Chemistry",
            "Information Systems",
            "Atomic and Molecular Physics, and Optics",
            "Biochemistry",
            "Instrumentation",
            "Electrical and Electronic Engineering"
        ]
    },
    {
        "title": "Macro-level traffic safety analysis in Shanghai, China",
        "authors": "Wang X.",
        "journal": "Accident Analysis and Prevention",
        "doi": "10.1016/j.aap.2019.02.014",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85061832713",
        "scopus_id": "85061832713",
        "abstract": "Continuing rapid growth in Shanghai, China, requires traffic safety to be considered at the earliest possible stage of transport planning. Macro-level traffic safety studies have been carried out extensively in many countries, but to date, few have been conducted in China. This study developed a macro-level safety model for 263 traffic analysis zones (TAZs) within the urban area of Shanghai in order to examine the relationship between traffic crash frequency and road network, traffic, socio-economic characteristics, and land use features. To account for the spatial correlations among TAZs, a Bayesian conditional autoregressive negative binomial model was estimated, linking crash frequencies in each TAZ to several independent variables. Modeling results showed that higher crash frequencies are associated with greater populations, road densities, total length of major and minor arterials, trip frequencies, and with shorter intersection spacing. The results from this study can help transportation planners and managers identify the crash contributing factors, and can lead to the development of improved safety planning and management.",
        "author_keywords": [
            "Bayesian conditional autoregressive model",
            "Macro-level safety modeling",
            "Traffic analysis zone",
            "Transportation safety planning"
        ],
        "subject_areas": [
            "Human Factors and Ergonomics",
            "Safety, Risk, Reliability and Quality",
            "Public Health, Environmental and Occupational Health"
        ]
    },
    {
        "title": "Geographical area network-structural health monitoring utility computing model",
        "authors": "Tariq H.",
        "journal": "ISPRS International Journal of Geo-Information",
        "doi": "10.3390/ijgi8030154",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85063745308",
        "scopus_id": "85063745308",
        "abstract": "In view of intensified disasters and fatalities caused by natural phenomena and geographical expansion, there is a pressing need for a more effective environment logging for a better management and urban planning. This paper proposes a novel utility computing model (UCM) for structural health monitoring (SHM) that would enable dynamic planning of monitoring systems in an efficient and cost-effective manner in form of a SHM geo-informatics system. The proposed UCM consists of networked SHM systems that send geometrical SHM variables to SHM-UCM gateways. Every gateway is routing the data to SHM-UCM servers running a geo-spatial patch health assessment and prediction algorithm. The inputs of the prediction algorithm are geometrical variables, environmental variables, and payloads. The proposed SHM-UCM is unique in terms of its capability to manage heterogeneous SHM resources. This has been tested in a case study on Qatar University (QU) in Doha Qatar, where it looked at where SHM nodes are distributed along with occupancy density in each building. This information was taken from QU routers and zone calculation models and were then compared to ideal SHM system data. Results show the effectiveness of the proposed model in logging and dynamically planning SHM.",
        "author_keywords": [
            "Geographical Area Network (GAN)",
            "Internet of Things (IoT)",
            "Structural Health Monitoring (SHM)",
            "Things as a Service (TaaS)",
            "Utility Computing (UC)"
        ],
        "subject_areas": [
            "Geography, Planning and Development",
            "Computers in Earth Sciences",
            "Earth and Planetary Sciences (miscellaneous)"
        ]
    },
    {
        "title": "Interaction effects between technology-driven urbanization and eco-environment: Evidence from China's East Zhejiang region",
        "authors": "Gu G.",
        "journal": "Sustainability (Switzerland)",
        "doi": "10.3390/su11030836",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85061155807",
        "scopus_id": "85061155807",
        "abstract": "With the rapid pace of urbanization in populous regions, the conflict between economic development and eco-environment becomes increasingly notable, inducing policy makers to implement new technological solutions for regional sustainable growth. Choosing the East Zhejiang region in China as a case study, this paper reveals the interaction effects between technology-driven urbanization and eco-environment, by compiling novel indexes for factors such as the degree of urbanization, environmental pressure, environmental protection, and environmental quality from 2005 to 2014, and adopting a data-intensive systemic approach. Differing from previous literature, an inverted \"U\" structure and panel vector autoregressive model are constructed to show that: (i) Given the acceleration of technology-driven urbanization, its surrounding eco-environment is still likely to be under greater pressure; (ii) the relationships between technology-driven urbanization and environmental factors in different regions are heterogeneous, either with a normal U-shaped curve or an inverted U-shaped curve; and (iii) the two-way interaction effects are significantly unbalanced, with long-term contribution rates of environmental quality and pressure on urbanization to be 57.8% and 78.88%, respectively, which is higher than the reversal effect. This study provides scientific reference for urban planning and advocates that more technological innovations should be implemented to help maintain sustainable urbanization processes.",
        "author_keywords": [
            "Eco-environment",
            "Interaction effects",
            "Technology-driven",
            "U-shape",
            "Urbanization"
        ],
        "subject_areas": [
            "Computer Science (miscellaneous)",
            "Geography, Planning and Development",
            "Renewable Energy, Sustainability and the Environment",
            "Environmental Science (miscellaneous)",
            "Energy Engineering and Power Technology",
            "Hardware and Architecture",
            "Computer Networks and Communications",
            "Management, Monitoring, Policy and Law"
        ]
    },
    {
        "title": "Spatio-temporal crime predictions in smart cities: A data-driven approach and experiments",
        "authors": "Catlett C.",
        "journal": "Pervasive and Mobile Computing",
        "doi": "10.1016/j.pmcj.2019.01.003",
        "publication_date": "2019",
        "document_type": "Article",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85060488293",
        "scopus_id": "85060488293",
        "abstract": "Steadily increasing urbanization is causing significant economic and social transformations in urban areas, posing several challenges related to city management and services. In particular, in cities with higher crime rates, effectively providing for public safety is an increasingly complex undertaking. To handle this complexity, new technologies are enabling police departments to access growing volumes of crime-related data that can be analyzed to understand patterns and trends. These technologies have potentially to increase the efficient deployment of police resources within a given territory and ultimately support more effective crime prevention. This paper presents a predictive approach based on spatial analysis and auto-regressive models to automatically detect high-risk crime regions in urban areas and to reliably forecast crime trends in each region. The algorithm result is a spatio-temporal crime forecasting model, composed of a set of crime-dense regions with associated crime predictors, each one representing a predictive model for estimating the number of crimes likely to occur in its associated region. The experimental evaluation was performed on two real-world datasets collected in the cities of Chicago and New York City. This evaluation shows that the proposed approach achieves good accuracy in spatial and temporal crime forecasting over rolling time horizons.",
        "author_keywords": [
            "Crime prediction",
            "Data analytics",
            "Smart city",
            "Urban computing"
        ],
        "subject_areas": [
            "Software",
            "Information Systems",
            "Hardware and Architecture",
            "Computer Science Applications",
            "Computer Networks and Communications"
        ]
    },
    {
        "title": "Accelerated Disaster Reconnaissance Using Automatic Traffic Sign Detection with UAV and AI",
        "authors": "Tsai Y.",
        "journal": "Computing in Civil Engineering 2019: Smart Cities, Sustainability, and Resilience - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",
        "doi": "10.1061/9780784482445.052",
        "publication_date": "2019",
        "document_type": "Conference Paper",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85068795209",
        "scopus_id": "85068795209",
        "abstract": "Because of frequent extreme weather conditions, accelerated disaster reconnaissance has become extremely important. In particular, surveying traffic sign damage and conditions has become essential for determining and prioritizing necessary repair/replacement. Under the research project sponsored by the National Academy of Sciences NCHRP-IDEA program, a conventional sign detection algorithm based on color, shape, and texture has been developed to process the images of signs. The developed algorithm has been enhanced by digital image processing and deep-learning methods, such as convolutional neural networks (CNN), generative adversarial networks (GAN), and region-based convolutional neural networks (RCNN). In this paper, a method is designed to process the images obtained using unmanned aerial vehicles (UAV), employing a model UAV, to further develop of our current research. The preliminary test shows that it is promising to use a UAV and machine learning to develop an expedited infrastructure condition evaluation following natural disasters because of its automatic and non-contact nature. The preliminary outcomes show the detection rates have satisfying FN rates and very low FP rates. Besides, the designed algorithm and data-gathering method provides a real-time and on-site computation capability that reduces the quantity of data to be stored by filtering out unnecessary data instantly.",
        "author_keywords": NaN,
        "subject_areas": NaN
    }
]