{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI Applications Analysis by Smart City Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaocarlos/Developer/Projects/genai-smartcity/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generative AI Model Classification in Smart City Research\n",
    "# Using semantic search and multi-strategy classification\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({\"font.size\": 12})\n",
    "plt.rcParams.update({\"font.family\": \"Times New Roman\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Classified Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 455 classified abstracts\n",
      "Found 401 abstracts with both domain classifications and contribution text\n",
      "\n",
      "Sample contribution:\n",
      "To address these issues, this study developed a multi-scale global perceptron network based on Transformer and CNN using novel encoder-decoders for enhancing contextual representation of buildings. Specifically, an improved multi-head-attention encoder is employed by constructing multi-scale tokens ...\n"
     ]
    }
   ],
   "source": [
    "# Load the previously classified abstracts\n",
    "with open(\"../data/06_classified_abstracts_smart_domains.json\", \"r\") as f:\n",
    "    classified_abstracts = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(classified_abstracts)} classified abstracts\")\n",
    "\n",
    "# Verify we have both domain classifications and contribution text\n",
    "abstracts_with_both = [\n",
    "    abstract\n",
    "    for abstract in classified_abstracts\n",
    "    if \"macro_domains\" in abstract\n",
    "    and \"contribution\" in abstract\n",
    "    and abstract[\"contribution\"].strip()\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Found {len(abstracts_with_both)} abstracts with both domain classifications and contribution text\"\n",
    ")\n",
    "\n",
    "# Display a sample contribution\n",
    "print(\"\\nSample contribution:\")\n",
    "print(abstracts_with_both[0][\"contribution\"][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generative AI Model Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-focused generative AI categories\n",
    "genai_model_categories = {\n",
    "    \"Transformer-Based Models\": [\n",
    "        \"transformer\",\n",
    "        \"gpt\",\n",
    "        \"bert\",\n",
    "        \"t5\",\n",
    "        \"llama\",\n",
    "        \"palm\",\n",
    "        \"chatgpt\",\n",
    "        \"gpt-2\",\n",
    "        \"gpt-3\",\n",
    "        \"gpt-4\",\n",
    "        \"large language model\",\n",
    "        \"llm\",\n",
    "        \"small language model\",\n",
    "        \"slm\",\n",
    "        \"foundation model\",\n",
    "        \"pretrained language model\",\n",
    "        \"encoder-decoder\",\n",
    "        \"attention mechanism\",\n",
    "        \"self-attention\",\n",
    "        \"generative pretrained transformer\",\n",
    "        \"claude\",\n",
    "        \"bard\",\n",
    "        \"google bard\",\n",
    "        \"mistral\",\n",
    "        \"gemini\",\n",
    "        \"genai\",\n",
    "        \"large flow model\",\n",
    "        \"lfm\",\n",
    "        \"flow model\",\n",
    "        \"foundation framework\",\n",
    "        \"foundational framework\",\n",
    "        \"gen ai\",\n",
    "        \"generative capability\",\n",
    "        \"generative capabilities\",\n",
    "        \"designed with ai\",\n",
    "        \"genai\",\n",
    "        \"ai capability\",\n",
    "    ],\n",
    "    \"Generative Adversarial Networks\": [\n",
    "        \"gan\",\n",
    "        \"generative adversarial network\",\n",
    "        \"wgan\",\n",
    "        \"wgan-gp\",\n",
    "        \"conditional gan\",\n",
    "        \"cgan\",\n",
    "        \"cycle gan\",\n",
    "        \"cyclegan\",\n",
    "        \"pix2pix\",\n",
    "        \"pix2pixhd\",\n",
    "        \"sr-gan\",\n",
    "        \"srgan\",\n",
    "        \"progressive gan\",\n",
    "        \"biggan\",\n",
    "        \"stylegan\",\n",
    "        \"5gt-gan\",\n",
    "        \"tabular gan\",\n",
    "        \"ctgan\",\n",
    "        \"stargan\",\n",
    "        \"adv-gan\",\n",
    "    ],\n",
    "    \"Diffusion Models\": [\n",
    "        \"diffusion model\",\n",
    "        \"ddpm\",\n",
    "        \"stable diffusion\",\n",
    "        \"latent diffusion\",\n",
    "        \"score-based model\",\n",
    "        \"noise prediction\",\n",
    "        \"denoising diffusion\",\n",
    "        \"ddim\",\n",
    "        \"guided diffusion\",\n",
    "        \"classifier-free guidance\",\n",
    "        \"ddpo\",\n",
    "        \"text-to-image diffusion\",\n",
    "    ],\n",
    "    \"Variational Autoencoders\": [\n",
    "        \"vae\",\n",
    "        \"variational autoencoder\",\n",
    "        \"beta-vae\",\n",
    "        \"conditional vae\",\n",
    "        \"cvae\",\n",
    "        \"vq-vae\",\n",
    "        \"vector quantized vae\",\n",
    "        \"hierarchical vae\",\n",
    "        \"disentangled vae\",\n",
    "        \"autoregressive models\",\n",
    "        \"autoencoder\",\n",
    "        \"latent space modeling\",\n",
    "    ],\n",
    "    \"Neural Radiance Fields & 3D Models\": [\n",
    "        \"nerf\",\n",
    "        \"neural radiance field\",\n",
    "        \"3d gan\",\n",
    "        \"3d generative model\",\n",
    "        \"neural rendering\",\n",
    "        \"implicit representation\",\n",
    "        \"point cloud generation\",\n",
    "        \"mesh generation\",\n",
    "        \"shape generation\",\n",
    "        \"3d reconstruction\",\n",
    "        \"neural implicit surface\",\n",
    "        \"occupancy network\",\n",
    "        \"signed distance function\",\n",
    "    ],\n",
    "    \"Hybrid & Multimodal Architectures\": [\n",
    "        \"multimodal model\",\n",
    "        \"vision-language model\",\n",
    "        \"clip\",\n",
    "        \"dall-e\",\n",
    "        \"imagen\",\n",
    "        \"flamingo\",\n",
    "        \"multimodal transformer\",\n",
    "        \"cross-attention\",\n",
    "        \"contrastive learning\",\n",
    "        \"multimodal embedding\",\n",
    "        \"cross-modal generation\",\n",
    "        \"multimodal fusion\",\n",
    "        \"multimodal alignment\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Add application context to help interpret the models in smart city context\n",
    "model_application_context = {\n",
    "    \"Transformer-Based Models\": \"Text generation, policy analysis, citizen service automation, urban planning documents\",\n",
    "    \"Generative Adversarial Networks\": \"Synthetic urban imagery, simulated traffic patterns, building facades, urban scene completion\",\n",
    "    \"Diffusion Models\": \"High-fidelity urban visualization, satellite imagery enhancement, urban design generation\",\n",
    "    \"Variational Autoencoders\": \"Urban pattern modeling, anomaly detection, compressed representations of city data\",\n",
    "    \"Neural Radiance Fields & 3D Models\": \"Digital twins, virtual urban environments, building modeling, urban scene synthesis\",\n",
    "    \"Hybrid & Multimodal Architectures\": \"Integrating visual and textual urban data, cross-modal urban information processing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Semantic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initial configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Check and download spaCy model if needed\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    import subprocess\n",
    "\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing without context validation ---\n",
      "Configuration: context validation: False, adaptive threshold: True\n",
      "Initializing embeddings models...\n",
      "Precomputing embeddings for model terms...\n",
      "Creating linguistic patterns for domain terminology...\n"
     ]
    }
   ],
   "source": [
    "class EnhancedModelClassifier:\n",
    "    def __init__(self, model_categories, use_context_validation=True, use_adaptive_threshold=True):\n",
    "        \"\"\"\n",
    "        Initialize the classifier with options to enable/disable features\n",
    "        \n",
    "        Args:\n",
    "            model_categories (dict): Dictionary of model categories and their terms\n",
    "            use_context_validation (bool): Whether to use context validation\n",
    "            use_adaptive_threshold (bool): Whether to use adaptive thresholding\n",
    "        \"\"\"\n",
    "        # Store configuration flags\n",
    "        self.use_context_validation = use_context_validation\n",
    "        self.use_adaptive_threshold = use_adaptive_threshold\n",
    "\n",
    "        print(f\"Configuration: context validation: {use_context_validation}, adaptive threshold: {use_adaptive_threshold}\")\n",
    "\n",
    "        # Use multiple embedding models to reduce single-model bias\n",
    "        print(\"Initializing embeddings models...\")\n",
    "        self.models = {\n",
    "            # \"general\": SentenceTransformer(\n",
    "            #     \"sentence-transformers/all-MiniLM-L12-v2\", device=DEVICE\n",
    "            # ),\n",
    "            # Using a more scientific model for technical text\n",
    "            \"scientific\": SentenceTransformer(\n",
    "                \"pritamdeka/S-PubMedBert-MS-MARCO\", device=DEVICE\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        self.model_categories = model_categories\n",
    "        self.category_embeddings = {}\n",
    "        self.term_embeddings = {}\n",
    "\n",
    "        print(\"Precomputing embeddings for model terms...\")\n",
    "        # Precompute embeddings with both models\n",
    "        for category, terms in model_categories.items():\n",
    "            self.category_embeddings[category] = {}\n",
    "            for model_name, model in self.models.items():\n",
    "                self.category_embeddings[category][model_name] = model.encode(\n",
    "                    category, convert_to_tensor=True\n",
    "                )\n",
    "\n",
    "            self.term_embeddings[category] = {}\n",
    "            for term in terms:\n",
    "                self.term_embeddings[category][term] = {\n",
    "                    model_name: model.encode(term, convert_to_tensor=True)\n",
    "                    for model_name, model in self.models.items()\n",
    "                }\n",
    "\n",
    "        # Create lemma patterns for domain-specific term detection\n",
    "        self.lemma_patterns = {}\n",
    "        self.nlp = nlp\n",
    "\n",
    "        print(\"Creating linguistic patterns for domain terminology...\")\n",
    "        for category, terms in self.model_categories.items():\n",
    "            category_patterns = set()\n",
    "            for term in terms:\n",
    "                term_doc = self.nlp(term)\n",
    "                key_lemmas = sorted(\n",
    "                    [\n",
    "                        token.lemma_\n",
    "                        for token in term_doc\n",
    "                        if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"]\n",
    "                    ]\n",
    "                )\n",
    "                if key_lemmas:\n",
    "                    category_patterns.add(tuple(key_lemmas))\n",
    "            self.lemma_patterns[category] = category_patterns\n",
    "\n",
    "    def get_best_similarity(self, text_embed, term_embeds):\n",
    "        \"\"\"Calculate the best similarity score across multiple embedding models\"\"\"\n",
    "        similarities = [\n",
    "            util.pytorch_cos_sim(text_embed[model_name], term_embeds[model_name])[\n",
    "                0\n",
    "            ].item()\n",
    "            for model_name in self.models.keys()\n",
    "        ]\n",
    "        return max(similarities)\n",
    "\n",
    "    def adaptive_threshold(self, term, base_threshold=0.75):\n",
    "        \"\"\"Calculate adaptive threshold based on term complexity\"\"\"\n",
    "        if not self.use_adaptive_threshold:\n",
    "            return base_threshold\n",
    "\n",
    "        term_length = len(term.split())\n",
    "        if term_length >= 4:  # Very specific terms\n",
    "            return base_threshold - 0.15\n",
    "        elif term_length >= 2:  # Multi-word terms\n",
    "            return base_threshold - 0.05\n",
    "        return base_threshold  # Single words need higher threshold\n",
    "\n",
    "    def validate_term_context(self, text, term):\n",
    "        \"\"\"\n",
    "        Check if term appears in a context indicating actual usage\n",
    "        Returns True if context validation is disabled\n",
    "        \"\"\"\n",
    "        # Skip validation if disabled\n",
    "        if not self.use_context_validation:\n",
    "            return True\n",
    "\n",
    "        positive_contexts = [\n",
    "            f\"using {term}\",\n",
    "            f\"use {term}\",\n",
    "            f\"based on {term}\",\n",
    "            f\"implement {term}\",\n",
    "            f\"our {term}\",\n",
    "            f\"proposed {term}\",\n",
    "            f\"novel {term}\",\n",
    "            f\"develop {term}\",\n",
    "            f\"train {term}\",\n",
    "            f\"fine-tune {term}\",\n",
    "            f\"employ {term}\",\n",
    "            f\"utilize {term}\",\n",
    "            f\"apply {term}\",\n",
    "            f\"architecture {term}\",\n",
    "            f\"framework {term}\",\n",
    "            f\"{term} approach\",\n",
    "            f\"{term} method\",\n",
    "            f\"{term} technique\",\n",
    "            f\"{term} model\",\n",
    "            f\"leveraging {term}\",\n",
    "            f\"powered by {term}\",\n",
    "        ]\n",
    "\n",
    "        negative_contexts = [\n",
    "            f\"unlike {term}\",\n",
    "            f\"compared to {term}\",\n",
    "            f\"in contrast to {term}\",\n",
    "            f\"outperform {term}\",\n",
    "            f\"better than {term}\",\n",
    "            f\"future work\",\n",
    "            f\"alternative to {term}\",\n",
    "            f\"instead of {term}\",\n",
    "            f\"limitation of {term}\",\n",
    "            f\"beyond {term}\",\n",
    "            f\"previous {term}\",\n",
    "            f\"conventional {term}\",\n",
    "            f\"traditional {term}\",\n",
    "            f\"standard {term}\",\n",
    "            f\"baseline {term}\",\n",
    "            f\"other {term}\",\n",
    "            f\"existing {term}\",\n",
    "        ]\n",
    "\n",
    "        # Check for positive contexts\n",
    "        positive_score = sum(\n",
    "            1 for context in positive_contexts if context.lower() in text.lower()\n",
    "        )\n",
    "\n",
    "        # Check for negative contexts\n",
    "        negative_score = sum(\n",
    "            1 for context in negative_contexts if context.lower() in text.lower()\n",
    "        )\n",
    "\n",
    "        # Calculate a context score (-1 to 1)\n",
    "        if positive_score + negative_score == 0:\n",
    "            return False  # No context clues at all\n",
    "\n",
    "        context_score = (positive_score - negative_score) / max(\n",
    "            1, positive_score + negative_score\n",
    "        )\n",
    "\n",
    "        return context_score > 0  # Return True if positive context outweighs negative\n",
    "\n",
    "    def classify_contribution(self, text, base_threshold=0.75):\n",
    "        \"\"\"\n",
    "        Classify text using a balanced ensemble of matching strategies\n",
    "        with bias reduction techniques and stricter filtering\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return {}\n",
    "\n",
    "        # Define match weights with stronger preference for exact matches\n",
    "        match_weights = {\n",
    "            \"exact\": 1.0,\n",
    "            \"token\": 0.7,\n",
    "            \"semantic\": 0.7,\n",
    "            \"domain_pattern\": 0.5,\n",
    "        }\n",
    "\n",
    "        text = text.lower()\n",
    "        results = {}\n",
    "\n",
    "        # Track potential biases and configuration\n",
    "        bias_metadata = {\n",
    "            \"text_truncated\": len(text) > 10000,\n",
    "            \"language\": \"english\",\n",
    "            \"embedding_models\": list(self.models.keys()),\n",
    "            \"base_threshold\": base_threshold,\n",
    "            \"tech_terms_analyzed\": 0,\n",
    "            \"named_entities_found\": 0,\n",
    "            \"use_context_validation\": self.use_context_validation,\n",
    "            \"use_adaptive_threshold\": self.use_adaptive_threshold\n",
    "        }\n",
    "\n",
    "        # Process text with spaCy for advanced linguistic analysis\n",
    "        doc = self.nlp(text[:10000])  # Limit length to avoid memory issues\n",
    "\n",
    "        # Extract technical terms and phrases that might be model references\n",
    "        tech_keywords = {\n",
    "            # Basic ML/AI terms\n",
    "            \"model\",\n",
    "            \"network\",\n",
    "            \"gan\",\n",
    "            \"transformer\",\n",
    "            \"ai\",\n",
    "            \"algorithm\",\n",
    "            \"vae\",\n",
    "            # Additional model architectures\n",
    "            \"encoder\",\n",
    "            \"diffusion\",\n",
    "            \"lstm\",\n",
    "            \"cnn\",\n",
    "            \"rnn\",\n",
    "            \"neural\",\n",
    "            \"deep\",\n",
    "            # Model characteristics\n",
    "            \"generative\",\n",
    "            \"predictive\",\n",
    "            \"adversarial\",\n",
    "            \"supervised\",\n",
    "            \"classifier\",\n",
    "            \"unsupervised\",\n",
    "            # Domain-specific terms\n",
    "            \"synthesis\",\n",
    "            \"recognition\",\n",
    "            \"generation\",\n",
    "            \"training\",\n",
    "            \"inference\",\n",
    "        }\n",
    "\n",
    "        # Extract tech phrases\n",
    "        tech_phrases = []\n",
    "        for chunk in doc.noun_chunks:\n",
    "            # Extract more comprehensively\n",
    "            if any(token.lemma_ in tech_keywords for token in chunk):\n",
    "                tech_phrases.append(chunk.text)\n",
    "            # Also check for tech bigrams/trigrams within longer chunks\n",
    "            elif len(chunk) > 3:\n",
    "                for i in range(len(chunk) - 1):\n",
    "                    if (\n",
    "                        chunk[i].lemma_ in tech_keywords\n",
    "                        or chunk[i + 1].lemma_ in tech_keywords\n",
    "                    ):\n",
    "                        tech_phrases.append(\n",
    "                            \" \".join([token.text for token in chunk[i : i + 2]])\n",
    "                        )\n",
    "\n",
    "        # Add named entities that might be model names\n",
    "        named_entities = [\n",
    "            ent.text\n",
    "            for ent in doc.ents\n",
    "            if ent.label_ in [\"ORG\", \"PRODUCT\", \"WORK_OF_ART\"]\n",
    "        ]\n",
    "        tech_phrases.extend(named_entities)\n",
    "\n",
    "        # Update metadata\n",
    "        bias_metadata[\"tech_terms_analyzed\"] = len(tech_phrases)\n",
    "        bias_metadata[\"named_entities_found\"] = len(named_entities)\n",
    "\n",
    "        # Examine both the full text and extracted technical phrases\n",
    "        texts_to_analyze = [text] + tech_phrases\n",
    "\n",
    "        # Look for domain-specific patterns in sentences with stricter criteria\n",
    "        domain_patterns = {}\n",
    "        for sent in doc.sents:\n",
    "            sent_lemmas = [\n",
    "                token.lemma_ for token in sent if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"]\n",
    "            ]\n",
    "            for i in range(len(sent_lemmas)):\n",
    "                for j in range(i + 1, min(i + 5, len(sent_lemmas))):\n",
    "                    ngram = tuple(sorted(sent_lemmas[i:j]))\n",
    "                    if len(ngram) < 2:  # Skip single words\n",
    "                        continue\n",
    "\n",
    "                    for category, patterns in self.lemma_patterns.items():\n",
    "                        for pattern in patterns:\n",
    "                            overlap = len(set(ngram).intersection(pattern)) / len(\n",
    "                                pattern\n",
    "                            )\n",
    "                            if overlap > 0.8:\n",
    "                                phrase_text = \" \".join(\n",
    "                                    [token.text for token in sent[i:j]]\n",
    "                                )\n",
    "\n",
    "                                # Only consider if there's contextual evidence\n",
    "                                if self.validate_term_context(text, phrase_text):\n",
    "                                    if category not in domain_patterns:\n",
    "                                        domain_patterns[category] = []\n",
    "\n",
    "                                    domain_patterns[category].append(\n",
    "                                        {\n",
    "                                            \"term\": phrase_text,\n",
    "                                            \"match_type\": \"domain_pattern\",\n",
    "                                            \"confidence\": overlap * 0.7,\n",
    "                                            \"pattern_overlap\": overlap,\n",
    "                                        }\n",
    "                                    )\n",
    "\n",
    "        for category, terms in self.model_categories.items():\n",
    "            all_matches = []\n",
    "\n",
    "            # Level 1: Direct exact matching\n",
    "            for term in terms:\n",
    "                pattern = r\"\\b\" + re.escape(term) + r\"\\b\"\n",
    "                if re.search(pattern, text):\n",
    "                    # Validate the context for exact matches too\n",
    "                    if self.validate_term_context(text, term):\n",
    "                        all_matches.append(\n",
    "                            {\"term\": term, \"match_type\": \"exact\", \"confidence\": 1.0}\n",
    "                        )\n",
    "\n",
    "            # Level 2: Token-based matching for multi-word terms\n",
    "            text_tokens = set(re.findall(r\"\\b\\w+\\b\", text))\n",
    "            for term in terms:\n",
    "                term_tokens = set(re.findall(r\"\\b\\w+\\b\", term))\n",
    "                if (\n",
    "                    term_tokens\n",
    "                    and term_tokens.issubset(text_tokens)\n",
    "                    and len(term_tokens) > 1\n",
    "                ):\n",
    "                    # Only consider multi-word token matches with positive context\n",
    "                    if self.validate_term_context(text, term):\n",
    "                        all_matches.append(\n",
    "                            {\n",
    "                                \"term\": term,\n",
    "                                \"match_type\": \"token\",\n",
    "                                \"confidence\": 0.7,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            # Level 3: Semantic similarity using embeddings (more selective)\n",
    "            for analyze_text in texts_to_analyze:\n",
    "                # Skip if too short\n",
    "                if len(analyze_text.split()) < 2:\n",
    "                    continue\n",
    "\n",
    "                # Encode with all models\n",
    "                text_embeddings = {\n",
    "                    model_name: model.encode(analyze_text, convert_to_tensor=True)\n",
    "                    for model_name, model in self.models.items()\n",
    "                }\n",
    "\n",
    "                # Check similarity to each term across models\n",
    "                for term in terms:\n",
    "                    term_threshold = self.adaptive_threshold(term, base_threshold)\n",
    "                    similarity = self.get_best_similarity(\n",
    "                        text_embeddings, self.term_embeddings[category][term]\n",
    "                    )\n",
    "\n",
    "                    if similarity > term_threshold:\n",
    "                        # Only add semantic matches with proper validation\n",
    "                        if similarity > 0.9 or self.validate_term_context(text, term):\n",
    "                            all_matches.append(\n",
    "                                {\n",
    "                                    \"term\": term,\n",
    "                                    \"match_type\": \"semantic\",\n",
    "                                    \"confidence\": similarity,\n",
    "                                    \"threshold_used\": term_threshold,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            # Add domain pattern matches if any\n",
    "            if category in domain_patterns:\n",
    "                all_matches.extend(domain_patterns[category])\n",
    "\n",
    "            # If we have any matches, calculate ensemble score and include in results\n",
    "            if all_matches:\n",
    "                # Remove duplicates, keeping highest confidence for each term\n",
    "                unique_matches = {}\n",
    "                for match in all_matches:\n",
    "                    term = match[\"term\"]\n",
    "                    if (\n",
    "                        term not in unique_matches\n",
    "                        or match[\"confidence\"] > unique_matches[term][\"confidence\"]\n",
    "                    ):\n",
    "                        unique_matches[term] = match\n",
    "\n",
    "                # Extract final matches list\n",
    "                final_matches = list(unique_matches.values())\n",
    "\n",
    "                # Calculate weighted ensemble confidence score\n",
    "                weighted_scores = [\n",
    "                    match_weights[match[\"match_type\"]] * match[\"confidence\"]\n",
    "                    for match in final_matches\n",
    "                ]\n",
    "                ensemble_confidence = sum(weighted_scores) / len(weighted_scores)\n",
    "\n",
    "                # Store the results\n",
    "                results[category] = {\n",
    "                    \"matches\": final_matches,\n",
    "                    \"confidence\": ensemble_confidence,\n",
    "                    \"match_count\": len(final_matches),\n",
    "                    \"match_types\": Counter(\n",
    "                        [match[\"match_type\"] for match in final_matches]\n",
    "                    ),\n",
    "                }\n",
    "\n",
    "        # Add bias metadata to results\n",
    "        results[\"_metadata\"] = bias_metadata\n",
    "\n",
    "        # Apply appropriate filtering criteria\n",
    "        filtered_results = {}\n",
    "        for category, result in results.items():\n",
    "            # Keep metadata\n",
    "            if category == \"_metadata\":\n",
    "                filtered_results[category] = result\n",
    "                continue\n",
    "\n",
    "            # Adjust filtering criteria based on whether validation is enabled\n",
    "            if self.use_context_validation:\n",
    "                # Stricter criteria when using validation\n",
    "                if (\n",
    "                    result[\"confidence\"] > 0.55\n",
    "                    and (\n",
    "                        \"exact\" in result[\"match_types\"]\n",
    "                        and result[\"match_types\"][\"exact\"] > 0\n",
    "                    )\n",
    "                ) or (\n",
    "                    result[\"confidence\"] > 0.6 and result[\"match_count\"] >= 2\n",
    "                ) or (\n",
    "                    result[\"confidence\"] > 0.7\n",
    "                ):\n",
    "                    filtered_results[category] = result\n",
    "            else:\n",
    "                # More lenient criteria when not using validation\n",
    "                # Use a staggered approach based on match types\n",
    "                if (\n",
    "                    \"exact\" in result[\"match_types\"] and result[\"match_types\"][\"exact\"] > 0\n",
    "                ) or (\n",
    "                    result[\"confidence\"] > 0.5 and result[\"match_count\"] >= 2\n",
    "                ) or (\n",
    "                    \"semantic\" in result[\"match_types\"] and \n",
    "                    result[\"match_types\"][\"semantic\"] > 0 and\n",
    "                    result[\"confidence\"] > 0.7\n",
    "                ) or (\n",
    "                    \"domain_pattern\" in result[\"match_types\"] and\n",
    "                    result[\"match_types\"][\"domain_pattern\"] > 1  # Require multiple domain pattern matches\n",
    "                ):\n",
    "                    filtered_results[category] = result\n",
    "\n",
    "        return filtered_results\n",
    "\n",
    "    def analyze_abstract(self, abstract_data, base_threshold=0.75):\n",
    "        \"\"\"Analyze an abstract with weighted sections, prioritizing contribution\"\"\"\n",
    "        if (\n",
    "            \"contribution\" not in abstract_data\n",
    "            or not abstract_data[\"contribution\"].strip()\n",
    "        ):\n",
    "            return {}\n",
    "\n",
    "        # Analyze the contribution with higher weight\n",
    "        contribution_results = self.classify_contribution(\n",
    "            abstract_data[\"contribution\"], base_threshold=base_threshold\n",
    "        )\n",
    "\n",
    "        # If available, analyze introduction with lower weight\n",
    "        introduction_results = {}\n",
    "        if \"introduction\" in abstract_data and abstract_data[\"introduction\"].strip():\n",
    "            introduction_results = self.classify_contribution(\n",
    "                abstract_data[\"introduction\"], base_threshold=base_threshold+0.1\n",
    "            )\n",
    "\n",
    "        # Combine results, prioritizing contribution\n",
    "        final_results = contribution_results.copy()\n",
    "\n",
    "        # Only incorporate introduction models that have strong evidence\n",
    "        for category, intro_data in introduction_results.items():\n",
    "            if category == \"_metadata\":\n",
    "                continue\n",
    "\n",
    "            if category not in final_results and intro_data[\"confidence\"] > 0.7:\n",
    "                # Only add high-confidence introduction matches\n",
    "                intro_data[\"confidence\"] *= 0.7  # Discount introduction confidence\n",
    "                final_results[category] = intro_data\n",
    "\n",
    "        return final_results\n",
    "\n",
    "\n",
    "# Initialize the classifier\n",
    "# classifier = EnhancedModelClassifier(genai_model_categories)\n",
    "print(\"\\n--- Testing without context validation ---\")\n",
    "classifier_no_context = EnhancedModelClassifier(\n",
    "    genai_model_categories, use_context_validation=False, use_adaptive_threshold=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Classify the Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying model architectures in contributions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing abstracts: 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 abstracts mentioning generative model architectures\n",
      "This represents 96.67% of all abstracts with contributions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each abstract\n",
    "print(\"Classifying model architectures in contributions...\")\n",
    "for abstract in tqdm(abstracts_with_both[:30], desc=\"Analyzing abstracts\"):\n",
    "    # Use the analyze_abstract method\n",
    "    model_classification = classifier_no_context.analyze_abstract(abstract, base_threshold=0.95)\n",
    "\n",
    "    # Store results\n",
    "    abstract[\"model_architectures\"] = model_classification\n",
    "\n",
    "# Count abstracts with ACTUAL identified model architectures (excluding _metadata only)\n",
    "abstracts_with_models = [\n",
    "    abstract\n",
    "    for abstract in abstracts_with_both[:30]\n",
    "    if \"model_architectures\" in abstract\n",
    "    and any(key != \"_metadata\" for key in abstract[\"model_architectures\"].keys())\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Found {len(abstracts_with_models)} abstracts mentioning generative model architectures\"\n",
    ")\n",
    "print(\n",
    "    f\"This represents {len(abstracts_with_models)/len(abstracts_with_both[:30])*100:.2f}% of all abstracts with contributions\"\n",
    ")\n",
    "\n",
    "# Save the results as a checkpoint\n",
    "output_dir = \"../data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, \"genai_model_classifications.json\"), \"w\") as f:\n",
    "    json.dump(abstracts_with_both, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different base thresholds to find the optimal setting\n",
    "thresholds = [0.65, 0.55, 0.45]\n",
    "results = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\nTesting with threshold {threshold}:\")\n",
    "\n",
    "    # Process abstracts\n",
    "    abstracts_test = copy.deepcopy(\n",
    "        abstracts_with_both[:15]\n",
    "    )  # Create a copy to avoid interference\n",
    "\n",
    "    for abstract in tqdm(abstracts_test, desc=f\"Threshold {threshold}\"):\n",
    "        model_classification = classifier_no_context.analyze_abstract(\n",
    "            abstract, base_threshold=threshold\n",
    "        )\n",
    "        abstract[\"model_architectures\"] = model_classification\n",
    "\n",
    "    # Count matches\n",
    "    abstracts_with_models = [\n",
    "        abstract\n",
    "        for abstract in abstracts_test\n",
    "        if \"model_architectures\" in abstract\n",
    "        and any(key != \"_metadata\" for key in abstract[\"model_architectures\"].keys())\n",
    "    ]\n",
    "\n",
    "    # Count match types\n",
    "    match_type_counts = {\"exact\": 0, \"token\": 0, \"semantic\": 0, \"domain_pattern\": 0}\n",
    "    model_counts = Counter()\n",
    "\n",
    "    for abstract in abstracts_with_models:\n",
    "        for category, data in abstract[\"model_architectures\"].items():\n",
    "            if category == \"_metadata\":\n",
    "                continue\n",
    "\n",
    "            model_counts[category] += 1\n",
    "\n",
    "            if \"match_types\" in data:\n",
    "                for match_type, count in data[\"match_types\"].items():\n",
    "                    match_type_counts[match_type] += count\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Found {len(abstracts_with_models)} abstracts with models\")\n",
    "    print(f\"Model distribution: {dict(model_counts)}\")\n",
    "    print(f\"Match types: {match_type_counts}\")\n",
    "\n",
    "    # Store for comparison\n",
    "    results[threshold] = {\n",
    "        \"count\": len(abstracts_with_models),\n",
    "        \"models\": dict(model_counts),\n",
    "        \"match_types\": match_type_counts,\n",
    "    }\n",
    "\n",
    "# Compare and recommend the best threshold\n",
    "print(\"\\nThreshold Comparison:\")\n",
    "for threshold, data in results.items():\n",
    "    semantic_ratio = (\n",
    "        data[\"match_types\"][\"semantic\"] / sum(data[\"match_types\"].values())\n",
    "        if sum(data[\"match_types\"].values()) > 0\n",
    "        else 0\n",
    "    )\n",
    "    print(\n",
    "        f\"Threshold {threshold}: {data['count']} abstracts, {semantic_ratio:.2%} semantic matches\"\n",
    "    )\n",
    "\n",
    "# Recommend the best threshold\n",
    "best_threshold = min(\n",
    "    results.items(),\n",
    "    key=lambda x: (\n",
    "        abs(x[1][\"match_types\"][\"semantic\"] / sum(x[1][\"match_types\"].values()) - 0.4)\n",
    "        if sum(x[1][\"match_types\"].values()) > 0\n",
    "        else 1\n",
    "    ),\n",
    ")[0]\n",
    "print(f\"\\nRecommended threshold: {best_threshold} (aims for ~40% semantic matches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Model Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Category Distribution:\n",
      "  - Transformer-Based Models: 30 abstracts\n",
      "  - Generative Adversarial Networks: 30 abstracts\n",
      "  - Diffusion Models: 30 abstracts\n",
      "  - Variational Autoencoders: 30 abstracts\n",
      "  - Neural Radiance Fields & 3D Models: 30 abstracts\n",
      "  - Hybrid & Multimodal Architectures: 30 abstracts\n",
      "\n",
      "Match Method Distribution:\n",
      "  - exact: 36 (1.15%)\n",
      "  - token: 1 (0.03%)\n",
      "  - semantic: 1979 (63.43%)\n",
      "  - domain_pattern: 1104 (35.38%)\n",
      "\n",
      "Top 10 Model Terms:\n",
      "  - large language model: 30\n",
      "  - foundation model: 30\n",
      "  - pretrained language model: 30\n",
      "  - attention mechanism: 30\n",
      "  - generative pretrained transformer: 30\n",
      "  - large flow model: 30\n",
      "  - flow model: 30\n",
      "  - foundation framework: 30\n",
      "  - foundational framework: 30\n",
      "  - generative capability: 30\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary to store model frequency by category\n",
    "model_category_counts = Counter()\n",
    "match_type_counts = {\"exact\": 0, \"token\": 0, \"semantic\": 0, \"domain_pattern\": 0}\n",
    "model_term_counts = Counter()\n",
    "\n",
    "# Collect data from the abstracts\n",
    "for abstract in abstracts_with_models:\n",
    "    for category, data in abstract[\"model_architectures\"].items():\n",
    "        # Skip the metadata field when counting model categories\n",
    "        if category == \"_metadata\":\n",
    "            continue\n",
    "\n",
    "        model_category_counts[category] += 1\n",
    "\n",
    "        # Count each matching term and match type\n",
    "        if \"matches\" in data:\n",
    "            for match in data[\"matches\"]:\n",
    "                model_term_counts[match[\"term\"]] += 1\n",
    "                match_type_counts[match[\"match_type\"]] += 1\n",
    "\n",
    "# Display category counts\n",
    "print(\"\\nModel Category Distribution:\")\n",
    "for category, count in model_category_counts.most_common():\n",
    "    print(f\"  - {category}: {count} abstracts\")\n",
    "\n",
    "# Display match type distribution\n",
    "print(\"\\nMatch Method Distribution:\")\n",
    "total_matches = sum(match_type_counts.values())\n",
    "for match_type, count in match_type_counts.items():\n",
    "    if total_matches > 0:  # Avoid division by zero\n",
    "        print(f\"  - {match_type}: {count} ({count/total_matches*100:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"  - {match_type}: {count} (0.00%)\")\n",
    "\n",
    "# Display top model terms\n",
    "print(\"\\nTop 10 Model Terms:\")\n",
    "for term, count in model_term_counts.most_common(10):\n",
    "    print(f\"  - {term}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Domain-Model Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of domains to model architectures\n",
    "domain_to_models = defaultdict(Counter)\n",
    "\n",
    "for abstract in abstracts_with_models:\n",
    "    domains = [d[\"domain\"] for d in abstract.get(\"macro_domains\", [])]\n",
    "    models = list(abstract[\"model_architectures\"].keys())\n",
    "\n",
    "    for domain in domains:\n",
    "        domain_to_models[domain].update(models)\n",
    "\n",
    "# Create matrix for domain-model relationships\n",
    "domains = sorted(domain_to_models.keys())\n",
    "model_categories = sorted(genai_model_categories.keys())\n",
    "\n",
    "# Create matrix data for heatmap\n",
    "matrix_data = []\n",
    "for domain in domains:\n",
    "    domain_data = []\n",
    "    for model in model_categories:\n",
    "        count = domain_to_models[domain][model]\n",
    "        domain_data.append(count)\n",
    "    matrix_data.append(domain_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "heatmap_df = pd.DataFrame(matrix_data, index=domains, columns=model_categories)\n",
    "\n",
    "# Print the top domains for each model category\n",
    "print(\"\\nTop Domains for Each Model Category:\")\n",
    "for model in model_categories:\n",
    "    print(f\"\\n{model}:\")\n",
    "    top_domains = sorted(\n",
    "        [\n",
    "            (domain, domain_to_models[domain][model])\n",
    "            for domain in domains\n",
    "            if domain_to_models[domain][model] > 0\n",
    "        ],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )[:3]\n",
    "\n",
    "    for domain, count in top_domains:\n",
    "        print(f\"  - {domain}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model Category Distribution Bar Chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "categories = [cat for cat, _ in model_category_counts.most_common()]\n",
    "counts = [count for _, count in model_category_counts.most_common()]\n",
    "\n",
    "sns.barplot(x=counts, y=categories, palette=\"viridis\")\n",
    "plt.xlabel(\"Number of Abstracts\")\n",
    "plt.ylabel(\"Generative AI Model Category\")\n",
    "plt.title(\"Distribution of Generative AI Model Categories in Smart City Research\")\n",
    "\n",
    "# Add value labels to the end of each bar\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(count + 0.5, i, str(count), va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"genai_model_distribution.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 2. Match Type Distribution Pie Chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "match_labels = [\n",
    "    f\"{match_type} ({count})\" for match_type, count in match_type_counts.items()\n",
    "]\n",
    "match_counts = list(match_type_counts.values())\n",
    "\n",
    "plt.pie(\n",
    "    match_counts,\n",
    "    labels=match_labels,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=sns.color_palette(\"Set2\"),\n",
    "    startangle=90,\n",
    "    explode=[0.05] * len(match_counts),\n",
    ")\n",
    "plt.title(\"Distribution of Match Types in Model Detection\")\n",
    "plt.savefig(os.path.join(output_dir, \"match_type_distribution.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 3. Domain-Model Heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "ax = sns.heatmap(heatmap_df, annot=True, fmt=\"d\", cmap=\"YlGnBu\", linewidths=0.5)\n",
    "plt.xlabel(\"Generative AI Model Category\")\n",
    "plt.ylabel(\"Smart City Domain\")\n",
    "plt.title(\"Heatmap of Generative AI Models Across Smart City Domains\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"domain_model_heatmap.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 4. Top Models in Top Domains\n",
    "# Get top 5 domains by total model mentions\n",
    "top_domain_counts = {\n",
    "    domain: sum(counts.values()) for domain, counts in domain_to_models.items()\n",
    "}\n",
    "top_domains = sorted(top_domain_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "top_domain_names = [d for d, _ in top_domains]\n",
    "\n",
    "# Create a subset dataframe for these domains\n",
    "top_domain_df = heatmap_df.loc[top_domain_names]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "top_domain_df.plot(kind=\"bar\", stacked=False, colormap=\"tab10\")\n",
    "plt.xlabel(\"Smart City Domain\")\n",
    "plt.ylabel(\"Number of Abstracts\")\n",
    "plt.title(\"Distribution of GenAI Model Categories in Top Smart City Domains\")\n",
    "plt.legend(title=\"Model Category\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"top_domains_model_distribution.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 5. Model term cloud (horizontal bar chart of top terms)\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_terms = [term for term, _ in model_term_counts.most_common(15)]\n",
    "term_counts = [count for _, count in model_term_counts.most_common(15)]\n",
    "\n",
    "sns.barplot(x=term_counts, y=top_terms, palette=\"rocket\")\n",
    "plt.xlabel(\"Number of Mentions\")\n",
    "plt.ylabel(\"Model Term\")\n",
    "plt.title(\"Top 15 Generative AI Model Terms in Smart City Research\")\n",
    "\n",
    "# Add value labels to the end of each bar\n",
    "for i, count in enumerate(term_counts):\n",
    "    plt.text(count + 0.3, i, str(count), va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"top_model_terms.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Representatative Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find representative examples for each model category\n",
    "examples = {}\n",
    "\n",
    "for abstract in abstracts_with_models:\n",
    "    for category in abstract[\"model_architectures\"].keys():\n",
    "        if category not in examples and \"doi\" in abstract:\n",
    "            if \"matches\" in abstract[\"model_architectures\"][category]:\n",
    "                terms = [\n",
    "                    match[\"term\"]\n",
    "                    for match in abstract[\"model_architectures\"][category][\"matches\"]\n",
    "                ]\n",
    "                confidence = abstract[\"model_architectures\"][category][\"confidence\"]\n",
    "            else:\n",
    "                terms = []\n",
    "                confidence = 0.0\n",
    "\n",
    "            # Store this example\n",
    "            examples[category] = {\n",
    "                \"doi\": abstract.get(\"doi\", \"Unknown\"),\n",
    "                \"contribution\": abstract[\"contribution\"][:300]\n",
    "                + \"...\",  # Truncate for readability\n",
    "                \"matched_terms\": terms,\n",
    "                \"confidence\": confidence,\n",
    "                \"domains\": [d[\"domain\"] for d in abstract.get(\"macro_domains\", [])],\n",
    "            }\n",
    "\n",
    "# Display examples\n",
    "print(\"\\n📚 Representative Examples for Each Model Category:\")\n",
    "\n",
    "for category in genai_model_categories.keys():\n",
    "    print(f\"\\n## {category}\")\n",
    "    if category in examples:\n",
    "        example = examples[category]\n",
    "        print(f\"DOI: {example['doi']}\")\n",
    "        print(f\"Smart City Domains: {', '.join(example['domains'])}\")\n",
    "        print(f\"Matched Terms: {', '.join(example['matched_terms'])}\")\n",
    "        print(f\"Confidence: {example['confidence']:.2f}\")\n",
    "        print(f\"Contribution: {example['contribution']}\")\n",
    "    else:\n",
    "        print(\"No example found for this category\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key statistics\n",
    "total_abstracts = len(abstracts_with_both)\n",
    "total_with_models = len(abstracts_with_models)\n",
    "percentage_with_models = (total_with_models / total_abstracts) * 100\n",
    "\n",
    "# Domains with highest model diversity\n",
    "domain_model_diversity = {\n",
    "    domain: len(counts) for domain, counts in domain_to_models.items()\n",
    "}\n",
    "diverse_domains = sorted(\n",
    "    domain_model_diversity.items(), key=lambda x: x[1], reverse=True\n",
    ")[:5]\n",
    "\n",
    "# Most frequently co-occurring models\n",
    "model_co_occurrence = defaultdict(int)\n",
    "for abstract in abstracts_with_models:\n",
    "    models = list(abstract[\"model_architectures\"].keys())\n",
    "    if len(models) >= 2:\n",
    "        for i in range(len(models)):\n",
    "            for j in range(i + 1, len(models)):\n",
    "                pair = tuple(sorted([models[i], models[j]]))\n",
    "                model_co_occurrence[pair] += 1\n",
    "\n",
    "top_pairs = sorted(model_co_occurrence.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Print summary insights\n",
    "print(\"\\n📊 Summary Insights:\")\n",
    "print(f\"Total abstracts analyzed: {total_abstracts}\")\n",
    "print(\n",
    "    f\"Abstracts mentioning generative AI models: {total_with_models} ({percentage_with_models:.2f}%)\"\n",
    ")\n",
    "print(f\"Total model mentions detected: {sum(model_category_counts.values())}\")\n",
    "\n",
    "print(\"\\nSmart City Domains with Highest Model Diversity:\")\n",
    "for domain, count in diverse_domains:\n",
    "    print(f\"  - {domain}: {count} different model categories\")\n",
    "\n",
    "print(\"\\nMost Frequently Co-occurring Model Categories:\")\n",
    "for pair, count in top_pairs:\n",
    "    print(f\"  - {pair[0]} + {pair[1]}: {count} abstracts\")\n",
    "\n",
    "print(\"\\nKey Applications by Model Category:\")\n",
    "for category, context in model_application_context.items():\n",
    "    if category in model_category_counts:\n",
    "        print(\n",
    "            f\"  - {category} ({model_category_counts[category]} abstracts): {context}\"\n",
    "        )\n",
    "\n",
    "# Create a summary chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "summary_data = [\n",
    "    total_with_models,  # Abstracts with models\n",
    "    total_abstracts - total_with_models,  # Abstracts without models\n",
    "]\n",
    "labels = [\n",
    "    f\"With GenAI Models\\n({percentage_with_models:.1f}%)\",\n",
    "    f\"Without GenAI Models\\n({100-percentage_with_models:.1f}%)\",\n",
    "]\n",
    "colors = [\"#2ecc71\", \"#e74c3c\"]\n",
    "\n",
    "plt.pie(\n",
    "    summary_data,\n",
    "    labels=labels,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=colors,\n",
    "    startangle=90,\n",
    "    explode=[0.1, 0],\n",
    ")\n",
    "plt.title(\"Proportion of Smart City Research Using Generative AI Models\")\n",
    "plt.savefig(os.path.join(output_dir, \"genai_adoption_summary.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output structure for the final analysis results\n",
    "analysis_results = {\n",
    "    \"metadata\": {\n",
    "        \"total_abstracts\": total_abstracts,\n",
    "        \"abstracts_with_models\": total_with_models,\n",
    "        \"percentage_with_models\": percentage_with_models,\n",
    "        \"model_categories\": genai_model_categories,\n",
    "    },\n",
    "    \"model_counts\": {\n",
    "        category: count for category, count in model_category_counts.most_common()\n",
    "    },\n",
    "    \"match_types\": match_type_counts,\n",
    "    \"top_model_terms\": {\n",
    "        term: count for term, count in model_term_counts.most_common(20)\n",
    "    },\n",
    "    \"domain_model_matrix\": heatmap_df.to_dict(),\n",
    "    \"model_co_occurrence\": {\n",
    "        f\"{pair[0]}__{pair[1]}\": count for pair, count in top_pairs\n",
    "    },\n",
    "    \"examples\": examples,\n",
    "}\n",
    "\n",
    "# Save results to file\n",
    "final_output_path = os.path.join(output_dir, \"08_genai_model_analysis_results.json\")\n",
    "with open(final_output_path, \"w\") as f:\n",
    "    json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Analysis complete! Final results saved to {final_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
