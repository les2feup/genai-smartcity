{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import spacy\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({\"font.size\": 12})\n",
    "plt.rcParams.update({\"font.family\": \"Times New Roman\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "journal",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publication_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "document_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism:url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scopus_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_keywords",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "subject_areas",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "introduction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contribution",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "genai_classification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_genai_application",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "classification_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "classification_labels",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "classification_scores",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "macro_domains",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fba25d74-f01e-441d-bcaa-977d4ecc2020",
       "rows": [
        [
         "0",
         "GeoAvatar: A big mobile phone positioning data-driven method for individualized pseudo personal mobility data generation",
         "Li P.",
         "Computers, Environment and Urban Systems",
         "10.1016/j.compenvurbsys.2025.102252",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/86000553754",
         "86000553754",
         "The importance of personal mobility data is widely recognized in various fields. However, the utilization of real personal mobility data raises privacy concerns. Therefore, it is crucial to generate pseudo personal mobility data that accurately reflects real-world mobility patterns while safeguarding user privacy. Nevertheless, existing methods for generating pseudo mobility data, mostly focusing on trip or trajectory generation, have limitations in capturing sufficient individual heterogeneity. To address these gaps, taking pseudo-person(avatar) as ground-zero, a novel individual-based human mobility generator named GeoAvatar has been proposed – which considering individual heterogeneity in spatial and temporal decision-making, incorporates demographic characteristics. Our method utilizes a deep generative model to generate heterogeneous individual life patterns, a variation inference model for inferring individual demographic characteristics, and a Bayesian-based approach for generating spatial choices considering individual demographic characteristics. Through our method, we have achieved generating realistic pseudo personal human mobility data - we evaluated the proposed method based on physical features – obeying common law of human mobility, activity features – showing diverse and realistic activities, and spatial-temporal characteristics – presenting high-accuracy in terms of temporal grid population and od-count, demonstrating its good performance, with both a big mobile phone GPS trajectory dataset from Tokyo Metropolis and a big mobile phone CDR dataset from Shanghai. Furthermore, this method maintains extensibility for broader applications, making it a promising framework for generating pseudo personal human mobility data.",
         "['Big mobility data', 'Generative model', 'GIS', 'Mahince learning', 'Smart City']",
         "['Geography, Planning and Development', 'Ecological Modeling', 'Environmental Science (all)', 'Urban Studies']",
         "The importance of personal mobility data is widely recognized in various fields. However, the utilization of real personal mobility data raises privacy concerns. Therefore, it is crucial to generate pseudo personal mobility data that accurately reflects real-world mobility patterns while safeguarding user privacy. Nevertheless, existing methods for generating pseudo mobility data, mostly focusing on trip or trajectory generation, have limitations in capturing sufficient individual heterogeneity. To address these gaps, taking pseudo-person(avatar) as ground-zero, a novel individual-based human mobility generator named GeoAvatar has been proposed – which considering individual heterogeneity in spatial and temporal decision-making, incorporates demographic characteristics.",
         "Our method utilizes a deep generative model to generate heterogeneous individual life patterns, a variation inference model for inferring individual demographic characteristics, and a Bayesian-based approach for generating spatial choices considering individual demographic characteristics. Through our method, we have achieved generating realistic pseudo personal human mobility data - we evaluated the proposed method based on physical features – obeying common law of human mobility, activity features – showing diverse and realistic activities, and spatial-temporal characteristics – presenting high-accuracy in terms of temporal grid population and od-count, demonstrating its good performance, with both a big mobile phone GPS trajectory dataset from Tokyo Metropolis and a big mobile phone CDR dataset from Shanghai. Furthermore, this method maintains extensibility for broader applications, making it a promising framework for generating pseudo personal human mobility data.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8703842163000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8703842163000001, 0.1296157688]}",
         "True",
         "0.8703842163000001",
         "['Mobility', 'Human', 'People', 'Transportation Systems', 'Logistics', 'Living', 'Business', 'Economic Management', 'Urban Management', 'Urban Planning', 'Industry', 'Construction', 'Socioeconomics', 'Multimodal Transport', 'Economy', 'Governance', 'Environment', 'Citizens', 'Pedestrian', 'Electric Vehicles', 'Marketing', 'Sustainability', 'Public Policies', 'Emergency Safety', 'Cybersecurity', 'Tourism', 'Finance', 'Public Services', 'Education', 'Traffic Management', 'Climate Change', 'Citizen Engagement', 'Energy Management', 'Social Equity', 'Power Distribution', 'Bicycle', 'Renewable Energy', 'Culture', 'Green Spaces', 'Waste Management', 'Pollution Control', 'Air Quality', 'Water Quality', 'Healthcare', 'Smart Grids', 'Housing', 'Public Transit', 'Buildings']",
         "[0.9896059632, 0.8164116144, 0.8087953925, 0.5389818549000001, 0.3266232014, 0.2026114315, 0.063433826, 0.0464966185, 0.0454934314, 0.0449606404, 0.0437749848, 0.0316078439, 0.027860526, 0.025448452700000002, 0.0227293018, 0.013360064500000001, 0.0113781318, 0.0110572008, 0.009968796700000001, 0.0082729273, 0.0082521094, 0.0075034257, 0.0065006255, 0.0052522384, 0.0048264312, 0.0035790217, 0.0031913589, 0.0030057624, 0.0029114767000000003, 0.0026309304, 0.0020460421, 0.0017382791000000002, 0.0016741673000000002, 0.0015550266000000001, 0.0015474029000000001, 0.0015122298, 0.0014123052, 0.00138044, 0.0013593464000000001, 0.0012931756000000001, 0.0012011437, 0.0011890183000000001, 0.0011479789000000001, 0.0011104414000000001, 0.0009948092, 0.0009099937, 0.0008981890000000001, 0.0006567006000000001]",
         "[{'domain': 'Smart Mobility', 'score': 0.9896059632}, {'domain': 'Smart People', 'score': 0.8164116144}]"
        ],
        [
         "1",
         "Demystifying SAR with attention",
         "Patnaik N.",
         "Expert Systems with Applications",
         "10.1016/j.eswa.2025.127182",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/86000797212",
         "86000797212",
         "Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the ability to capture data under challenging conditions such as cloud cover and darkness. However, its grayscale format and speckle noise hinder interpretability and pose significant challenges for traditional processing methods. This study introduces an innovative framework for SAR image colorization, leveraging an Attention-Based WGAN-GP (Wasserstein GAN with Gradient Penalty). The model incorporates multi-head self-attention mechanisms to enhance feature extraction, capture long-range dependencies, and dynamically suppress noise through a novel variance-based attention adjustment mechanism. Extensive evaluations on Sentinel-1 and Sentinel-2 datasets across diverse terrains, including agriculture, urban areas, barren land, and grasslands, demonstrate the model's superiority over existing approaches. It achieves an LPIPS score of 0.27, SSIM of 0.76, and an average inference time of 0.22 s, showcasing its ability to preserve spatial coherence and perceptual quality even in complex, noisy environments. This capability enables real-time applications in disaster management, flood monitoring, and urban planning, providing actionable insights and advancing the state-of-the-art in SAR image processing.",
         "['Attention', 'Deep learning', 'Generative adversarial networks', 'Image colorization', 'Image restoration', 'Multihead attention', 'Noise', 'SAR', 'Sentinel']",
         "['Engineering (all)', 'Computer Science Applications', 'Artificial Intelligence']",
         "Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the ability to capture data under challenging conditions such as cloud cover and darkness. However, its grayscale format and speckle noise hinder interpretability and pose significant challenges for traditional processing methods.",
         "This study introduces an innovative framework for SAR image colorization, leveraging an Attention-Based WGAN-GP (Wasserstein GAN with Gradient Penalty). The model incorporates multi-head self-attention mechanisms to enhance feature extraction, capture long-range dependencies, and dynamically suppress noise through a novel variance-based attention adjustment mechanism. Extensive evaluations on Sentinel-1 and Sentinel-2 datasets across diverse terrains, including agriculture, urban areas, barren land, and grasslands, demonstrate the model's superiority over existing approaches. It achieves an LPIPS score of 0.27, SSIM of 0.76, and an average inference time of 0.22 s, showcasing its ability to preserve spatial coherence and perceptual quality even in complex, noisy environments. This capability enables real-time applications in disaster management, flood monitoring, and urban planning, providing actionable insights and advancing the state-of-the-art in SAR image processing.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9013352394, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9013352394, 0.0986647382]}",
         "True",
         "0.9013352394",
         "['Environment', 'Public Services', 'Business', 'Climate Change', 'Living', 'Buildings', 'Construction', 'Human', 'Industry', 'Power Distribution', 'Urban Management', 'Citizens', 'Mobility', 'Air Quality', 'Public Transit', 'Logistics', 'Pedestrian', 'Transportation Systems', 'Green Spaces', 'Water Quality', 'Emergency Safety', 'Housing', 'Governance', 'Multimodal Transport', 'People', 'Socioeconomics', 'Education', 'Public Policies', 'Sustainability', 'Energy Management', 'Pollution Control', 'Waste Management', 'Urban Planning', 'Electric Vehicles', 'Renewable Energy', 'Social Equity', 'Economic Management', 'Traffic Management', 'Healthcare', 'Economy', 'Citizen Engagement', 'Finance', 'Smart Grids', 'Tourism', 'Culture', 'Cybersecurity', 'Marketing', 'Bicycle']",
         "[0.6324490309, 0.028749804900000002, 0.0051401048, 0.0038975298, 0.0037373602, 0.0037206223, 0.0026540533, 0.0022417365, 0.002171641, 0.0018733091000000001, 0.0014402645, 0.0013511293, 0.0013073577000000001, 0.0012991292, 0.0012789884000000001, 0.0012463116000000002, 0.0012023989, 0.00093028, 0.0009186530000000001, 0.0009142093, 0.0008908164, 0.0007357239000000001, 0.0007224348, 0.0007199417, 0.0006801286, 0.0006480966, 0.0005820354, 0.0005685718, 0.0005508505, 0.0005481259, 0.0005253599000000001, 0.0005225445000000001, 0.0005176439, 0.0005037361, 0.0004987447, 0.0004631905, 0.0004609285, 0.0004552701, 0.0004477894, 0.00042750540000000004, 0.000422124, 0.0004091494, 0.0003994158, 0.00037496750000000004, 0.00036729920000000004, 0.00035705890000000003, 0.00035560210000000004, 0.0003278833]",
         "[{'domain': 'Smart Environment', 'score': 0.6324490309}]"
        ],
        [
         "2",
         "MiM-UNet: An efficient building image segmentation network integrating state space models",
         "Liu D.",
         "Alexandria Engineering Journal",
         "10.1016/j.aej.2025.02.035",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85218637730",
         "85218637730",
         "With the advancement of remote sensing technology, the analysis of complex terrain images has become crucial for urban planning and geographic information extraction. However, existing models face significant challenges in processing intricate building structures: Transformer-based models suffer from high computational complexity and memory demands, while Convolutional Neural Networks (CNNs) often struggle to capture features across multiple scales and hierarchical levels. To address these limitations, we propose a novel architecture, Mamba-in-Mamba U-Net (MiM-UNet), which integrates the design principles of state–space models (SSMs) to enhance both computational efficiency and feature extraction capacity. Specifically, MiM-UNet refines the traditional encoder–decoder framework by introducing Mamba-in-Mamba blocks, enabling precise multi-scale feature capture and efficient information fusion. Experimental results demonstrate that MiM-UNet outperforms state-of-the-art models in segmentation accuracy on the Massachusetts building dataset, while substantially reducing computational overhead, highlighting its superior performance and promising potential for practical applications.",
         "['Building segmentation', 'Complex terrain', 'Deep learning', 'Remote sensing images', 'State space models']",
         "['Engineering (all)']",
         "With the advancement of remote sensing technology, the analysis of complex terrain images has become crucial for urban planning and geographic information extraction. However, existing models face significant challenges in processing intricate building structures: Transformer-based models suffer from high computational complexity and memory demands, while Convolutional Neural Networks (CNNs) often struggle to capture features across multiple scales and hierarchical levels.",
         "To address these limitations, we propose a novel architecture, Mamba-in-Mamba U-Net (MiM-UNet), which integrates the design principles of state–space models (SSMs) to enhance both computational efficiency and feature extraction capacity. Specifically, MiM-UNet refines the traditional encoder–decoder framework by introducing Mamba-in-Mamba blocks, enabling precise multi-scale feature capture and efficient information fusion. Experimental results demonstrate that MiM-UNet outperforms state-of-the-art models in segmentation accuracy on the Massachusetts building dataset, while substantially reducing computational overhead, highlighting its superior performance and promising potential for practical applications.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8159721494000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8159721494000001, 0.18402785060000001]}",
         "True",
         "0.8159721494000001",
         "['Environment', 'Urban Planning', 'Buildings', 'Urban Management', 'Housing', 'Business', 'Construction', 'Industry', 'Public Services', 'Multimodal Transport', 'Emergency Safety', 'Living', 'Human', 'Power Distribution', 'Citizens', 'Pedestrian', 'Governance', 'People', 'Public Policies', 'Sustainability', 'Logistics', 'Public Transit', 'Mobility', 'Socioeconomics', 'Transportation Systems', 'Green Spaces', 'Education', 'Electric Vehicles', 'Climate Change', 'Economic Management', 'Energy Management', 'Waste Management', 'Renewable Energy', 'Smart Grids', 'Economy', 'Social Equity', 'Tourism', 'Finance', 'Culture', 'Cybersecurity', 'Citizen Engagement', 'Healthcare', 'Water Quality', 'Pollution Control', 'Air Quality', 'Marketing', 'Traffic Management', 'Bicycle']",
         "[0.8005703092, 0.7748115659, 0.5123480558, 0.26313909890000003, 0.017528373700000002, 0.0040664524, 0.0033240574, 0.0031575083, 0.001527156, 0.0011245436, 0.0009155684, 0.0008905319, 0.0006719668, 0.0005973935, 0.0005840933, 0.0005709711, 0.0005692602, 0.0005388025000000001, 0.0005367923, 0.0005300757, 0.0005120519, 0.0004962001000000001, 0.0004911134, 0.0004891514, 0.0004673791, 0.00046331100000000005, 0.000458513, 0.00045184230000000004, 0.000449537, 0.0004448392, 0.00044362100000000005, 0.0004355113, 0.00042954470000000004, 0.00042358, 0.0004198819, 0.00041536000000000003, 0.00040058700000000005, 0.00039853180000000004, 0.0003959437, 0.00038318390000000003, 0.0003785927, 0.0003757891, 0.0003700606, 0.0003685455, 0.000366196, 0.0003485652, 0.00032640990000000003, 0.0003063497]",
         "[{'domain': 'Smart Environment', 'score': 0.8005703092}, {'domain': 'Smart Governance', 'score': 0.7748115659}, {'domain': 'Smart Living', 'score': 0.5123480558}]"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>prism:url</th>\n",
       "      <th>scopus_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author_keywords</th>\n",
       "      <th>subject_areas</th>\n",
       "      <th>introduction</th>\n",
       "      <th>contribution</th>\n",
       "      <th>genai_classification</th>\n",
       "      <th>is_genai_application</th>\n",
       "      <th>classification_score</th>\n",
       "      <th>classification_labels</th>\n",
       "      <th>classification_scores</th>\n",
       "      <th>macro_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GeoAvatar: A big mobile phone positioning data-driven method for individualized pseudo personal ...</td>\n",
       "      <td>Li P.</td>\n",
       "      <td>Computers, Environment and Urban Systems</td>\n",
       "      <td>10.1016/j.compenvurbsys.2025.102252</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/86000553754</td>\n",
       "      <td>86000553754</td>\n",
       "      <td>The importance of personal mobility data is widely recognized in various fields. However, the ut...</td>\n",
       "      <td>[Big mobility data, Generative model, GIS, Mahince learning, Smart City]</td>\n",
       "      <td>[Geography, Planning and Development, Ecological Modeling, Environmental Science (all), Urban St...</td>\n",
       "      <td>The importance of personal mobility data is widely recognized in various fields. However, the ut...</td>\n",
       "      <td>Our method utilizes a deep generative model to generate heterogeneous individual life patterns, ...</td>\n",
       "      <td>{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.870384</td>\n",
       "      <td>[Mobility, Human, People, Transportation Systems, Logistics, Living, Business, Economic Manageme...</td>\n",
       "      <td>[0.9896059632, 0.8164116144, 0.8087953925, 0.5389818549000001, 0.3266232014, 0.2026114315, 0.063...</td>\n",
       "      <td>[{'domain': 'Smart Mobility', 'score': 0.9896059632}, {'domain': 'Smart People', 'score': 0.8164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demystifying SAR with attention</td>\n",
       "      <td>Patnaik N.</td>\n",
       "      <td>Expert Systems with Applications</td>\n",
       "      <td>10.1016/j.eswa.2025.127182</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/86000797212</td>\n",
       "      <td>86000797212</td>\n",
       "      <td>Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the abil...</td>\n",
       "      <td>[Attention, Deep learning, Generative adversarial networks, Image colorization, Image restoratio...</td>\n",
       "      <td>[Engineering (all), Computer Science Applications, Artificial Intelligence]</td>\n",
       "      <td>Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the abil...</td>\n",
       "      <td>This study introduces an innovative framework for SAR image colorization, leveraging an Attentio...</td>\n",
       "      <td>{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.901335</td>\n",
       "      <td>[Environment, Public Services, Business, Climate Change, Living, Buildings, Construction, Human,...</td>\n",
       "      <td>[0.6324490309, 0.028749804900000002, 0.0051401048, 0.0038975298, 0.0037373602, 0.0037206223, 0.0...</td>\n",
       "      <td>[{'domain': 'Smart Environment', 'score': 0.6324490309}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MiM-UNet: An efficient building image segmentation network integrating state space models</td>\n",
       "      <td>Liu D.</td>\n",
       "      <td>Alexandria Engineering Journal</td>\n",
       "      <td>10.1016/j.aej.2025.02.035</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85218637730</td>\n",
       "      <td>85218637730</td>\n",
       "      <td>With the advancement of remote sensing technology, the analysis of complex terrain images has be...</td>\n",
       "      <td>[Building segmentation, Complex terrain, Deep learning, Remote sensing images, State space models]</td>\n",
       "      <td>[Engineering (all)]</td>\n",
       "      <td>With the advancement of remote sensing technology, the analysis of complex terrain images has be...</td>\n",
       "      <td>To address these limitations, we propose a novel architecture, Mamba-in-Mamba U-Net (MiM-UNet), ...</td>\n",
       "      <td>{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0....</td>\n",
       "      <td>True</td>\n",
       "      <td>0.815972</td>\n",
       "      <td>[Environment, Urban Planning, Buildings, Urban Management, Housing, Business, Construction, Indu...</td>\n",
       "      <td>[0.8005703092, 0.7748115659, 0.5123480558, 0.26313909890000003, 0.017528373700000002, 0.00406645...</td>\n",
       "      <td>[{'domain': 'Smart Environment', 'score': 0.8005703092}, {'domain': 'Smart Governance', 'score':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 title  \\\n",
       "0  GeoAvatar: A big mobile phone positioning data-driven method for individualized pseudo personal ...   \n",
       "1                                                                      Demystifying SAR with attention   \n",
       "2            MiM-UNet: An efficient building image segmentation network integrating state space models   \n",
       "\n",
       "      authors                                   journal  \\\n",
       "0       Li P.  Computers, Environment and Urban Systems   \n",
       "1  Patnaik N.          Expert Systems with Applications   \n",
       "2      Liu D.            Alexandria Engineering Journal   \n",
       "\n",
       "                                   doi  publication_date document_type  \\\n",
       "0  10.1016/j.compenvurbsys.2025.102252              2025       Article   \n",
       "1           10.1016/j.eswa.2025.127182              2025       Article   \n",
       "2            10.1016/j.aej.2025.02.035              2025       Article   \n",
       "\n",
       "                                                         prism:url  \\\n",
       "0  https://api.elsevier.com/content/abstract/scopus_id/86000553754   \n",
       "1  https://api.elsevier.com/content/abstract/scopus_id/86000797212   \n",
       "2  https://api.elsevier.com/content/abstract/scopus_id/85218637730   \n",
       "\n",
       "     scopus_id  \\\n",
       "0  86000553754   \n",
       "1  86000797212   \n",
       "2  85218637730   \n",
       "\n",
       "                                                                                              abstract  \\\n",
       "0  The importance of personal mobility data is widely recognized in various fields. However, the ut...   \n",
       "1  Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the abil...   \n",
       "2  With the advancement of remote sensing technology, the analysis of complex terrain images has be...   \n",
       "\n",
       "                                                                                       author_keywords  \\\n",
       "0                             [Big mobility data, Generative model, GIS, Mahince learning, Smart City]   \n",
       "1  [Attention, Deep learning, Generative adversarial networks, Image colorization, Image restoratio...   \n",
       "2   [Building segmentation, Complex terrain, Deep learning, Remote sensing images, State space models]   \n",
       "\n",
       "                                                                                         subject_areas  \\\n",
       "0  [Geography, Planning and Development, Ecological Modeling, Environmental Science (all), Urban St...   \n",
       "1                          [Engineering (all), Computer Science Applications, Artificial Intelligence]   \n",
       "2                                                                                  [Engineering (all)]   \n",
       "\n",
       "                                                                                          introduction  \\\n",
       "0  The importance of personal mobility data is widely recognized in various fields. However, the ut...   \n",
       "1  Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the abil...   \n",
       "2  With the advancement of remote sensing technology, the analysis of complex terrain images has be...   \n",
       "\n",
       "                                                                                          contribution  \\\n",
       "0  Our method utilizes a deep generative model to generate heterogeneous individual life patterns, ...   \n",
       "1  This study introduces an innovative framework for SAR image colorization, leveraging an Attentio...   \n",
       "2  To address these limitations, we propose a novel architecture, Mamba-in-Mamba U-Net (MiM-UNet), ...   \n",
       "\n",
       "                                                                                  genai_classification  \\\n",
       "0  {'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0....   \n",
       "1  {'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0....   \n",
       "2  {'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0....   \n",
       "\n",
       "   is_genai_application  classification_score  \\\n",
       "0                  True              0.870384   \n",
       "1                  True              0.901335   \n",
       "2                  True              0.815972   \n",
       "\n",
       "                                                                                 classification_labels  \\\n",
       "0  [Mobility, Human, People, Transportation Systems, Logistics, Living, Business, Economic Manageme...   \n",
       "1  [Environment, Public Services, Business, Climate Change, Living, Buildings, Construction, Human,...   \n",
       "2  [Environment, Urban Planning, Buildings, Urban Management, Housing, Business, Construction, Indu...   \n",
       "\n",
       "                                                                                 classification_scores  \\\n",
       "0  [0.9896059632, 0.8164116144, 0.8087953925, 0.5389818549000001, 0.3266232014, 0.2026114315, 0.063...   \n",
       "1  [0.6324490309, 0.028749804900000002, 0.0051401048, 0.0038975298, 0.0037373602, 0.0037206223, 0.0...   \n",
       "2  [0.8005703092, 0.7748115659, 0.5123480558, 0.26313909890000003, 0.017528373700000002, 0.00406645...   \n",
       "\n",
       "                                                                                         macro_domains  \n",
       "0  [{'domain': 'Smart Mobility', 'score': 0.9896059632}, {'domain': 'Smart People', 'score': 0.8164...  \n",
       "1                                             [{'domain': 'Smart Environment', 'score': 0.6324490309}]  \n",
       "2  [{'domain': 'Smart Environment', 'score': 0.8005703092}, {'domain': 'Smart Governance', 'score':...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../data/06_classified_macro_smart_city_domains.json\")\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define GenAI Technologies and Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 107 keywords to identify Generative AI applications\n"
     ]
    }
   ],
   "source": [
    "# Define Generative AI technologies and related keywords\n",
    "# Load from a JSON file\n",
    "with open(\"../data/config/genai_technology_domains.json\", \"r\", encoding=\"utf8\") as f:\n",
    "    genai_technologies = json.load(f)\n",
    "\n",
    "# Flatten keywords list for initial screening\n",
    "all_genai_keywords = []\n",
    "for tech, keywords in genai_technologies.items():\n",
    "    all_genai_keywords.extend(keywords)\n",
    "all_genai_keywords = set(all_genai_keywords)\n",
    "\n",
    "print(\n",
    "    f\"Using {len(all_genai_keywords)} keywords to identify Generative AI applications\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Semantic Matching Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading sentence embedding model...\n",
      "Loaded spaCy model\n",
      "Computing embeddings for GenAI keywords...\n"
     ]
    }
   ],
   "source": [
    "# Set device for computation\n",
    "DEVICE = (\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load sentence transformer model\n",
    "print(\"Loading sentence embedding model...\")\n",
    "sbert_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\", device=DEVICE)\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Loaded spaCy model\")\n",
    "except:\n",
    "    print(\"Installing spaCy model...\")\n",
    "    import os\n",
    "\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Loaded spaCy model\")\n",
    "\n",
    "# Pre-compute embeddings for all keywords\n",
    "print(\"Computing embeddings for GenAI keywords...\")\n",
    "keyword_list = list(all_genai_keywords)\n",
    "keyword_embeddings = sbert_model.encode(keyword_list, convert_to_tensor=True)\n",
    "\n",
    "# Create mappings from technologies to keyword indices\n",
    "tech_keyword_indices = {}\n",
    "for tech, tech_keywords in genai_technologies.items():\n",
    "    tech_keyword_indices[tech] = [\n",
    "        keyword_list.index(kw) for kw in tech_keywords if kw in keyword_list\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Keywords Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_genai_semantic(text, similarity_threshold=0.4):\n",
    "    \"\"\"\n",
    "    Enhanced detection using semantic similarity to find GenAI applications\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to analyze\n",
    "        similarity_threshold (float): Minimum similarity score to consider a match\n",
    "        \n",
    "    Returns:\n",
    "        dict: Detection results with is_genai flag, confidence score, and matched keywords\n",
    "    \"\"\"\n",
    "    # Handle None or empty text\n",
    "    if text is None or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\n",
    "            \"is_genai\": False,\n",
    "            \"confidence\": 0.0,\n",
    "            \"matched_keywords\": [],\n",
    "            \"technology_categories\": [],\n",
    "            \"bridge_terms\": [],\n",
    "            \"semantic_matches\": []\n",
    "        }\n",
    "        \n",
    "    # 3. SEMANTIC MATCHING: Improved approach\n",
    "    semantic_matches = []\n",
    "    try:\n",
    "        # Split text into shorter segments for better matching\n",
    "        sentences = re.split(r'[.!?]', text)\n",
    "        sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n",
    "        \n",
    "        # If text is very long, use sentences instead of full text\n",
    "        text_segments = sentences if len(sentences) > 3 else [text]\n",
    "        \n",
    "        # Process each segment\n",
    "        for segment in text_segments:\n",
    "            # Encode the segment\n",
    "            segment_embedding = sbert_model.encode(segment, convert_to_tensor=True)\n",
    "            \n",
    "            # Calculate similarity with all keywords\n",
    "            similarities = util.pytorch_cos_sim(segment_embedding, keyword_embeddings)[0]\n",
    "            \n",
    "            # Find the most similar keywords\n",
    "            best_matches = torch.topk(similarities, k=min(5, len(similarities)))\n",
    "            \n",
    "            for score_idx, keyword_idx in enumerate(best_matches.indices):\n",
    "                score = best_matches.values[score_idx].item()\n",
    "                if score >= similarity_threshold:\n",
    "                    keyword = keyword_list[keyword_idx]\n",
    "                    semantic_matches.append((keyword, score))\n",
    "                    \n",
    "        # Remove duplicates, keeping highest score\n",
    "        unique_matches = {}\n",
    "        for keyword, score in semantic_matches:\n",
    "            if keyword not in unique_matches or score > unique_matches[keyword]:\n",
    "                unique_matches[keyword] = score\n",
    "        \n",
    "        semantic_matches = [(k, v) for k, v in unique_matches.items()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in semantic matching: {e}\")\n",
    "        semantic_matches = []\n",
    "    \n",
    "    # Sort matches by score in descending order\n",
    "    semantic_matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Determine if this is a GenAI application based on semantic matches\n",
    "    is_genai = len(semantic_matches) > 0\n",
    "    \n",
    "    # Calculate confidence score (highest match score or 0)\n",
    "    confidence = semantic_matches[0][1] if semantic_matches else 0.0\n",
    "    \n",
    "    # Extract matched keywords without scores for easier processing\n",
    "    matched_keywords = [keyword for keyword, _ in semantic_matches]\n",
    "    \n",
    "    # Determine technology categories based on matched keywords\n",
    "    technology_categories = []\n",
    "    for tech, tech_keywords in genai_technologies.items():\n",
    "        # If any matched keyword is in this technology's keywords, add the technology\n",
    "        if any(keyword in tech_keywords for keyword, _ in semantic_matches):\n",
    "            technology_categories.append(tech)\n",
    "    \n",
    "    # Extract key terms from the text for bridge analysis\n",
    "    # This extracts terms that might connect GenAI to smart city concepts\n",
    "    bridge_terms = []\n",
    "    if text and len(text) > 10:\n",
    "        try:\n",
    "            # Process with spaCy to get important terms\n",
    "            doc = nlp(text[:5000])  # Limit text size to avoid processing too much\n",
    "            \n",
    "            # Extract nouns, verbs, and important modifiers\n",
    "            term_counter = Counter()\n",
    "            for token in doc:\n",
    "                if token.is_alpha and not token.is_stop and len(token.text) > 2:\n",
    "                    if token.pos_ in (\"NOUN\", \"VERB\", \"ADJ\", \"PROPN\"):\n",
    "                        term_counter[token.lemma_.lower()] += 1\n",
    "            \n",
    "            # Get the most common terms\n",
    "            bridge_terms = [(term, count) for term, count in term_counter.most_common(5)]\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting bridge terms: {e}\")\n",
    "    \n",
    "    # Return results in expected format\n",
    "    return {\n",
    "        \"is_genai\": is_genai,\n",
    "        \"confidence\": confidence,\n",
    "        \"matched_keywords\": matched_keywords,\n",
    "        \"technology_categories\": technology_categories,\n",
    "        \"bridge_terms\": bridge_terms,\n",
    "        \"semantic_matches\": semantic_matches\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Keywords Detection Functions to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed47323724284a93b10a2f0a7d2c42c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying semantic detection:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply semantic detection\n",
    "tqdm.pandas(desc=\"Applying semantic detection\")\n",
    "# Add author keywords if available, otherwise just use contribution\n",
    "df[\"semantic_detection\"] = df.progress_apply(\n",
    "    lambda row: detect_genai_semantic(\n",
    "        row[\"contribution\"] + (\n",
    "            \" \" + \" \".join(row[\"author_keywords\"]) if isinstance(row[\"author_keywords\"], list) else \"\"\n",
    "        )\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Extract semantic results\n",
    "df[\"semantic_is_genai\"] = df[\"semantic_detection\"].apply(lambda x: x[\"is_genai\"])\n",
    "df[\"semantic_confidence\"] = df[\"semantic_detection\"].apply(lambda x: x[\"confidence\"])\n",
    "df[\"semantic_keywords\"] = df[\"semantic_detection\"].apply(lambda x: x[\"matched_keywords\"])\n",
    "df[\"semantic_categories\"] = df[\"semantic_detection\"].apply(lambda x: x[\"technology_categories\"])\n",
    "df[\"bridge_terms\"] = df[\"semantic_detection\"].apply(lambda x: x[\"bridge_terms\"])\n",
    "df[\"semantic_matches\"] = df[\"semantic_detection\"].apply(lambda x: x[\"semantic_matches\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts with semantic GenAI detection: 232 (97.48%)\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\n",
    "    f\"Abstracts with semantic GenAI detection: {df['semantic_is_genai'].sum()} ({df['semantic_is_genai'].mean()*100:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "journal",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "doi",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publication_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "document_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism:url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scopus_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_keywords",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "subject_areas",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "introduction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contribution",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "genai_classification",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "is_genai_application",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "classification_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "classification_labels",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "classification_scores",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "macro_domains",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "semantic_detection",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "semantic_is_genai",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "semantic_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "semantic_keywords",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "semantic_categories",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "bridge_terms",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "semantic_matches",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4ee9715d-c32d-447e-8106-04c5fb229281",
       "rows": [
        [
         "0",
         "GeoAvatar: A big mobile phone positioning data-driven method for individualized pseudo personal mobility data generation",
         "Li P.",
         "Computers, Environment and Urban Systems",
         "10.1016/j.compenvurbsys.2025.102252",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/86000553754",
         "86000553754",
         "The importance of personal mobility data is widely recognized in various fields. However, the utilization of real personal mobility data raises privacy concerns. Therefore, it is crucial to generate pseudo personal mobility data that accurately reflects real-world mobility patterns while safeguarding user privacy. Nevertheless, existing methods for generating pseudo mobility data, mostly focusing on trip or trajectory generation, have limitations in capturing sufficient individual heterogeneity. To address these gaps, taking pseudo-person(avatar) as ground-zero, a novel individual-based human mobility generator named GeoAvatar has been proposed – which considering individual heterogeneity in spatial and temporal decision-making, incorporates demographic characteristics. Our method utilizes a deep generative model to generate heterogeneous individual life patterns, a variation inference model for inferring individual demographic characteristics, and a Bayesian-based approach for generating spatial choices considering individual demographic characteristics. Through our method, we have achieved generating realistic pseudo personal human mobility data - we evaluated the proposed method based on physical features – obeying common law of human mobility, activity features – showing diverse and realistic activities, and spatial-temporal characteristics – presenting high-accuracy in terms of temporal grid population and od-count, demonstrating its good performance, with both a big mobile phone GPS trajectory dataset from Tokyo Metropolis and a big mobile phone CDR dataset from Shanghai. Furthermore, this method maintains extensibility for broader applications, making it a promising framework for generating pseudo personal human mobility data.",
         "['Big mobility data', 'Generative model', 'GIS', 'Mahince learning', 'Smart City']",
         "['Geography, Planning and Development', 'Ecological Modeling', 'Environmental Science (all)', 'Urban Studies']",
         "The importance of personal mobility data is widely recognized in various fields. However, the utilization of real personal mobility data raises privacy concerns. Therefore, it is crucial to generate pseudo personal mobility data that accurately reflects real-world mobility patterns while safeguarding user privacy. Nevertheless, existing methods for generating pseudo mobility data, mostly focusing on trip or trajectory generation, have limitations in capturing sufficient individual heterogeneity. To address these gaps, taking pseudo-person(avatar) as ground-zero, a novel individual-based human mobility generator named GeoAvatar has been proposed – which considering individual heterogeneity in spatial and temporal decision-making, incorporates demographic characteristics.",
         "Our method utilizes a deep generative model to generate heterogeneous individual life patterns, a variation inference model for inferring individual demographic characteristics, and a Bayesian-based approach for generating spatial choices considering individual demographic characteristics. Through our method, we have achieved generating realistic pseudo personal human mobility data - we evaluated the proposed method based on physical features – obeying common law of human mobility, activity features – showing diverse and realistic activities, and spatial-temporal characteristics – presenting high-accuracy in terms of temporal grid population and od-count, demonstrating its good performance, with both a big mobile phone GPS trajectory dataset from Tokyo Metropolis and a big mobile phone CDR dataset from Shanghai. Furthermore, this method maintains extensibility for broader applications, making it a promising framework for generating pseudo personal human mobility data.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8703842163000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8703842163000001, 0.1296157688]}",
         "True",
         "0.8703842163000001",
         "['Mobility', 'Human', 'People', 'Transportation Systems', 'Logistics', 'Living', 'Business', 'Economic Management', 'Urban Management', 'Urban Planning', 'Industry', 'Construction', 'Socioeconomics', 'Multimodal Transport', 'Economy', 'Governance', 'Environment', 'Citizens', 'Pedestrian', 'Electric Vehicles', 'Marketing', 'Sustainability', 'Public Policies', 'Emergency Safety', 'Cybersecurity', 'Tourism', 'Finance', 'Public Services', 'Education', 'Traffic Management', 'Climate Change', 'Citizen Engagement', 'Energy Management', 'Social Equity', 'Power Distribution', 'Bicycle', 'Renewable Energy', 'Culture', 'Green Spaces', 'Waste Management', 'Pollution Control', 'Air Quality', 'Water Quality', 'Healthcare', 'Smart Grids', 'Housing', 'Public Transit', 'Buildings']",
         "[0.9896059632, 0.8164116144, 0.8087953925, 0.5389818549000001, 0.3266232014, 0.2026114315, 0.063433826, 0.0464966185, 0.0454934314, 0.0449606404, 0.0437749848, 0.0316078439, 0.027860526, 0.025448452700000002, 0.0227293018, 0.013360064500000001, 0.0113781318, 0.0110572008, 0.009968796700000001, 0.0082729273, 0.0082521094, 0.0075034257, 0.0065006255, 0.0052522384, 0.0048264312, 0.0035790217, 0.0031913589, 0.0030057624, 0.0029114767000000003, 0.0026309304, 0.0020460421, 0.0017382791000000002, 0.0016741673000000002, 0.0015550266000000001, 0.0015474029000000001, 0.0015122298, 0.0014123052, 0.00138044, 0.0013593464000000001, 0.0012931756000000001, 0.0012011437, 0.0011890183000000001, 0.0011479789000000001, 0.0011104414000000001, 0.0009948092, 0.0009099937, 0.0008981890000000001, 0.0006567006000000001]",
         "[{'domain': 'Smart Mobility', 'score': 0.9896059632}, {'domain': 'Smart People', 'score': 0.8164116144}]",
         "{'is_genai': True, 'confidence': 0.48666954040527344, 'matched_keywords': ['generative model', '3d generative model'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('method', 4), ('generate', 4), ('mobility', 4), ('model', 3), ('individual', 3)], 'semantic_matches': [('generative model', 0.48666954040527344), ('3d generative model', 0.41732609272003174)]}",
         "True",
         "0.48666954040527344",
         "['generative model', '3d generative model']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models']",
         "[('method', 4), ('generate', 4), ('mobility', 4), ('model', 3), ('individual', 3)]",
         "[('generative model', 0.48666954040527344), ('3d generative model', 0.41732609272003174)]"
        ],
        [
         "1",
         "Demystifying SAR with attention",
         "Patnaik N.",
         "Expert Systems with Applications",
         "10.1016/j.eswa.2025.127182",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/86000797212",
         "86000797212",
         "Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the ability to capture data under challenging conditions such as cloud cover and darkness. However, its grayscale format and speckle noise hinder interpretability and pose significant challenges for traditional processing methods. This study introduces an innovative framework for SAR image colorization, leveraging an Attention-Based WGAN-GP (Wasserstein GAN with Gradient Penalty). The model incorporates multi-head self-attention mechanisms to enhance feature extraction, capture long-range dependencies, and dynamically suppress noise through a novel variance-based attention adjustment mechanism. Extensive evaluations on Sentinel-1 and Sentinel-2 datasets across diverse terrains, including agriculture, urban areas, barren land, and grasslands, demonstrate the model's superiority over existing approaches. It achieves an LPIPS score of 0.27, SSIM of 0.76, and an average inference time of 0.22 s, showcasing its ability to preserve spatial coherence and perceptual quality even in complex, noisy environments. This capability enables real-time applications in disaster management, flood monitoring, and urban planning, providing actionable insights and advancing the state-of-the-art in SAR image processing.",
         "['Attention', 'Deep learning', 'Generative adversarial networks', 'Image colorization', 'Image restoration', 'Multihead attention', 'Noise', 'SAR', 'Sentinel']",
         "['Engineering (all)', 'Computer Science Applications', 'Artificial Intelligence']",
         "Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the ability to capture data under challenging conditions such as cloud cover and darkness. However, its grayscale format and speckle noise hinder interpretability and pose significant challenges for traditional processing methods.",
         "This study introduces an innovative framework for SAR image colorization, leveraging an Attention-Based WGAN-GP (Wasserstein GAN with Gradient Penalty). The model incorporates multi-head self-attention mechanisms to enhance feature extraction, capture long-range dependencies, and dynamically suppress noise through a novel variance-based attention adjustment mechanism. Extensive evaluations on Sentinel-1 and Sentinel-2 datasets across diverse terrains, including agriculture, urban areas, barren land, and grasslands, demonstrate the model's superiority over existing approaches. It achieves an LPIPS score of 0.27, SSIM of 0.76, and an average inference time of 0.22 s, showcasing its ability to preserve spatial coherence and perceptual quality even in complex, noisy environments. This capability enables real-time applications in disaster management, flood monitoring, and urban planning, providing actionable insights and advancing the state-of-the-art in SAR image processing.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9013352394, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9013352394, 0.0986647382]}",
         "True",
         "0.9013352394",
         "['Environment', 'Public Services', 'Business', 'Climate Change', 'Living', 'Buildings', 'Construction', 'Human', 'Industry', 'Power Distribution', 'Urban Management', 'Citizens', 'Mobility', 'Air Quality', 'Public Transit', 'Logistics', 'Pedestrian', 'Transportation Systems', 'Green Spaces', 'Water Quality', 'Emergency Safety', 'Housing', 'Governance', 'Multimodal Transport', 'People', 'Socioeconomics', 'Education', 'Public Policies', 'Sustainability', 'Energy Management', 'Pollution Control', 'Waste Management', 'Urban Planning', 'Electric Vehicles', 'Renewable Energy', 'Social Equity', 'Economic Management', 'Traffic Management', 'Healthcare', 'Economy', 'Citizen Engagement', 'Finance', 'Smart Grids', 'Tourism', 'Culture', 'Cybersecurity', 'Marketing', 'Bicycle']",
         "[0.6324490309, 0.028749804900000002, 0.0051401048, 0.0038975298, 0.0037373602, 0.0037206223, 0.0026540533, 0.0022417365, 0.002171641, 0.0018733091000000001, 0.0014402645, 0.0013511293, 0.0013073577000000001, 0.0012991292, 0.0012789884000000001, 0.0012463116000000002, 0.0012023989, 0.00093028, 0.0009186530000000001, 0.0009142093, 0.0008908164, 0.0007357239000000001, 0.0007224348, 0.0007199417, 0.0006801286, 0.0006480966, 0.0005820354, 0.0005685718, 0.0005508505, 0.0005481259, 0.0005253599000000001, 0.0005225445000000001, 0.0005176439, 0.0005037361, 0.0004987447, 0.0004631905, 0.0004609285, 0.0004552701, 0.0004477894, 0.00042750540000000004, 0.000422124, 0.0004091494, 0.0003994158, 0.00037496750000000004, 0.00036729920000000004, 0.00035705890000000003, 0.00035560210000000004, 0.0003278833]",
         "[{'domain': 'Smart Environment', 'score': 0.6324490309}]",
         "{'is_genai': True, 'confidence': 0.6297489404678345, 'matched_keywords': ['attention mechanism', 'wgan-gp', 'self-attention', 'cross-attention', 'sr-gan', 'generative adversarial network', 'score-based model', 'imagen', '5gt-gan', '3d gan', 'contrastive learning', 'noise prediction', 'adv-gan'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('attention', 5), ('image', 4), ('sar', 3), ('colorization', 2), ('base', 2)], 'semantic_matches': [('attention mechanism', 0.6297489404678345), ('wgan-gp', 0.524022102355957), ('self-attention', 0.48064807057380676), ('cross-attention', 0.4765915274620056), ('sr-gan', 0.46357226371765137), ('generative adversarial network', 0.4598832130432129), ('score-based model', 0.44982585310935974), ('imagen', 0.4453151226043701), ('5gt-gan', 0.43930697441101074), ('3d gan', 0.43273431062698364), ('contrastive learning', 0.431244820356369), ('noise prediction', 0.42798101902008057), ('adv-gan', 0.4200151562690735)]}",
         "True",
         "0.6297489404678345",
         "['attention mechanism', 'wgan-gp', 'self-attention', 'cross-attention', 'sr-gan', 'generative adversarial network', 'score-based model', 'imagen', '5gt-gan', '3d gan', 'contrastive learning', 'noise prediction', 'adv-gan']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('attention', 5), ('image', 4), ('sar', 3), ('colorization', 2), ('base', 2)]",
         "[('attention mechanism', 0.6297489404678345), ('wgan-gp', 0.524022102355957), ('self-attention', 0.48064807057380676), ('cross-attention', 0.4765915274620056), ('sr-gan', 0.46357226371765137), ('generative adversarial network', 0.4598832130432129), ('score-based model', 0.44982585310935974), ('imagen', 0.4453151226043701), ('5gt-gan', 0.43930697441101074), ('3d gan', 0.43273431062698364), ('contrastive learning', 0.431244820356369), ('noise prediction', 0.42798101902008057), ('adv-gan', 0.4200151562690735)]"
        ],
        [
         "2",
         "MiM-UNet: An efficient building image segmentation network integrating state space models",
         "Liu D.",
         "Alexandria Engineering Journal",
         "10.1016/j.aej.2025.02.035",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85218637730",
         "85218637730",
         "With the advancement of remote sensing technology, the analysis of complex terrain images has become crucial for urban planning and geographic information extraction. However, existing models face significant challenges in processing intricate building structures: Transformer-based models suffer from high computational complexity and memory demands, while Convolutional Neural Networks (CNNs) often struggle to capture features across multiple scales and hierarchical levels. To address these limitations, we propose a novel architecture, Mamba-in-Mamba U-Net (MiM-UNet), which integrates the design principles of state–space models (SSMs) to enhance both computational efficiency and feature extraction capacity. Specifically, MiM-UNet refines the traditional encoder–decoder framework by introducing Mamba-in-Mamba blocks, enabling precise multi-scale feature capture and efficient information fusion. Experimental results demonstrate that MiM-UNet outperforms state-of-the-art models in segmentation accuracy on the Massachusetts building dataset, while substantially reducing computational overhead, highlighting its superior performance and promising potential for practical applications.",
         "['Building segmentation', 'Complex terrain', 'Deep learning', 'Remote sensing images', 'State space models']",
         "['Engineering (all)']",
         "With the advancement of remote sensing technology, the analysis of complex terrain images has become crucial for urban planning and geographic information extraction. However, existing models face significant challenges in processing intricate building structures: Transformer-based models suffer from high computational complexity and memory demands, while Convolutional Neural Networks (CNNs) often struggle to capture features across multiple scales and hierarchical levels.",
         "To address these limitations, we propose a novel architecture, Mamba-in-Mamba U-Net (MiM-UNet), which integrates the design principles of state–space models (SSMs) to enhance both computational efficiency and feature extraction capacity. Specifically, MiM-UNet refines the traditional encoder–decoder framework by introducing Mamba-in-Mamba blocks, enabling precise multi-scale feature capture and efficient information fusion. Experimental results demonstrate that MiM-UNet outperforms state-of-the-art models in segmentation accuracy on the Massachusetts building dataset, while substantially reducing computational overhead, highlighting its superior performance and promising potential for practical applications.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8159721494000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8159721494000001, 0.18402785060000001]}",
         "True",
         "0.8159721494000001",
         "['Environment', 'Urban Planning', 'Buildings', 'Urban Management', 'Housing', 'Business', 'Construction', 'Industry', 'Public Services', 'Multimodal Transport', 'Emergency Safety', 'Living', 'Human', 'Power Distribution', 'Citizens', 'Pedestrian', 'Governance', 'People', 'Public Policies', 'Sustainability', 'Logistics', 'Public Transit', 'Mobility', 'Socioeconomics', 'Transportation Systems', 'Green Spaces', 'Education', 'Electric Vehicles', 'Climate Change', 'Economic Management', 'Energy Management', 'Waste Management', 'Renewable Energy', 'Smart Grids', 'Economy', 'Social Equity', 'Tourism', 'Finance', 'Culture', 'Cybersecurity', 'Citizen Engagement', 'Healthcare', 'Water Quality', 'Pollution Control', 'Air Quality', 'Marketing', 'Traffic Management', 'Bicycle']",
         "[0.8005703092, 0.7748115659, 0.5123480558, 0.26313909890000003, 0.017528373700000002, 0.0040664524, 0.0033240574, 0.0031575083, 0.001527156, 0.0011245436, 0.0009155684, 0.0008905319, 0.0006719668, 0.0005973935, 0.0005840933, 0.0005709711, 0.0005692602, 0.0005388025000000001, 0.0005367923, 0.0005300757, 0.0005120519, 0.0004962001000000001, 0.0004911134, 0.0004891514, 0.0004673791, 0.00046331100000000005, 0.000458513, 0.00045184230000000004, 0.000449537, 0.0004448392, 0.00044362100000000005, 0.0004355113, 0.00042954470000000004, 0.00042358, 0.0004198819, 0.00041536000000000003, 0.00040058700000000005, 0.00039853180000000004, 0.0003959437, 0.00038318390000000003, 0.0003785927, 0.0003757891, 0.0003700606, 0.0003685455, 0.000366196, 0.0003485652, 0.00032640990000000003, 0.0003063497]",
         "[{'domain': 'Smart Environment', 'score': 0.8005703092}, {'domain': 'Smart Governance', 'score': 0.7748115659}, {'domain': 'Smart Living', 'score': 0.5123480558}]",
         "{'is_genai': True, 'confidence': 0.632642388343811, 'matched_keywords': ['encoder-decoder', 'latent space modeling', 'autoencoder', 'shape generation', 'neural rendering', 'vision-language model'], 'technology_categories': ['Transformer-Based Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('mamba', 4), ('mim', 3), ('unet', 3), ('state', 3), ('model', 3)], 'semantic_matches': [('encoder-decoder', 0.632642388343811), ('latent space modeling', 0.44094717502593994), ('autoencoder', 0.4145693778991699), ('shape generation', 0.4131760001182556), ('neural rendering', 0.41149023175239563), ('vision-language model', 0.4053937792778015)]}",
         "True",
         "0.632642388343811",
         "['encoder-decoder', 'latent space modeling', 'autoencoder', 'shape generation', 'neural rendering', 'vision-language model']",
         "['Transformer-Based Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('mamba', 4), ('mim', 3), ('unet', 3), ('state', 3), ('model', 3)]",
         "[('encoder-decoder', 0.632642388343811), ('latent space modeling', 0.44094717502593994), ('autoencoder', 0.4145693778991699), ('shape generation', 0.4131760001182556), ('neural rendering', 0.41149023175239563), ('vision-language model', 0.4053937792778015)]"
        ],
        [
         "3",
         "Building Change Detection in Aerial Imagery Using End-to-End Deep Learning Semantic Segmentation Techniques",
         "Teo T.A.",
         "Buildings",
         "10.3390/buildings15050695",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/86000578375",
         "86000578375",
         "Automatic building change detection is essential for updating geospatial data, urban planning, and land use management. The objective of this study is to propose a transformer-based UNet-like framework for end-to-end building change detection, integrating multi-temporal and multi-source data to improve efficiency and accuracy. Unlike conventional methods that focus on either spectral imagery or digital surface models (DSMs), the proposed method combines RGB color imagery, DSMs, and building vector maps in a three-branch Siamese architecture to enhance spatial, spectral, and elevation-based feature extraction. We chose Hsinchu, Taiwan as the experimental site and used 1:1000 digital topographic maps and airborne imagery from 2017, 2020, and 2023. The experimental results demonstrated that the data fusion model significantly outperforms other data combinations, achieving higher accuracy and robustness in detecting building changes. The RGB images provide spectral and texture details, DSMs offer structural and elevation context, and the building vector map enhances semantic consistency. This research advances building change detection by introducing a fully transformer-based model for end-to-end change detection, incorporating diverse geospatial data sources, and improving accuracy over traditional CNN-based methods. The proposed framework offers a scalable and automated solution for modern mapping workflows, contributing to more efficient geospatial data updating and urban monitoring.",
         "['buildings', 'change detection', 'deep learning', 'map updating']",
         "['Architecture', 'Civil and Structural Engineering', 'Building and Construction']",
         "Automatic building change detection is essential for updating geospatial data, urban planning, and land use management.",
         "The objective of this study is to propose a transformer-based UNet-like framework for end-to-end building change detection, integrating multi-temporal and multi-source data to improve efficiency and accuracy. Unlike conventional methods that focus on either spectral imagery or digital surface models (DSMs), the proposed method combines RGB color imagery, DSMs, and building vector maps in a three-branch Siamese architecture to enhance spatial, spectral, and elevation-based feature extraction. We chose Hsinchu, Taiwan as the experimental site and used 1:1000 digital topographic maps and airborne imagery from 2017, 2020, and 2023. The experimental results demonstrated that the data fusion model significantly outperforms other data combinations, achieving higher accuracy and robustness in detecting building changes. The RGB images provide spectral and texture details, DSMs offer structural and elevation context, and the building vector map enhances semantic consistency. This research advances building change detection by introducing a fully transformer-based model for end-to-end change detection, incorporating diverse geospatial data sources, and improving accuracy over traditional CNN-based methods. The proposed framework offers a scalable and automated solution for modern mapping workflows, contributing to more efficient geospatial data updating and urban monitoring.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9531222582000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9531222582000001, 0.0468777344]}",
         "True",
         "0.9531222582000001",
         "['Buildings', 'Urban Planning', 'Construction', 'Urban Management', 'Public Services', 'Environment', 'Housing', 'Business', 'Smart Grids', 'Governance', 'Industry', 'Living', 'Public Policies', 'Logistics', 'Sustainability', 'Climate Change', 'Power Distribution', 'Multimodal Transport', 'Electric Vehicles', 'Human', 'Mobility', 'Economy', 'Socioeconomics', 'Citizens', 'Renewable Energy', 'People', 'Economic Management', 'Public Transit', 'Transportation Systems', 'Air Quality', 'Pedestrian', 'Green Spaces', 'Energy Management', 'Social Equity', 'Education', 'Citizen Engagement', 'Waste Management', 'Cybersecurity', 'Healthcare', 'Emergency Safety', 'Tourism', 'Finance', 'Water Quality', 'Pollution Control', 'Culture', 'Traffic Management', 'Bicycle', 'Marketing']",
         "[0.9861167073, 0.898650229, 0.6620252132000001, 0.6395537853000001, 0.2649227679, 0.2593763471, 0.0478937477, 0.0314517431, 0.0190900117, 0.0054282593, 0.0037818018000000003, 0.0018244246, 0.0012220399, 0.0010225209, 0.0007863381000000001, 0.0007590723000000001, 0.0007233847, 0.0005704198, 0.0005593382, 0.0005478754, 0.0005328408, 0.0005215118000000001, 0.0005123514, 0.0005042219, 0.00047275750000000004, 0.00045183260000000004, 0.00043788210000000004, 0.0004260196, 0.000423887, 0.00039387490000000004, 0.0003933559, 0.0003862063, 0.0003855276, 0.00037807600000000003, 0.0003735395, 0.0003711968, 0.0003608706, 0.000358553, 0.0003569782, 0.0003518533, 0.0003499464, 0.0003454337, 0.0003441642, 0.0003333319, 0.0003259288, 0.00031217640000000003, 0.00030940810000000004, 0.0002898849]",
         "[{'domain': 'Smart Living', 'score': 0.9861167073}, {'domain': 'Smart Governance', 'score': 0.898650229}]",
         "{'is_genai': True, 'confidence': 0.5988814830780029, 'matched_keywords': ['transformer', 'generative pretrained transformer', 'multimodal transformer', 'imagen', 'multimodal fusion', 'neural rendering', 'neural radiance field'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('change', 5), ('base', 4), ('end', 4), ('building', 4), ('detection', 4)], 'semantic_matches': [('transformer', 0.5988814830780029), ('generative pretrained transformer', 0.5384024381637573), ('multimodal transformer', 0.533332347869873), ('imagen', 0.4278738498687744), ('multimodal fusion', 0.42510393261909485), ('neural rendering', 0.4206916391849518), ('neural radiance field', 0.40488162636756897)]}",
         "True",
         "0.5988814830780029",
         "['transformer', 'generative pretrained transformer', 'multimodal transformer', 'imagen', 'multimodal fusion', 'neural rendering', 'neural radiance field']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('change', 5), ('base', 4), ('end', 4), ('building', 4), ('detection', 4)]",
         "[('transformer', 0.5988814830780029), ('generative pretrained transformer', 0.5384024381637573), ('multimodal transformer', 0.533332347869873), ('imagen', 0.4278738498687744), ('multimodal fusion', 0.42510393261909485), ('neural rendering', 0.4206916391849518), ('neural radiance field', 0.40488162636756897)]"
        ],
        [
         "4",
         "Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin",
         "Huang J.",
         "Environmental Science and Ecotechnology",
         "10.1016/j.ese.2025.100526",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85216848180",
         "85216848180",
         "Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.",
         "['Foundation models', 'Generative artificial intelligence', 'Generative spatial artificial intelligence', 'Large flow model', 'Sustainable smart cities', 'Urban digital twin', 'Urban planning and design']",
         "['Environmental Engineering', 'Ecology', 'Environmental Science (miscellaneous)']",
         "Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption.",
         "This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9540014267, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9540014267, 0.045998614300000004]}",
         "True",
         "0.9540014267",
         "['Urban Planning', 'Urban Management', 'Sustainability', 'Multimodal Transport', 'Construction', 'Environment', 'Mobility', 'Living', 'Public Services', 'Socioeconomics', 'Buildings', 'Business', 'Public Policies', 'People', 'Water Quality', 'Transportation Systems', 'Human', 'Housing', 'Energy Management', 'Public Transit', 'Industry', 'Logistics', 'Power Distribution', 'Economy', 'Citizens', 'Governance', 'Pollution Control', 'Emergency Safety', 'Green Spaces', 'Air Quality', 'Economic Management', 'Citizen Engagement', 'Waste Management', 'Social Equity', 'Smart Grids', 'Climate Change', 'Marketing', 'Culture', 'Finance', 'Traffic Management', 'Pedestrian', 'Electric Vehicles', 'Education', 'Renewable Energy', 'Tourism', 'Healthcare', 'Cybersecurity', 'Bicycle']",
         "[0.9958809614, 0.8571100831, 0.40149432420000003, 0.036717657, 0.0271584447, 0.0257922839, 0.0232893731, 0.0208638627, 0.0181917381, 0.0165479537, 0.011019052000000001, 0.0095856246, 0.009083176, 0.0083737997, 0.0061233155000000004, 0.0053145373, 0.0049612932, 0.0046017743, 0.0040124194, 0.0039492249, 0.0037900847000000002, 0.0028462748, 0.0021594861, 0.0021186627, 0.0017655964, 0.0015084606, 0.0013012978000000001, 0.0012880432, 0.0012605013000000001, 0.0012308996000000001, 0.0011368558, 0.0010821468, 0.0008959399, 0.0008505217, 0.0007977595, 0.0007329495, 0.0006267126000000001, 0.0005887586, 0.0005827076, 0.0005570402, 0.000551529, 0.0005049926, 0.0004963243, 0.0004536678, 0.00045217740000000003, 0.00043689170000000004, 0.00040832570000000004, 0.0003852229]",
         "[{'domain': 'Smart Governance', 'score': 0.9958809614}, {'domain': 'Smart Environment', 'score': 0.40149432420000003}]",
         "{'is_genai': True, 'confidence': 0.6537469625473022, 'matched_keywords': ['large flow model', 'flow model', 'foundational framework', 'foundation model', 'foundation framework', 'lfm', '3d generative model'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('urban', 9), ('flow', 5), ('model', 5), ('city', 5), ('lfm', 4)], 'semantic_matches': [('large flow model', 0.6537469625473022), ('flow model', 0.6234424114227295), ('foundational framework', 0.5722938179969788), ('foundation model', 0.5585178732872009), ('foundation framework', 0.5511143207550049), ('lfm', 0.431374728679657), ('3d generative model', 0.4051932394504547)]}",
         "True",
         "0.6537469625473022",
         "['large flow model', 'flow model', 'foundational framework', 'foundation model', 'foundation framework', 'lfm', '3d generative model']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models']",
         "[('urban', 9), ('flow', 5), ('model', 5), ('city', 5), ('lfm', 4)]",
         "[('large flow model', 0.6537469625473022), ('flow model', 0.6234424114227295), ('foundational framework', 0.5722938179969788), ('foundation model', 0.5585178732872009), ('foundation framework', 0.5511143207550049), ('lfm', 0.431374728679657), ('3d generative model', 0.4051932394504547)]"
        ],
        [
         "5",
         "Can we realize seamless traffic safety at smart intersections by predicting and preventing impending crashes?",
         "Hassan Anik B.M.T.",
         "Accident Analysis and Prevention",
         "10.1016/j.aap.2024.107908",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85213567305",
         "85213567305",
         "Intersections are frequently identified as crash hotspots for roadways in major cities, leading to significant human casualties. We propose crash likelihood prediction as an effective strategy to proactively prevent intersection crashes. So far, no reliable models have been developed for intersections that effectively account for the variation in crash types and the cyclical nature of Signal Phasing and Timing (SPaT) and traffic flow. Moreover, the limited research available has primarily relied on sampling techniques to address data imbalance, without exploring alternative solutions. We develop an anomaly detection framework by integrating Generative Adversarial Networks (GANs) and Transformers to predict the likelihood of cycle-level crashes at intersections. The model is built using high-resolution event data extracted from Automated Traffic Signal Performance Measures (ATSPM), including SPaT and traffic flow insights from 11 intersections in Seminole County, Florida. Our framework demonstrates a sensitivity of 76% in predicting crash events using highly imbalanced crash data along with real-world SPaT and traffic data, highlighting its potential for deployment at smart intersections. Overall, the results provide a roadmap for city-wide implementation at smart intersections, with the potential for multiple real-time solutions for impending crashes. These include adjustments in signal timing, driver warnings using various means, and more efficient emergency response, all with major implications for creating more livable and safe cities.",
         "['Anomaly detection', 'Crash likelihood prediction', 'GANs', 'Proactive safety measures', 'Smart cities', 'Smart intersections', 'Transformers']",
         "['Human Factors and Ergonomics', 'Safety, Risk, Reliability and Quality', 'Public Health, Environmental and Occupational Health', 'Law']",
         "Intersections are frequently identified as crash hotspots for roadways in major cities, leading to significant human casualties.",
         "We propose crash likelihood prediction as an effective strategy to proactively prevent intersection crashes. So far, no reliable models have been developed for intersections that effectively account for the variation in crash types and the cyclical nature of Signal Phasing and Timing (SPaT) and traffic flow. Moreover, the limited research available has primarily relied on sampling techniques to address data imbalance, without exploring alternative solutions. We develop an anomaly detection framework by integrating Generative Adversarial Networks (GANs) and Transformers to predict the likelihood of cycle-level crashes at intersections. The model is built using high-resolution event data extracted from Automated Traffic Signal Performance Measures (ATSPM), including SPaT and traffic flow insights from 11 intersections in Seminole County, Florida. Our framework demonstrates a sensitivity of 76% in predicting crash events using highly imbalanced crash data along with real-world SPaT and traffic data, highlighting its potential for deployment at smart intersections. Overall, the results provide a roadmap for city-wide implementation at smart intersections, with the potential for multiple real-time solutions for impending crashes. These include adjustments in signal timing, driver warnings using various means, and more efficient emergency response, all with major implications for creating more livable and safe cities.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.721539259, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.721539259, 0.2784608006]}",
         "True",
         "0.721539259",
         "['Transportation Systems', 'Mobility', 'Traffic Management', 'Urban Management', 'Urban Planning', 'Human', 'Living', 'Emergency Safety', 'People', 'Logistics', 'Environment', 'Citizens', 'Public Services', 'Public Policies', 'Economic Management', 'Socioeconomics', 'Multimodal Transport', 'Business', 'Citizen Engagement', 'Governance', 'Economy', 'Social Equity', 'Construction', 'Pedestrian', 'Energy Management', 'Industry', 'Electric Vehicles', 'Public Transit', 'Power Distribution', 'Sustainability', 'Climate Change', 'Renewable Energy', 'Pollution Control', 'Smart Grids', 'Air Quality', 'Green Spaces', 'Finance', 'Education', 'Bicycle', 'Culture', 'Buildings', 'Waste Management', 'Cybersecurity', 'Housing', 'Healthcare', 'Marketing', 'Tourism', 'Water Quality']",
         "[0.9720867872000001, 0.9552190304, 0.8788835406000001, 0.4363254011, 0.3919655383, 0.1567896456, 0.0978540257, 0.07365936790000001, 0.048676271, 0.037909548700000004, 0.0238177516, 0.0209990181, 0.0102855098, 0.008759669000000001, 0.0012403458, 0.000913584, 0.0007903890000000001, 0.0006355546000000001, 0.0004924412, 0.0004792457, 0.0004424297, 0.00041615630000000004, 0.00040751320000000004, 0.0004010188, 0.0003603257, 0.0003536048, 0.0003514802, 0.00033979210000000004, 0.0003346385, 0.00033008960000000003, 0.0003258202, 0.0003103807, 0.0003032538, 0.000301476, 0.000293712, 0.0002904936, 0.0002900734, 0.0002894705, 0.0002846882, 0.0002844904, 0.0002843593, 0.00028314270000000003, 0.0002826136, 0.0002804694, 0.0002789655, 0.00027863430000000004, 0.0002782074, 0.0002778839]",
         "[{'domain': 'Smart Mobility', 'score': 0.9720867872000001}, {'domain': 'Smart Governance', 'score': 0.4363254011}]",
         "{'is_genai': True, 'confidence': 0.4626944065093994, 'matched_keywords': ['cycle gan', 'noise prediction', 'cyclegan', '3d gan', 'conditional gan'], 'technology_categories': ['Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('crash', 8), ('intersection', 7), ('traffic', 4), ('datum', 4), ('smart', 4)], 'semantic_matches': [('cycle gan', 0.4626944065093994), ('noise prediction', 0.4428831934928894), ('cyclegan', 0.43661928176879883), ('3d gan', 0.4120197594165802), ('conditional gan', 0.40765640139579773)]}",
         "True",
         "0.4626944065093994",
         "['cycle gan', 'noise prediction', 'cyclegan', '3d gan', 'conditional gan']",
         "['Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models']",
         "[('crash', 8), ('intersection', 7), ('traffic', 4), ('datum', 4), ('smart', 4)]",
         "[('cycle gan', 0.4626944065093994), ('noise prediction', 0.4428831934928894), ('cyclegan', 0.43661928176879883), ('3d gan', 0.4120197594165802), ('conditional gan', 0.40765640139579773)]"
        ],
        [
         "6",
         "Edge Implicit Weighting with graph transformers for robust intrusion detection in Internet of Things network",
         "Karpagavalli C.",
         "Computers and Security",
         "10.1016/j.cose.2024.104299",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85212849609",
         "85212849609",
         "In recent years, the Internet of Things devices have progressively deployed in various applications including smart cities, intelligent transportation, healthcare, and agriculture. However, this widespread adaptation of the Internet of Things networks has been vulnerable to several attacks. Lack of security protocols, unauthorized access, and improper device updates lead the Internet of Things environment to several attacks, which impact network security and confidentiality of users. This paper develops an innovative approach that integrates Edge Implicit Weighting and Aggregated Graph Transformer architecture for accurate and timely intrusion detection. The proposed technique aggregates information from both one-hop and two-hop neighbors to derive immediate and extended relational context thereby improving the detection of complex attacks. This approach designs an Edge Implicit Weighting mechanism that allows the model to prioritize structurally significant relationships and enhance the accuracy of attack detection. The multi-head attention mechanism is introduced to enhance the detection of relevant patterns even in highly variable traffic scenarios. Further, the proposed framework incorporates the Synthetic Minority Over-sampling Technique to generate synthetic samples of minority classes to reduce class imbalance problems and attain balanced detection performance across all classes. The performance of the proposed detection technique is analyzed using multiple datasets with standard evaluation parameters. The proposed technique achieves outstanding performance results including an accuracy of 98.87% and a recall of 98.36%. From this experimental validation, it's clear that the proposed framework provides robust performance under diverse network conditions and handles imbalanced data effectively.",
         "['Class imbalance', 'Dual aggregation', 'Edge Implicit Weighting', 'Graph transformer', 'Internet of Things', 'Intrusion detection system', 'Multi-head attention mechanism', 'Network security']",
         "['Computer Science (all)', 'Law']",
         "In recent years, the Internet of Things devices have progressively deployed in various applications including smart cities, intelligent transportation, healthcare, and agriculture. However, this widespread adaptation of the Internet of Things networks has been vulnerable to several attacks. Lack of security protocols, unauthorized access, and improper device updates lead the Internet of Things environment to several attacks, which impact network security and confidentiality of users.",
         "This paper develops an innovative approach that integrates Edge Implicit Weighting and Aggregated Graph Transformer architecture for accurate and timely intrusion detection. The proposed technique aggregates information from both one-hop and two-hop neighbors to derive immediate and extended relational context thereby improving the detection of complex attacks. This approach designs an Edge Implicit Weighting mechanism that allows the model to prioritize structurally significant relationships and enhance the accuracy of attack detection. The multi-head attention mechanism is introduced to enhance the detection of relevant patterns even in highly variable traffic scenarios. Further, the proposed framework incorporates the Synthetic Minority Over-sampling Technique to generate synthetic samples of minority classes to reduce class imbalance problems and attain balanced detection performance across all classes. The performance of the proposed detection technique is analyzed using multiple datasets with standard evaluation parameters. The proposed technique achieves outstanding performance results including an accuracy of 98.87% and a recall of 98.36%. From this experimental validation, it's clear that the proposed framework provides robust performance under diverse network conditions and handles imbalanced data effectively.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9414298534000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9414298534000001, 0.058570101900000004]}",
         "True",
         "0.9414298534000001",
         "['Cybersecurity', 'Industry', 'Environment', 'Business', 'Public Services', 'Living', 'Socioeconomics', 'Smart Grids', 'Citizens', 'Economy', 'Construction', 'Public Policies', 'Governance', 'Urban Management', 'Economic Management', 'Emergency Safety', 'Healthcare', 'Logistics', 'Sustainability', 'Buildings', 'Energy Management', 'Pedestrian', 'Urban Planning', 'Power Distribution', 'Electric Vehicles', 'Air Quality', 'Transportation Systems', 'Mobility', 'Renewable Energy', 'Traffic Management', 'Water Quality', 'Multimodal Transport', 'Citizen Engagement', 'Housing', 'Human', 'Climate Change', 'Social Equity', 'Green Spaces', 'People', 'Education', 'Culture', 'Public Transit', 'Finance', 'Waste Management', 'Marketing', 'Bicycle', 'Pollution Control', 'Tourism']",
         "[0.6749405265, 0.5611295104, 0.20876136420000002, 0.0790863186, 0.0077230628, 0.006207855, 0.0039295005000000004, 0.0027186410000000004, 0.0026838176, 0.0024520173, 0.0021536271, 0.0017305486000000001, 0.0013176845000000001, 0.0010544066000000001, 0.0010125166, 0.0009869928, 0.0009382574, 0.0007640885000000001, 0.0006955369, 0.0006593915, 0.0006539075000000001, 0.0005925819, 0.0005890465, 0.0005882754, 0.0005601635, 0.0005528543, 0.0005404149, 0.0005253946, 0.0005161015, 0.0005021633, 0.000496941, 0.0004923088000000001, 0.00048786010000000004, 0.0004826777, 0.0004795083, 0.00047334700000000005, 0.0004568533, 0.00045478630000000004, 0.0004530099, 0.0004416717, 0.000434956, 0.0004321323, 0.0004288351, 0.0004212538, 0.0004180787, 0.0004144347, 0.0004110973, 0.0004027195]",
         "[{'domain': 'Smart Governance', 'score': 0.6749405265}, {'domain': 'Smart Economy', 'score': 0.5611295104}]",
         "{'is_genai': True, 'confidence': 0.6559167504310608, 'matched_keywords': ['attention mechanism', 'cross-attention', 'self-attention', 'score-based model', 'transformer', 'generative adversarial network', 'hierarchical vae', 'multimodal transformer'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Diffusion Models', 'Variational Autoencoders', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('detection', 7), ('propose', 5), ('technique', 4), ('class', 4), ('performance', 4)], 'semantic_matches': [('attention mechanism', 0.6559167504310608), ('cross-attention', 0.5933870077133179), ('self-attention', 0.50624018907547), ('score-based model', 0.45096829533576965), ('transformer', 0.4476205110549927), ('generative adversarial network', 0.42430996894836426), ('hierarchical vae', 0.41536083817481995), ('multimodal transformer', 0.4048207104206085)]}",
         "True",
         "0.6559167504310608",
         "['attention mechanism', 'cross-attention', 'self-attention', 'score-based model', 'transformer', 'generative adversarial network', 'hierarchical vae', 'multimodal transformer']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Diffusion Models', 'Variational Autoencoders', 'Hybrid & Multimodal Architectures']",
         "[('detection', 7), ('propose', 5), ('technique', 4), ('class', 4), ('performance', 4)]",
         "[('attention mechanism', 0.6559167504310608), ('cross-attention', 0.5933870077133179), ('self-attention', 0.50624018907547), ('score-based model', 0.45096829533576965), ('transformer', 0.4476205110549927), ('generative adversarial network', 0.42430996894836426), ('hierarchical vae', 0.41536083817481995), ('multimodal transformer', 0.4048207104206085)]"
        ],
        [
         "7",
         "Learning to sculpt neural cityscapes",
         "Zhu J.",
         "Visual Computer",
         "10.1007/s00371-024-03528-7",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85198419104",
         "85198419104",
         "We introduce a system that learns to sculpt 3D models of massive urban environments. The majority of humans live their lives in urban environments, using detailed virtual models for applications as diverse as virtual worlds, special effects, and urban planning. Generating such 3D models from exemplars manually is time-consuming, while 3D deep learning approaches have high memory costs. In this paper, we present a technique for training 2D neural networks to repeatedly sculpt a plane into a large-scale 3D urban environment. An initial coarse depth map is created by a GAN model, from which we refine 3D normal and depth using an image translation network regularized by a linear system. The networks are trained using real-world data to allow generative synthesis of meshes at scale. We exploit sculpting from multiple viewpoints to generate a highly detailed, concave, and water-tight 3D mesh. We show cityscapes at scales of 100×1600 meters with more than 2 million triangles, and demonstrate that our results are objectively and subjectively similar to our exemplars.",
         "['Deep learning', 'Linear programming', 'Mesh deformation', 'Terrain mesh']",
         "['Software', 'Computer Vision and Pattern Recognition', 'Computer Graphics and Computer-Aided Design']",
         "We introduce a system that learns to sculpt 3D models of massive urban environments. The majority of humans live their lives in urban environments, using detailed virtual models for applications as diverse as virtual worlds, special effects, and urban planning. Generating such 3D models from exemplars manually is time-consuming, while 3D deep learning approaches have high memory costs. In this paper, we present a technique for training 2D neural networks to repeatedly sculpt a plane into a large-scale 3D urban environment. An initial coarse depth map is created by a GAN model, from which we refine 3D normal and depth using an image translation network regularized by a linear system. The networks are trained using real-world data to allow generative synthesis of meshes at scale. We exploit sculpting from multiple viewpoints to generate a highly detailed, concave, and water-tight 3D mesh. We show cityscapes at scales of 100×1600 meters with more than 2 million triangles, and demonstrate that our results are objectively and subjectively similar to our exemplars.",
         "We introduce a system that learns to sculpt 3D models of massive urban environments. The majority of humans live their lives in urban environments, using detailed virtual models for applications as diverse as virtual worlds, special effects, and urban planning. Generating such 3D models from exemplars manually is time-consuming, while 3D deep learning approaches have high memory costs. In this paper, we present a technique for training 2D neural networks to repeatedly sculpt a plane into a large-scale 3D urban environment. An initial coarse depth map is created by a GAN model, from which we refine 3D normal and depth using an image translation network regularized by a linear system. The networks are trained using real-world data to allow generative synthesis of meshes at scale. We exploit sculpting from multiple viewpoints to generate a highly detailed, concave, and water-tight 3D mesh. We show cityscapes at scales of 100×1600 meters with more than 2 million triangles, and demonstrate that our results are objectively and subjectively similar to our exemplars.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9791163802, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9791163802, 0.0208836701]}",
         "True",
         "0.9791163802",
         "['Environment', 'Construction', 'Industry', 'Buildings', 'Urban Planning', 'Urban Management', 'Living', 'Business', 'Public Services', 'Housing', 'Citizens', 'Human', 'Culture', 'Logistics', 'Emergency Safety', 'Education', 'Mobility', 'Multimodal Transport', 'Economic Management', 'Energy Management', 'Power Distribution', 'Public Transit', 'Electric Vehicles', 'Public Policies', 'Smart Grids', 'People', 'Citizen Engagement', 'Socioeconomics', 'Sustainability', 'Economy', 'Renewable Energy', 'Transportation Systems', 'Air Quality', 'Governance', 'Cybersecurity', 'Climate Change', 'Pedestrian', 'Social Equity', 'Pollution Control', 'Waste Management', 'Water Quality', 'Tourism', 'Finance', 'Healthcare', 'Traffic Management', 'Marketing', 'Bicycle', 'Green Spaces']",
         "[0.6632261872, 0.23745129999999998, 0.0779878348, 0.0290665887, 0.0210945141, 0.0101952376, 0.0053484887, 0.0029414124, 0.0017469801, 0.0011999237000000001, 0.0011402569, 0.0009143861, 0.0009062474, 0.0007935202, 0.0007453101, 0.0007367574, 0.0007071894, 0.0006019651, 0.0005375977, 0.00047013350000000003, 0.00046284390000000004, 0.0004599685, 0.0004464483, 0.0004461014, 0.0004426794, 0.00044198290000000003, 0.0004409001, 0.0004360975, 0.00043494510000000004, 0.0004322311, 0.0004273201, 0.0004263251, 0.00042590280000000003, 0.0004220551, 0.0004124493, 0.0004110136, 0.0004014848, 0.0003947668, 0.0003912128, 0.00038815510000000003, 0.0003822666, 0.000377573, 0.00037282440000000003, 0.00036524560000000003, 0.00036081080000000004, 0.0003584346, 0.00032782490000000003, 0.0003269634]",
         "[{'domain': 'Smart Environment', 'score': 0.6632261872}]",
         "{'is_genai': True, 'confidence': 0.6005690097808838, 'matched_keywords': ['mesh generation', '3d generative model', 'neural rendering', '3d gan', '3d reconstruction', 'generative adversarial network', 'generative capabilities', 'shape generation', 'sr-gan', 'progressive gan', 'designed with ai', 'contrastive learning', 'latent space modeling', 'vision-language model', 'adv-gan'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('model', 4), ('urban', 4), ('mesh', 4), ('sculpt', 3), ('environment', 3)], 'semantic_matches': [('mesh generation', 0.6005690097808838), ('3d generative model', 0.5699205994606018), ('neural rendering', 0.5680311918258667), ('3d gan', 0.5543006658554077), ('3d reconstruction', 0.49887824058532715), ('generative adversarial network', 0.4868398904800415), ('generative capabilities', 0.45844656229019165), ('shape generation', 0.44325047731399536), ('sr-gan', 0.44131869077682495), ('progressive gan', 0.43230998516082764), ('designed with ai', 0.4213806688785553), ('contrastive learning', 0.4116847813129425), ('latent space modeling', 0.411174476146698), ('vision-language model', 0.40670159459114075), ('adv-gan', 0.4034997522830963)]}",
         "True",
         "0.6005690097808838",
         "['mesh generation', '3d generative model', 'neural rendering', '3d gan', '3d reconstruction', 'generative adversarial network', 'generative capabilities', 'shape generation', 'sr-gan', 'progressive gan', 'designed with ai', 'contrastive learning', 'latent space modeling', 'vision-language model', 'adv-gan']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('model', 4), ('urban', 4), ('mesh', 4), ('sculpt', 3), ('environment', 3)]",
         "[('mesh generation', 0.6005690097808838), ('3d generative model', 0.5699205994606018), ('neural rendering', 0.5680311918258667), ('3d gan', 0.5543006658554077), ('3d reconstruction', 0.49887824058532715), ('generative adversarial network', 0.4868398904800415), ('generative capabilities', 0.45844656229019165), ('shape generation', 0.44325047731399536), ('sr-gan', 0.44131869077682495), ('progressive gan', 0.43230998516082764), ('designed with ai', 0.4213806688785553), ('contrastive learning', 0.4116847813129425), ('latent space modeling', 0.411174476146698), ('vision-language model', 0.40670159459114075), ('adv-gan', 0.4034997522830963)]"
        ],
        [
         "8",
         "Intelligent generation and interpretability analysis of shear wall structure design by learning from multidimensional to high-dimensional features",
         "Yu Y.",
         "Engineering Structures",
         "10.1016/j.engstruct.2024.119472",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85211970583",
         "85211970583",
         "The intelligent design of shear wall structures is a critical aspect of smart construction, with a high demand for research and applications. Accurately predicting the shear wall ratio (i.e., the shear wall area-to-floor area ratio) during cost estimation and rapidly generating shear wall layouts during early design is essential. However, the unclear influences of numerous design feature parameters hinder the enhancement of generative AI design. This affects both the prediction of shear wall ratios from multidimensional features and the generation of shear wall layouts from high-dimensional features. Therefore, a method for generating key structural design features using machine learning (ML) and generative adversarial networks (GANs), along with model interpretation, is proposed in this study. Existing shear wall design data are collected, and features such as the architectural plan geometry, seismic design conditions, and shear wall ratios are extracted to establish a dataset. Key shear wall ratio parameters are predicted using an ML model with multidimensional design features as inputs, and interpretability analysis is conducted using Shapley Additive Explanations (SHAP). Concurrently, a GAN model is built to generate shear wall designs using fused image-text high-dimensional features, and the influence patterns of design features are explained through sensitivity analysis. The analysis results indicate that the prediction accuracy is effectively enhanced by ML-based multidimensional feature learning, shear wall designs are effectively generated by GAN-based high-dimensional feature learning, and seismic design intensity and structural height are revealed as significant factors through interpretability analysis. Furthermore, when high-dimensional feature inputs are available, the generation of comprehensive features should be prioritized for shear wall structural designs.",
         "['Generative adversarial networks', 'Intelligent structural design', 'Interpretable machine learning', 'Multi- and high-dimensional feature analysis', 'Shear wall structure']",
         "['Civil and Structural Engineering']",
         "The intelligent design of shear wall structures is a critical aspect of smart construction, with a high demand for research and applications. Accurately predicting the shear wall ratio (i.e., the shear wall area-to-floor area ratio) during cost estimation and rapidly generating shear wall layouts during early design is essential. However, the unclear influences of numerous design feature parameters hinder the enhancement of generative AI design. This affects both the prediction of shear wall ratios from multidimensional features and the generation of shear wall layouts from high-dimensional features.",
         "Therefore, a method for generating key structural design features using machine learning (ML) and generative adversarial networks (GANs), along with model interpretation, is proposed in this study. Existing shear wall design data are collected, and features such as the architectural plan geometry, seismic design conditions, and shear wall ratios are extracted to establish a dataset. Key shear wall ratio parameters are predicted using an ML model with multidimensional design features as inputs, and interpretability analysis is conducted using Shapley Additive Explanations (SHAP). Concurrently, a GAN model is built to generate shear wall designs using fused image-text high-dimensional features, and the influence patterns of design features are explained through sensitivity analysis. The analysis results indicate that the prediction accuracy is effectively enhanced by ML-based multidimensional feature learning, shear wall designs are effectively generated by GAN-based high-dimensional feature learning, and seismic design intensity and structural height are revealed as significant factors through interpretability analysis. Furthermore, when high-dimensional feature inputs are available, the generation of comprehensive features should be prioritized for shear wall structural designs.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9415545464, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9415545464, 0.0584454201]}",
         "True",
         "0.9415545464",
         "['Construction', 'Industry', 'Buildings', 'Housing', 'Business', 'Public Services', 'Environment', 'Sustainability', 'Emergency Safety', 'Living', 'Transportation Systems', 'Power Distribution', 'Green Spaces', 'Multimodal Transport', 'Smart Grids', 'Mobility', 'Logistics', 'Renewable Energy', 'Economy', 'Human', 'Citizens', 'Energy Management', 'Healthcare', 'Public Transit', 'Water Quality', 'Urban Planning', 'People', 'Air Quality', 'Electric Vehicles', 'Pollution Control', 'Urban Management', 'Education', 'Climate Change', 'Economic Management', 'Cybersecurity', 'Socioeconomics', 'Social Equity', 'Waste Management', 'Finance', 'Tourism', 'Public Policies', 'Governance', 'Traffic Management', 'Pedestrian', 'Citizen Engagement', 'Culture', 'Bicycle', 'Marketing']",
         "[0.9731584191, 0.24205242100000002, 0.16102747620000002, 0.038067922000000004, 0.0249865688, 0.009117134800000001, 0.0077822739, 0.0038519274000000004, 0.0033830977, 0.0030699864, 0.0027247495, 0.0026227890000000004, 0.0020123988, 0.001870686, 0.0015507679, 0.0014282445000000001, 0.0013610756, 0.0011775114000000001, 0.0010814256, 0.0009997066, 0.0009692883, 0.0009548655, 0.0009509993, 0.0009371983000000001, 0.0008799763000000001, 0.0008216951, 0.0007931812000000001, 0.0007570562, 0.0007461646, 0.000742915, 0.0007128019, 0.0006755912, 0.0006722863, 0.0006630658000000001, 0.0006460418, 0.0006273486, 0.0006055681, 0.0006014163, 0.0005789816, 0.0005654054, 0.0005540681, 0.0005489813, 0.0005489787, 0.0005291433, 0.0005241530000000001, 0.0004875882, 0.0004602741, 0.00042487570000000004]",
         "[{'domain': 'Smart Living', 'score': 0.9731584191}]",
         "{'is_genai': True, 'confidence': 0.5457202792167664, 'matched_keywords': ['3d gan', 'generative model', 'generative adversarial network', '3d generative model', 'generative capabilities', 'generative capability', 'sr-gan', 'adv-gan', 'progressive gan', 'conditional gan', 'flow model'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('design', 10), ('feature', 10), ('shear', 7), ('wall', 7), ('analysis', 5)], 'semantic_matches': [('3d gan', 0.5457202792167664), ('generative model', 0.521614670753479), ('generative adversarial network', 0.49794256687164307), ('3d generative model', 0.4866143465042114), ('generative capabilities', 0.47995105385780334), ('generative capability', 0.475460946559906), ('sr-gan', 0.4504925608634949), ('adv-gan', 0.44217953085899353), ('progressive gan', 0.4289168119430542), ('conditional gan', 0.42577242851257324), ('flow model', 0.42125096917152405)]}",
         "True",
         "0.5457202792167664",
         "['3d gan', 'generative model', 'generative adversarial network', '3d generative model', 'generative capabilities', 'generative capability', 'sr-gan', 'adv-gan', 'progressive gan', 'conditional gan', 'flow model']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models']",
         "[('design', 10), ('feature', 10), ('shear', 7), ('wall', 7), ('analysis', 5)]",
         "[('3d gan', 0.5457202792167664), ('generative model', 0.521614670753479), ('generative adversarial network', 0.49794256687164307), ('3d generative model', 0.4866143465042114), ('generative capabilities', 0.47995105385780334), ('generative capability', 0.475460946559906), ('sr-gan', 0.4504925608634949), ('adv-gan', 0.44217953085899353), ('progressive gan', 0.4289168119430542), ('conditional gan', 0.42577242851257324), ('flow model', 0.42125096917152405)]"
        ],
        [
         "9",
         "AI Agent-Based Intelligent Urban Digital Twin (I-UDT): Concept, Methodology, and Case Studies",
         "Choi S.",
         "Smart Cities",
         "10.3390/smartcities8010028",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85218882823",
         "85218882823",
         "Highlights: What are the main findings? In the developed AI agent-based intelligent digital twin (I-DT), UBEM overcomes the limitations of the traditional UBEM approach and enables efficient analysis of urban building energy. GPT-based UBEM effectively performed the core functions of UBEM, serving as a key technology in I-UDT applications and services. What are the implications of the main findings? The I-UDT enables more accurate and comprehensive urban energy management, supporting the development of sustainable cities and carbon-neutral strategies. Implementing I-UDTs enables urban policymakers to make data-driven decisions, improve energy efficiency, and enhance the scalability of digital twin applications. The concept of digital twins (DTs) has expanded to encompass buildings and cities, with urban building energy modeling (UBEM) playing a crucial role in predicting urban-scale energy consumption via modeling individual energy use and interactions. As a virtual model within urban digital twins (UDTs), UBEM offers the potential for managing energy in sustainable cities. However, UDTs face challenges with regard to integrating large-scale data and relying on bottom-up UBEM approaches. In this study, we propose an AI agent-based intelligent urban digital twin (I-UDT) to enhance DTs’ technical realization and UBEM’s service functionality. Integrating GPT within the UDT enabled the efficient integration of fragmented city-scale data and the extraction of building features, addressing the limitations of the service realization of traditional UBEM. This framework ensures continuous updates of the virtual urban model and the streamlined provision of updated information to users in future studies. This research establishes the concept of an I-UDT and lays a foundation for future implementations. The case studies include (1) data analysis, (2) prediction, (3) feature engineering, and (4) information services for 3500 buildings in Seoul. Through these case studies, the I-UDT was integrated and analyzed scattered data, predicted energy consumption, derived conditioned areas, and evaluated buildings on benchmark.",
         "['AI (artificial intelligence) agent', 'digital twins (DTs)', 'generative pre-trained transformers (GPTs)', 'OpenAI', 'urban building energy modeling (UBEM)', 'urban building informatics', 'urban digital twins (UDTs)']",
         "['Urban Studies', 'Artificial Intelligence', 'Electrical and Electronic Engineering']",
         "Highlights: What are the main findings? In the developed AI agent-based intelligent digital twin (I-DT), UBEM overcomes the limitations of the traditional UBEM approach and enables efficient analysis of urban building energy. GPT-based UBEM effectively performed the core functions of UBEM, serving as a key technology in I-UDT applications and services. What are the implications of the main findings? The I-UDT enables more accurate and comprehensive urban energy management, supporting the development of sustainable cities and carbon-neutral strategies. Implementing I-UDTs enables urban policymakers to make data-driven decisions, improve energy efficiency, and enhance the scalability of digital twin applications. The concept of digital twins (DTs) has expanded to encompass buildings and cities, with urban building energy modeling (UBEM) playing a crucial role in predicting urban-scale energy consumption via modeling individual energy use and interactions. As a virtual model within urban digital twins (UDTs), UBEM offers the potential for managing energy in sustainable cities. However, UDTs face challenges with regard to integrating large-scale data and relying on bottom-up UBEM approaches.",
         "In this study, we propose an AI agent-based intelligent urban digital twin (I-UDT) to enhance DTs’ technical realization and UBEM’s service functionality. Integrating GPT within the UDT enabled the efficient integration of fragmented city-scale data and the extraction of building features, addressing the limitations of the service realization of traditional UBEM. This framework ensures continuous updates of the virtual urban model and the streamlined provision of updated information to users in future studies. This research establishes the concept of an I-UDT and lays a foundation for future implementations. The case studies include (1) data analysis, (2) prediction, (3) feature engineering, and (4) information services for 3500 buildings in Seoul. Through these case studies, the I-UDT was integrated and analyzed scattered data, predicted energy consumption, derived conditioned areas, and evaluated buildings on benchmark.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9893116355, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9893116355, 0.010688310500000001]}",
         "True",
         "0.9893116355",
         "['Energy Management', 'Sustainability', 'Urban Management', 'Environment', 'Buildings', 'Urban Planning', 'Public Services', 'Economy', 'Public Policies', 'Construction', 'Socioeconomics', 'Business', 'Economic Management', 'Power Distribution', 'Climate Change', 'Renewable Energy', 'Living', 'Industry', 'Housing', 'Logistics', 'Emergency Safety', 'Multimodal Transport', 'Smart Grids', 'Education', 'Governance', 'People', 'Air Quality', 'Mobility', 'Social Equity', 'Marketing', 'Pollution Control', 'Finance', 'Transportation Systems', 'Public Transit', 'Water Quality', 'Tourism', 'Green Spaces', 'Human', 'Electric Vehicles', 'Citizen Engagement', 'Citizens', 'Cybersecurity', 'Pedestrian', 'Culture', 'Healthcare', 'Waste Management', 'Traffic Management', 'Bicycle']",
         "[0.9372216463, 0.8313320875, 0.7804586887, 0.5997819901, 0.4588811696, 0.2051801085, 0.0401814803, 0.0328078009, 0.0272806957, 0.0233397577, 0.022183405200000002, 0.018063630900000002, 0.0124856839, 0.0115563031, 0.0103260269, 0.0051557245, 0.0051326118, 0.0047527868000000004, 0.0029586528000000003, 0.0019521432, 0.0015985351000000001, 0.0014961546, 0.0014842728, 0.0013790058, 0.0013631115000000001, 0.0011792317, 0.0011495489000000001, 0.0011264790000000001, 0.0010788155, 0.0010187979, 0.0009907146, 0.0008981205, 0.0008913603, 0.0008893819, 0.0008691073, 0.0008157372, 0.000795146, 0.0006732788, 0.0006428979, 0.0006353327, 0.0005922740000000001, 0.0005322606, 0.0005207710000000001, 0.0005191906, 0.0005182981, 0.0004897688, 0.0004524748, 0.00038124670000000004]",
         "[{'domain': 'Smart Environment', 'score': 0.9372216463}, {'domain': 'Smart Governance', 'score': 0.7804586887}, {'domain': 'Smart Living', 'score': 0.4588811696}]",
         "{'is_genai': True, 'confidence': 0.5321555137634277, 'matched_keywords': ['designed with ai', 'generative pretrained transformer', 'ai capability', 'gpt', 'transformer', 'gpt-4', 'multimodal transformer', 'gen ai', 'gpt-3', 'gpt-2'], 'technology_categories': ['Transformer-Based Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('urban', 5), ('building', 5), ('study', 4), ('udt', 4), ('digital', 3)], 'semantic_matches': [('designed with ai', 0.5321555137634277), ('generative pretrained transformer', 0.49104785919189453), ('ai capability', 0.4793395400047302), ('gpt', 0.46611374616622925), ('transformer', 0.4344174563884735), ('gpt-4', 0.41889896988868713), ('multimodal transformer', 0.41193073987960815), ('gen ai', 0.4103669822216034), ('gpt-3', 0.4080660045146942), ('gpt-2', 0.40532252192497253)]}",
         "True",
         "0.5321555137634277",
         "['designed with ai', 'generative pretrained transformer', 'ai capability', 'gpt', 'transformer', 'gpt-4', 'multimodal transformer', 'gen ai', 'gpt-3', 'gpt-2']",
         "['Transformer-Based Models', 'Hybrid & Multimodal Architectures']",
         "[('urban', 5), ('building', 5), ('study', 4), ('udt', 4), ('digital', 3)]",
         "[('designed with ai', 0.5321555137634277), ('generative pretrained transformer', 0.49104785919189453), ('ai capability', 0.4793395400047302), ('gpt', 0.46611374616622925), ('transformer', 0.4344174563884735), ('gpt-4', 0.41889896988868713), ('multimodal transformer', 0.41193073987960815), ('gen ai', 0.4103669822216034), ('gpt-3', 0.4080660045146942), ('gpt-2', 0.40532252192497253)]"
        ],
        [
         "10",
         "Exploring the Ambient in Relation to Urban Life and AI",
         "McKenna H.P.",
         "Urban Science",
         "10.3390/urbansci9020026",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85218864818",
         "85218864818",
         "The purpose of this paper is to explore the nature of the ambient in an era of artificial intelligence (AI), focusing on the urban context. As such, this paper explores evolving understandings of the ambient in everyday life encompassing a range of elements such as awareness, computing, experiences, information, and intelligence in relation to rapidly evolving and emerging applications of AI and generative AI in urban environments. A review of the research and practice literature for the ambient in relation to urban AI is provided in this paper enabling formulation of a conceptual framework to guide the exploration. A poll conducted online using the Whova platform during a hybrid (e.g., virtual and in person) conference event provides insight into the awareness element in the context of AI from the perspective of researchers, students, practitioners, and other conference participants and attendees (e.g., government business, etc.). Implications for urban life, smart cities, learning cities, and future cities are discussed, giving rise to challenges and opportunities for research and practice going forward. This work is significant in that a range of perspectives across a variety of domains emerge for the ambient in relation to everyday life and AI and to urban AI.",
         "['ambient awareness', 'ambient computing', 'ambient engineering', 'ambient experiences', 'ambient information', 'artificial intelligence', 'awareness', 'generative AI', 'learning cities', 'smart cities']",
         "['Geography, Planning and Development', 'Environmental Science (miscellaneous)', 'Waste Management and Disposal', 'Urban Studies', 'Pollution']",
         "The purpose of this paper is to explore the nature of the ambient in an era of artificial intelligence (AI), focusing on the urban context. As such, this paper explores evolving understandings of the ambient in everyday life encompassing a range of elements such as awareness, computing, experiences, information, and intelligence in relation to rapidly evolving and emerging applications of AI and generative AI in urban environments. A review of the research and practice literature for the ambient in relation to urban AI is provided in this paper enabling formulation of a conceptual framework to guide the exploration. A poll conducted online using the Whova platform during a hybrid (e.g., virtual and in person) conference event provides insight into the awareness element in the context of AI from the perspective of researchers, students, practitioners, and other conference participants and attendees (e.g., government business, etc.). Implications for urban life, smart cities, learning cities, and future cities are discussed, giving rise to challenges and opportunities for research and practice going forward. This work is significant in that a range of perspectives across a variety of domains emerge for the ambient in relation to everyday life and AI and to urban AI.",
         "The purpose of this paper is to explore the nature of the ambient in an era of artificial intelligence (AI), focusing on the urban context. As such, this paper explores evolving understandings of the ambient in everyday life encompassing a range of elements such as awareness, computing, experiences, information, and intelligence in relation to rapidly evolving and emerging applications of AI and generative AI in urban environments. A review of the research and practice literature for the ambient in relation to urban AI is provided in this paper enabling formulation of a conceptual framework to guide the exploration. A poll conducted online using the Whova platform during a hybrid (e.g., virtual and in person) conference event provides insight into the awareness element in the context of AI from the perspective of researchers, students, practitioners, and other conference participants and attendees (e.g., government business, etc.). Implications for urban life, smart cities, learning cities, and future cities are discussed, giving rise to challenges and opportunities for research and practice going forward. This work is significant in that a range of perspectives across a variety of domains emerge for the ambient in relation to everyday life and AI and to urban AI.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.899748981, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.899748981, 0.10025103390000001]}",
         "True",
         "0.899748981",
         "['Environment', 'Urban Planning', 'Living', 'Construction', 'Culture', 'Urban Management', 'People', 'Public Services', 'Public Policies', 'Citizen Engagement', 'Citizens', 'Industry', 'Air Quality', 'Economic Management', 'Logistics', 'Buildings', 'Pedestrian', 'Human', 'Socioeconomics', 'Multimodal Transport', 'Education', 'Business', 'Emergency Safety', 'Mobility', 'Housing', 'Pollution Control', 'Transportation Systems', 'Economy', 'Electric Vehicles', 'Water Quality', 'Power Distribution', 'Green Spaces', 'Public Transit', 'Energy Management', 'Governance', 'Traffic Management', 'Social Equity', 'Sustainability', 'Waste Management', 'Marketing', 'Climate Change', 'Tourism', 'Smart Grids', 'Cybersecurity', 'Renewable Energy', 'Healthcare', 'Bicycle', 'Finance']",
         "[0.780898571, 0.219743669, 0.1559436917, 0.055755462500000005, 0.0478316098, 0.041001562000000005, 0.0204027873, 0.0138581367, 0.0127088567, 0.010754585300000001, 0.0105471984, 0.009900175, 0.009894779000000001, 0.0092336433, 0.0092065362, 0.0086461082, 0.0080470154, 0.007715315600000001, 0.0069350759000000005, 0.006794034, 0.0065713548, 0.0053569255, 0.004678362, 0.0044929301000000005, 0.0044487328, 0.0037709230000000002, 0.0036245759, 0.0034166661, 0.0031858615, 0.0029961837, 0.0028463209, 0.0026652829, 0.0026055917000000002, 0.0025995281000000003, 0.002216273, 0.0021180657, 0.0018450810000000002, 0.001831134, 0.0016203831, 0.0012871891, 0.0012002015, 0.0011798119, 0.0011331073, 0.0010894845000000001, 0.0009664062, 0.0008344412000000001, 0.0006776379, 0.0005676907000000001]",
         "[{'domain': 'Smart Environment', 'score': 0.780898571}]",
         "{'is_genai': True, 'confidence': 0.5700490474700928, 'matched_keywords': ['designed with ai', 'ai capability', 'gen ai'], 'technology_categories': ['Transformer-Based Models'], 'bridge_terms': [('ambient', 9), ('urban', 5), ('city', 5), ('awareness', 4), ('paper', 3)], 'semantic_matches': [('designed with ai', 0.5700490474700928), ('ai capability', 0.5443627238273621), ('gen ai', 0.48022156953811646)]}",
         "True",
         "0.5700490474700928",
         "['designed with ai', 'ai capability', 'gen ai']",
         "['Transformer-Based Models']",
         "[('ambient', 9), ('urban', 5), ('city', 5), ('awareness', 4), ('paper', 3)]",
         "[('designed with ai', 0.5700490474700928), ('ai capability', 0.5443627238273621), ('gen ai', 0.48022156953811646)]"
        ],
        [
         "11",
         "LLM Agents for Smart City Management: Enhancing Decision Support Through Multi-Agent AI Systems",
         "Kalyuzhnaya A.",
         "Smart Cities",
         "10.3390/smartcities8010019",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85218862736",
         "85218862736",
         "Highlights: What are the main findings? For smart city management, LLM-based multi-agent systems achieve 94–99% accuracy in routing urban queries and demonstrate significant improvements in response quality (G-Eval scores of 0.68–0.74) compared to standalone LLMs (0.30–0.38). Achievement of high scores in routing queries and response accuracy is possible with middle-size LLM models rather than the biggest LLM models. What is the implication of the main findings? The multi-agent LLM approach enables efficient processing of complex urban planning tasks while maintaining high relevance in responses, making it practical for real-world city management applications. LLM agents can effectively augment human decision making in urban planning by reducing task completion time from days to hours while maintaining accuracy and accountability in complex scenarios. This study investigates the implementation of LLM agents in smart city management, leveraging both the inherent language processing abilities of LLMs and the distributed problem solving capabilities of multi-agent systems for the improvement of urban decision making processes. A multi-agent system architecture combines LLMs with existing urban information systems to process complex queries and generate contextually relevant responses for urban planning and management. The research is focused on three main hypotheses testing: (1) LLM agents’ capability for effective routing and processing diverse urban queries, (2) the effectiveness of Retrieval-Augmented Generation (RAG) technology in improving response accuracy when working with local knowledge and regulations, and (3) the impact of integrating LLM agents with existing urban information systems. Our experimental results, based on a comprehensive validation dataset of 150 question–answer pairs, demonstrate significant improvements in decision support capabilities. The multi-agent system achieved pipeline selection accuracy of 94–99% across different models, while the integration of RAG technology improved response accuracy by 17% for strategic development queries and 55% for service accessibility questions. The combined use of document databases and service APIs resulted in the highest performance metrics (G-Eval scores of 0.68–0.74) compared to standalone LLM responses (0.30–0.38). Using St. Petersburg’s Digital Urban Platform as a testbed, we demonstrate the practical applicability of this approach to create integrated city management systems with support complex urban decision making processes. This research contributes to the growing field of AI-enhanced urban management by providing empirical evidence of LLM agents’ effectiveness in processing heterogeneous urban data and supporting strategic planning decisions. Our findings suggest that LLM-based multi-agent systems can significantly enhance the efficiency and accuracy of urban decision making while maintaining high relevance in responses.",
         "['data-driven management', 'large language model', 'LLM', 'LLM agent', 'multi-agent system', 'smart city management', 'strategic management']",
         "['Urban Studies', 'Artificial Intelligence', 'Electrical and Electronic Engineering']",
         "Highlights: What are the main findings? For smart city management, LLM-based multi-agent systems achieve 94–99% accuracy in routing urban queries and demonstrate significant improvements in response quality (G-Eval scores of 0.68–0.74) compared to standalone LLMs (0.30–0.38). Achievement of high scores in routing queries and response accuracy is possible with middle-size LLM models rather than the biggest LLM models. What is the implication of the main findings? The multi-agent LLM approach enables efficient processing of complex urban planning tasks while maintaining high relevance in responses, making it practical for real-world city management applications. LLM agents can effectively augment human decision making in urban planning by reducing task completion time from days to hours while maintaining accuracy and accountability in complex scenarios.",
         "This study investigates the implementation of LLM agents in smart city management, leveraging both the inherent language processing abilities of LLMs and the distributed problem solving capabilities of multi-agent systems for the improvement of urban decision making processes. A multi-agent system architecture combines LLMs with existing urban information systems to process complex queries and generate contextually relevant responses for urban planning and management. The research is focused on three main hypotheses testing: (1) LLM agents’ capability for effective routing and processing diverse urban queries, (2) the effectiveness of Retrieval-Augmented Generation (RAG) technology in improving response accuracy when working with local knowledge and regulations, and (3) the impact of integrating LLM agents with existing urban information systems. Our experimental results, based on a comprehensive validation dataset of 150 question–answer pairs, demonstrate significant improvements in decision support capabilities. The multi-agent system achieved pipeline selection accuracy of 94–99% across different models, while the integration of RAG technology improved response accuracy by 17% for strategic development queries and 55% for service accessibility questions. The combined use of document databases and service APIs resulted in the highest performance metrics (G-Eval scores of 0.68–0.74) compared to standalone LLM responses (0.30–0.38). Using St. Petersburg’s Digital Urban Platform as a testbed, we demonstrate the practical applicability of this approach to create integrated city management systems with support complex urban decision making processes. This research contributes to the growing field of AI-enhanced urban management by providing empirical evidence of LLM agents’ effectiveness in processing heterogeneous urban data and supporting strategic planning decisions. Our findings suggest that LLM-based multi-agent systems can significantly enhance the efficiency and accuracy of urban decision making while maintaining high relevance in responses.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8288702369000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8288702369000001, 0.1711296886]}",
         "True",
         "0.8288702369000001",
         "['Urban Management', 'Urban Planning', 'Public Services', 'Public Policies', 'Living', 'Governance', 'People', 'Socioeconomics', 'Logistics', 'Environment', 'Industry', 'Human', 'Business', 'Citizen Engagement', 'Construction', 'Emergency Safety', 'Mobility', 'Multimodal Transport', 'Buildings', 'Power Distribution', 'Sustainability', 'Citizens', 'Economy', 'Renewable Energy', 'Economic Management', 'Smart Grids', 'Green Spaces', 'Social Equity', 'Education', 'Energy Management', 'Pedestrian', 'Culture', 'Air Quality', 'Electric Vehicles', 'Public Transit', 'Climate Change', 'Housing', 'Transportation Systems', 'Cybersecurity', 'Pollution Control', 'Marketing', 'Water Quality', 'Traffic Management', 'Healthcare', 'Tourism', 'Finance', 'Bicycle', 'Waste Management']",
         "[0.9333452582, 0.5808871984, 0.015489404100000001, 0.0144855091, 0.0048390944000000005, 0.0043225321, 0.0025599599, 0.0021509561, 0.0021003131, 0.0020179788, 0.0014153287, 0.0013553079000000001, 0.0013464576000000001, 0.0012250278000000001, 0.0010579478000000001, 0.0008758939000000001, 0.0007674679000000001, 0.0006166939000000001, 0.0005818055, 0.0005817922, 0.0005664506, 0.0005153674, 0.0005152978, 0.0004963953000000001, 0.0004944511000000001, 0.0004930328, 0.0004752526, 0.0004707037, 0.0004656392, 0.0004407165, 0.0004407103, 0.00043879030000000004, 0.0004352549, 0.00043355600000000003, 0.00043029580000000003, 0.0004135176, 0.0003772967, 0.0003663981, 0.00036487950000000004, 0.0003647758, 0.0003513902, 0.0003439887, 0.000333369, 0.0003290042, 0.0003255084, 0.00032075880000000004, 0.0003138045, 0.0003121091]",
         "[{'domain': 'Smart Governance', 'score': 0.9333452582}]",
         "{'is_genai': True, 'confidence': 0.5623342394828796, 'matched_keywords': ['llm', 'large language model', 'score-based model', 'small language model', 'vision-language model'], 'technology_categories': ['Transformer-Based Models', 'Diffusion Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('agent', 10), ('urban', 10), ('llm', 8), ('system', 8), ('management', 7)], 'semantic_matches': [('llm', 0.5623342394828796), ('large language model', 0.4774594306945801), ('score-based model', 0.44645410776138306), ('small language model', 0.4306797981262207), ('vision-language model', 0.402824342250824)]}",
         "True",
         "0.5623342394828796",
         "['llm', 'large language model', 'score-based model', 'small language model', 'vision-language model']",
         "['Transformer-Based Models', 'Diffusion Models', 'Hybrid & Multimodal Architectures']",
         "[('agent', 10), ('urban', 10), ('llm', 8), ('system', 8), ('management', 7)]",
         "[('llm', 0.5623342394828796), ('large language model', 0.4774594306945801), ('score-based model', 0.44645410776138306), ('small language model', 0.4306797981262207), ('vision-language model', 0.402824342250824)]"
        ],
        [
         "12",
         "A rapid approach to urban traffic noise mapping with a generative adversarial network",
         "Yang X.",
         "Applied Acoustics",
         "10.1016/j.apacoust.2024.110268",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85203849001",
         "85203849001",
         "With rapid urbanisation and the accompanying increase in traffic density, traffic noise has become a major concern in urban planning. However, traditional grid noise mapping methods have limitations in terms of time consumption, software costs, and a lack of parameter integration interfaces. These limitations hinder their ability to meet the need for iterative updates and rapid performance feedback in the early design stages of street-scale urban planning. Herein, we developed a rapid urban traffic noise mapping technique that leverages generative adversarial networks (GANs) as a surrogate model. This approach enables the rapid assessment of urban traffic noise distribution by using urban elements such as roads and buildings as the input. The mean values for the mean squared error (RMSE) and structural similarity index (SSIM) are 0.3024 dB(A) and 0.8528, respectively, for the validation dataset. The trained model is integrated into Grasshopper as a tool, facilitating the rapid generation of traffic noise maps. This integration allows urban designers and planners, even those without expertise in acoustics, to easily anticipate changes in acoustics impacts caused by design in the early design stages.",
         "['Generative adversarial networks', 'Noise mapping', 'pix2pix', 'Urban spatial feature']",
         "['Acoustics and Ultrasonics']",
         "With rapid urbanisation and the accompanying increase in traffic density, traffic noise has become a major concern in urban planning. However, traditional grid noise mapping methods have limitations in terms of time consumption, software costs, and a lack of parameter integration interfaces. These limitations hinder their ability to meet the need for iterative updates and rapid performance feedback in the early design stages of street-scale urban planning. Herein, we developed a rapid urban traffic noise mapping technique that leverages generative adversarial networks (GANs) as a surrogate model.",
         "This approach enables the rapid assessment of urban traffic noise distribution by using urban elements such as roads and buildings as the input. The mean values for the mean squared error (RMSE) and structural similarity index (SSIM) are 0.3024 dB(A) and 0.8528, respectively, for the validation dataset. The trained model is integrated into Grasshopper as a tool, facilitating the rapid generation of traffic noise maps. This integration allows urban designers and planners, even those without expertise in acoustics, to easily anticipate changes in acoustics impacts caused by design in the early design stages.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8947096467000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8947096467000001, 0.10529030860000001]}",
         "True",
         "0.8947096467000001",
         "['Urban Planning', 'Environment', 'Transportation Systems', 'Urban Management', 'Mobility', 'Traffic Management', 'Logistics', 'Public Services', 'Construction', 'Living', 'Power Distribution', 'Business', 'Multimodal Transport', 'Socioeconomics', 'Industry', 'Smart Grids', 'Emergency Safety', 'Public Policies', 'Sustainability', 'Economic Management', 'People', 'Pollution Control', 'Citizens', 'Electric Vehicles', 'Social Equity', 'Economy', 'Renewable Energy', 'Citizen Engagement', 'Human', 'Governance', 'Energy Management', 'Education', 'Air Quality', 'Buildings', 'Finance', 'Climate Change', 'Waste Management', 'Culture', 'Cybersecurity', 'Green Spaces', 'Marketing', 'Water Quality', 'Housing', 'Healthcare', 'Public Transit', 'Bicycle', 'Pedestrian', 'Tourism']",
         "[0.9984453917, 0.8261995912000001, 0.8221027255000001, 0.7018573284, 0.6955375671, 0.2086233348, 0.0815544203, 0.0627606139, 0.051709350200000004, 0.0419938564, 0.0297255833, 0.0271778796, 0.026413805800000002, 0.024953652200000002, 0.019490156300000002, 0.0184019879, 0.0174621381, 0.0174061004, 0.0122408308, 0.011014763300000001, 0.0101516824, 0.0095263151, 0.0061781211, 0.005277048800000001, 0.0052384464, 0.0037289076000000003, 0.0029854400000000002, 0.0025384484, 0.0021216418, 0.0020966297000000003, 0.001998503, 0.0018730654, 0.0011431309, 0.0009357390000000001, 0.0008810962, 0.0008156025000000001, 0.0007493508, 0.0007190881, 0.0007159159, 0.0007052045, 0.0006325437, 0.0006274129, 0.0006116108, 0.0005502407, 0.0004844001, 0.00046501880000000004, 0.00044297440000000003, 0.0004290664]",
         "[{'domain': 'Smart Governance', 'score': 0.9984453917}, {'domain': 'Smart Environment', 'score': 0.8261995912000001}, {'domain': 'Smart Mobility', 'score': 0.8221027255000001}]",
         "{'is_genai': True, 'confidence': 0.581736147403717, 'matched_keywords': ['generative adversarial network', 'noise prediction', 'score-based model'], 'technology_categories': ['Generative Adversarial Networks', 'Diffusion Models'], 'bridge_terms': [('urban', 4), ('noise', 3), ('rapid', 2), ('traffic', 2), ('mean', 2)], 'semantic_matches': [('generative adversarial network', 0.581736147403717), ('noise prediction', 0.49234169721603394), ('score-based model', 0.4158559739589691)]}",
         "True",
         "0.581736147403717",
         "['generative adversarial network', 'noise prediction', 'score-based model']",
         "['Generative Adversarial Networks', 'Diffusion Models']",
         "[('urban', 4), ('noise', 3), ('rapid', 2), ('traffic', 2), ('mean', 2)]",
         "[('generative adversarial network', 0.581736147403717), ('noise prediction', 0.49234169721603394), ('score-based model', 0.4158559739589691)]"
        ],
        [
         "13",
         "Adaptive Cyber Defence: Leveraging GANs for Simulating and Mitigating Advanced Network Attacks in IoT Environments",
         "Rao P.K.",
         "Lecture Notes in Networks and Systems",
         "10.1007/978-981-97-9762-2_19",
         "2025",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/86000713763",
         "86000713763",
         "The progressive dissemination of the Internet of Things (IoT) and Wireless Sensor Networks (WSNs) has ushered in a new era of connectivity, with vast applications spanning from medicare to smart city infrastructure. However, this expansion has been paralleled by a corresponding increase in the sophistication and variety of cyber threats targeting these networks. Traditional cyber security measures, designed for a less dynamic threat landscape, are proving increasingly insufficient in protecting against the innovative and varied attack methods now in commonplace. This study introduces an innovative application of Generative Adversarial Networks (GANs) to address this challenge, presenting a novel framework for the simulation and mitigation of advanced network attacks, particularly focusing on Distributed Denial of Service (DDoS) and spoofing attacks which pose significant threats in IoT environments. Generative Adversarial Networks (GANs), comprising two neural networks-the generator and the discriminator compete in a game-theoretic scenario, facilitating a deep understanding of attack patterns through the generation of realistic, synthetic cyber-attack scenarios. This research exploits GANs to bridge the gap between the static nature of traditional security protocols and the dynamic, evolving landscape of cyber threats. By training on a comprehensive dataset of known attacks and normal network activities, our proposed model, the Dynamic Adaptive Threat Simulation GAN (DATS-GAN), is capable of producing varied and realistic attack scenarios. These simulations serve a dual purpose: they not only enhance the detection capabilities and responsiveness of current security systems but also provide a basis for the development of new, adaptive security mechanisms capable of dynamically responding to the ever-changing cyber threat landscape. The effectiveness of DATS-GAN is demonstrated through extensive empirical analysis, highlighting significant improvements in the detection precision and reaction times of security frameworks within WSNs. Moreover, the generated synthetic attack scenarios provide a valuable resource for training machine learning models, leading to the advancement of adaptive security solutions that maintain a high readiness level against emerging cyber threats. The outcomes of this research hold substantial promise for the cyber security domain, showcasing the potential of GANs to revolutionize network defenses against sophisticated cyber threats in IoT and WSN environments.",
         "['Adaptive security mechanisms', 'AI in cyber defence', 'Cybersecurity in WSN', 'DDoS attack mitigation', 'Generative Adversarial Networks (GANs)', 'IoT security', 'Network attack simulation']",
         "['Control and Systems Engineering', 'Signal Processing', 'Computer Networks and Communications']",
         "The progressive dissemination of the Internet of Things (IoT) and Wireless Sensor Networks (WSNs) has ushered in a new era of connectivity, with vast applications spanning from medicare to smart city infrastructure. However, this expansion has been paralleled by a corresponding increase in the sophistication and variety of cyber threats targeting these networks. Traditional cyber security measures, designed for a less dynamic threat landscape, are proving increasingly insufficient in protecting against the innovative and varied attack methods now in commonplace.",
         "This study introduces an innovative application of Generative Adversarial Networks (GANs) to address this challenge, presenting a novel framework for the simulation and mitigation of advanced network attacks, particularly focusing on Distributed Denial of Service (DDoS) and spoofing attacks which pose significant threats in IoT environments. Generative Adversarial Networks (GANs), comprising two neural networks-the generator and the discriminator compete in a game-theoretic scenario, facilitating a deep understanding of attack patterns through the generation of realistic, synthetic cyber-attack scenarios. This research exploits GANs to bridge the gap between the static nature of traditional security protocols and the dynamic, evolving landscape of cyber threats. By training on a comprehensive dataset of known attacks and normal network activities, our proposed model, the Dynamic Adaptive Threat Simulation GAN (DATS-GAN), is capable of producing varied and realistic attack scenarios. These simulations serve a dual purpose: they not only enhance the detection capabilities and responsiveness of current security systems but also provide a basis for the development of new, adaptive security mechanisms capable of dynamically responding to the ever-changing cyber threat landscape. The effectiveness of DATS-GAN is demonstrated through extensive empirical analysis, highlighting significant improvements in the detection precision and reaction times of security frameworks within WSNs. Moreover, the generated synthetic attack scenarios provide a valuable resource for training machine learning models, leading to the advancement of adaptive security solutions that maintain a high readiness level against emerging cyber threats. The outcomes of this research hold substantial promise for the cyber security domain, showcasing the potential of GANs to revolutionize network defenses against sophisticated cyber threats in IoT and WSN environments.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9831300378000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9831300378000001, 0.0168699827]}",
         "True",
         "0.9831300378000001",
         "['Cybersecurity', 'Industry', 'Business', 'Public Services', 'Environment', 'Economy', 'Citizens', 'Socioeconomics', 'Smart Grids', 'Public Policies', 'Emergency Safety', 'Economic Management', 'Construction', 'Healthcare', 'Air Quality', 'Living', 'Governance', 'Sustainability', 'Urban Management', 'Traffic Management', 'Water Quality', 'Human', 'Buildings', 'Education', 'Logistics', 'Social Equity', 'Energy Management', 'Finance', 'Multimodal Transport', 'Urban Planning', 'Green Spaces', 'People', 'Culture', 'Renewable Energy', 'Power Distribution', 'Climate Change', 'Citizen Engagement', 'Mobility', 'Transportation Systems', 'Electric Vehicles', 'Pollution Control', 'Bicycle', 'Waste Management', 'Public Transit', 'Pedestrian', 'Housing', 'Marketing', 'Tourism']",
         "[0.9975341558, 0.4648720026, 0.2549318075, 0.0227441955, 0.005200306, 0.0046885638, 0.0043211444, 0.0035534899000000003, 0.0023097191, 0.0022068429, 0.0018929866000000001, 0.0013670825, 0.0012450085, 0.0012434297000000001, 0.0012331435, 0.0011656653, 0.001137267, 0.0009967136, 0.0008745462, 0.0008396310000000001, 0.0008011572, 0.0007935474, 0.0007426853, 0.0006949006, 0.0006688583, 0.0006205968, 0.000608944, 0.000598178, 0.0005961115, 0.0005931899, 0.0005512866, 0.0005496993000000001, 0.0005384707, 0.0005187345, 0.0005099344, 0.0005001003000000001, 0.0004786006, 0.000472254, 0.0004684511, 0.0004682817, 0.0004590994, 0.00045842400000000003, 0.0004432141, 0.0004427551, 0.00043158270000000004, 0.0004203875, 0.00041396, 0.0003884003]",
         "[{'domain': 'Smart Governance', 'score': 0.9975341558}, {'domain': 'Smart Economy', 'score': 0.4648720026}]",
         "{'is_genai': True, 'confidence': 0.5866246819496155, 'matched_keywords': ['adv-gan', 'gan', 'conditional gan', 'generative adversarial network', 'progressive gan', 'sr-gan', '5gt-gan', 'cycle gan', 'wgan-gp'], 'technology_categories': ['Generative Adversarial Networks'], 'bridge_terms': [('attack', 9), ('security', 8), ('cyber', 7), ('threat', 6), ('network', 5)], 'semantic_matches': [('adv-gan', 0.5866246819496155), ('gan', 0.5717625617980957), ('conditional gan', 0.5669281482696533), ('generative adversarial network', 0.561025857925415), ('progressive gan', 0.5562928915023804), ('sr-gan', 0.5142717361450195), ('5gt-gan', 0.5136348009109497), ('cycle gan', 0.5075744390487671), ('wgan-gp', 0.44234567880630493)]}",
         "True",
         "0.5866246819496155",
         "['adv-gan', 'gan', 'conditional gan', 'generative adversarial network', 'progressive gan', 'sr-gan', '5gt-gan', 'cycle gan', 'wgan-gp']",
         "['Generative Adversarial Networks']",
         "[('attack', 9), ('security', 8), ('cyber', 7), ('threat', 6), ('network', 5)]",
         "[('adv-gan', 0.5866246819496155), ('gan', 0.5717625617980957), ('conditional gan', 0.5669281482696533), ('generative adversarial network', 0.561025857925415), ('progressive gan', 0.5562928915023804), ('sr-gan', 0.5142717361450195), ('5gt-gan', 0.5136348009109497), ('cycle gan', 0.5075744390487671), ('wgan-gp', 0.44234567880630493)]"
        ],
        [
         "14",
         "Smart Energy Management: From Conventional Optimization to Generative AI Techniques",
         "Mongaillard T.",
         "Lecture Notes in Intelligent Transportation and Infrastructure",
         "10.1007/978-3-031-72959-1_15",
         "2025",
         "Book Chapter",
         "https://api.elsevier.com/content/abstract/scopus_id/86000657801",
         "86000657801",
         "This chapter explores the evolution of power consumption scheduling in smart cities, focusing on smart homes and electric vehicle charging. It discusses the transition from classical optimization techniques to heuristic methods like genetic algorithms and swarm optimization for addressing complex energy management problems. The chapter also highlights the growing importance of machine learning, particularly artificial neural networks and reinforcement learning, in predicting energy demand and optimizing scheduling decisions. Additionally, it delves into the potential of generative AI, including generative adversarial networks and large language models, to revolutionize power scheduling by generating realistic scenarios, improving user interaction, and enabling more personalized and efficient energy management strategies.",
         null,
         null,
         "This chapter explores the evolution of power consumption scheduling in smart cities, focusing on smart homes and electric vehicle charging. It discusses the transition from classical optimization techniques to heuristic methods like genetic algorithms and swarm optimization for addressing complex energy management problems. The chapter also highlights the growing importance of machine learning, particularly artificial neural networks and reinforcement learning, in predicting energy demand and optimizing scheduling decisions. Additionally, it delves into the potential of generative AI, including generative adversarial networks and large language models, to revolutionize power scheduling by generating realistic scenarios, improving user interaction, and enabling more personalized and efficient energy management strategies.",
         "This chapter explores the evolution of power consumption scheduling in smart cities, focusing on smart homes and electric vehicle charging. It discusses the transition from classical optimization techniques to heuristic methods like genetic algorithms and swarm optimization for addressing complex energy management problems. The chapter also highlights the growing importance of machine learning, particularly artificial neural networks and reinforcement learning, in predicting energy demand and optimizing scheduling decisions. Additionally, it delves into the potential of generative AI, including generative adversarial networks and large language models, to revolutionize power scheduling by generating realistic scenarios, improving user interaction, and enabling more personalized and efficient energy management strategies.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9570516944, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9570516944, 0.0429482795]}",
         "True",
         "0.9570516944",
         "['Energy Management', 'Smart Grids', 'Sustainability', 'Industry', 'Public Services', 'Urban Management', 'Buildings', 'Business', 'Environment', 'Economic Management', 'Power Distribution', 'Living', 'Economy', 'Socioeconomics', 'Logistics', 'Renewable Energy', 'Construction', 'Urban Planning', 'People', 'Citizens', 'Human', 'Housing', 'Public Policies', 'Electric Vehicles', 'Education', 'Mobility', 'Multimodal Transport', 'Finance', 'Emergency Safety', 'Marketing', 'Transportation Systems', 'Cybersecurity', 'Governance', 'Culture', 'Climate Change', 'Citizen Engagement', 'Social Equity', 'Pedestrian', 'Air Quality', 'Healthcare', 'Tourism', 'Bicycle', 'Traffic Management', 'Pollution Control', 'Green Spaces', 'Water Quality', 'Public Transit', 'Waste Management']",
         "[0.9017672539, 0.7932715416, 0.1837767512, 0.1107276455, 0.1102802977, 0.0997068062, 0.09828702360000001, 0.0975860283, 0.08547054230000001, 0.053463857600000005, 0.0405394882, 0.0382853299, 0.0233530793, 0.0232632644, 0.0213208199, 0.013793102500000001, 0.0094784116, 0.0092928, 0.0081714923, 0.0071222046, 0.0065361368, 0.0056947973, 0.0056445659000000006, 0.0056043039000000005, 0.0051905219, 0.0024352253, 0.0021758236, 0.0020330104, 0.0015907908, 0.0014017737, 0.001072748, 0.0010197682, 0.0009933761, 0.0009739223, 0.0007804089, 0.0007499096, 0.0007437916, 0.0007008475000000001, 0.0006758413, 0.0006606271, 0.000643594, 0.0005716824, 0.0005536251, 0.0005383264, 0.0005325857, 0.0005316246000000001, 0.0004943063, 0.0004079368]",
         "[{'domain': 'Smart Environment', 'score': 0.9017672539}]",
         "{'is_genai': True, 'confidence': 0.5502844452857971, 'matched_keywords': ['generative capabilities', 'generative capability', 'generative adversarial network', 'generative model', 'generative pretrained transformer'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks'], 'bridge_terms': [('scheduling', 3), ('energy', 3), ('chapter', 2), ('power', 2), ('smart', 2)], 'semantic_matches': [('generative capabilities', 0.5502844452857971), ('generative capability', 0.522860050201416), ('generative adversarial network', 0.5204201936721802), ('generative model', 0.5041308403015137), ('generative pretrained transformer', 0.44182008504867554)]}",
         "True",
         "0.5502844452857971",
         "['generative capabilities', 'generative capability', 'generative adversarial network', 'generative model', 'generative pretrained transformer']",
         "['Transformer-Based Models', 'Generative Adversarial Networks']",
         "[('scheduling', 3), ('energy', 3), ('chapter', 2), ('power', 2), ('smart', 2)]",
         "[('generative capabilities', 0.5502844452857971), ('generative capability', 0.522860050201416), ('generative adversarial network', 0.5204201936721802), ('generative model', 0.5041308403015137), ('generative pretrained transformer', 0.44182008504867554)]"
        ],
        [
         "15",
         "Harnessing the Power of Large Language Models for Sustainable and Intelligent Transportation Systems in the Electric Vehicle Era",
         "Abraham A.",
         "Lecture Notes in Intelligent Transportation and Infrastructure",
         "10.1007/978-3-031-72959-1_5",
         "2025",
         "Book Chapter",
         "https://api.elsevier.com/content/abstract/scopus_id/86000600826",
         "86000600826",
         "Urban ecosystems in the midst of digital transformation utilize technologies like Internet of Things (IoT), big data, and artificial intelligence (AI) to elevate citizens’ well-being and champion sustainable development. Notably, LLMs such as GPT-3 or GPT-4, crafted by OpenAI, and Google’s AI tools like Gemini and Bard, stand as pivotal components, holding immense potential to revolutionize EVs in smart city initiatives. Generative AI and LLM integration prove influential in optimizing EV functionalities, enhancing security, and fortifying data privacy. This chapter delves into battery technology, battery capacities, energy storage, charging infrastructure optimization, autonomous driving, educational outreach, energy management, and predictive maintenance. In particular, LLMs address EV challenges by optimizing routes, speeds, and behaviors, reducing energy usage and emissions. They facilitate the smart integration of EVs and renewable energy sources, managing charging schedules based on availability and grid demands. Additionally, LLMs contribute to public education on EV benefits, environmental impact, cost savings, and sustainable transportation promotion. The chapter explores synergies between LLMs and EVs, focusing on potential applications and challenges, propelling progress in ITSs. Similarly, Multimodal Large Language Models (MLLMs) and their potential applications in the era of the EV represent a promising frontier in this landscape, offering enhanced capabilities to interpret and generate multimodal data, further enriching the EV ecosystem.",
         null,
         null,
         "Urban ecosystems in the midst of digital transformation utilize technologies like Internet of Things (IoT), big data, and artificial intelligence (AI) to elevate citizens’ well-being and champion sustainable development. Notably, LLMs such as GPT-3 or GPT-4, crafted by OpenAI, and Google’s AI tools like Gemini and Bard, stand as pivotal components, holding immense potential to revolutionize EVs in smart city initiatives. Generative AI and LLM integration prove influential in optimizing EV functionalities, enhancing security, and fortifying data privacy.",
         "This chapter delves into battery technology, battery capacities, energy storage, charging infrastructure optimization, autonomous driving, educational outreach, energy management, and predictive maintenance. In particular, LLMs address EV challenges by optimizing routes, speeds, and behaviors, reducing energy usage and emissions. They facilitate the smart integration of EVs and renewable energy sources, managing charging schedules based on availability and grid demands. Additionally, LLMs contribute to public education on EV benefits, environmental impact, cost savings, and sustainable transportation promotion. The chapter explores synergies between LLMs and EVs, focusing on potential applications and challenges, propelling progress in ITSs. Similarly, Multimodal Large Language Models (MLLMs) and their potential applications in the era of the EV represent a promising frontier in this landscape, offering enhanced capabilities to interpret and generate multimodal data, further enriching the EV ecosystem.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9592565894, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9592565894, 0.040743392]}",
         "True",
         "0.9592565894",
         "['Urban Management', 'Urban Planning', 'Public Services', 'Electric Vehicles', 'Living', 'Citizens', 'Citizen Engagement', 'Sustainability', 'Governance', 'Public Policies', 'Socioeconomics', 'Multimodal Transport', 'Industry', 'Logistics', 'Smart Grids', 'Energy Management', 'Construction', 'Business', 'Buildings', 'People', 'Cybersecurity', 'Environment', 'Mobility', 'Emergency Safety', 'Economy', 'Social Equity', 'Human', 'Power Distribution', 'Economic Management', 'Public Transit', 'Education', 'Marketing', 'Renewable Energy', 'Culture', 'Housing', 'Green Spaces', 'Water Quality', 'Air Quality', 'Transportation Systems', 'Pedestrian', 'Climate Change', 'Healthcare', 'Traffic Management', 'Waste Management', 'Finance', 'Pollution Control', 'Tourism', 'Bicycle']",
         "[0.6629307866, 0.41485983130000004, 0.0902432725, 0.0828751549, 0.0152446274, 0.0100585585, 0.005872727800000001, 0.0057266727, 0.0046097594, 0.0044820225, 0.0041451817, 0.0034536044, 0.0024134521, 0.0022124939, 0.0020049401000000002, 0.001995937, 0.0015408682, 0.0015022161, 0.0014005199000000001, 0.0012420657000000001, 0.0011965181, 0.0011302456, 0.0010781275, 0.0008976304, 0.0008660922, 0.0007093780000000001, 0.0006762564, 0.0006551134000000001, 0.0005796868, 0.0004847726, 0.00047250090000000003, 0.00046389580000000003, 0.00046330540000000004, 0.0004464936, 0.000441446, 0.0004310483, 0.0004266186, 0.0004223473, 0.00040204840000000004, 0.0003952164, 0.0003917225, 0.0003759595, 0.00035792450000000003, 0.0003567573, 0.0003532059, 0.00034552890000000004, 0.0003427064, 0.0003024947]",
         "[{'domain': 'Smart Governance', 'score': 0.6629307866}]",
         "{'is_genai': True, 'confidence': 0.5142045617103577, 'matched_keywords': ['multimodal model', 'large language model', 'small language model', 'llm', 'generative model', 'pretrained language model'], 'technology_categories': ['Transformer-Based Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('energy', 4), ('chapter', 2), ('battery', 2), ('charge', 2), ('llms', 2)], 'semantic_matches': [('multimodal model', 0.5142045617103577), ('large language model', 0.5006977319717407), ('small language model', 0.45116904377937317), ('llm', 0.4500049948692322), ('generative model', 0.4389333128929138), ('pretrained language model', 0.42831528186798096)]}",
         "True",
         "0.5142045617103577",
         "['multimodal model', 'large language model', 'small language model', 'llm', 'generative model', 'pretrained language model']",
         "['Transformer-Based Models', 'Hybrid & Multimodal Architectures']",
         "[('energy', 4), ('chapter', 2), ('battery', 2), ('charge', 2), ('llms', 2)]",
         "[('multimodal model', 0.5142045617103577), ('large language model', 0.5006977319717407), ('small language model', 0.45116904377937317), ('llm', 0.4500049948692322), ('generative model', 0.4389333128929138), ('pretrained language model', 0.42831528186798096)]"
        ],
        [
         "16",
         "Large language model empowered smart city mobility",
         "Chen Y.",
         "Frontiers of Engineering Management",
         "10.1007/s42524-025-4213-0",
         "2025",
         "Note",
         "https://api.elsevier.com/content/abstract/scopus_id/86000221064",
         "86000221064",
         "Smart city mobility faces mounting challenges as urban mobility systems grow increasingly complex. Large language models (LLMs) have promise in interpreting and processing multi-modal urban data, but issues like model instability, computational inefficiency, and concerns about reliability hinder their implementations. In this Comment, we outline feasible LLM application scenarios, critically evaluate existing challenges, and highlight avenues for advancing LLM-based mobility systems through multi-modal data integration and developing robust, lightweight models.",
         "['large language model', 'smart city mobility', 'transportation', 'urban computing']",
         "['Decision Sciences (miscellaneous)', 'Management Science and Operations Research']",
         "Smart city mobility faces mounting challenges as urban mobility systems grow increasingly complex. Large language models (LLMs) have promise in interpreting and processing multi-modal urban data, but issues like model instability, computational inefficiency, and concerns about reliability hinder their implementations.",
         "In this Comment, we outline feasible LLM application scenarios, critically evaluate existing challenges, and highlight avenues for advancing LLM-based mobility systems through multi-modal data integration and developing robust, lightweight models.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.819242239, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.819242239, 0.1807578057]}",
         "True",
         "0.819242239",
         "['Mobility', 'Multimodal Transport', 'Transportation Systems', 'Urban Management', 'Traffic Management', 'Urban Planning', 'Public Policies', 'Business', 'Public Services', 'Living', 'Logistics', 'Public Transit', 'Industry', 'Socioeconomics', 'People', 'Governance', 'Human', 'Economy', 'Environment', 'Citizens', 'Economic Management', 'Construction', 'Emergency Safety', 'Pedestrian', 'Smart Grids', 'Finance', 'Electric Vehicles', 'Marketing', 'Sustainability', 'Cybersecurity', 'Power Distribution', 'Citizen Engagement', 'Social Equity', 'Energy Management', 'Climate Change', 'Renewable Energy', 'Bicycle', 'Culture', 'Education', 'Air Quality', 'Green Spaces', 'Healthcare', 'Buildings', 'Water Quality', 'Pollution Control', 'Tourism', 'Housing', 'Waste Management']",
         "[0.9870635867, 0.9645484686, 0.8559128046000001, 0.2672301829, 0.0581125356, 0.0412676223, 0.0343279243, 0.0092856176, 0.0072302152, 0.0030912226, 0.0021862008, 0.0016657333, 0.0016377121, 0.0015237657, 0.0010968989, 0.0008450910000000001, 0.0006781094, 0.0006522764000000001, 0.0006447741, 0.0005854825, 0.0005166349000000001, 0.0005087103, 0.00048567230000000003, 0.00044785230000000004, 0.000441435, 0.00042211900000000004, 0.0004216334, 0.00040949380000000003, 0.0004064815, 0.00040090920000000003, 0.0003912413, 0.0003846732, 0.0003825473, 0.0003753448, 0.0003716489, 0.0003642722, 0.00035243, 0.0003320531, 0.0003276506, 0.00032340930000000003, 0.0003231821, 0.00032042860000000003, 0.00031294090000000003, 0.0003115209, 0.0003032978, 0.0002987347, 0.0002918355, 0.0002895478]",
         "[{'domain': 'Smart Mobility', 'score': 0.9870635867}]",
         "{'is_genai': True, 'confidence': 0.4587656259536743, 'matched_keywords': ['llm'], 'technology_categories': ['Transformer-Based Models'], 'bridge_terms': [('llm', 2), ('mobility', 2), ('model', 2), ('comment', 1), ('outline', 1)], 'semantic_matches': [('llm', 0.4587656259536743)]}",
         "True",
         "0.4587656259536743",
         "['llm']",
         "['Transformer-Based Models']",
         "[('llm', 2), ('mobility', 2), ('model', 2), ('comment', 1), ('outline', 1)]",
         "[('llm', 0.4587656259536743)]"
        ],
        [
         "17",
         "Research on extraction and application of elements of suzhou subway public art design based on deep learning",
         "Huang Y.",
         "Salud, Ciencia y Tecnologia - Serie de Conferencias",
         "10.56294/sctconf20251482",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/86000124515",
         "86000124515",
         "Introduction: Public art in urban spaces enhances aesthetics, reflects cultural identity, fosters community engagement, and contributes to place making, transforming everyday environments into meaningful, interactive public experiences. Limitations include a lack of deep learning applications in extracting public art elements, limited exploration of cultural integration, and insufficient focus on interactive design methods. Method: The proposed Great Cane Rat Algorithm-Tuned Scalable Generative Adversarial Network (GCR-SGAN) optimizes SGAN performance using GCRO for generating high-quality public art designs. The dataset includes images of public art, featuring murals, sculptures, and design elements for training and analysis. Histogram equalization will enhance image contrast, improving details, while Visual Geometry Group 16 (VGG16) feature extraction will capture high-level visual patterns and features, creating a robust representation for subsequent analysis and model training. The proposed work integrates SGAN for generating high-quality public art designs with GCR optimization to enhance GAN training, improving convergence stability, generation quality, and scalability for effective art design generation and analysis. Results: The results demonstrate that the GCR-SGAN model had accuracy of 0,98, which efficiently generates high-quality public art designs, optimizing both visual appeal and training stability. Conclusion: The approach effectively advances the generation of diverse, scalable art for real-world applications. Conclusions: This research is to apply deep learning techniques to extract and analyze elements of public art in Suzhou Subway, exploring their cultural significance, design patterns, and potential applications in urban planning, enhancing the aesthetic and functional aspects of subway spaces",
         "['Deep Learning', 'Great Cane Rat Algorithm', 'Public Art Design', 'Public Art Design', 'Scalable Generative Adversarial Network']",
         "['Multidisciplinary']",
         "Introduction: Public art in urban spaces enhances aesthetics, reflects cultural identity, fosters community engagement, and contributes to place making, transforming everyday environments into meaningful, interactive public experiences. Limitations include a lack of deep learning applications in extracting public art elements, limited exploration of cultural integration, and insufficient focus on interactive design methods. Method: The proposed Great Cane Rat Algorithm-Tuned Scalable Generative Adversarial Network (GCR-SGAN) optimizes SGAN performance using GCRO for generating high-quality public art designs. The dataset includes images of public art, featuring murals, sculptures, and design elements for training and analysis. Histogram equalization will enhance image contrast, improving details, while Visual Geometry Group 16 (VGG16) feature extraction will capture high-level visual patterns and features, creating a robust representation for subsequent analysis and model training. The proposed work integrates SGAN for generating high-quality public art designs with GCR optimization to enhance GAN training, improving convergence stability, generation quality, and scalability for effective art design generation and analysis. Results: The results demonstrate that the GCR-SGAN model had accuracy of 0,98, which efficiently generates high-quality public art designs, optimizing both visual appeal and training stability. Conclusion: The approach effectively advances the generation of diverse, scalable art for real-world applications.",
         "Conclusions: This research is to apply deep learning techniques to extract and analyze elements of public art in Suzhou Subway, exploring their cultural significance, design patterns, and potential applications in urban planning, enhancing the aesthetic and functional aspects of subway spaces",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9459506273, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9459506273, 0.054049342900000005]}",
         "True",
         "0.9459506273",
         "['Culture', 'Environment', 'Urban Planning', 'Public Policies', 'Living', 'Urban Management', 'Public Services', 'Industry', 'Construction', 'Citizen Engagement', 'Social Equity', 'Business', 'Socioeconomics', 'Citizens', 'Power Distribution', 'Education', 'Buildings', 'Emergency Safety', 'Economic Management', 'Sustainability', 'Multimodal Transport', 'Mobility', 'Renewable Energy', 'Governance', 'Energy Management', 'People', 'Human', 'Electric Vehicles', 'Air Quality', 'Logistics', 'Climate Change', 'Marketing', 'Pedestrian', 'Water Quality', 'Pollution Control', 'Smart Grids', 'Economy', 'Tourism', 'Bicycle', 'Transportation Systems', 'Waste Management', 'Housing', 'Public Transit', 'Cybersecurity', 'Healthcare', 'Traffic Management', 'Green Spaces', 'Finance']",
         "[0.810834527, 0.3725754619, 0.028688445700000002, 0.0042212047, 0.0036721730000000004, 0.0033338668000000003, 0.0032562625, 0.0029932682, 0.0022230684, 0.0021134485, 0.0017768879, 0.0016814689, 0.0015547544000000001, 0.0011317086000000001, 0.0011144271000000001, 0.0010672068, 0.0009695736, 0.0008643726000000001, 0.0008234869, 0.0007575693, 0.0007289643, 0.0006936665000000001, 0.000666688, 0.0006474590000000001, 0.0006264012, 0.0006209224, 0.0006009259000000001, 0.0005736478, 0.000563405, 0.0005317013, 0.00051041, 0.0004985254, 0.0004927803000000001, 0.0004898319, 0.0004618564, 0.00045988320000000003, 0.0004536154, 0.0004408797, 0.0004349951, 0.00043364600000000004, 0.0004280301, 0.0004241243, 0.0004235561, 0.00041205180000000003, 0.0004083714, 0.0004000294, 0.0003990527, 0.0003786892]",
         "[{'domain': 'Smart Living', 'score': 0.810834527}]",
         "{'is_genai': False, 'confidence': 0.0, 'matched_keywords': [], 'technology_categories': [], 'bridge_terms': [('public', 3), ('art', 3), ('design', 3), ('deep', 2), ('learning', 2)], 'semantic_matches': []}",
         "False",
         "0.0",
         "[]",
         "[]",
         "[('public', 3), ('art', 3), ('design', 3), ('deep', 2), ('learning', 2)]",
         "[]"
        ],
        [
         "18",
         "Person Re-identification Method Based on Hybrid Real-Synthetic Data",
         "Qi L.",
         "Jisuanji Yanjiu yu Fazhan/Computer Research and Development",
         "10.7544/issn1000-1239.202330718",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85218939768",
         "85218939768",
         "In recent years, the rapid urbanization and development of the social economy have led to a growing focus on public safety issues. Governments across the world are increasingly promoting the construction of smart cities and intelligent security systems to safeguard the lives and property of citizens and maintain social stability. Person re-identification (ReID) is an essential technology for building smart cities, with significant implications for security monitoring and criminal investigation applications. The goal of person re-identification is to accurately identify specific individuals captured under different cameras. However, due to intra-class differences resulting from various factors such as illumination, viewpoint, occlusion, and pose, person re-identification remains a challenging task in the field of computer vision. Although existing fully supervised person re-identification methods have made significant progress, the scarcity of data and labels poses a bottleneck for further improving model performance. To address this challenge, we introduce a more complex and diverse synthetic dataset with easy-to-obtain labels for auxiliary training, and propose a novel camera-aware asymmetric adversarial learning (CAAL) method that overcomes intra-class variation among multiple cameras and the domain-shift between real data and synthetic data, enabling the learning of camera-invariant feature representations from diverse data sources. Furthermore, to mitigate the impact of misleading information carried by synthetic datasets and prevent the model from overfitting to synthetic data during adversarial training, we propose using an auxiliary network trained on real-world data to constrain the training of the backbone network. Finally, we conduct extensive experiments on two public datasets to demonstrate the effectiveness of the proposed method.",
         "['adversarial learning', 'computer vision', 'image retrieval', 'knowledge distillation', 'person re-identification']",
         "['Software', 'Hardware and Architecture', 'Computer Networks and Communications']",
         "In recent years, the rapid urbanization and development of the social economy have led to a growing focus on public safety issues. Governments across the world are increasingly promoting the construction of smart cities and intelligent security systems to safeguard the lives and property of citizens and maintain social stability. Person re-identification (ReID) is an essential technology for building smart cities, with significant implications for security monitoring and criminal investigation applications. The goal of person re-identification is to accurately identify specific individuals captured under different cameras. However, due to intra-class differences resulting from various factors such as illumination, viewpoint, occlusion, and pose, person re-identification remains a challenging task in the field of computer vision. Although existing fully supervised person re-identification methods have made significant progress, the scarcity of data and labels poses a bottleneck for further improving model performance.",
         "To address this challenge, we introduce a more complex and diverse synthetic dataset with easy-to-obtain labels for auxiliary training, and propose a novel camera-aware asymmetric adversarial learning (CAAL) method that overcomes intra-class variation among multiple cameras and the domain-shift between real data and synthetic data, enabling the learning of camera-invariant feature representations from diverse data sources. Furthermore, to mitigate the impact of misleading information carried by synthetic datasets and prevent the model from overfitting to synthetic data during adversarial training, we propose using an auxiliary network trained on real-world data to constrain the training of the backbone network. Finally, we conduct extensive experiments on two public datasets to demonstrate the effectiveness of the proposed method.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8608036041, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8608036041, 0.139196381]}",
         "True",
         "0.8608036041",
         "['People', 'Human', 'Citizens', 'Governance', 'Urban Management', 'Public Services', 'Living', 'Public Policies', 'Socioeconomics', 'Cybersecurity', 'Construction', 'Emergency Safety', 'Urban Planning', 'Environment', 'Pedestrian', 'Buildings', 'Economy', 'Multimodal Transport', 'Public Transit', 'Mobility', 'Transportation Systems', 'Logistics', 'Citizen Engagement', 'Electric Vehicles', 'Economic Management', 'Business', 'Power Distribution', 'Energy Management', 'Social Equity', 'Sustainability', 'Climate Change', 'Air Quality', 'Industry', 'Culture', 'Healthcare', 'Renewable Energy', 'Marketing', 'Smart Grids', 'Traffic Management', 'Green Spaces', 'Water Quality', 'Housing', 'Finance', 'Pollution Control', 'Waste Management', 'Bicycle', 'Education', 'Tourism']",
         "[0.9938597679000001, 0.9145616293000001, 0.2933537066, 0.172394067, 0.09319771830000001, 0.0698217899, 0.0639252812, 0.055807706000000006, 0.012145326500000001, 0.0052887038, 0.0052600987, 0.0031201486000000003, 0.0026770141, 0.0017090178, 0.0009706285, 0.0007755956, 0.0006244804, 0.0005515395, 0.0005077344000000001, 0.0004964892, 0.0004921361, 0.00045470950000000003, 0.0004434977, 0.0004404721, 0.00043970260000000003, 0.00042196940000000004, 0.0004112395, 0.0004019171, 0.0003941322, 0.00039394150000000004, 0.0003890279, 0.0003856552, 0.0003835816, 0.0003829163, 0.0003775677, 0.000374743, 0.00037401240000000004, 0.00036967040000000003, 0.0003692416, 0.00036890100000000004, 0.0003672715, 0.0003594851, 0.0003557518, 0.0003535969, 0.0003491045, 0.00034771840000000004, 0.0003476105, 0.0003241013]",
         "[{'domain': 'Smart People', 'score': 0.9938597679000001}]",
         "{'is_genai': True, 'confidence': 0.5159686803817749, 'matched_keywords': ['contrastive learning', 'vision-language model', 'generative adversarial network', 'neural rendering', 'imagen', 'multimodal model', 'variational autoencoder'], 'technology_categories': ['Generative Adversarial Networks', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('datum', 5), ('synthetic', 4), ('dataset', 3), ('training', 3), ('propose', 3)], 'semantic_matches': [('contrastive learning', 0.5159686803817749), ('vision-language model', 0.487015962600708), ('generative adversarial network', 0.465094655752182), ('neural rendering', 0.4534566104412079), ('imagen', 0.41628456115722656), ('multimodal model', 0.40363234281539917), ('variational autoencoder', 0.4006572365760803)]}",
         "True",
         "0.5159686803817749",
         "['contrastive learning', 'vision-language model', 'generative adversarial network', 'neural rendering', 'imagen', 'multimodal model', 'variational autoencoder']",
         "['Generative Adversarial Networks', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('datum', 5), ('synthetic', 4), ('dataset', 3), ('training', 3), ('propose', 3)]",
         "[('contrastive learning', 0.5159686803817749), ('vision-language model', 0.487015962600708), ('generative adversarial network', 0.465094655752182), ('neural rendering', 0.4534566104412079), ('imagen', 0.41628456115722656), ('multimodal model', 0.40363234281539917), ('variational autoencoder', 0.4006572365760803)]"
        ],
        [
         "19",
         "Introduction: AI for and in Urban Planning",
         "Wang T.",
         "Urban Planning",
         "10.17645/up.9417",
         "2025",
         "Editorial",
         "https://api.elsevier.com/content/abstract/scopus_id/85216960085",
         "85216960085",
         "As a tool serving other disciplines of enquiry, artificial intelligence (AI) offers the potential of a potent discovery, a design and analysis paradigm to address (new) questions in urban planning. This thematic issue raises a forum for cross‐disciplinary dialogues at the intersection of urban planning and AI. Nine articles discuss both emerging use cases in urban planning practice and the relevant AI techniques being used and developed, as well as articulate the challenges associated. Future development of AI in urban planning shall address the ethical, inclusive, and just implications of AI applications for urban planning while navigating human and AI agents’ interactions and intra‐actions to facilitate a better understanding of the intentions of AI development and use, and the impacts on the behaviour of designers and users in complex urban planning practices.",
         "['artificial intelligence', 'development and evaluation needs', 'social‐technical evaluations', 'urban planning practices']",
         "['Urban Studies']",
         "As a tool serving other disciplines of enquiry, artificial intelligence (AI) offers the potential of a potent discovery, a design and analysis paradigm to address (new) questions in urban planning. This thematic issue raises a forum for cross‐disciplinary dialogues at the intersection of urban planning and AI. Nine articles discuss both emerging use cases in urban planning practice and the relevant AI techniques being used and developed, as well as articulate the challenges associated. Future development of AI in urban planning shall address the ethical, inclusive, and just implications of AI applications for urban planning while navigating human and AI agents’ interactions and intra‐actions to facilitate a better understanding of the intentions of AI development and use, and the impacts on the behaviour of designers and users in complex urban planning practices.",
         "As a tool serving other disciplines of enquiry, artificial intelligence (AI) offers the potential of a potent discovery, a design and analysis paradigm to address (new) questions in urban planning. This thematic issue raises a forum for cross‐disciplinary dialogues at the intersection of urban planning and AI. Nine articles discuss both emerging use cases in urban planning practice and the relevant AI techniques being used and developed, as well as articulate the challenges associated. Future development of AI in urban planning shall address the ethical, inclusive, and just implications of AI applications for urban planning while navigating human and AI agents’ interactions and intra‐actions to facilitate a better understanding of the intentions of AI development and use, and the impacts on the behaviour of designers and users in complex urban planning practices.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8572659492, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8572659492, 0.1427340806]}",
         "True",
         "0.8572659492",
         "['Urban Planning', 'Construction', 'Public Policies', 'Urban Management', 'People', 'Public Services', 'Buildings', 'Housing', 'Governance', 'Emergency Safety', 'Living', 'Environment', 'Education', 'Socioeconomics', 'Human', 'Citizens', 'Culture', 'Multimodal Transport', 'Economic Management', 'Power Distribution', 'Business', 'Smart Grids', 'Economy', 'Mobility', 'Social Equity', 'Electric Vehicles', 'Public Transit', 'Citizen Engagement', 'Industry', 'Water Quality', 'Green Spaces', 'Air Quality', 'Sustainability', 'Energy Management', 'Transportation Systems', 'Renewable Energy', 'Climate Change', 'Pedestrian', 'Cybersecurity', 'Logistics', 'Bicycle', 'Healthcare', 'Pollution Control', 'Tourism', 'Traffic Management', 'Waste Management', 'Finance', 'Marketing']",
         "[0.9383020997, 0.0077092154, 0.0049362485000000005, 0.0040843305, 0.0037284296000000003, 0.0032283012000000003, 0.0025030461, 0.0020762279000000002, 0.0018641403000000001, 0.0018441947, 0.0018221440000000002, 0.0016772026, 0.0016209264, 0.0014110639, 0.0012994743, 0.0011711421, 0.0011276819, 0.0010999435, 0.0009872762, 0.0009400916, 0.0009140727000000001, 0.0008554694, 0.0008174922, 0.0008158382, 0.0008016368, 0.0007809766, 0.0007205418000000001, 0.0007165942, 0.0007056369, 0.0006931052, 0.0006630126, 0.0006502886, 0.0006430183000000001, 0.0006365115, 0.0006102921, 0.0006055583000000001, 0.0005905231000000001, 0.0005515477, 0.0005514834, 0.0005151458, 0.0005103518, 0.0005055548, 0.0005023606, 0.0004966771, 0.0004813663, 0.000466315, 0.00045899920000000004, 0.00044828800000000003]",
         "[{'domain': 'Smart Governance', 'score': 0.9383020997}]",
         "{'is_genai': True, 'confidence': 0.6151596307754517, 'matched_keywords': ['designed with ai', 'ai capability', 'gen ai'], 'technology_categories': ['Transformer-Based Models'], 'bridge_terms': [('urban', 7), ('planning', 7), ('practice', 3), ('development', 3), ('artificial', 2)], 'semantic_matches': [('designed with ai', 0.6151596307754517), ('ai capability', 0.5808793306350708), ('gen ai', 0.5237419009208679)]}",
         "True",
         "0.6151596307754517",
         "['designed with ai', 'ai capability', 'gen ai']",
         "['Transformer-Based Models']",
         "[('urban', 7), ('planning', 7), ('practice', 3), ('development', 3), ('artificial', 2)]",
         "[('designed with ai', 0.6151596307754517), ('ai capability', 0.5808793306350708), ('gen ai', 0.5237419009208679)]"
        ],
        [
         "20",
         "A 3D Self-Awareness Diffusion Network for Multimodal Classification",
         "Ma M.",
         "IEEE Transactions on Multimedia",
         "10.1109/TMM.2025.3535295",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85216858184",
         "85216858184",
         "As imaging sensor technology in remote sensing has advanced quickly, multimodal fusion classification has become an important research direction in land cover and urban planning classification tasks. While generative models and image classification have greatly benefited from diffusion models, the present ones primarily concentrate on single-modality-driven diffusion processes. Therefore, this paper presents a 3D self-awareness diffusion network (3DSA-DiffNet) for multispectral (MS) and panchromatic (PAN) image fusion classification, which would make it easier to classify heterogeneous data from various sensors. First, in order to model the relationship between multi-channel spectra and multi-pixel spatial distributions as well as samples, respectively, a spatial-spectral joint denoising network (S2 JD-Net) is proposed. It can incorporate the diffusion process into the neural network to enhance the quality of diffusion features. Secondly, to imitate the brain's spatial-spectral coexistence learning mechanism, this work offers a 3D self-awareness module (3DSA-Module) that can learn the weight of each pixel in 3D space, resulting in extraordinarily high feature representation capabilities. Finally, experimental verification demonstrates that the 3D self-awareness diffusion fusion network driven by brain inspiration outperforms more sophisticated approaches on the Xi'an, Huhhot, and Muufl datasets.",
         "['3D self-attention mechanism', 'Diffusion model', 'fusion classification', 'multimodal', 'remote sensing images']",
         "['Signal Processing', 'Media Technology', 'Computer Science Applications', 'Electrical and Electronic Engineering']",
         "As imaging sensor technology in remote sensing has advanced quickly, multimodal fusion classification has become an important research direction in land cover and urban planning classification tasks. While generative models and image classification have greatly benefited from diffusion models, the present ones primarily concentrate on single-modality-driven diffusion processes.",
         "Therefore, this paper presents a 3D self-awareness diffusion network (3DSA-DiffNet) for multispectral (MS) and panchromatic (PAN) image fusion classification, which would make it easier to classify heterogeneous data from various sensors. First, in order to model the relationship between multi-channel spectra and multi-pixel spatial distributions as well as samples, respectively, a spatial-spectral joint denoising network (S2 JD-Net) is proposed. It can incorporate the diffusion process into the neural network to enhance the quality of diffusion features. Secondly, to imitate the brain's spatial-spectral coexistence learning mechanism, this work offers a 3D self-awareness module (3DSA-Module) that can learn the weight of each pixel in 3D space, resulting in extraordinarily high feature representation capabilities. Finally, experimental verification demonstrates that the 3D self-awareness diffusion fusion network driven by brain inspiration outperforms more sophisticated approaches on the Xi'an, Huhhot, and Muufl datasets.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8534167409000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8534167409000001, 0.1465832591]}",
         "True",
         "0.8534167409000001",
         "['Environment', 'Urban Planning', 'Urban Management', 'Climate Change', 'Public Services', 'Industry', 'Business', 'Construction', 'Transportation Systems', 'Emergency Safety', 'Buildings', 'Green Spaces', 'Socioeconomics', 'Public Policies', 'Governance', 'Housing', 'Logistics', 'Mobility', 'Living', 'Electric Vehicles', 'Economic Management', 'Multimodal Transport', 'Social Equity', 'Human', 'Citizens', 'Sustainability', 'Economy', 'Public Transit', 'People', 'Pedestrian', 'Education', 'Renewable Energy', 'Power Distribution', 'Pollution Control', 'Energy Management', 'Tourism', 'Air Quality', 'Smart Grids', 'Finance', 'Healthcare', 'Waste Management', 'Citizen Engagement', 'Water Quality', 'Marketing', 'Cybersecurity', 'Culture', 'Bicycle', 'Traffic Management']",
         "[0.9180898070000001, 0.0132219186, 0.0029412094000000003, 0.0028469639, 0.0024703133, 0.0023725778, 0.0016132727, 0.0010031322, 0.0008701613, 0.0008351346000000001, 0.0008249794, 0.0007936081, 0.0007597079000000001, 0.0007124714, 0.0006123187000000001, 0.0005632548000000001, 0.0005595880000000001, 0.0005344409, 0.0005323941, 0.0005297192000000001, 0.000501501, 0.0004868315, 0.00048226810000000003, 0.0004797693, 0.00047766830000000004, 0.0004489764, 0.0004235829, 0.0004223954, 0.00042121330000000003, 0.0004189063, 0.0004186839, 0.0004170088, 0.0004022559, 0.0003907041, 0.0003820205, 0.0003819914, 0.0003692514, 0.00036133400000000005, 0.0003579885, 0.00035284220000000004, 0.0003523337, 0.0003493513, 0.0003433436, 0.00034043450000000004, 0.0003295567, 0.0003146924, 0.0003143798, 0.0003075589]",
         "[{'domain': 'Smart Environment', 'score': 0.9180898070000001}]",
         "{'is_genai': True, 'confidence': 0.6774588823318481, 'matched_keywords': ['diffusion model', 'guided diffusion', 'latent diffusion', 'stable diffusion', 'text-to-image diffusion', 'multimodal fusion', 'neural rendering', 'neural implicit surface', 'multimodal model', '3d reconstruction', 'contrastive learning', '3d generative model'], 'technology_categories': ['Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('diffusion', 5), ('self', 4), ('network', 4), ('awareness', 3), ('fusion', 3)], 'semantic_matches': [('diffusion model', 0.6774588823318481), ('guided diffusion', 0.6753383874893188), ('latent diffusion', 0.6083431839942932), ('stable diffusion', 0.5977597236633301), ('text-to-image diffusion', 0.5943381786346436), ('multimodal fusion', 0.5382364392280579), ('neural rendering', 0.5239782333374023), ('neural implicit surface', 0.4693869948387146), ('multimodal model', 0.44915586709976196), ('3d reconstruction', 0.43733954429626465), ('contrastive learning', 0.4319435656070709), ('3d generative model', 0.4260263741016388)]}",
         "True",
         "0.6774588823318481",
         "['diffusion model', 'guided diffusion', 'latent diffusion', 'stable diffusion', 'text-to-image diffusion', 'multimodal fusion', 'neural rendering', 'neural implicit surface', 'multimodal model', '3d reconstruction', 'contrastive learning', '3d generative model']",
         "['Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('diffusion', 5), ('self', 4), ('network', 4), ('awareness', 3), ('fusion', 3)]",
         "[('diffusion model', 0.6774588823318481), ('guided diffusion', 0.6753383874893188), ('latent diffusion', 0.6083431839942932), ('stable diffusion', 0.5977597236633301), ('text-to-image diffusion', 0.5943381786346436), ('multimodal fusion', 0.5382364392280579), ('neural rendering', 0.5239782333374023), ('neural implicit surface', 0.4693869948387146), ('multimodal model', 0.44915586709976196), ('3d reconstruction', 0.43733954429626465), ('contrastive learning', 0.4319435656070709), ('3d generative model', 0.4260263741016388)]"
        ],
        [
         "21",
         "TomoSAR 3D reconstruction: Cascading adversarial strategy with sparse observation trajectory",
         "Zhu X.",
         "IET Computer Vision",
         "10.1049/cvi2.70001",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85216789668",
         "85216789668",
         "Synthetic aperture radar tomography (TomoSAR) has shown significant potential for the 3D Reconstruction of buildings, especially in critical areas such as topographic mapping, urban planning, and disaster monitoring. In practical applications, the constraints of observation trajectories frequently lead to the acquisition of a limited dataset of sparse SAR images, presenting challenges for TomoSAR 3D Reconstruction and affecting its signal-to-noise ratio and elevation resolution performance. The study introduces a cascade adversarial strategy based on the Conditional Generative Adversarial Network (CGAN), optimised explicitly for sparse observation trajectories. In the preliminary phase of the CGAN, the U-Net architecture was employed to capture more global information and enhance image detail recovery capability, which is subsequently utilised in the cascade refinement network. The ResNet34 residual network in the advanced network stage was adopted to bolster feature extraction and image generation capabilities further. Based on experimental validation performed on the curated TomoSAR 3D super-resolution dataset tailored for buildings, the findings reveal that the methodology yields a notable enhancement in image quality and accuracy compared to other techniques.",
         "['computer vision', 'learning (artificial intelligence)', 'remote sensing']",
         "['Software', 'Computer Vision and Pattern Recognition']",
         "Synthetic aperture radar tomography (TomoSAR) has shown significant potential for the 3D Reconstruction of buildings, especially in critical areas such as topographic mapping, urban planning, and disaster monitoring. In practical applications, the constraints of observation trajectories frequently lead to the acquisition of a limited dataset of sparse SAR images, presenting challenges for TomoSAR 3D Reconstruction and affecting its signal-to-noise ratio and elevation resolution performance.",
         "The study introduces a cascade adversarial strategy based on the Conditional Generative Adversarial Network (CGAN), optimised explicitly for sparse observation trajectories. In the preliminary phase of the CGAN, the U-Net architecture was employed to capture more global information and enhance image detail recovery capability, which is subsequently utilised in the cascade refinement network. The ResNet34 residual network in the advanced network stage was adopted to bolster feature extraction and image generation capabilities further. Based on experimental validation performed on the curated TomoSAR 3D super-resolution dataset tailored for buildings, the findings reveal that the methodology yields a notable enhancement in image quality and accuracy compared to other techniques.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9248148203000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9248148203000001, 0.075185135]}",
         "True",
         "0.9248148203000001",
         "['Buildings', 'Environment', 'Public Services', 'Industry', 'Urban Planning', 'Urban Management', 'Construction', 'Business', 'Emergency Safety', 'Housing', 'Mobility', 'Citizens', 'Living', 'Governance', 'Logistics', 'Human', 'Public Policies', 'Multimodal Transport', 'Air Quality', 'People', 'Power Distribution', 'Pedestrian', 'Sustainability', 'Socioeconomics', 'Public Transit', 'Social Equity', 'Economic Management', 'Economy', 'Green Spaces', 'Education', 'Electric Vehicles', 'Climate Change', 'Renewable Energy', 'Energy Management', 'Transportation Systems', 'Citizen Engagement', 'Waste Management', 'Smart Grids', 'Water Quality', 'Healthcare', 'Pollution Control', 'Finance', 'Culture', 'Cybersecurity', 'Marketing', 'Traffic Management', 'Tourism', 'Bicycle']",
         "[0.9118142724, 0.19380065800000001, 0.0356986597, 0.0331443399, 0.0230068974, 0.014664477700000001, 0.0132294782, 0.0118481955, 0.0045569376, 0.0039361189000000005, 0.0018432576, 0.0017885589, 0.0015790425, 0.0014924014, 0.0012654051, 0.0012328587000000001, 0.0010167537, 0.0009432341000000001, 0.0008522857000000001, 0.0008113729000000001, 0.000780422, 0.0007084932, 0.0006783979, 0.0006743817000000001, 0.0005980097000000001, 0.0005880925, 0.0005768216, 0.0005643124, 0.0005602273, 0.0005488461, 0.0005384801000000001, 0.0005218923, 0.0005218564, 0.0004995834, 0.0004922996000000001, 0.0004701997, 0.00046952610000000004, 0.00046884760000000003, 0.00045178330000000003, 0.00044992910000000004, 0.0004484572, 0.0004326054, 0.00042011420000000004, 0.0004088385, 0.00039754030000000004, 0.0003971848, 0.0003820025, 0.00034481700000000003]",
         "[{'domain': 'Smart Living', 'score': 0.9118142724}]",
         "{'is_genai': True, 'confidence': 0.6363064646720886, 'matched_keywords': ['generative adversarial network', 'contrastive learning', 'neural rendering', 'wgan-gp', 'generative model', 'imagen', 'vision-language model', '3d reconstruction', '3d gan', 'cgan', 'sr-gan', 'designed with ai', 'autoregressive models'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('network', 4), ('image', 3), ('cascade', 2), ('adversarial', 2), ('base', 2)], 'semantic_matches': [('generative adversarial network', 0.6363064646720886), ('contrastive learning', 0.5244296789169312), ('neural rendering', 0.5092135667800903), ('wgan-gp', 0.47003984451293945), ('generative model', 0.4638383388519287), ('imagen', 0.4334927201271057), ('vision-language model', 0.423682302236557), ('3d reconstruction', 0.4190986454486847), ('3d gan', 0.4173523187637329), ('cgan', 0.41701748967170715), ('sr-gan', 0.41185230016708374), ('designed with ai', 0.4091964066028595), ('autoregressive models', 0.4009525179862976)]}",
         "True",
         "0.6363064646720886",
         "['generative adversarial network', 'contrastive learning', 'neural rendering', 'wgan-gp', 'generative model', 'imagen', 'vision-language model', '3d reconstruction', '3d gan', 'cgan', 'sr-gan', 'designed with ai', 'autoregressive models']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('network', 4), ('image', 3), ('cascade', 2), ('adversarial', 2), ('base', 2)]",
         "[('generative adversarial network', 0.6363064646720886), ('contrastive learning', 0.5244296789169312), ('neural rendering', 0.5092135667800903), ('wgan-gp', 0.47003984451293945), ('generative model', 0.4638383388519287), ('imagen', 0.4334927201271057), ('vision-language model', 0.423682302236557), ('3d reconstruction', 0.4190986454486847), ('3d gan', 0.4173523187637329), ('cgan', 0.41701748967170715), ('sr-gan', 0.41185230016708374), ('designed with ai', 0.4091964066028595), ('autoregressive models', 0.4009525179862976)]"
        ],
        [
         "22",
         "Mobile Crowdsensing and Remote Sensing in Smart Cities: An Introduction",
         "Tony Santhosh G.",
         "Internet of Things",
         "10.1007/978-3-031-72732-0_1",
         "2025",
         "Book Chapter",
         "https://api.elsevier.com/content/abstract/scopus_id/85216380647",
         "85216380647",
         "The concept of smart cities has emerged as a transformative approach to urban planning and management, leveraging cutting-edge technologies to enhance the quality of life for urban residents. Two pivotal technologies driving the smart city revolution are mobile crowdsensing and remote sensing. This book chapter provides a comprehensive exploration of these technologies and their integration within the context of smart cities. Mobile crowdsensing harnesses the ubiquity of smartphones and wearable devices to gather real-time data from citizens. This data encompasses various aspects of urban life, including traffic patterns, air quality, noise levels, and more. The chapter delves into the intricacies of mobile crowdsensing, from task design and participant recruitment to data collection, fusion, and analysis. It highlights the role of citizens as active contributors to urban data generation and the impact of this approach on informed decision-making by city planners. Remote sensing, on the other hand, offers a bird’s-eye view of urban landscapes through satellites, drones, and other sensor-equipped platforms. This technology provides valuable insights into land use, environmental conditions, infrastructure, and more. The chapter explores the deployment of remote sensing in urban environments, covering sensor placement, data collection, transmission, processing, and interpretation. It underscores the significance of remote sensing in monitoring urban sprawl, environmental changes, and sustainable development. A major focus of the chapter is the integration of mobile crowdsensing and remote sensing within the smart city framework. By combining real-time, citizen-generated data with comprehensive remote sensing insights, cities can gain a holistic understanding of their complex ecosystems. This integrated approach empowers city planners, policymakers, and environmental agencies to make informed decisions regarding urban development, resource allocation, and emergency response. Throughout the chapter, practical examples and case studies illustrate the real-world applications of mobile crowdsensing and remote sensing in smart cities. These examples showcase how cities worldwide are leveraging these technologies to optimize transportation systems, manage public spaces, monitor pollution levels, and respond to urban challenges effectively. In conclusion, this book chapter provides a thorough exploration of mobile crowdsensing and remote sensing as fundamental pillars of smart city development. It emphasizes the role of these technologies in shaping sustainable and efficient urban landscapes, promoting citizen engagement, and enabling data-driven decision-making. The chapter serves as a valuable resource for researchers, urban planners, policymakers, and anyone interested in the dynamic field of smart cities and the technologies that drive them.",
         "['Algorithm optimization', 'Feature extraction', 'Mobile crowdsensing', 'Remote sensing', 'Sensor fusion', 'Ubiquitous mobile devices', 'Urban planning']",
         "['Signal Processing', 'Instrumentation', 'Computer Science Applications', 'Computer Networks and Communications', 'Computational Theory and Mathematics', 'Artificial Intelligence']",
         "The concept of smart cities has emerged as a transformative approach to urban planning and management, leveraging cutting-edge technologies to enhance the quality of life for urban residents. Two pivotal technologies driving the smart city revolution are mobile crowdsensing and remote sensing. This book chapter provides a comprehensive exploration of these technologies and their integration within the context of smart cities. Mobile crowdsensing harnesses the ubiquity of smartphones and wearable devices to gather real-time data from citizens. This data encompasses various aspects of urban life, including traffic patterns, air quality, noise levels, and more. The chapter delves into the intricacies of mobile crowdsensing, from task design and participant recruitment to data collection, fusion, and analysis.",
         "It highlights the role of citizens as active contributors to urban data generation and the impact of this approach on informed decision-making by city planners. Remote sensing, on the other hand, offers a bird’s-eye view of urban landscapes through satellites, drones, and other sensor-equipped platforms. This technology provides valuable insights into land use, environmental conditions, infrastructure, and more. The chapter explores the deployment of remote sensing in urban environments, covering sensor placement, data collection, transmission, processing, and interpretation. It underscores the significance of remote sensing in monitoring urban sprawl, environmental changes, and sustainable development. A major focus of the chapter is the integration of mobile crowdsensing and remote sensing within the smart city framework. By combining real-time, citizen-generated data with comprehensive remote sensing insights, cities can gain a holistic understanding of their complex ecosystems. This integrated approach empowers city planners, policymakers, and environmental agencies to make informed decisions regarding urban development, resource allocation, and emergency response. Throughout the chapter, practical examples and case studies illustrate the real-world applications of mobile crowdsensing and remote sensing in smart cities. These examples showcase how cities worldwide are leveraging these technologies to optimize transportation systems, manage public spaces, monitor pollution levels, and respond to urban challenges effectively. In conclusion, this book chapter provides a thorough exploration of mobile crowdsensing and remote sensing as fundamental pillars of smart city development. It emphasizes the role of these technologies in shaping sustainable and efficient urban landscapes, promoting citizen engagement, and enabling data-driven decision-making. The chapter serves as a valuable resource for researchers, urban planners, policymakers, and anyone interested in the dynamic field of smart cities and the technologies that drive them.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8542191386, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8542191386, 0.1457808912]}",
         "True",
         "0.8542191386",
         "['Urban Planning', 'Urban Management', 'People', 'Human', 'Citizens', 'Living', 'Governance', 'Business', 'Public Services', 'Environment', 'Mobility', 'Public Policies', 'Industry', 'Construction', 'Pedestrian', 'Socioeconomics', 'Air Quality', 'Emergency Safety', 'Citizen Engagement', 'Economy', 'Economic Management', 'Buildings', 'Water Quality', 'Marketing', 'Culture', 'Pollution Control', 'Education', 'Climate Change', 'Bicycle', 'Logistics', 'Housing', 'Finance', 'Power Distribution', 'Transportation Systems', 'Multimodal Transport', 'Sustainability', 'Renewable Energy', 'Cybersecurity', 'Social Equity', 'Public Transit', 'Energy Management', 'Electric Vehicles', 'Smart Grids', 'Healthcare', 'Tourism', 'Green Spaces', 'Waste Management', 'Traffic Management']",
         "[0.9303168058, 0.15565298500000002, 0.057258501600000004, 0.0542419218, 0.0252129752, 0.0236105192, 0.0199841429, 0.0192276146, 0.0145814884, 0.0145484125, 0.012061758, 0.0081656147, 0.006932228800000001, 0.0058451951000000005, 0.0033084566, 0.0023418223, 0.0022280940000000003, 0.0022050445, 0.0017399134, 0.0015809208, 0.0009160924, 0.0009129006, 0.0007999639, 0.0006502324000000001, 0.0006444119, 0.0006140779000000001, 0.0005646818, 0.0005591002, 0.0005541149000000001, 0.0005437362, 0.0005379035, 0.0005143136000000001, 0.0005011950000000001, 0.0004771919, 0.00047264640000000004, 0.000470862, 0.0004472524, 0.00044476760000000003, 0.0004434337, 0.0004414417, 0.0004380144, 0.0004152804, 0.0004121035, 0.0004021272, 0.00039785920000000004, 0.0003861208, 0.0003523331, 0.00033623320000000003]",
         "[{'domain': 'Smart Governance', 'score': 0.9303168058}]",
         "{'is_genai': False, 'confidence': 0.0, 'matched_keywords': [], 'technology_categories': [], 'bridge_terms': [('urban', 9), ('city', 8), ('remote', 8), ('sensing', 6), ('chapter', 5)], 'semantic_matches': []}",
         "False",
         "0.0",
         "[]",
         "[]",
         "[('urban', 9), ('city', 8), ('remote', 8), ('sensing', 6), ('chapter', 5)]",
         "[]"
        ],
        [
         "23",
         "Integrating LLMs With ITS: Recent Advances, Potentials, Challenges, and Future Directions",
         "Mahmud D.",
         "IEEE Transactions on Intelligent Transportation Systems",
         "10.1109/TITS.2025.3528116",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85216263322",
         "85216263322",
         "Intelligent Transportation Systems (ITS) are crucial for the development and operation of smart cities, addressing key challenges in efficiency, productivity, and environmental sustainability. This paper comprehensively reviews the transformative potential of Large Language Models (LLMs) in optimizing ITS. Initially, we provide an extensive overview of ITS, highlighting its components, operational principles, and overall effectiveness. We then delve into the theoretical background of various LLM techniques, such as GPT, T5, CTRL, and BERT, elucidating their relevance to ITS applications. Following this, we examine the wide-ranging applications of LLMs within ITS, including traffic flow prediction, vehicle detection and classification, autonomous driving, traffic sign recognition, and pedestrian detection. Our analysis reveals how these advanced models can significantly enhance traffic management and safety. Finally, we explore the challenges and limitations LLMs face in ITS, such as data availability, computational constraints, and ethical considerations. We also present several future research directions and potential innovations to address these challenges. This paper aims to guide researchers and practitioners through the complexities and opportunities of integrating LLMs in ITS, offering a roadmap to create more efficient, sustainable, and responsive next-generation transportation systems.",
         "['autonomous driving', 'Intelligent transportation systems', 'large language models', 'traffic flow optimization', 'traffic management']",
         "['Automotive Engineering', 'Mechanical Engineering', 'Computer Science Applications']",
         "Intelligent Transportation Systems (ITS) are crucial for the development and operation of smart cities, addressing key challenges in efficiency, productivity, and environmental sustainability.",
         "This paper comprehensively reviews the transformative potential of Large Language Models (LLMs) in optimizing ITS. Initially, we provide an extensive overview of ITS, highlighting its components, operational principles, and overall effectiveness. We then delve into the theoretical background of various LLM techniques, such as GPT, T5, CTRL, and BERT, elucidating their relevance to ITS applications. Following this, we examine the wide-ranging applications of LLMs within ITS, including traffic flow prediction, vehicle detection and classification, autonomous driving, traffic sign recognition, and pedestrian detection. Our analysis reveals how these advanced models can significantly enhance traffic management and safety. Finally, we explore the challenges and limitations LLMs face in ITS, such as data availability, computational constraints, and ethical considerations. We also present several future research directions and potential innovations to address these challenges. This paper aims to guide researchers and practitioners through the complexities and opportunities of integrating LLMs in ITS, offering a roadmap to create more efficient, sustainable, and responsive next-generation transportation systems.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.736694634, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.736694634, 0.2633053064]}",
         "True",
         "0.736694634",
         "['Transportation Systems', 'Mobility', 'Logistics', 'Urban Management', 'Business', 'Public Services', 'Industry', 'Public Policies', 'Traffic Management', 'Urban Planning', 'Economy', 'Multimodal Transport', 'Public Transit', 'Sustainability', 'Living', 'Socioeconomics', 'Economic Management', 'Environment', 'People', 'Governance', 'Citizens', 'Human', 'Construction', 'Electric Vehicles', 'Climate Change', 'Energy Management', 'Smart Grids', 'Finance', 'Bicycle', 'Emergency Safety', 'Renewable Energy', 'Citizen Engagement', 'Power Distribution', 'Air Quality', 'Cybersecurity', 'Buildings', 'Pedestrian', 'Green Spaces', 'Education', 'Social Equity', 'Pollution Control', 'Waste Management', 'Culture', 'Tourism', 'Marketing', 'Healthcare', 'Water Quality', 'Housing']",
         "[0.9944205284000001, 0.9655013084, 0.4874160588, 0.4733197689, 0.3927324116, 0.26485225560000003, 0.19367760420000002, 0.1072647646, 0.0852876529, 0.0542477965, 0.035391826200000004, 0.015298747500000001, 0.0150705865, 0.0041005053000000005, 0.0033692191, 0.0029573282, 0.0016096028, 0.0013868286, 0.0012876351000000001, 0.001130189, 0.0008801139000000001, 0.0006562371, 0.0006480007, 0.0005647719, 0.0005203582, 0.0004136483, 0.0004132485, 0.0004036522, 0.0004003638, 0.00039734600000000003, 0.00038472020000000003, 0.0003613531, 0.00035646370000000003, 0.0003563682, 0.00035083280000000003, 0.0003496473, 0.0003413699, 0.000340551, 0.0003397273, 0.00033617740000000003, 0.0003353416, 0.0003247107, 0.0003138194, 0.00031150650000000003, 0.0003098237, 0.0003098014, 0.000297627, 0.00029043360000000003]",
         "[{'domain': 'Smart Mobility', 'score': 0.9944205284000001}, {'domain': 'Smart Economy', 'score': 0.4874160588}, {'domain': 'Smart Governance', 'score': 0.4733197689}]",
         "{'is_genai': True, 'confidence': 0.7182498574256897, 'matched_keywords': ['large language model', 'pretrained language model', 'small language model', 'llm', 'vision-language model', 'generative model', 't5'], 'technology_categories': ['Transformer-Based Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('traffic', 5), ('llms', 3), ('paper', 2), ('potential', 2), ('large', 2)], 'semantic_matches': [('large language model', 0.7182498574256897), ('pretrained language model', 0.6233713030815125), ('small language model', 0.6119903326034546), ('llm', 0.4999007284641266), ('vision-language model', 0.4907296895980835), ('generative model', 0.4860866367816925), ('t5', 0.4216315746307373)]}",
         "True",
         "0.7182498574256897",
         "['large language model', 'pretrained language model', 'small language model', 'llm', 'vision-language model', 'generative model', 't5']",
         "['Transformer-Based Models', 'Hybrid & Multimodal Architectures']",
         "[('traffic', 5), ('llms', 3), ('paper', 2), ('potential', 2), ('large', 2)]",
         "[('large language model', 0.7182498574256897), ('pretrained language model', 0.6233713030815125), ('small language model', 0.6119903326034546), ('llm', 0.4999007284641266), ('vision-language model', 0.4907296895980835), ('generative model', 0.4860866367816925), ('t5', 0.4216315746307373)]"
        ],
        [
         "24",
         "Semi-Supervised Change Detection with Data Augmentation and Adaptive Thresholding for High-Resolution Remote Sensing Images",
         "Zhang W.",
         "Remote Sensing",
         "10.3390/rs17020178",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85215769768",
         "85215769768",
         "Change detection (CD) is an important research direction in the field of remote sensing, which aims to analyze the changes in the same area over different periods and is widely used in urban planning and environmental protection. While supervised learning methods in change detection have demonstrated substantial efficacy, they are often hindered by the rising costs associated with data annotation. Semi-supervised methods have attracted increasing interest, offering promising results with limited data labeling. These approaches typically employ strategies such as consistency regularization, pseudo-labeling, and generative adversarial networks. However, they usually face the problems of insufficient data augmentation and unbalanced quality and quantity of pseudo-labeling. To address the above problems, we propose a semi-supervised change detection method with data augmentation and adaptive threshold updating (DA-AT) for high-resolution remote sensing images. Firstly, a channel-level data augmentation (CLDA) technique is designed to enhance the strong augmentation effect and improve consistency regularization so as to address the problem of insufficient feature representation. Secondly, an adaptive threshold (AT) is proposed to dynamically adjust the threshold during the training process to balance the quality and quantity of pseudo-labeling so as to optimize the self-training process. Finally, an adaptive class weight (ACW) mechanism is proposed to alleviate the impact of the imbalance between the changed classes and the unchanged classes, which effectively enhances the learning ability of the model for the changed classes. We verify the effectiveness and robustness of the proposed method on two high-resolution remote sensing image datasets, WHU-CD and LEVIR-CD. We compare our method to five state-of-the-art change detection methods and show that it achieves better or comparable results.",
         "['adaptive threshold', 'consistency regularization', 'pseudo-labeling', 'semi-supervised change detection', 'unbalanced']",
         "['Earth and Planetary Sciences (all)']",
         "Change detection (CD) is an important research direction in the field of remote sensing, which aims to analyze the changes in the same area over different periods and is widely used in urban planning and environmental protection. While supervised learning methods in change detection have demonstrated substantial efficacy, they are often hindered by the rising costs associated with data annotation. Semi-supervised methods have attracted increasing interest, offering promising results with limited data labeling. These approaches typically employ strategies such as consistency regularization, pseudo-labeling, and generative adversarial networks. However, they usually face the problems of insufficient data augmentation and unbalanced quality and quantity of pseudo-labeling.",
         "To address the above problems, we propose a semi-supervised change detection method with data augmentation and adaptive threshold updating (DA-AT) for high-resolution remote sensing images. Firstly, a channel-level data augmentation (CLDA) technique is designed to enhance the strong augmentation effect and improve consistency regularization so as to address the problem of insufficient feature representation. Secondly, an adaptive threshold (AT) is proposed to dynamically adjust the threshold during the training process to balance the quality and quantity of pseudo-labeling so as to optimize the self-training process. Finally, an adaptive class weight (ACW) mechanism is proposed to alleviate the impact of the imbalance between the changed classes and the unchanged classes, which effectively enhances the learning ability of the model for the changed classes. We verify the effectiveness and robustness of the proposed method on two high-resolution remote sensing image datasets, WHU-CD and LEVIR-CD. We compare our method to five state-of-the-art change detection methods and show that it achieves better or comparable results.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7524419427, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7524419427, 0.24755808710000002]}",
         "True",
         "0.7524419427",
         "['Environment', 'Climate Change', 'Sustainability', 'Industry', 'Air Quality', 'Business', 'Public Services', 'Buildings', 'Construction', 'Public Policies', 'Water Quality', 'Urban Management', 'Living', 'Electric Vehicles', 'Multimodal Transport', 'Socioeconomics', 'Governance', 'Public Transit', 'Transportation Systems', 'Urban Planning', 'Economic Management', 'Logistics', 'Renewable Energy', 'Emergency Safety', 'Mobility', 'Green Spaces', 'Economy', 'Energy Management', 'Power Distribution', 'Housing', 'Citizens', 'Smart Grids', 'People', 'Human', 'Tourism', 'Pedestrian', 'Cybersecurity', 'Education', 'Social Equity', 'Healthcare', 'Pollution Control', 'Waste Management', 'Citizen Engagement', 'Finance', 'Bicycle', 'Marketing', 'Culture', 'Traffic Management']",
         "[0.9421498179000001, 0.1071527973, 0.0079766549, 0.0037642394, 0.0017398511, 0.0016414841000000002, 0.0016212426000000002, 0.0012773491000000001, 0.0012767228, 0.0012591799000000001, 0.0008777067, 0.0008772640000000001, 0.0007638911, 0.0007281414, 0.0006788965000000001, 0.0006542811, 0.0006540341, 0.0006436232, 0.0006348779, 0.0006091543, 0.0005860553, 0.0005772924, 0.0005547337, 0.0005532044, 0.0005202022000000001, 0.0005076134, 0.0005053841, 0.0005049753000000001, 0.000492778, 0.0004881787, 0.0004748539, 0.0004619822, 0.00045854040000000004, 0.0004291357, 0.0004266109, 0.00042543320000000003, 0.000420144, 0.0004163056, 0.00041443480000000004, 0.0004075122, 0.0004067837, 0.000403979, 0.0003944991, 0.0003854773, 0.0003743231, 0.000340932, 0.00033105170000000003, 0.0003262612]",
         "[{'domain': 'Smart Environment', 'score': 0.9421498179000001}]",
         "{'is_genai': True, 'confidence': 0.4580938220024109, 'matched_keywords': ['variational autoencoder', 'contrastive learning', 'score-based model', 'noise prediction'], 'technology_categories': ['Diffusion Models', 'Variational Autoencoders', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('change', 5), ('propose', 4), ('method', 4), ('adaptive', 4), ('threshold', 4)], 'semantic_matches': [('variational autoencoder', 0.4580938220024109), ('contrastive learning', 0.43030115962028503), ('score-based model', 0.4088401794433594), ('noise prediction', 0.40178653597831726)]}",
         "True",
         "0.4580938220024109",
         "['variational autoencoder', 'contrastive learning', 'score-based model', 'noise prediction']",
         "['Diffusion Models', 'Variational Autoencoders', 'Hybrid & Multimodal Architectures']",
         "[('change', 5), ('propose', 4), ('method', 4), ('adaptive', 4), ('threshold', 4)]",
         "[('variational autoencoder', 0.4580938220024109), ('contrastive learning', 0.43030115962028503), ('score-based model', 0.4088401794433594), ('noise prediction', 0.40178653597831726)]"
        ],
        [
         "25",
         "AI-Based Malicious Encrypted Traffic Detection in 5G Data Collection and Secure Sharing",
         "Han G.",
         "Electronics (Switzerland)",
         "10.3390/electronics14010051",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85214533890",
         "85214533890",
         "With the development and widespread application of network information, new technologies led by 5G are emerging, resulting in an increasingly complex network security environment and more diverse attack methods. Unlike traditional networks, 5G networks feature higher connection density, faster data transmission speeds, and lower latency, which are widely applied in scenarios such as smart cities, the Internet of Things, and autonomous driving. The vast amounts of sensitive data generated by these applications become primary targets during the processes of collection and secure sharing, and unauthorized access or tampering could lead to severe data breaches and integrity issues. However, as 5G networks extensively employ encryption technologies to protect data transmission, attackers can hide malicious content within encrypted communication, rendering traditional content-based traffic detection methods ineffective for identifying malicious encrypted traffic. To address this challenge, this paper proposes a malicious encrypted traffic detection method based on reconstructive domain adaptation and adversarial hybrid neural networks. The proposed method integrates generative adversarial networks with ResNet, ResNeXt, and DenseNet to construct an adversarial hybrid neural network, aiming to tackle the challenges of encrypted traffic detection. On this basis, a reconstructive domain adaptation module is introduced to reduce the distribution discrepancy between the source domain and the target domain, thereby enhancing cross-domain detection capabilities. By preprocessing traffic data from public datasets, the proposed method is capable of extracting deep features from encrypted traffic without the need for decryption. The generator utilizes the adversarial hybrid neural network module to generate realistic malicious encrypted traffic samples, while the discriminator achieves sample classification through high-dimensional feature extraction. Additionally, the domain classifier within the reconstructive domain adaptation module further improves the model’s stability and generalization across different network environments and time periods. Experimental results demonstrate that the proposed method significantly improves the accuracy and efficiency of malicious encrypted traffic detection in 5G network environments, effectively enhancing the detection performance of malicious traffic in 5G networks.",
         "['adversarial generative networks', 'deep learning', 'domain adaptation', 'encrypt malicious traffic', 'hybrid neural networks']",
         "['Control and Systems Engineering', 'Signal Processing', 'Hardware and Architecture', 'Computer Networks and Communications', 'Electrical and Electronic Engineering']",
         "With the development and widespread application of network information, new technologies led by 5G are emerging, resulting in an increasingly complex network security environment and more diverse attack methods. Unlike traditional networks, 5G networks feature higher connection density, faster data transmission speeds, and lower latency, which are widely applied in scenarios such as smart cities, the Internet of Things, and autonomous driving. The vast amounts of sensitive data generated by these applications become primary targets during the processes of collection and secure sharing, and unauthorized access or tampering could lead to severe data breaches and integrity issues. However, as 5G networks extensively employ encryption technologies to protect data transmission, attackers can hide malicious content within encrypted communication, rendering traditional content-based traffic detection methods ineffective for identifying malicious encrypted traffic.",
         "To address this challenge, this paper proposes a malicious encrypted traffic detection method based on reconstructive domain adaptation and adversarial hybrid neural networks. The proposed method integrates generative adversarial networks with ResNet, ResNeXt, and DenseNet to construct an adversarial hybrid neural network, aiming to tackle the challenges of encrypted traffic detection. On this basis, a reconstructive domain adaptation module is introduced to reduce the distribution discrepancy between the source domain and the target domain, thereby enhancing cross-domain detection capabilities. By preprocessing traffic data from public datasets, the proposed method is capable of extracting deep features from encrypted traffic without the need for decryption. The generator utilizes the adversarial hybrid neural network module to generate realistic malicious encrypted traffic samples, while the discriminator achieves sample classification through high-dimensional feature extraction. Additionally, the domain classifier within the reconstructive domain adaptation module further improves the model’s stability and generalization across different network environments and time periods. Experimental results demonstrate that the proposed method significantly improves the accuracy and efficiency of malicious encrypted traffic detection in 5G network environments, effectively enhancing the detection performance of malicious traffic in 5G networks.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.946269989, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.946269989, 0.0537299812]}",
         "True",
         "0.946269989",
         "['Cybersecurity', 'Industry', 'Environment', 'Business', 'Mobility', 'Public Services', 'Multimodal Transport', 'Traffic Management', 'Citizens', 'Public Policies', 'Emergency Safety', 'Finance', 'Urban Management', 'Green Spaces', 'Governance', 'Construction', 'Education', 'Living', 'Economy', 'Economic Management', 'Human', 'Public Transit', 'Socioeconomics', 'Power Distribution', 'Social Equity', 'Logistics', 'Buildings', 'Transportation Systems', 'People', 'Urban Planning', 'Air Quality', 'Energy Management', 'Healthcare', 'Pedestrian', 'Sustainability', 'Citizen Engagement', 'Climate Change', 'Renewable Energy', 'Marketing', 'Water Quality', 'Pollution Control', 'Culture', 'Smart Grids', 'Electric Vehicles', 'Housing', 'Waste Management', 'Bicycle', 'Tourism']",
         "[0.9110500813, 0.1923032701, 0.1688919812, 0.0336210653, 0.02344504, 0.0062997048, 0.0038147294000000003, 0.0018116583000000002, 0.0016543104000000001, 0.00155629, 0.0011494452, 0.001141852, 0.000881376, 0.0007275710000000001, 0.0006704366, 0.0006561350000000001, 0.0006384781, 0.0006052034, 0.0005936602, 0.0005233267, 0.0004918351000000001, 0.0004420067, 0.00044009510000000003, 0.0004292798, 0.0004279744, 0.0004187064, 0.00041392720000000004, 0.00040717710000000003, 0.0004005386, 0.00039954110000000004, 0.0003973959, 0.0003955268, 0.00039238120000000004, 0.00038713960000000004, 0.00038550410000000003, 0.00038024660000000003, 0.0003718091, 0.0003694676, 0.0003646507, 0.0003642648, 0.0003632865, 0.00035806, 0.0003493385, 0.00034821310000000003, 0.000346609, 0.0003457027, 0.00033167790000000004, 0.0003290603]",
         "[{'domain': 'Smart Governance', 'score': 0.9110500813}]",
         "{'is_genai': True, 'confidence': 0.7062047719955444, 'matched_keywords': ['generative adversarial network', 'generative capabilities', 'generative capability', 'encoder-decoder', 'variational autoencoder', 'multimodal embedding', 'cross-modal generation', 'generative model', 'hierarchical vae'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Variational Autoencoders', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('network', 9), ('traffic', 8), ('domain', 8), ('malicious', 5), ('encrypt', 5)], 'semantic_matches': [('generative adversarial network', 0.7062047719955444), ('generative capabilities', 0.4427882134914398), ('generative capability', 0.43977463245391846), ('encoder-decoder', 0.43731755018234253), ('variational autoencoder', 0.43572288751602173), ('multimodal embedding', 0.4347383677959442), ('cross-modal generation', 0.4342746436595917), ('generative model', 0.4309697151184082), ('hierarchical vae', 0.40715304017066956)]}",
         "True",
         "0.7062047719955444",
         "['generative adversarial network', 'generative capabilities', 'generative capability', 'encoder-decoder', 'variational autoencoder', 'multimodal embedding', 'cross-modal generation', 'generative model', 'hierarchical vae']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Variational Autoencoders', 'Hybrid & Multimodal Architectures']",
         "[('network', 9), ('traffic', 8), ('domain', 8), ('malicious', 5), ('encrypt', 5)]",
         "[('generative adversarial network', 0.7062047719955444), ('generative capabilities', 0.4427882134914398), ('generative capability', 0.43977463245391846), ('encoder-decoder', 0.43731755018234253), ('variational autoencoder', 0.43572288751602173), ('multimodal embedding', 0.4347383677959442), ('cross-modal generation', 0.4342746436595917), ('generative model', 0.4309697151184082), ('hierarchical vae', 0.40715304017066956)]"
        ],
        [
         "26",
         "Intelligent Agent Based Clustering and Optimal Multipath Routing for Energy-Efficient Wireless Sensor Networks in Smart City Applications: A Distributed AI-Driven Approach",
         "Patra B.K.",
         "Communications in Computer and Information Science",
         "10.1007/978-3-031-75170-7_22",
         "2025",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/85214109518",
         "85214109518",
         "The study proposes an innovative approach to enhance energy efficiency in Wireless Sensor Networks (WSNs) for smart city applications. The primary focus is on leveraging distributed artificial intelligence (AI) and multipath routing techniques to address challenges such as unequal clustering, poor cluster head selection, and excessive power consumption within WSNs. The approach uses agent-based clustering, where autonomous AI agents dynamically form clusters of sensor nodes based on real-time data characteristics. These clusters are then used for multipath routing, optimizing energy consumption, reliability, and congestion reduction. The distributed nature of AI agents allows for adaptive cluster formations. This algorithm aims to address issues related to uneven clustering, inefficient cluster head selection, and excessive power consumption. Additionally, the integration of agent-based clustering is proposed, involving the deployment of autonomous AI agents that dynamically cluster sensor nodes based on real-time data properties. These AI agents facilitate self-organization and adaptability, ensuring that clusters accurately reflect the evolving data landscape in urban environments. The approach also employs sophisticated energy management strategies at the sensor node level, such as duty cycling, adaptive transmission power control, and sleep-wake scheduling. Simulations in a smart city environment show significant improvements in energy efficiency, prolonging the network’s operational lifespan and improving service quality by mitigating data loss and latency issues. This approach contributes to the sustainable development and performance optimization of smart city infrastructure.",
         "['Clustering', 'Distributed Artificial Intelligence', 'Energy Efficiency', 'Multipath Routing', 'Smart Cities', 'Wireless Sensor Networks']",
         "['Computer Science (all)', 'Mathematics (all)']",
         "The study proposes an innovative approach to enhance energy efficiency in Wireless Sensor Networks (WSNs) for smart city applications. The primary focus is on leveraging distributed artificial intelligence (AI) and multipath routing techniques to address challenges such as unequal clustering, poor cluster head selection, and excessive power consumption within WSNs. The approach uses agent-based clustering, where autonomous AI agents dynamically form clusters of sensor nodes based on real-time data characteristics. These clusters are then used for multipath routing, optimizing energy consumption, reliability, and congestion reduction. The distributed nature of AI agents allows for adaptive cluster formations. This algorithm aims to address issues related to uneven clustering, inefficient cluster head selection, and excessive power consumption. Additionally, the integration of agent-based clustering is proposed, involving the deployment of autonomous AI agents that dynamically cluster sensor nodes based on real-time data properties. These AI agents facilitate self-organization and adaptability, ensuring that clusters accurately reflect the evolving data landscape in urban environments. The approach also employs sophisticated energy management strategies at the sensor node level, such as duty cycling, adaptive transmission power control, and sleep-wake scheduling. Simulations in a smart city environment show significant improvements in energy efficiency, prolonging the network’s operational lifespan and improving service quality by mitigating data loss and latency issues. This approach contributes to the sustainable development and performance optimization of smart city infrastructure.",
         "The study proposes an innovative approach to enhance energy efficiency in Wireless Sensor Networks (WSNs) for smart city applications. The primary focus is on leveraging distributed artificial intelligence (AI) and multipath routing techniques to address challenges such as unequal clustering, poor cluster head selection, and excessive power consumption within WSNs. The approach uses agent-based clustering, where autonomous AI agents dynamically form clusters of sensor nodes based on real-time data characteristics. These clusters are then used for multipath routing, optimizing energy consumption, reliability, and congestion reduction. The distributed nature of AI agents allows for adaptive cluster formations. This algorithm aims to address issues related to uneven clustering, inefficient cluster head selection, and excessive power consumption. Additionally, the integration of agent-based clustering is proposed, involving the deployment of autonomous AI agents that dynamically cluster sensor nodes based on real-time data properties. These AI agents facilitate self-organization and adaptability, ensuring that clusters accurately reflect the evolving data landscape in urban environments. The approach also employs sophisticated energy management strategies at the sensor node level, such as duty cycling, adaptive transmission power control, and sleep-wake scheduling. Simulations in a smart city environment show significant improvements in energy efficiency, prolonging the network’s operational lifespan and improving service quality by mitigating data loss and latency issues. This approach contributes to the sustainable development and performance optimization of smart city infrastructure.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7887420654, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7887420654, 0.211257875]}",
         "True",
         "0.7887420654",
         "['Energy Management', 'Sustainability', 'Environment', 'Industry', 'Business', 'Public Services', 'Economy', 'Socioeconomics', 'Economic Management', 'Mobility', 'Urban Planning', 'Living', 'Urban Management', 'Construction', 'Climate Change', 'Emergency Safety', 'Air Quality', 'Smart Grids', 'Public Policies', 'Multimodal Transport', 'Power Distribution', 'Citizens', 'Water Quality', 'Buildings', 'Education', 'Renewable Energy', 'Cybersecurity', 'Logistics', 'Transportation Systems', 'People', 'Pollution Control', 'Citizen Engagement', 'Green Spaces', 'Social Equity', 'Governance', 'Marketing', 'Waste Management', 'Tourism', 'Housing', 'Finance', 'Pedestrian', 'Electric Vehicles', 'Human', 'Traffic Management', 'Culture', 'Bicycle', 'Public Transit', 'Healthcare']",
         "[0.7550542951, 0.6827105880000001, 0.18064729870000001, 0.1452267468, 0.0302167498, 0.0301030446, 0.013402299000000001, 0.0095314803, 0.008675995300000001, 0.0070451838, 0.0067568724, 0.006647423800000001, 0.0065719872000000006, 0.0065411516000000005, 0.004856348, 0.0041427654, 0.0036180057000000003, 0.0033386971000000003, 0.0030265024, 0.0026746502000000003, 0.0021835517, 0.0021159358, 0.0020057375000000002, 0.0017604785000000002, 0.0016787187, 0.0016724515, 0.0014527654, 0.0014486206, 0.0013367116, 0.0013177454, 0.0012228888, 0.0010268601000000001, 0.0009122551, 0.0008601758000000001, 0.0008464680000000001, 0.0008041221, 0.0007810487, 0.0007469788, 0.0007450387000000001, 0.0007370712, 0.0007299108, 0.0007275018, 0.0007245779, 0.0007210202, 0.0006312517, 0.0006279541, 0.0006088362, 0.0005555252]",
         "[{'domain': 'Smart Environment', 'score': 0.7550542951}]",
         "{'is_genai': True, 'confidence': 0.5736041069030762, 'matched_keywords': ['ai capability', 'designed with ai', 'gen ai', 'generative adversarial network', 'occupancy network'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('cluster', 8), ('agent', 6), ('energy', 5), ('sensor', 5), ('approach', 4)], 'semantic_matches': [('ai capability', 0.5736041069030762), ('designed with ai', 0.5134618878364563), ('gen ai', 0.47080495953559875), ('generative adversarial network', 0.4512563943862915), ('occupancy network', 0.42580658197402954)]}",
         "True",
         "0.5736041069030762",
         "['ai capability', 'designed with ai', 'gen ai', 'generative adversarial network', 'occupancy network']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models']",
         "[('cluster', 8), ('agent', 6), ('energy', 5), ('sensor', 5), ('approach', 4)]",
         "[('ai capability', 0.5736041069030762), ('designed with ai', 0.5134618878364563), ('gen ai', 0.47080495953559875), ('generative adversarial network', 0.4512563943862915), ('occupancy network', 0.42580658197402954)]"
        ],
        [
         "27",
         "GIS Cartography A Guide to Effective Map Design",
         "Peterson G.N.",
         "GIS Cartography A Guide to Effective Map Design",
         "10.1201/9781003531302",
         "2025",
         "Book",
         "https://api.elsevier.com/content/abstract/scopus_id/85213912301",
         "85213912301",
         "The new edition of this well-established introductory cartography textbook is updated to respond to the demand for critical engagement with new technologies, the passion for inclusive design, and for preparing students to build competence in fundamental skills. Written in a friendly style, it is enjoyable to read and includes over 200 figures and maps, explaining everything from layout design to dynamic cartography issues. A new chapter discusses the role of artificial intelligence (AI) in cartography, and a significant expansion to 3D cartography has been incorporated into existing chapters. A new chapter on accessibility provides a thorough understanding of universal design. Additional updates include placements and best practices for digital map elements, global labeling techniques including language support, hybrid map styling, multiscale map testing, and information on 4D mapping. New in the Fourth Edition: Exploration of geospatial AI and generative AI in cartography and how they can already make an impact on workflows. New material on vision, motor, and cognitive accessibility techniques in map design. Expanded discussion on 3D cartography. All chapters are updated with new data and important new developments in cartography, including the importance of accessible design to ensure inclusivity for all users. Updated study questions and exercises to enhance student engagement and comprehension. New discussions of techniques such as aquarium cutaways, integrated north arrows, joy plots, hybrid satellite maps, crafted hachuring, as well as updated information on resolution and file types. This book is written as a go-to guide for learning the art and science of mapmaking. It is for undergraduate and graduate students taking courses in GIS and cartography and studying fields such as geography, geophysics, environmental engineering, urban planning, and so on. It is also a valuable resource for professionals interested in learning techniques and technologies for creating maps and visualizing geospatial datasets.",
         null,
         null,
         "The new edition of this well-established introductory cartography textbook is updated to respond to the demand for critical engagement with new technologies, the passion for inclusive design, and for preparing students to build competence in fundamental skills. Written in a friendly style, it is enjoyable to read and includes over 200 figures and maps, explaining everything from layout design to dynamic cartography issues. A new chapter discusses the role of artificial intelligence (AI) in cartography, and a significant expansion to 3D cartography has been incorporated into existing chapters. A new chapter on accessibility provides a thorough understanding of universal design. Additional updates include placements and best practices for digital map elements, global labeling techniques including language support, hybrid map styling, multiscale map testing, and information on 4D mapping. New in the Fourth Edition: Exploration of geospatial AI and generative AI in cartography and how they can already make an impact on workflows. New material on vision, motor, and cognitive accessibility techniques in map design. Expanded discussion on 3D cartography. All chapters are updated with new data and important new developments in cartography, including the importance of accessible design to ensure inclusivity for all users. Updated study questions and exercises to enhance student engagement and comprehension. New discussions of techniques such as aquarium cutaways, integrated north arrows, joy plots, hybrid satellite maps, crafted hachuring, as well as updated information on resolution and file types. This book is written as a go-to guide for learning the art and science of mapmaking. It is for undergraduate and graduate students taking courses in GIS and cartography and studying fields such as geography, geophysics, environmental engineering, urban planning, and so on. It is also a valuable resource for professionals interested in learning techniques and technologies for creating maps and visualizing geospatial datasets.",
         "The new edition of this well-established introductory cartography textbook is updated to respond to the demand for critical engagement with new technologies, the passion for inclusive design, and for preparing students to build competence in fundamental skills. Written in a friendly style, it is enjoyable to read and includes over 200 figures and maps, explaining everything from layout design to dynamic cartography issues. A new chapter discusses the role of artificial intelligence (AI) in cartography, and a significant expansion to 3D cartography has been incorporated into existing chapters. A new chapter on accessibility provides a thorough understanding of universal design. Additional updates include placements and best practices for digital map elements, global labeling techniques including language support, hybrid map styling, multiscale map testing, and information on 4D mapping. New in the Fourth Edition: Exploration of geospatial AI and generative AI in cartography and how they can already make an impact on workflows. New material on vision, motor, and cognitive accessibility techniques in map design. Expanded discussion on 3D cartography. All chapters are updated with new data and important new developments in cartography, including the importance of accessible design to ensure inclusivity for all users. Updated study questions and exercises to enhance student engagement and comprehension. New discussions of techniques such as aquarium cutaways, integrated north arrows, joy plots, hybrid satellite maps, crafted hachuring, as well as updated information on resolution and file types. This book is written as a go-to guide for learning the art and science of mapmaking. It is for undergraduate and graduate students taking courses in GIS and cartography and studying fields such as geography, geophysics, environmental engineering, urban planning, and so on. It is also a valuable resource for professionals interested in learning techniques and technologies for creating maps and visualizing geospatial datasets.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.6516404748, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.6516404748, 0.3483595848]}",
         "True",
         "0.6516404748",
         "['Education', 'Industry', 'People', 'Social Equity', 'Living', 'Human', 'Environment', 'Culture', 'Multimodal Transport', 'Emergency Safety', 'Public Services', 'Citizens', 'Citizen Engagement', 'Water Quality', 'Climate Change', 'Business', 'Socioeconomics', 'Public Policies', 'Construction', 'Renewable Energy', 'Green Spaces', 'Electric Vehicles', 'Economic Management', 'Air Quality', 'Mobility', 'Tourism', 'Transportation Systems', 'Energy Management', 'Public Transit', 'Logistics', 'Governance', 'Buildings', 'Sustainability', 'Housing', 'Economy', 'Power Distribution', 'Pedestrian', 'Pollution Control', 'Healthcare', 'Waste Management', 'Smart Grids', 'Bicycle', 'Finance', 'Cybersecurity', 'Traffic Management', 'Marketing', 'Urban Planning', 'Urban Management']",
         "[0.6152316332000001, 0.0053009982, 0.0036351872000000003, 0.0033363872, 0.0028553547000000003, 0.0027898988, 0.0025415632000000002, 0.0019184982, 0.0017833101, 0.0016894500000000001, 0.0016780854, 0.0015068640000000001, 0.0012366968, 0.0012166742000000001, 0.0011348267, 0.0011140364, 0.0011043351, 0.0011007062, 0.001062046, 0.0010602697, 0.0009946685, 0.0009557343000000001, 0.0009340741, 0.0008411134, 0.0008079171, 0.0007886992, 0.000770178, 0.0007538851000000001, 0.0007338303, 0.0007237598, 0.0007046181, 0.0006827685, 0.0006775316, 0.0006372503, 0.0006169645000000001, 0.0006155078, 0.0005855292000000001, 0.0005833474, 0.0005635095, 0.0005104012, 0.0005099369, 0.0005095717, 0.0005088543, 0.0004941526, 0.00046950510000000003, 0.0004683611, 0.0004536682, 0.0004401548]",
         "[{'domain': 'Smart People', 'score': 0.6152316332000001}]",
         "{'is_genai': True, 'confidence': 0.5985579490661621, 'matched_keywords': ['3d reconstruction', 'vision-language model', '3d generative model', 'ai capability', 'designed with ai', 'shape generation', 'contrastive learning', 'gen ai'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('new', 9), ('cartography', 8), ('map', 7), ('update', 5), ('design', 5)], 'semantic_matches': [('3d reconstruction', 0.5985579490661621), ('vision-language model', 0.5131552219390869), ('3d generative model', 0.492963969707489), ('ai capability', 0.48561030626296997), ('designed with ai', 0.4760540723800659), ('shape generation', 0.4197741746902466), ('contrastive learning', 0.40433362126350403), ('gen ai', 0.4010811150074005)]}",
         "True",
         "0.5985579490661621",
         "['3d reconstruction', 'vision-language model', '3d generative model', 'ai capability', 'designed with ai', 'shape generation', 'contrastive learning', 'gen ai']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('new', 9), ('cartography', 8), ('map', 7), ('update', 5), ('design', 5)]",
         "[('3d reconstruction', 0.5985579490661621), ('vision-language model', 0.5131552219390869), ('3d generative model', 0.492963969707489), ('ai capability', 0.48561030626296997), ('designed with ai', 0.4760540723800659), ('shape generation', 0.4197741746902466), ('contrastive learning', 0.40433362126350403), ('gen ai', 0.4010811150074005)]"
        ],
        [
         "28",
         "UP-Diff: Latent Diffusion Model for Remote Sensing Urban Prediction",
         "Wang Z.",
         "IEEE Geoscience and Remote Sensing Letters",
         "10.1109/LGRS.2024.3520133",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85213040539",
         "85213040539",
         "Remote sensing (RS) technology has become essential for monitoring urban development, including applications like population growth analysis, transportation congestion forecasting, and climate change detection (CD). However, its potential for future urban planning (UP), particularly in predicting future urban layouts remains largely unexplored. This study introduces UP-Diff, a novel method leveraging generative models for UP, to address this gap. UP-Diff leverages information from current urban layouts and planned change maps to predict future urban configurations. Key challenges addressed include the integration of urban layouts and change maps into latent diffusion model (LDM) through careful architecture improvements and the mitigation of limited training data by employing a pretrained stable diffusion (SD) model with fixed weights, trainable ConvNeXt, and trainable cross-attention layers. Our method significantly streamlines the UP process by automating layout predictions, thus reducing the time and effort required compared to traditional manual methods. Comprehensive evaluations on the learning, vision, and RS dataset (LEVIR-CD) and Sun Yat-Sen University dataset (SYSU-CD) validate that UP-Diff achieves high-fidelity predictions of future urban layouts, demonstrating its effectiveness and potential for advancing RS-based UP methodologies. Our code and model weights are available at https://github.com/zeyuwang-zju/UP-Diff.",
         "['Cross-attention', 'latent diffusion model (LDM)', 'remote sensing (RS)', 'UP-Diff', 'urban planning (UP)']",
         "['Geotechnical Engineering and Engineering Geology', 'Electrical and Electronic Engineering']",
         "Remote sensing (RS) technology has become essential for monitoring urban development, including applications like population growth analysis, transportation congestion forecasting, and climate change detection (CD). However, its potential for future urban planning (UP), particularly in predicting future urban layouts remains largely unexplored.",
         "This study introduces UP-Diff, a novel method leveraging generative models for UP, to address this gap. UP-Diff leverages information from current urban layouts and planned change maps to predict future urban configurations. Key challenges addressed include the integration of urban layouts and change maps into latent diffusion model (LDM) through careful architecture improvements and the mitigation of limited training data by employing a pretrained stable diffusion (SD) model with fixed weights, trainable ConvNeXt, and trainable cross-attention layers. Our method significantly streamlines the UP process by automating layout predictions, thus reducing the time and effort required compared to traditional manual methods. Comprehensive evaluations on the learning, vision, and RS dataset (LEVIR-CD) and Sun Yat-Sen University dataset (SYSU-CD) validate that UP-Diff achieves high-fidelity predictions of future urban layouts, demonstrating its effectiveness and potential for advancing RS-based UP methodologies. Our code and model weights are available at https://github.com/zeyuwang-zju/UP-Diff.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7332412004000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7332412004000001, 0.2667587698]}",
         "True",
         "0.7332412004000001",
         "['Urban Planning', 'Urban Management', 'Environment', 'Public Services', 'People', 'Buildings', 'Living', 'Business', 'Human', 'Socioeconomics', 'Governance', 'Climate Change', 'Public Policies', 'Economy', 'Mobility', 'Housing', 'Industry', 'Construction', 'Economic Management', 'Sustainability', 'Citizens', 'Logistics', 'Pedestrian', 'Transportation Systems', 'Multimodal Transport', 'Public Transit', 'Education', 'Social Equity', 'Power Distribution', 'Emergency Safety', 'Green Spaces', 'Finance', 'Electric Vehicles', 'Air Quality', 'Traffic Management', 'Citizen Engagement', 'Energy Management', 'Culture', 'Renewable Energy', 'Healthcare', 'Bicycle', 'Cybersecurity', 'Smart Grids', 'Water Quality', 'Waste Management', 'Marketing', 'Tourism', 'Pollution Control']",
         "[0.9579924941, 0.6772720218, 0.44656333330000003, 0.046207349700000004, 0.0425159149, 0.0261618905, 0.0219238531, 0.0213759728, 0.018104095, 0.0097761247, 0.0095444806, 0.008500312500000001, 0.0071943104, 0.0068718754000000005, 0.0049381247, 0.0048345765, 0.0041535045, 0.0034362117, 0.0020423296, 0.0019686467, 0.0019314105000000001, 0.0010803165, 0.0009608665000000001, 0.0009026377, 0.0007044531, 0.000675909, 0.0006556289, 0.0005392996, 0.0005383912, 0.0005183412, 0.000494906, 0.0004762731, 0.00047472300000000003, 0.00044818930000000004, 0.000446534, 0.0004361654, 0.00043420220000000003, 0.0004277428, 0.0004096101, 0.0003960842, 0.0003848034, 0.0003817029, 0.0003786194, 0.0003714381, 0.0003701774, 0.0003682033, 0.00035269340000000003, 0.0003451935]",
         "[{'domain': 'Smart Governance', 'score': 0.9579924941}, {'domain': 'Smart Environment', 'score': 0.44656333330000003}]",
         "{'is_genai': True, 'confidence': 0.5718766450881958, 'matched_keywords': ['diffusion model', 'guided diffusion', 'generative model', 'latent diffusion', 'text-to-image diffusion', '3d generative model', 'denoising diffusion', 'pretrained language model', 'generative capability', 'generative capabilities', 'large language model', 'variational autoencoder'], 'technology_categories': ['Transformer-Based Models', 'Diffusion Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('model', 5), ('urban', 5), ('diff', 4), ('layout', 4), ('method', 3)], 'semantic_matches': [('diffusion model', 0.5718766450881958), ('guided diffusion', 0.5662865042686462), ('generative model', 0.5640861988067627), ('latent diffusion', 0.4881972670555115), ('text-to-image diffusion', 0.4879401922225952), ('3d generative model', 0.4826897382736206), ('denoising diffusion', 0.46806126832962036), ('pretrained language model', 0.4533918797969818), ('generative capability', 0.4372304081916809), ('generative capabilities', 0.4342157542705536), ('large language model', 0.42968645691871643), ('variational autoencoder', 0.42608320713043213)]}",
         "True",
         "0.5718766450881958",
         "['diffusion model', 'guided diffusion', 'generative model', 'latent diffusion', 'text-to-image diffusion', '3d generative model', 'denoising diffusion', 'pretrained language model', 'generative capability', 'generative capabilities', 'large language model', 'variational autoencoder']",
         "['Transformer-Based Models', 'Diffusion Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models']",
         "[('model', 5), ('urban', 5), ('diff', 4), ('layout', 4), ('method', 3)]",
         "[('diffusion model', 0.5718766450881958), ('guided diffusion', 0.5662865042686462), ('generative model', 0.5640861988067627), ('latent diffusion', 0.4881972670555115), ('text-to-image diffusion', 0.4879401922225952), ('3d generative model', 0.4826897382736206), ('denoising diffusion', 0.46806126832962036), ('pretrained language model', 0.4533918797969818), ('generative capability', 0.4372304081916809), ('generative capabilities', 0.4342157542705536), ('large language model', 0.42968645691871643), ('variational autoencoder', 0.42608320713043213)]"
        ],
        [
         "29",
         "Forecasting land surface drought in urban environments based on machine learning model",
         "Chen J.",
         "Sustainable Cities and Society",
         "10.1016/j.scs.2024.106048",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85212344455",
         "85212344455",
         "Urban drought, a subtype of socio-economic drought, has received limited attention compared to other types. Given the shifts in water supply patterns due to global climate change and ongoing urbanization, understanding and predicting how urban design affects drought is crucial for sustainable human settlements. Previous research has primarily focused on large-scale predictive modeling, making it difficult for architects and urban designers to address potential drought risks. This study addresses that issue by proposing an urban planning prediction model based on generative adversarial networks that integrates temperature vegetation dryness index (TVDI) maps. The model is trained on relevant datasets by using Guangzhou as a case study, including land cover, land surface temperature, and normalized difference vegetation index data. TVDI maps are generated from untrained image pairs based on urban planning parameters. Model validation, including accuracy analysis and scenario simulations, is conducted to assess the model's ability to predict urban land surface drought resulting from changes in urban planning. This approach highlights its proactive capacity to anticipate and reveal long-term or gradually unfolding drought trends, offering valid tools for urban design and planning.",
         "['Generative Adversarial Networks (GAN)', 'Machine learning', 'Temperature Vegetation Dryness Index (TVDI)', 'Urban drought']",
         "['Geography, Planning and Development', 'Civil and Structural Engineering', 'Renewable Energy, Sustainability and the Environment', 'Transportation']",
         "Urban drought, a subtype of socio-economic drought, has received limited attention compared to other types. Given the shifts in water supply patterns due to global climate change and ongoing urbanization, understanding and predicting how urban design affects drought is crucial for sustainable human settlements. Previous research has primarily focused on large-scale predictive modeling, making it difficult for architects and urban designers to address potential drought risks.",
         "This study addresses that issue by proposing an urban planning prediction model based on generative adversarial networks that integrates temperature vegetation dryness index (TVDI) maps. The model is trained on relevant datasets by using Guangzhou as a case study, including land cover, land surface temperature, and normalized difference vegetation index data. TVDI maps are generated from untrained image pairs based on urban planning parameters. Model validation, including accuracy analysis and scenario simulations, is conducted to assess the model's ability to predict urban land surface drought resulting from changes in urban planning. This approach highlights its proactive capacity to anticipate and reveal long-term or gradually unfolding drought trends, offering valid tools for urban design and planning.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9534298778, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9534298778, 0.0465700924]}",
         "True",
         "0.9534298778",
         "['Environment', 'Urban Planning', 'Sustainability', 'Urban Management', 'Socioeconomics', 'Living', 'Buildings', 'Construction', 'Water Quality', 'Climate Change', 'Human', 'Housing', 'Public Services', 'People', 'Economic Management', 'Public Policies', 'Social Equity', 'Economy', 'Emergency Safety', 'Citizens', 'Business', 'Governance', 'Logistics', 'Industry', 'Green Spaces', 'Mobility', 'Healthcare', 'Energy Management', 'Citizen Engagement', 'Culture', 'Pollution Control', 'Renewable Energy', 'Multimodal Transport', 'Power Distribution', 'Finance', 'Marketing', 'Education', 'Waste Management', 'Smart Grids', 'Transportation Systems', 'Electric Vehicles', 'Cybersecurity', 'Tourism', 'Air Quality', 'Pedestrian', 'Public Transit', 'Bicycle', 'Traffic Management']",
         "[0.9703714848, 0.8746429682, 0.761932373, 0.5289353728, 0.38783279060000003, 0.3578694463, 0.24059037860000002, 0.1518775523, 0.1375042349, 0.12490426, 0.0909241065, 0.0326904096, 0.0316613391, 0.0279376172, 0.026014721, 0.0221511573, 0.0143936099, 0.0114026358, 0.0105807846, 0.0089395922, 0.0085899578, 0.0022359418000000002, 0.0012871701, 0.0008003133000000001, 0.0006117566000000001, 0.0005723456, 0.0005441522000000001, 0.0005347938, 0.0005311758, 0.0005095472, 0.0004993055, 0.000494958, 0.0004743462, 0.00046843700000000004, 0.0004545791, 0.000424207, 0.00042350840000000004, 0.0004153772, 0.00040395620000000003, 0.0003992067, 0.00036698400000000005, 0.0003493625, 0.0003476716, 0.0003327439, 0.00032604140000000003, 0.0003259045, 0.0002940032, 0.0002844607]",
         "[{'domain': 'Smart Environment', 'score': 0.9703714848}, {'domain': 'Smart Governance', 'score': 0.8746429682}]",
         "{'is_genai': True, 'confidence': 0.44484376907348633, 'matched_keywords': ['generative adversarial network'], 'technology_categories': ['Generative Adversarial Networks'], 'bridge_terms': [('urban', 6), ('planning', 4), ('model', 4), ('temperature', 3), ('vegetation', 3)], 'semantic_matches': [('generative adversarial network', 0.44484376907348633)]}",
         "True",
         "0.44484376907348633",
         "['generative adversarial network']",
         "['Generative Adversarial Networks']",
         "[('urban', 6), ('planning', 4), ('model', 4), ('temperature', 3), ('vegetation', 3)]",
         "[('generative adversarial network', 0.44484376907348633)]"
        ],
        [
         "30",
         "GroundUp: Rapid Sketch-Based 3D City Massing",
         "Ünlü G.E.",
         "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
         "10.1007/978-3-031-73209-6_13",
         "2025",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/85210022862",
         "85210022862",
         "We propose GroundUp, the first sketch-based ideation tool for 3D city massing of urban areas. We focus on early-stage urban design, where sketching is a common tool and the design starts from balancing building volumes (masses) and open spaces. With Human-Centered AI in mind, we aim to help architects quickly revise their ideas by easily switching between 2D sketches and 3D models, allowing for smoother iteration and sharing of ideas. Inspired by feedback from architects and existing workflows, our system takes as a first input a user sketch of multiple buildings in a top-down view. The user then draws a perspective sketch of the envisioned site. Our method is designed to exploit the complementarity of information in the two sketches and allows users to quickly preview and adjust the inferred 3D shapes. Our model has two main components. First, we propose a novel sketch-to-depth prediction network for perspective sketches that exploits top-down sketch shapes. Second, we use depth cues derived from the perspective sketch as a condition to our diffusion model, which ultimately completes the geometry in a top-down view. Thus, our final 3D geometry is represented as a heightfield, allowing users to construct the city “from the ground up”. The code, datasets, and interface are available at visual.cs.ucl.ac.uk/pubs/groundup.",
         null,
         null,
         "We propose GroundUp, the first sketch-based ideation tool for 3D city massing of urban areas. We focus on early-stage urban design, where sketching is a common tool and the design starts from balancing building volumes (masses) and open spaces. With Human-Centered AI in mind, we aim to help architects quickly revise their ideas by easily switching between 2D sketches and 3D models, allowing for smoother iteration and sharing of ideas. Inspired by feedback from architects and existing workflows, our system takes as a first input a user sketch of multiple buildings in a top-down view. The user then draws a perspective sketch of the envisioned site. Our method is designed to exploit the complementarity of information in the two sketches and allows users to quickly preview and adjust the inferred 3D shapes. Our model has two main components. First, we propose a novel sketch-to-depth prediction network for perspective sketches that exploits top-down sketch shapes. Second, we use depth cues derived from the perspective sketch as a condition to our diffusion model, which ultimately completes the geometry in a top-down view. Thus, our final 3D geometry is represented as a heightfield, allowing users to construct the city “from the ground up”. The code, datasets, and interface are available at visual.cs.ucl.ac.uk/pubs/groundup.",
         "We propose GroundUp, the first sketch-based ideation tool for 3D city massing of urban areas. We focus on early-stage urban design, where sketching is a common tool and the design starts from balancing building volumes (masses) and open spaces. With Human-Centered AI in mind, we aim to help architects quickly revise their ideas by easily switching between 2D sketches and 3D models, allowing for smoother iteration and sharing of ideas. Inspired by feedback from architects and existing workflows, our system takes as a first input a user sketch of multiple buildings in a top-down view. The user then draws a perspective sketch of the envisioned site. Our method is designed to exploit the complementarity of information in the two sketches and allows users to quickly preview and adjust the inferred 3D shapes. Our model has two main components. First, we propose a novel sketch-to-depth prediction network for perspective sketches that exploits top-down sketch shapes. Second, we use depth cues derived from the perspective sketch as a condition to our diffusion model, which ultimately completes the geometry in a top-down view. Thus, our final 3D geometry is represented as a heightfield, allowing users to construct the city “from the ground up”. The code, datasets, and interface are available at visual.cs.ucl.ac.uk/pubs/groundup.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9372671247000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9372671247000001, 0.0627329201]}",
         "True",
         "0.9372671247000001",
         "['Buildings', 'Urban Planning', 'Environment', 'Construction', 'Industry', 'Housing', 'Education', 'Living', 'People', 'Human', 'Public Services', 'Urban Management', 'Business', 'Culture', 'Public Policies', 'Socioeconomics', 'Economic Management', 'Emergency Safety', 'Citizens', 'Sustainability', 'Economy', 'Citizen Engagement', 'Social Equity', 'Power Distribution', 'Logistics', 'Governance', 'Water Quality', 'Pollution Control', 'Energy Management', 'Climate Change', 'Multimodal Transport', 'Air Quality', 'Pedestrian', 'Renewable Energy', 'Waste Management', 'Mobility', 'Marketing', 'Cybersecurity', 'Smart Grids', 'Public Transit', 'Electric Vehicles', 'Green Spaces', 'Transportation Systems', 'Finance', 'Bicycle', 'Tourism', 'Healthcare', 'Traffic Management']",
         "[0.7225217819, 0.4148624241, 0.3346184492, 0.056685932, 0.0203571133, 0.015928892400000002, 0.0154547812, 0.014147059100000001, 0.0124619259, 0.0106375562, 0.0073288502000000005, 0.0042127338, 0.0040454553, 0.0029423391, 0.002029635, 0.0011981318000000001, 0.0011367471, 0.0010938799, 0.0009854698, 0.0008266382, 0.0006595661, 0.0006256873, 0.0005737407, 0.0005617096000000001, 0.0005552125, 0.000537076, 0.0005099013, 0.0004921377, 0.0004802624, 0.0004780922, 0.0004761205, 0.0004638156, 0.000458058, 0.0004488483, 0.0004402238, 0.00042545, 0.00042315990000000003, 0.00042292800000000004, 0.00042219750000000003, 0.00041527830000000004, 0.00040916870000000003, 0.000394901, 0.0003944772, 0.0003937339, 0.0003935813, 0.000390493, 0.0003860919, 0.0003846821]",
         "[{'domain': 'Smart Living', 'score': 0.7225217819}, {'domain': 'Smart Governance', 'score': 0.4148624241}]",
         "{'is_genai': True, 'confidence': 0.5334031581878662, 'matched_keywords': ['neural rendering', 'designed with ai', '3d generative model', 'multimodal model', 'guided diffusion', 'generative model', '3d reconstruction', 'vision-language model', 'diffusion model', 'neural implicit surface', 'shape generation', 'contrastive learning', 'flow model', 'latent space modeling'], 'technology_categories': ['Transformer-Based Models', 'Diffusion Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('sketch', 9), ('user', 4), ('design', 3), ('model', 3), ('allow', 3)], 'semantic_matches': [('neural rendering', 0.5334031581878662), ('designed with ai', 0.5332404375076294), ('3d generative model', 0.5261890888214111), ('multimodal model', 0.5140476822853088), ('guided diffusion', 0.5118683576583862), ('generative model', 0.5087403655052185), ('3d reconstruction', 0.49902430176734924), ('vision-language model', 0.49000808596611023), ('diffusion model', 0.47403258085250854), ('neural implicit surface', 0.46297186613082886), ('shape generation', 0.4534648656845093), ('contrastive learning', 0.448537141084671), ('flow model', 0.40622735023498535), ('latent space modeling', 0.40580469369888306)]}",
         "True",
         "0.5334031581878662",
         "['neural rendering', 'designed with ai', '3d generative model', 'multimodal model', 'guided diffusion', 'generative model', '3d reconstruction', 'vision-language model', 'diffusion model', 'neural implicit surface', 'shape generation', 'contrastive learning', 'flow model', 'latent space modeling']",
         "['Transformer-Based Models', 'Diffusion Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('sketch', 9), ('user', 4), ('design', 3), ('model', 3), ('allow', 3)]",
         "[('neural rendering', 0.5334031581878662), ('designed with ai', 0.5332404375076294), ('3d generative model', 0.5261890888214111), ('multimodal model', 0.5140476822853088), ('guided diffusion', 0.5118683576583862), ('generative model', 0.5087403655052185), ('3d reconstruction', 0.49902430176734924), ('vision-language model', 0.49000808596611023), ('diffusion model', 0.47403258085250854), ('neural implicit surface', 0.46297186613082886), ('shape generation', 0.4534648656845093), ('contrastive learning', 0.448537141084671), ('flow model', 0.40622735023498535), ('latent space modeling', 0.40580469369888306)]"
        ],
        [
         "31",
         "Building usage prediction in complex urban scenes by fusing text and facade features from street view images using deep learning",
         "Ramalingam S.P.",
         "Building and Environment",
         "10.1016/j.buildenv.2024.112174",
         "2025",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85206071722",
         "85206071722",
         "Building usage maps are inputs to many urban planning applications, however, the existing methods and the available data have limitations in generating instance-level high-resolution usage maps. In this study we tackle this problem by utilizing Street View Images (SVIs) and proposing a novel ensemble learning architecture that leverages building facade features and text extracted from hoardings, posters, etc. on buildings to predict the usage class. A pre-trained object detection model i.e., Grounding DINO, is implemented to efficiently identify buildings. A novel manually labeled training data of detected buildings corresponding to their usage is used to extract features from building facades across diverse Indian cities (Hyderabad, Mumbai, Bangalore, Delhi) using Vision Transformer (ViT) model. Following this, CLIPSeg a pre-trained segmentation model is used to recognizes text specifically on building elements like signs, posters, and banners. We then leverage GPT-3.5 Turbo, a Large Language Model (LLM), fine-tuned with a specifically designed few-shot prompting method, to infer building usage from the recognized text. To achieve optimal performance, the proposed ensemble linear metaclassifier combines predictions from ViT and LLM model. The predicted building usages are attributed to their corresponding locations to develop spatial maps. An analysis of our framework compared against ground truth data collected from various Indian cities reveals significantly accurate outcomes. Our findings highlight the utility of textual information in classifying utilities and commercial buildings, while features extracted from vision models prove more informative for residential buildings. Our approach can automate the generation of roadside building attributes and usage details on a larger scale.",
         "['Building text', 'Building usage map', 'GIS', 'LLM', 'Multi-modal deep learning', 'Street view image']",
         "['Environmental Engineering', 'Civil and Structural Engineering', 'Geography, Planning and Development', 'Building and Construction']",
         "Building usage maps are inputs to many urban planning applications, however, the existing methods and the available data have limitations in generating instance-level high-resolution usage maps.",
         "In this study we tackle this problem by utilizing Street View Images (SVIs) and proposing a novel ensemble learning architecture that leverages building facade features and text extracted from hoardings, posters, etc. on buildings to predict the usage class. A pre-trained object detection model i.e., Grounding DINO, is implemented to efficiently identify buildings. A novel manually labeled training data of detected buildings corresponding to their usage is used to extract features from building facades across diverse Indian cities (Hyderabad, Mumbai, Bangalore, Delhi) using Vision Transformer (ViT) model. Following this, CLIPSeg a pre-trained segmentation model is used to recognizes text specifically on building elements like signs, posters, and banners. We then leverage GPT-3.5 Turbo, a Large Language Model (LLM), fine-tuned with a specifically designed few-shot prompting method, to infer building usage from the recognized text. To achieve optimal performance, the proposed ensemble linear metaclassifier combines predictions from ViT and LLM model. The predicted building usages are attributed to their corresponding locations to develop spatial maps. An analysis of our framework compared against ground truth data collected from various Indian cities reveals significantly accurate outcomes. Our findings highlight the utility of textual information in classifying utilities and commercial buildings, while features extracted from vision models prove more informative for residential buildings. Our approach can automate the generation of roadside building attributes and usage details on a larger scale.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7117540836, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7117540836, 0.28824585680000003]}",
         "True",
         "0.7117540836",
         "['Buildings', 'Urban Planning', 'Urban Management', 'Construction', 'Environment', 'Housing', 'Business', 'Public Services', 'Socioeconomics', 'Living', 'Governance', 'Public Policies', 'Economic Management', 'Logistics', 'Industry', 'Economy', 'Sustainability', 'Emergency Safety', 'Energy Management', 'Multimodal Transport', 'Human', 'Mobility', 'Electric Vehicles', 'People', 'Citizens', 'Transportation Systems', 'Power Distribution', 'Smart Grids', 'Social Equity', 'Public Transit', 'Education', 'Climate Change', 'Renewable Energy', 'Citizen Engagement', 'Traffic Management', 'Air Quality', 'Pedestrian', 'Finance', 'Green Spaces', 'Water Quality', 'Healthcare', 'Tourism', 'Waste Management', 'Pollution Control', 'Culture', 'Cybersecurity', 'Bicycle', 'Marketing']",
         "[0.9978593588, 0.9850290418000001, 0.7214719057, 0.6258604527, 0.5593144894000001, 0.34223967790000004, 0.0052301409, 0.0015288525, 0.0013515141, 0.0010845216, 0.0009897032, 0.0007496050000000001, 0.0006647024, 0.000651593, 0.0006155837, 0.0005979566000000001, 0.0005768921, 0.0005562931000000001, 0.0005300275, 0.0005097400000000001, 0.000496762, 0.00048546980000000004, 0.0004788772, 0.00047451160000000004, 0.0004629492, 0.00044826830000000003, 0.00044381790000000003, 0.0004126147, 0.00040667700000000004, 0.0004018838, 0.00040143890000000004, 0.0003986066, 0.0003981825, 0.00039435910000000003, 0.0003760694, 0.0003684703, 0.0003683854, 0.0003612301, 0.0003579445, 0.0003459995, 0.0003458759, 0.0003439634, 0.0003432463, 0.0003410767, 0.0003379589, 0.0003179435, 0.00030782410000000003, 0.0003073328]",
         "[{'domain': 'Smart Living', 'score': 0.9978593588}, {'domain': 'Smart Governance', 'score': 0.9850290418000001}, {'domain': 'Smart Environment', 'score': 0.5593144894000001}]",
         "{'is_genai': True, 'confidence': 0.7101255059242249, 'matched_keywords': ['gpt-3', 'gpt-4', 'gpt-2', 'gpt', 'large language model', 'pretrained language model', 'small language model', 'clip', 'vision-language model', 'generative model', 'multimodal model', 'cross-modal generation', 'multimodal embedding', 'variational autoencoder', 'score-based model', 'text-to-image diffusion', 'noise prediction', 'contrastive learning', 'neural rendering', 'chatgpt', 'autoregressive models'], 'technology_categories': ['Transformer-Based Models', 'Diffusion Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('building', 10), ('usage', 6), ('model', 6), ('text', 4), ('build', 3)], 'semantic_matches': [('gpt-3', 0.7101255059242249), ('gpt-4', 0.6560104489326477), ('gpt-2', 0.6496403813362122), ('gpt', 0.6230357885360718), ('large language model', 0.6147577166557312), ('pretrained language model', 0.613377034664154), ('small language model', 0.5607509613037109), ('clip', 0.48964837193489075), ('vision-language model', 0.4827195405960083), ('generative model', 0.46028557419776917), ('multimodal model', 0.4542420208454132), ('cross-modal generation', 0.44065457582473755), ('multimodal embedding', 0.44009625911712646), ('variational autoencoder', 0.4268607497215271), ('score-based model', 0.4119209051132202), ('text-to-image diffusion', 0.40372326970100403), ('noise prediction', 0.4033578634262085), ('contrastive learning', 0.4032924771308899), ('neural rendering', 0.40216779708862305), ('chatgpt', 0.4020984172821045), ('autoregressive models', 0.40157416462898254)]}",
         "True",
         "0.7101255059242249",
         "['gpt-3', 'gpt-4', 'gpt-2', 'gpt', 'large language model', 'pretrained language model', 'small language model', 'clip', 'vision-language model', 'generative model', 'multimodal model', 'cross-modal generation', 'multimodal embedding', 'variational autoencoder', 'score-based model', 'text-to-image diffusion', 'noise prediction', 'contrastive learning', 'neural rendering', 'chatgpt', 'autoregressive models']",
         "['Transformer-Based Models', 'Diffusion Models', 'Variational Autoencoders', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('building', 10), ('usage', 6), ('model', 6), ('text', 4), ('build', 3)]",
         "[('gpt-3', 0.7101255059242249), ('gpt-4', 0.6560104489326477), ('gpt-2', 0.6496403813362122), ('gpt', 0.6230357885360718), ('large language model', 0.6147577166557312), ('pretrained language model', 0.613377034664154), ('small language model', 0.5607509613037109), ('clip', 0.48964837193489075), ('vision-language model', 0.4827195405960083), ('generative model', 0.46028557419776917), ('multimodal model', 0.4542420208454132), ('cross-modal generation', 0.44065457582473755), ('multimodal embedding', 0.44009625911712646), ('variational autoencoder', 0.4268607497215271), ('score-based model', 0.4119209051132202), ('text-to-image diffusion', 0.40372326970100403), ('noise prediction', 0.4033578634262085), ('contrastive learning', 0.4032924771308899), ('neural rendering', 0.40216779708862305), ('chatgpt', 0.4020984172821045), ('autoregressive models', 0.40157416462898254)]"
        ],
        [
         "32",
         "Multimodal Large Language Models as Built Environment Auditing Tools",
         "Jang K.M.",
         "Professional Geographer",
         "10.1080/00330124.2024.2404894",
         "2025",
         "Note",
         "https://api.elsevier.com/content/abstract/scopus_id/85205928657",
         "85205928657",
         "This research showcases the transformative potential of large language models (LLMs) for built environment auditing from street-view images. By empirically testing the performances of two multimodal LLMs, ChatGPT and Gemini, we confirmed that LLM-based audits strongly agree with virtual audits processed by a conventional deep learning-based method (DeepLabv3+), which has been widely adopted by existing studies on urban visual analytics. Unlike conventional field or virtual audits that require labor-intensive manual inspection or technical expertise to run computer vision algorithms, our results show that LLMs can offer an intuitive tool despite the user’s level of technical proficiency. This would allow a broader range of policy and planning stakeholders to employ LLM-based built environment auditing instruments for smart urban infrastructure management.",
         "['audit', 'built environment', 'ChatGPT', 'Gemini', 'street-view images']",
         "['Geography, Planning and Development', 'Earth-Surface Processes']",
         "This research showcases the transformative potential of large language models (LLMs) for built environment auditing from street-view images. By empirically testing the performances of two multimodal LLMs, ChatGPT and Gemini, we confirmed that LLM-based audits strongly agree with virtual audits processed by a conventional deep learning-based method (DeepLabv3+), which has been widely adopted by existing studies on urban visual analytics. Unlike conventional field or virtual audits that require labor-intensive manual inspection or technical expertise to run computer vision algorithms, our results show that LLMs can offer an intuitive tool despite the user’s level of technical proficiency. This would allow a broader range of policy and planning stakeholders to employ LLM-based built environment auditing instruments for smart urban infrastructure management.",
         "This research showcases the transformative potential of large language models (LLMs) for built environment auditing from street-view images. By empirically testing the performances of two multimodal LLMs, ChatGPT and Gemini, we confirmed that LLM-based audits strongly agree with virtual audits processed by a conventional deep learning-based method (DeepLabv3+), which has been widely adopted by existing studies on urban visual analytics. Unlike conventional field or virtual audits that require labor-intensive manual inspection or technical expertise to run computer vision algorithms, our results show that LLMs can offer an intuitive tool despite the user’s level of technical proficiency. This would allow a broader range of policy and planning stakeholders to employ LLM-based built environment auditing instruments for smart urban infrastructure management.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7049210072000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7049210072000001, 0.2950790226]}",
         "True",
         "0.7049210072000001",
         "['Environment', 'Buildings', 'Urban Planning', 'Urban Management', 'Construction', 'Public Policies', 'Housing', 'Public Services', 'Industry', 'Business', 'Living', 'Sustainability', 'Governance', 'Socioeconomics', 'Citizens', 'Economic Management', 'Emergency Safety', 'Human', 'Mobility', 'Power Distribution', 'People', 'Pedestrian', 'Logistics', 'Economy', 'Citizen Engagement', 'Renewable Energy', 'Smart Grids', 'Education', 'Social Equity', 'Tourism', 'Energy Management', 'Electric Vehicles', 'Water Quality', 'Air Quality', 'Waste Management', 'Climate Change', 'Pollution Control', 'Public Transit', 'Culture', 'Cybersecurity', 'Green Spaces', 'Marketing', 'Transportation Systems', 'Finance', 'Bicycle', 'Healthcare', 'Multimodal Transport', 'Traffic Management']",
         "[0.8390650153, 0.7918662429000001, 0.7616773844, 0.5696226954, 0.1128830984, 0.0578634702, 0.0466563292, 0.0353879929, 0.0243654922, 0.0233886503, 0.0233683977, 0.0188115146, 0.015030644800000001, 0.0104972208, 0.0085374722, 0.0051871273, 0.0041805771, 0.0033522304, 0.0031453432, 0.0029619497, 0.0025818537, 0.0025084896000000002, 0.0023997293000000003, 0.0023282419000000003, 0.0022123165, 0.0020629065, 0.0017621975, 0.0015525696000000002, 0.0012445730000000001, 0.0009172169000000001, 0.0008751916000000001, 0.0008603862, 0.0008404888000000001, 0.0007856412000000001, 0.0007565385, 0.0007513713, 0.0007451652000000001, 0.0006976797, 0.0006732229, 0.0006537394, 0.0005830053, 0.0005292459, 0.0005098315, 0.000447226, 0.0004397203, 0.0004056051, 0.00039987350000000003, 0.0003918599]",
         "[{'domain': 'Smart Environment', 'score': 0.8390650153}, {'domain': 'Smart Living', 'score': 0.7918662429000001}, {'domain': 'Smart Governance', 'score': 0.7616773844}]",
         "{'is_genai': True, 'confidence': 0.5562499165534973, 'matched_keywords': ['vision-language model', 'large language model', 'chatgpt', 'generative model', 'small language model', '3d generative model'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('llms', 3), ('build', 3), ('environment', 3), ('base', 3), ('audits', 3)], 'semantic_matches': [('vision-language model', 0.5562499165534973), ('large language model', 0.48231256008148193), ('chatgpt', 0.4607197046279907), ('generative model', 0.45577651262283325), ('small language model', 0.4345323145389557), ('3d generative model', 0.4172356128692627)]}",
         "True",
         "0.5562499165534973",
         "['vision-language model', 'large language model', 'chatgpt', 'generative model', 'small language model', '3d generative model']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('llms', 3), ('build', 3), ('environment', 3), ('base', 3), ('audits', 3)]",
         "[('vision-language model', 0.5562499165534973), ('large language model', 0.48231256008148193), ('chatgpt', 0.4607197046279907), ('generative model', 0.45577651262283325), ('small language model', 0.4345323145389557), ('3d generative model', 0.4172356128692627)]"
        ],
        [
         "33",
         "Large language model as parking planning agent in the context of mixed period of autonomous vehicles and Human-Driven vehicles",
         "Jin Y.",
         "Sustainable Cities and Society",
         "10.1016/j.scs.2024.105940",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85208127887",
         "85208127887",
         "Autonomous vehicles (AVs) are anticipated to revolutionize future transportation, necessitating updates to traffic infrastructure, particularly parking facilities, due to the unique characteristics of AVs compared to Human-Driven Vehicles (HDVs). During the transition period in which AVs and HDVs coexist, adaptable infrastructure is essential to accommodate both vehicle types. Traditional research, typically reliant on complex mathematical models and simulations, faces challenges in adapting to diverse urban settings, requiring substantial time and resources. To address these challenges, a government-level framework was developed, enabling urban planners to quickly and accurately evaluate and optimize existing parking facilities for future AV and HDV coexistence scenarios. The framework integrates a Large Language Model (LLM) to enhance flexibility and efficiency in parking planning throughout the transitional period. Structured guidance is incorporated to enhance decision-making precision and reduce LLM hallucination risks. The flexibility, robustness, and accuracy of the framework were validated through step-by-step and end-to-end testing using real-world datasets. Specifically, the framework achieved 91.1 % comprehensiveness and 70.2 % consistency in Indicator Selection Module testing, a 68.9 % success rate in the Single Indicator Calculation Module, and a 66.7 % success rate in end-to-end testing, demonstrating its practical value in supporting cities during AV integration. Finally, the success rates of different LLM agent modules were further explored, along with a comparison of multiple LLMs and an analysis of key issues related to LLM trustworthiness in urban planning applications. The research highlights the potential of LLMs in advancing urban planning processes and optimizing existing infrastructure, contributing to smarter and more adaptable urban environments.",
         "['Autonomous vehicles', 'Large Language Models', 'Parking facility Planning']",
         "['Geography, Planning and Development', 'Civil and Structural Engineering', 'Renewable Energy, Sustainability and the Environment', 'Transportation']",
         "Autonomous vehicles (AVs) are anticipated to revolutionize future transportation, necessitating updates to traffic infrastructure, particularly parking facilities, due to the unique characteristics of AVs compared to Human-Driven Vehicles (HDVs). During the transition period in which AVs and HDVs coexist, adaptable infrastructure is essential to accommodate both vehicle types. Traditional research, typically reliant on complex mathematical models and simulations, faces challenges in adapting to diverse urban settings, requiring substantial time and resources. To address these challenges, a government-level framework was developed, enabling urban planners to quickly and accurately evaluate and optimize existing parking facilities for future AV and HDV coexistence scenarios. The framework integrates a Large Language Model (LLM) to enhance flexibility and efficiency in parking planning throughout the transitional period. Structured guidance is incorporated to enhance decision-making precision and reduce LLM hallucination risks. The flexibility, robustness, and accuracy of the framework were validated through step-by-step and end-to-end testing using real-world datasets. Specifically, the framework achieved 91.1 % comprehensiveness and 70.2 % consistency in Indicator Selection Module testing, a 68.9 % success rate in the Single Indicator Calculation Module, and a 66.7 % success rate in end-to-end testing, demonstrating its practical value in supporting cities during AV integration. Finally, the success rates of different LLM agent modules were further explored, along with a comparison of multiple LLMs and an analysis of key issues related to LLM trustworthiness in urban planning applications.",
         "The research highlights the potential of LLMs in advancing urban planning processes and optimizing existing infrastructure, contributing to smarter and more adaptable urban environments.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9818286896, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9818286896, 0.0181712508]}",
         "True",
         "0.9818286896",
         "['Urban Planning', 'Transportation Systems', 'Mobility', 'Urban Management', 'Traffic Management', 'Public Services', 'Multimodal Transport', 'Public Policies', 'Governance', 'Construction', 'Socioeconomics', 'Economic Management', 'Environment', 'Economy', 'Logistics', 'Living', 'People', 'Emergency Safety', 'Business', 'Power Distribution', 'Citizens', 'Sustainability', 'Education', 'Citizen Engagement', 'Human', 'Energy Management', 'Social Equity', 'Finance', 'Marketing', 'Smart Grids', 'Buildings', 'Cybersecurity', 'Water Quality', 'Public Transit', 'Air Quality', 'Pollution Control', 'Industry', 'Culture', 'Waste Management', 'Renewable Energy', 'Green Spaces', 'Climate Change', 'Tourism', 'Housing', 'Healthcare', 'Pedestrian', 'Bicycle', 'Electric Vehicles']",
         "[0.9639382958, 0.9506198764, 0.9247519970000001, 0.6334687471, 0.36012488600000003, 0.11523398010000001, 0.0731754676, 0.0621316507, 0.0515159778, 0.0358942561, 0.0243929084, 0.017460769, 0.010015199, 0.0059415931, 0.0054881531, 0.0037754206, 0.0030870275, 0.0020980539, 0.0020101964000000003, 0.0014487113, 0.0013421196000000001, 0.0013347454, 0.0009991805, 0.0009750074, 0.0008929912000000001, 0.0008558851000000001, 0.0007548136, 0.0006683994, 0.0006608300000000001, 0.0006228531000000001, 0.0005753016000000001, 0.000544416, 0.0005396556, 0.0004974188000000001, 0.0004763878, 0.00045852020000000004, 0.0004558747, 0.0004507583, 0.0004502565, 0.00043861050000000004, 0.0004378645, 0.00042271450000000004, 0.0004126827, 0.0004082166, 0.00040524690000000004, 0.0003931769, 0.0003562087, 0.000319184]",
         "[{'domain': 'Smart Governance', 'score': 0.9639382958}, {'domain': 'Smart Mobility', 'score': 0.9506198764}]",
         "{'is_genai': False, 'confidence': 0.0, 'matched_keywords': [], 'technology_categories': [], 'bridge_terms': [('urban', 2), ('planning', 2), ('research', 1), ('highlight', 1), ('potential', 1)], 'semantic_matches': []}",
         "False",
         "0.0",
         "[]",
         "[]",
         "[('urban', 2), ('planning', 2), ('research', 1), ('highlight', 1), ('potential', 1)]",
         "[]"
        ],
        [
         "34",
         "Evaluating a global citizenship course on developing business students' AI literacy skills",
         "Ching A.C.H.",
         "Effective Practices in AI Literacy Education: Case Studies and Reflections",
         "10.1108/978-1-83608-852-320241010",
         "2024",
         "Book Chapter",
         "https://api.elsevier.com/content/abstract/scopus_id/85213116018",
         "85213116018",
         "Nowadays, as organisations and companies increasingly harness the power of artificial intelligence (AI), there is a growing need to ensure future professionals in fields such as business and management can possess relevant necessary knowledge, skills, and mindset for navigating the ethical and social implications of AI technologies. This study evaluated the effects of a specialised AI literacy course designed for business students at a university in Hong Kong. The course aimed to equip participants with a basic understanding of AI concepts via self-paced materials, hands-on activities, case study discussion, and design thinking activities. Through a mixed-methods approach involving evaluation surveys and student and teacher reflections, this case study examined how effectively the course developed the students' AI literacies as future business leaders and global digital citizens. AI competencies include understanding basic AI and generative AI (GenAI), using AI applications ethically, critically analysing AI-powered systems, identifying potential societal risks, and making data-driven decisions while upholding ethical principles. The findings provide valuable insights into the role of targeted AI education in preparing the next generation of business professionals for navigating the evolving data landscape and contributing to the responsible advancement of these transformative technologies.",
         "['AI competency', 'AI literacy', 'Business', 'Digital citizenship', 'Generative AI', 'Smart city']",
         "['Social Sciences (all)']",
         "Nowadays, as organisations and companies increasingly harness the power of artificial intelligence (AI), there is a growing need to ensure future professionals in fields such as business and management can possess relevant necessary knowledge, skills, and mindset for navigating the ethical and social implications of AI technologies.",
         "This study evaluated the effects of a specialised AI literacy course designed for business students at a university in Hong Kong. The course aimed to equip participants with a basic understanding of AI concepts via self-paced materials, hands-on activities, case study discussion, and design thinking activities. Through a mixed-methods approach involving evaluation surveys and student and teacher reflections, this case study examined how effectively the course developed the students' AI literacies as future business leaders and global digital citizens. AI competencies include understanding basic AI and generative AI (GenAI), using AI applications ethically, critically analysing AI-powered systems, identifying potential societal risks, and making data-driven decisions while upholding ethical principles. The findings provide valuable insights into the role of targeted AI education in preparing the next generation of business professionals for navigating the evolving data landscape and contributing to the responsible advancement of these transformative technologies.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7795666456, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7795666456, 0.2204333097]}",
         "True",
         "0.7795666456",
         "['Business', 'Industry', 'Governance', 'Economy', 'Education', 'Socioeconomics', 'People', 'Economic Management', 'Social Equity', 'Living', 'Public Policies', 'Finance', 'Human', 'Culture', 'Public Services', 'Marketing', 'Citizens', 'Power Distribution', 'Multimodal Transport', 'Cybersecurity', 'Urban Planning', 'Urban Management', 'Citizen Engagement', 'Green Spaces', 'Pedestrian', 'Emergency Safety', 'Construction', 'Electric Vehicles', 'Public Transit', 'Smart Grids', 'Environment', 'Air Quality', 'Logistics', 'Sustainability', 'Buildings', 'Mobility', 'Renewable Energy', 'Transportation Systems', 'Water Quality', 'Healthcare', 'Climate Change', 'Bicycle', 'Pollution Control', 'Housing', 'Tourism', 'Traffic Management', 'Energy Management', 'Waste Management']",
         "[0.7084605694, 0.5650458932, 0.2667043805, 0.1370176673, 0.0827800706, 0.0672961101, 0.0447472036, 0.0101209879, 0.0046748300000000005, 0.0030724921, 0.0028529142000000003, 0.0019125235000000001, 0.0017772348, 0.0009855086, 0.0009788889000000001, 0.0009342689, 0.0006799868, 0.000554239, 0.0005479910000000001, 0.0005431021, 0.0005126275, 0.0004961133000000001, 0.0004866606, 0.0004777928, 0.0004611158, 0.0004533428, 0.0004347369, 0.0004333736, 0.0004310709, 0.0004304334, 0.0004220498, 0.0004181681, 0.00041744600000000003, 0.0004147754, 0.0004145186, 0.00041231700000000004, 0.0004082574, 0.0004078412, 0.0003976839, 0.00038962970000000003, 0.0003835843, 0.00037962280000000003, 0.0003627991, 0.00036162550000000003, 0.0003606449, 0.0003592218, 0.0003553395, 0.0003471586]",
         "[{'domain': 'Smart Economy', 'score': 0.7084605694}]",
         "{'is_genai': True, 'confidence': 0.6645059585571289, 'matched_keywords': ['ai capability', 'gen ai', 'designed with ai', 'generative capabilities'], 'technology_categories': ['Transformer-Based Models'], 'bridge_terms': [('business', 4), ('study', 3), ('literacy', 3), ('course', 3), ('student', 3)], 'semantic_matches': [('ai capability', 0.6645059585571289), ('gen ai', 0.6045910120010376), ('designed with ai', 0.5907852649688721), ('generative capabilities', 0.40425270795822144)]}",
         "True",
         "0.6645059585571289",
         "['ai capability', 'gen ai', 'designed with ai', 'generative capabilities']",
         "['Transformer-Based Models']",
         "[('business', 4), ('study', 3), ('literacy', 3), ('course', 3), ('student', 3)]",
         "[('ai capability', 0.6645059585571289), ('gen ai', 0.6045910120010376), ('designed with ai', 0.5907852649688721), ('generative capabilities', 0.40425270795822144)]"
        ],
        [
         "35",
         "Investigating the Performance of Open-Vocabulary Classification Algorithms for Pathway and Surface Material Detection in Urban Environments",
         "de Moraes Vestena K.",
         "ISPRS International Journal of Geo-Information",
         "10.3390/ijgi13120422",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85213246629",
         "85213246629",
         "Mapping pavement types, especially in sidewalks, is essential for urban planning and mobility studies. Identifying pavement materials is a key factor in assessing mobility, such as walkability and wheelchair usability. However, satellite imagery in this scenario is limited, and in situ mapping can be costly. A promising solution is to extract such geospatial features from street-level imagery. This study explores using open-vocabulary classification algorithms to segment and identify pavement types and surface materials in this scenario. Our approach uses large language models (LLMs) to improve the accuracy of classifying different pavement types. The methodology involves two experiments: the first uses free prompting with random street-view images, employing Grounding Dino and SAM algorithms to assess performance across categories. The second experiment evaluates standardized pavement classification using the Deep Pavements dataset and a fine-tuned CLIP algorithm optimized for detecting OSM-compliant pavement categories. The study presents open resources, such as the Deep Pavements dataset and a fine-tuned CLIP-based model, demonstrating a significant improvement in the true positive rate (TPR) from 56.04% to 93.5%. Our findings highlight both the potential and limitations of current open-vocabulary algorithms and emphasize the importance of diverse training datasets. This study advances urban feature mapping by offering a more intuitive and accurate approach to geospatial data extraction, enhancing urban accessibility and mobility mapping.",
         "['open-vocabulary algorithms', 'pavement segmentation', 'street-view imagery', 'surface material detection', 'urban mobility']",
         "['Geography, Planning and Development', 'Computers in Earth Sciences', 'Earth and Planetary Sciences (miscellaneous)']",
         "Mapping pavement types, especially in sidewalks, is essential for urban planning and mobility studies. Identifying pavement materials is a key factor in assessing mobility, such as walkability and wheelchair usability. However, satellite imagery in this scenario is limited, and in situ mapping can be costly. A promising solution is to extract such geospatial features from street-level imagery.",
         "This study explores using open-vocabulary classification algorithms to segment and identify pavement types and surface materials in this scenario. Our approach uses large language models (LLMs) to improve the accuracy of classifying different pavement types. The methodology involves two experiments: the first uses free prompting with random street-view images, employing Grounding Dino and SAM algorithms to assess performance across categories. The second experiment evaluates standardized pavement classification using the Deep Pavements dataset and a fine-tuned CLIP algorithm optimized for detecting OSM-compliant pavement categories. The study presents open resources, such as the Deep Pavements dataset and a fine-tuned CLIP-based model, demonstrating a significant improvement in the true positive rate (TPR) from 56.04% to 93.5%. Our findings highlight both the potential and limitations of current open-vocabulary algorithms and emphasize the importance of diverse training datasets. This study advances urban feature mapping by offering a more intuitive and accurate approach to geospatial data extraction, enhancing urban accessibility and mobility mapping.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8074118495, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8074118495, 0.1925881654]}",
         "True",
         "0.8074118495",
         "['Urban Planning', 'Mobility', 'Transportation Systems', 'Environment', 'Urban Management', 'Multimodal Transport', 'Pedestrian', 'Logistics', 'Construction', 'Public Services', 'Living', 'Business', 'Citizens', 'Human', 'Traffic Management', 'Sustainability', 'Emergency Safety', 'Industry', 'Economic Management', 'Governance', 'Public Policies', 'Power Distribution', 'Economy', 'Socioeconomics', 'Housing', 'Tourism', 'Education', 'Public Transit', 'Energy Management', 'Citizen Engagement', 'Pollution Control', 'Finance', 'Climate Change', 'Waste Management', 'Smart Grids', 'Renewable Energy', 'People', 'Marketing', 'Buildings', 'Electric Vehicles', 'Healthcare', 'Social Equity', 'Cybersecurity', 'Culture', 'Water Quality', 'Air Quality', 'Bicycle', 'Green Spaces']",
         "[0.9653328657, 0.937887609, 0.8634675741000001, 0.7472376227, 0.6951608062, 0.3003901839, 0.16000874340000001, 0.0836964548, 0.0555660911, 0.0316255353, 0.0254562087, 0.0090763588, 0.0070146779, 0.0053793057, 0.0032836751000000003, 0.0027421662, 0.0016321385000000002, 0.0016208648000000001, 0.0014953094000000001, 0.0012552419000000001, 0.0010096333000000001, 0.0008988657, 0.0007777925, 0.0006644414, 0.000654308, 0.0006054607000000001, 0.0005817616000000001, 0.0005394225, 0.000519488, 0.0005154178000000001, 0.0005149418, 0.0005107349, 0.000501549, 0.0004925137, 0.0004632575, 0.00046028480000000004, 0.0004602782, 0.00045821150000000004, 0.0004551989, 0.0004536305, 0.00043845820000000004, 0.000426528, 0.00037910200000000003, 0.00037262870000000003, 0.00036479300000000003, 0.0003590108, 0.00034711240000000003, 0.00033945490000000003]",
         "[{'domain': 'Smart Governance', 'score': 0.9653328657}, {'domain': 'Smart Mobility', 'score': 0.937887609}, {'domain': 'Smart Environment', 'score': 0.7472376227}]",
         "{'is_genai': True, 'confidence': 0.4496920704841614, 'matched_keywords': ['large language model', 'pretrained language model', 'contrastive learning', 'small language model', 'generative capabilities', 'generative capability'], 'technology_categories': ['Transformer-Based Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('algorithm', 5), ('pavement', 5), ('open', 4), ('study', 3), ('vocabulary', 3)], 'semantic_matches': [('large language model', 0.4496920704841614), ('pretrained language model', 0.44416946172714233), ('contrastive learning', 0.44228988885879517), ('small language model', 0.4203319549560547), ('generative capabilities', 0.409808486700058), ('generative capability', 0.4094102084636688)]}",
         "True",
         "0.4496920704841614",
         "['large language model', 'pretrained language model', 'contrastive learning', 'small language model', 'generative capabilities', 'generative capability']",
         "['Transformer-Based Models', 'Hybrid & Multimodal Architectures']",
         "[('algorithm', 5), ('pavement', 5), ('open', 4), ('study', 3), ('vocabulary', 3)]",
         "[('large language model', 0.4496920704841614), ('pretrained language model', 0.44416946172714233), ('contrastive learning', 0.44228988885879517), ('small language model', 0.4203319549560547), ('generative capabilities', 0.409808486700058), ('generative capability', 0.4094102084636688)]"
        ],
        [
         "36",
         "Integrating Spatiotemporal and Travel-Related Information for Accurate Urban Passenger Profiling Using GANs",
         "Duan X.",
         "Land",
         "10.3390/land13122178",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85213227350",
         "85213227350",
         "The elaborate description of passenger travel profiles is of significant importance in urban planning, socioeconomic structural design, and individual travel preference analysis. Traditional models often lack consideration of personalized features and exhibit suboptimal performance in constructing spatiotemporal dependencies. To address these issues, this paper proposes a method that integrates spatiotemporal information with travel-related information and employs generative adversarial networks (GANs) for adversarial training. This method accurately fits the true distribution of user travel data, thereby providing detailed profiles of public transportation passengers’ travel behavior. Specifically, the proposed approach considers the complete travel chain of individuals, establishes a spatiotemporal constraint representation model, and utilizes GANs to simulate the distribution of passenger travel, obtaining more compact and high-level travel vector features. The empirical results demonstrate that the proposed method accurately captures passengers’ travel patterns in both the temporal and spatial dimensions, offering technical support for urban transportation planning.",
         "['adversarial learning', 'passenger travel profile', 'smart card data', 'spatiotemporal dependency relationship', 'urban sustainable development']",
         "['Global and Planetary Change', 'Ecology', 'Nature and Landscape Conservation']",
         "The elaborate description of passenger travel profiles is of significant importance in urban planning, socioeconomic structural design, and individual travel preference analysis. Traditional models often lack consideration of personalized features and exhibit suboptimal performance in constructing spatiotemporal dependencies.",
         "To address these issues, this paper proposes a method that integrates spatiotemporal information with travel-related information and employs generative adversarial networks (GANs) for adversarial training. This method accurately fits the true distribution of user travel data, thereby providing detailed profiles of public transportation passengers’ travel behavior. Specifically, the proposed approach considers the complete travel chain of individuals, establishes a spatiotemporal constraint representation model, and utilizes GANs to simulate the distribution of passenger travel, obtaining more compact and high-level travel vector features. The empirical results demonstrate that the proposed method accurately captures passengers’ travel patterns in both the temporal and spatial dimensions, offering technical support for urban transportation planning.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9913480878, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9913480878, 0.0086519783]}",
         "True",
         "0.9913480878",
         "['Mobility', 'Transportation Systems', 'Urban Planning', 'Public Transit', 'Logistics', 'People', 'Urban Management', 'Human', 'Socioeconomics', 'Multimodal Transport', 'Living', 'Environment', 'Business', 'Construction', 'Public Services', 'Economy', 'Electric Vehicles', 'Tourism', 'Traffic Management', 'Citizens', 'Economic Management', 'Public Policies', 'Industry', 'Governance', 'Emergency Safety', 'Sustainability', 'Education', 'Social Equity', 'Housing', 'Smart Grids', 'Power Distribution', 'Renewable Energy', 'Climate Change', 'Green Spaces', 'Energy Management', 'Buildings', 'Culture', 'Citizen Engagement', 'Air Quality', 'Healthcare', 'Finance', 'Cybersecurity', 'Pollution Control', 'Pedestrian', 'Bicycle', 'Marketing', 'Waste Management', 'Water Quality']",
         "[0.9761340618000001, 0.9722931385, 0.9426574707, 0.7757251859000001, 0.5391362309000001, 0.4514505565, 0.2308731675, 0.2067379057, 0.1588103324, 0.1187270433, 0.0391944833, 0.0386425033, 0.020792035400000002, 0.018179925200000002, 0.0075889509, 0.006966598300000001, 0.0062754806, 0.006096852000000001, 0.004559299, 0.0044969097, 0.003688016, 0.0010366539, 0.0007513504, 0.0006548744, 0.0006296166, 0.0005617877, 0.0005601762, 0.0005589167, 0.0005466935000000001, 0.0005447256, 0.0004896257000000001, 0.00047207, 0.00047163600000000005, 0.00045600560000000004, 0.0004457175, 0.0004455241, 0.0004431366, 0.0004317837, 0.0004069039, 0.0004026666, 0.0003976784, 0.0003976351, 0.0003884122, 0.00037439520000000004, 0.00037265730000000003, 0.00036438110000000003, 0.0003625835, 0.0003409856]",
         "[{'domain': 'Smart Mobility', 'score': 0.9761340618000001}, {'domain': 'Smart Governance', 'score': 0.9426574707}, {'domain': 'Smart Economy', 'score': 0.5391362309000001}, {'domain': 'Smart People', 'score': 0.4514505565}]",
         "{'is_genai': True, 'confidence': 0.5946518778800964, 'matched_keywords': ['generative adversarial network', 'generative capabilities', 'flow model', 'generative capability', 'large flow model'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks'], 'bridge_terms': [('travel', 8), ('passenger', 4), ('propose', 3), ('method', 3), ('spatiotemporal', 3)], 'semantic_matches': [('generative adversarial network', 0.5946518778800964), ('generative capabilities', 0.4366419017314911), ('flow model', 0.43495023250579834), ('generative capability', 0.4200829267501831), ('large flow model', 0.41908466815948486)]}",
         "True",
         "0.5946518778800964",
         "['generative adversarial network', 'generative capabilities', 'flow model', 'generative capability', 'large flow model']",
         "['Transformer-Based Models', 'Generative Adversarial Networks']",
         "[('travel', 8), ('passenger', 4), ('propose', 3), ('method', 3), ('spatiotemporal', 3)]",
         "[('generative adversarial network', 0.5946518778800964), ('generative capabilities', 0.4366419017314911), ('flow model', 0.43495023250579834), ('generative capability', 0.4200829267501831), ('large flow model', 0.41908466815948486)]"
        ],
        [
         "37",
         "Artificial Intelligence-Enabled Metaverse for Sustainable Smart Cities: Technologies, Applications, Challenges, and Future Directions",
         "Lifelo Z.",
         "Electronics (Switzerland)",
         "10.3390/electronics13244874",
         "2024",
         "Review",
         "https://api.elsevier.com/content/abstract/scopus_id/85213202921",
         "85213202921",
         "Rapid urbanisation has intensified the need for sustainable solutions to address challenges in urban infrastructure, climate change, and resource constraints. This study reveals that Artificial Intelligence (AI)-enabled metaverse offers transformative potential for developing sustainable smart cities. AI techniques, such as machine learning, deep learning, generative AI (GAI), and large language models (LLMs), enhance the metaverse’s capabilities in data analysis, urban decision making, and personalised user experiences. The study further examines how these advanced AI models facilitate key metaverse technologies such as big data analytics, natural language processing (NLP), computer vision, digital twins, Internet of Things (IoT), Edge AI, and 5G/6G networks. Applications across various smart city domains—environment, mobility, energy, health, governance, and economy, and real-world use cases of virtual cities like Singapore, Seoul, and Lisbon are presented, demonstrating AI’s effectiveness in the metaverse for smart cities. However, AI-enabled metaverse in smart cities presents challenges related to data acquisition and management, privacy, security, interoperability, scalability, and ethical considerations. These challenges’ societal and technological implications are discussed, highlighting the need for robust data governance frameworks and AI ethics guidelines. Future directions emphasise advancing AI model architectures and algorithms, enhancing privacy and security measures, promoting ethical AI practices, addressing performance measures, and fostering stakeholder collaboration. By addressing these challenges, the full potential of AI-enabled metaverse can be harnessed to enhance sustainability, adaptability, and livability in smart cities.",
         "['adaptive urban systems', 'artificial intelligence', 'digital twins', 'generative AI', 'large language models', 'metaverse', 'smart cities', 'sustainable cities', 'urban planning', 'urban transformation']",
         "['Control and Systems Engineering', 'Signal Processing', 'Hardware and Architecture', 'Computer Networks and Communications', 'Electrical and Electronic Engineering']",
         "Rapid urbanisation has intensified the need for sustainable solutions to address challenges in urban infrastructure, climate change, and resource constraints.",
         "This study reveals that Artificial Intelligence (AI)-enabled metaverse offers transformative potential for developing sustainable smart cities. AI techniques, such as machine learning, deep learning, generative AI (GAI), and large language models (LLMs), enhance the metaverse’s capabilities in data analysis, urban decision making, and personalised user experiences. The study further examines how these advanced AI models facilitate key metaverse technologies such as big data analytics, natural language processing (NLP), computer vision, digital twins, Internet of Things (IoT), Edge AI, and 5G/6G networks. Applications across various smart city domains—environment, mobility, energy, health, governance, and economy, and real-world use cases of virtual cities like Singapore, Seoul, and Lisbon are presented, demonstrating AI’s effectiveness in the metaverse for smart cities. However, AI-enabled metaverse in smart cities presents challenges related to data acquisition and management, privacy, security, interoperability, scalability, and ethical considerations. These challenges’ societal and technological implications are discussed, highlighting the need for robust data governance frameworks and AI ethics guidelines. Future directions emphasise advancing AI model architectures and algorithms, enhancing privacy and security measures, promoting ethical AI practices, addressing performance measures, and fostering stakeholder collaboration. By addressing these challenges, the full potential of AI-enabled metaverse can be harnessed to enhance sustainability, adaptability, and livability in smart cities.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7803587914, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7803587914, 0.2196412086]}",
         "True",
         "0.7803587914",
         "['Sustainability', 'Urban Planning', 'Urban Management', 'Living', 'Human', 'People', 'Environment', 'Socioeconomics', 'Public Policies', 'Construction', 'Citizens', 'Public Services', 'Climate Change', 'Mobility', 'Buildings', 'Governance', 'Housing', 'Logistics', 'Economy', 'Transportation Systems', 'Economic Management', 'Business', 'Public Transit', 'Power Distribution', 'Energy Management', 'Multimodal Transport', 'Electric Vehicles', 'Citizen Engagement', 'Industry', 'Emergency Safety', 'Renewable Energy', 'Green Spaces', 'Smart Grids', 'Air Quality', 'Waste Management', 'Pollution Control', 'Social Equity', 'Water Quality', 'Finance', 'Traffic Management', 'Pedestrian', 'Education', 'Healthcare', 'Marketing', 'Cybersecurity', 'Bicycle', 'Culture', 'Tourism']",
         "[0.9874159098, 0.9645866156, 0.9586057067, 0.390691638, 0.1856438518, 0.1754663736, 0.142069459, 0.1358103305, 0.1218422279, 0.0896727517, 0.0634473041, 0.041285950700000004, 0.0396569483, 0.0281806327, 0.020649936100000002, 0.0194844604, 0.0182414595, 0.017681976800000002, 0.013914234900000001, 0.0101238992, 0.008548639700000001, 0.0068762386, 0.0061039696, 0.0060018818, 0.0049853357, 0.004916862100000001, 0.0044553364, 0.0040174923, 0.0021581070000000003, 0.0020474950000000003, 0.00150493, 0.0014524092, 0.0013761356, 0.0012616346, 0.001197244, 0.0011637138, 0.0009027048, 0.0008964761, 0.0006827302000000001, 0.00045243560000000004, 0.000443115, 0.0004373037, 0.0004012391, 0.0003989473, 0.00039546760000000003, 0.00039529560000000003, 0.0003541317, 0.0003147938]",
         "[{'domain': 'Smart Environment', 'score': 0.9874159098}, {'domain': 'Smart Governance', 'score': 0.9645866156}]",
         "{'is_genai': True, 'confidence': 0.597321629524231, 'matched_keywords': ['ai capability', 'designed with ai', 'gen ai', 'generative capabilities', 'point cloud generation'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('city', 8), ('metaverse', 7), ('smart', 6), ('model', 4), ('urban', 4)], 'semantic_matches': [('ai capability', 0.597321629524231), ('designed with ai', 0.5374309420585632), ('gen ai', 0.5071794390678406), ('generative capabilities', 0.4277040362358093), ('point cloud generation', 0.41975751519203186)]}",
         "True",
         "0.597321629524231",
         "['ai capability', 'designed with ai', 'gen ai', 'generative capabilities', 'point cloud generation']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models']",
         "[('city', 8), ('metaverse', 7), ('smart', 6), ('model', 4), ('urban', 4)]",
         "[('ai capability', 0.597321629524231), ('designed with ai', 0.5374309420585632), ('gen ai', 0.5071794390678406), ('generative capabilities', 0.4277040362358093), ('point cloud generation', 0.41975751519203186)]"
        ],
        [
         "38",
         "SolarGAN for Meso-Level Solar Radiation Prediction at the Urban Scale: A Case Study in Boston",
         "Lu Y.",
         "Remote Sensing",
         "10.3390/rs16234524",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85212189872",
         "85212189872",
         "Evaluating solar radiation distribution at the urban scale is crucial for optimizing the placement and size of solar installations and managing urban heat. This study introduces a method for predicting urban solar radiation using 2D mapping data, applying a Generative Adversarial Network (GAN) model to the city of Boston. Traditional solar radiation simulation methods, such as 3D modeling and satellite imagery, require complex and resource-intensive data inputs. In contrast, this research allows open-source 2D urban geographic information—such as building footprints, heights, and terrain—to predict solar radiation at various spatial scales (150 m, 300 m, and 500 m). The GAN model, using detailed 3D urban modeling and simulation results, trained paired datasets of geographic information and solar radiation heatmaps. It achieved high accuracy and resolution, with the 300 m scale model demonstrating the best performance (R2 = 0.864). The model’s capability to generate high-resolution (2 m) solar radiation maps from simplified inputs demonstrates the potential of GANs for urban climate data prediction, offering a rapid and efficient alternative to traditional methods. This approach holds significant potential for urban planning, particularly in optimizing photovoltaic (PV) system layouts and managing the UHI effect.",
         "['Generative Adversarial Network (GAN)', 'remote sensing data', 'solar radiation mapping', 'urban morphology']",
         "['Earth and Planetary Sciences (all)']",
         "Evaluating solar radiation distribution at the urban scale is crucial for optimizing the placement and size of solar installations and managing urban heat.",
         "This study introduces a method for predicting urban solar radiation using 2D mapping data, applying a Generative Adversarial Network (GAN) model to the city of Boston. Traditional solar radiation simulation methods, such as 3D modeling and satellite imagery, require complex and resource-intensive data inputs. In contrast, this research allows open-source 2D urban geographic information—such as building footprints, heights, and terrain—to predict solar radiation at various spatial scales (150 m, 300 m, and 500 m). The GAN model, using detailed 3D urban modeling and simulation results, trained paired datasets of geographic information and solar radiation heatmaps. It achieved high accuracy and resolution, with the 300 m scale model demonstrating the best performance (R2 = 0.864). The model’s capability to generate high-resolution (2 m) solar radiation maps from simplified inputs demonstrates the potential of GANs for urban climate data prediction, offering a rapid and efficient alternative to traditional methods. This approach holds significant potential for urban planning, particularly in optimizing photovoltaic (PV) system layouts and managing the UHI effect.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9573933482, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9573933482, 0.0426065847]}",
         "True",
         "0.9573933482",
         "['Environment', 'Renewable Energy', 'Urban Planning', 'Sustainability', 'Energy Management', 'Urban Management', 'Climate Change', 'Living', 'Business', 'Construction', 'Public Services', 'Buildings', 'Industry', 'Public Policies', 'Housing', 'Power Distribution', 'Citizens', 'Human', 'Economic Management', 'Governance', 'Logistics', 'Economy', 'Socioeconomics', 'People', 'Mobility', 'Multimodal Transport', 'Electric Vehicles', 'Green Spaces', 'Social Equity', 'Pedestrian', 'Citizen Engagement', 'Smart Grids', 'Emergency Safety', 'Transportation Systems', 'Public Transit', 'Healthcare', 'Finance', 'Education', 'Air Quality', 'Pollution Control', 'Tourism', 'Waste Management', 'Marketing', 'Water Quality', 'Bicycle', 'Cybersecurity', 'Culture', 'Traffic Management']",
         "[0.9571574926, 0.9079638720000001, 0.7698265314, 0.5902718306, 0.41836282610000003, 0.1632674634, 0.06727402660000001, 0.0386019237, 0.0206346717, 0.018595727200000002, 0.017485408100000002, 0.010864642400000001, 0.006090349100000001, 0.0057128556, 0.0038792235, 0.0024004837, 0.0011793445, 0.0011349848, 0.0009993331, 0.0007553342, 0.0006761297, 0.0006625024000000001, 0.0006155697, 0.0005707181, 0.0005049972, 0.00048297810000000004, 0.00046999600000000003, 0.0004635409, 0.00044225, 0.0004349758, 0.0004342892, 0.0004241148, 0.0004134437, 0.0003862458, 0.0003810574, 0.00037503330000000003, 0.00036497300000000004, 0.0003567285, 0.00034772350000000004, 0.0003463876, 0.000338856, 0.00033343530000000003, 0.00033323580000000003, 0.0003330413, 0.00033279880000000004, 0.0003198328, 0.00031571780000000003, 0.0003153549]",
         "[{'domain': 'Smart Environment', 'score': 0.9571574926}, {'domain': 'Smart Governance', 'score': 0.7698265314}]",
         "{'is_genai': True, 'confidence': 0.5168173313140869, 'matched_keywords': ['adv-gan', '3d gan', 'score-based model', 'cycle gan', 'gan', 'conditional gan', 'progressive gan', 'sr-gan'], 'technology_categories': ['Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('urban', 6), ('solar', 6), ('radiation', 6), ('datum', 4), ('gan', 4)], 'semantic_matches': [('adv-gan', 0.5168173313140869), ('3d gan', 0.47761598229408264), ('score-based model', 0.46480613946914673), ('cycle gan', 0.45849162340164185), ('gan', 0.4514774978160858), ('conditional gan', 0.4379921555519104), ('progressive gan', 0.4181321859359741), ('sr-gan', 0.4074317216873169)]}",
         "True",
         "0.5168173313140869",
         "['adv-gan', '3d gan', 'score-based model', 'cycle gan', 'gan', 'conditional gan', 'progressive gan', 'sr-gan']",
         "['Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models']",
         "[('urban', 6), ('solar', 6), ('radiation', 6), ('datum', 4), ('gan', 4)]",
         "[('adv-gan', 0.5168173313140869), ('3d gan', 0.47761598229408264), ('score-based model', 0.46480613946914673), ('cycle gan', 0.45849162340164185), ('gan', 0.4514774978160858), ('conditional gan', 0.4379921555519104), ('progressive gan', 0.4181321859359741), ('sr-gan', 0.4074317216873169)]"
        ],
        [
         "39",
         "Exploring hybrid models for identifying locations for active mobility pathways using real-time spatial Delphi and GANs",
         "Calleo Y.",
         "European Transport Research Review",
         "10.1186/s12544-024-00685-7",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85208942208",
         "85208942208",
         "The spatial planning process is considered an extremely complex system, as it comprises different variables that interrelate and interact with each other. Effectively addressing this spatial complexity necessitates a multidisciplinary approach, as unified methodologies may prove insufficient. Specifically, in urban planning, it is increasingly crucial to prioritize bike lanes, bike stations, and pedestrian zones, for functional transportation infrastructures. This approach can enhance cities by improving air quality, reducing emissions, and boosting public health and safety through physical activity and accident prevention. However, implementing these changes requires careful planning, community engagement, and stakeholder collaboration. This paper proposes a hybrid model for identifying optimal locations for bike lanes, bike stations, and pedestrian zones adopting Real-Time Spatial Delphi and Generative Adversarial Networks (GANs). The Real-Time Spatial Delphi is a modified version of the traditional Delphi method that incorporates real-time feedback and visualization of group response in real-time, aiming to achieve a convergence of opinions among experts on the territory. Nevertheless, these judgments are a spatial representation not visible in reality, and with the spread of artificial intelligence models, different implementations can support the planning process, such as the use of GANs. In this case, GANs can be exploited by adopting pre-existing location images resulting from experts’ judgments to illustrate the proposed intervention’s visual impact. To demonstrate the effectiveness of our hybrid model, we apply it to the city of Dublin. The results showcased how the method helps stakeholders, policymakers, and citizens in visualizing the proposed changes and gauging their potential impact with greater precision.",
         "['Artificial intelligence', 'Generative adversarial networks', 'Real-time spatial Delphi', 'Spatial planning']",
         "['Automotive Engineering', 'Transportation', 'Mechanical Engineering']",
         "The spatial planning process is considered an extremely complex system, as it comprises different variables that interrelate and interact with each other. Effectively addressing this spatial complexity necessitates a multidisciplinary approach, as unified methodologies may prove insufficient. Specifically, in urban planning, it is increasingly crucial to prioritize bike lanes, bike stations, and pedestrian zones, for functional transportation infrastructures.",
         "This approach can enhance cities by improving air quality, reducing emissions, and boosting public health and safety through physical activity and accident prevention. However, implementing these changes requires careful planning, community engagement, and stakeholder collaboration. This paper proposes a hybrid model for identifying optimal locations for bike lanes, bike stations, and pedestrian zones adopting Real-Time Spatial Delphi and Generative Adversarial Networks (GANs). The Real-Time Spatial Delphi is a modified version of the traditional Delphi method that incorporates real-time feedback and visualization of group response in real-time, aiming to achieve a convergence of opinions among experts on the territory. Nevertheless, these judgments are a spatial representation not visible in reality, and with the spread of artificial intelligence models, different implementations can support the planning process, such as the use of GANs. In this case, GANs can be exploited by adopting pre-existing location images resulting from experts’ judgments to illustrate the proposed intervention’s visual impact. To demonstrate the effectiveness of our hybrid model, we apply it to the city of Dublin. The results showcased how the method helps stakeholders, policymakers, and citizens in visualizing the proposed changes and gauging their potential impact with greater precision.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9222887158, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9222887158, 0.0777112469]}",
         "True",
         "0.9222887158",
         "['Urban Planning', 'Environment', 'Multimodal Transport', 'Mobility', 'Buildings', 'Pedestrian', 'Construction', 'Urban Management', 'Bicycle', 'Transportation Systems', 'Living', 'Public Transit', 'Housing', 'Sustainability', 'Citizens', 'Emergency Safety', 'Human', 'Business', 'Public Policies', 'Climate Change', 'Green Spaces', 'Public Services', 'Education', 'Citizen Engagement', 'Power Distribution', 'People', 'Tourism', 'Logistics', 'Electric Vehicles', 'Governance', 'Socioeconomics', 'Social Equity', 'Renewable Energy', 'Economy', 'Industry', 'Economic Management', 'Traffic Management', 'Cybersecurity', 'Culture', 'Healthcare', 'Air Quality', 'Finance', 'Energy Management', 'Smart Grids', 'Water Quality', 'Pollution Control', 'Waste Management', 'Marketing']",
         "[0.9979888201, 0.6671251655, 0.0854380429, 0.0172793884, 0.0107857985, 0.010637912000000001, 0.0036193754000000003, 0.0025760338, 0.0021651546, 0.0016281607, 0.0016033746, 0.0012114814, 0.0010707297, 0.0008718486, 0.0005998121000000001, 0.0005287639, 0.0005105538, 0.0004878282, 0.00046132510000000004, 0.000448769, 0.0004423672, 0.0004378489, 0.0004287105, 0.0004085787, 0.000396453, 0.0003954241, 0.0003890588, 0.0003830729, 0.0003806025, 0.00037551340000000004, 0.00036897110000000004, 0.0003681782, 0.0003647561, 0.00035508750000000003, 0.0003491823, 0.0003460895, 0.0003339188, 0.0003297124, 0.0003262741, 0.0003249269, 0.0003243647, 0.0003229894, 0.0003204936, 0.00031668230000000004, 0.0003159004, 0.0003049586, 0.0002977853, 0.00029218260000000003]",
         "[{'domain': 'Smart Governance', 'score': 0.9979888201}, {'domain': 'Smart Environment', 'score': 0.6671251655}]",
         "{'is_genai': True, 'confidence': 0.6241966485977173, 'matched_keywords': ['generative adversarial network', 'sr-gan', '3d gan', 'gan', 'conditional gan', 'progressive gan', 'cyclegan', 'vision-language model', 'generative capabilities', '3d generative model', 'generative capability', 'cycle gan', 'generative model'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('real', 5), ('time', 5), ('spatial', 5), ('delphi', 4), ('planning', 3)], 'semantic_matches': [('generative adversarial network', 0.6241966485977173), ('sr-gan', 0.5521576404571533), ('3d gan', 0.542305052280426), ('gan', 0.539668619632721), ('conditional gan', 0.5202105641365051), ('progressive gan', 0.5172698497772217), ('cyclegan', 0.4492267370223999), ('vision-language model', 0.4456039071083069), ('generative capabilities', 0.4305832087993622), ('3d generative model', 0.4280940294265747), ('generative capability', 0.4220113456249237), ('cycle gan', 0.41633176803588867), ('generative model', 0.40755778551101685)]}",
         "True",
         "0.6241966485977173",
         "['generative adversarial network', 'sr-gan', '3d gan', 'gan', 'conditional gan', 'progressive gan', 'cyclegan', 'vision-language model', 'generative capabilities', '3d generative model', 'generative capability', 'cycle gan', 'generative model']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('real', 5), ('time', 5), ('spatial', 5), ('delphi', 4), ('planning', 3)]",
         "[('generative adversarial network', 0.6241966485977173), ('sr-gan', 0.5521576404571533), ('3d gan', 0.542305052280426), ('gan', 0.539668619632721), ('conditional gan', 0.5202105641365051), ('progressive gan', 0.5172698497772217), ('cyclegan', 0.4492267370223999), ('vision-language model', 0.4456039071083069), ('generative capabilities', 0.4305832087993622), ('3d generative model', 0.4280940294265747), ('generative capability', 0.4220113456249237), ('cycle gan', 0.41633176803588867), ('generative model', 0.40755778551101685)]"
        ],
        [
         "40",
         "Integrative Remote Sensing Approaches Using Generative Adversarial Networks for Urban Heat Island Analysis and Mitigation",
         "Sundar G.",
         "Remote Sensing in Earth Systems Sciences",
         "10.1007/s41976-024-00156-6",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85207754175",
         "85207754175",
         "The phenomenon of urban heat islands (UHI) presents a critical challenge for urban sustainability, exacerbating local temperatures, increasing energy demands, and impairing public health. Traditional methods for addressing UHI are often resource-intensive and slow. This study introduces a novel approach, utilizing a Hybrid CycleGAN-SVM (HCGS) model that leverages the synergy of Generative Adversarial Networks (GANs) and Support Vector Machines (SVMs) to efficiently analyze and mitigate UHI effects through high-resolution satellite imagery and temperature data. The model incorporates Enhanced Vision Transformers (EViTs) for superior feature extraction, adept at capturing intricate spatial and spectral urban patterns. The CycleGAN component of the model generates high-quality synthetic imagery, enhancing the dataset and addressing class imbalances, thereby bolstering the SVM classifier’s ability to precisely pinpoint heat-prone urban areas. Implemented in Google Colab, the HCGS model demonstrated exceptional performance, achieving a classification accuracy of 0.98. This indicates its potential as an effective tool for urban heat mitigation, offering actionable insights for urban planning and policy-making. By integrating advanced machine learning techniques with remote sensing data, the HCGS model paves the way for innovative climate adaptation strategies, fostering more sustainable and resilient urban environments.",
         "['Enhanced Vision Transformers', 'EViTs', 'GANs', 'Generative Adversarial Networks', 'HCGS model', 'Hybrid CycleGAN-SVM', 'Satellite imagery', 'Support Vector Machines', 'SVM', 'UHI effect', 'Urban heat island']",
         "['Oceanography', 'Geography, Planning and Development', 'Computers in Earth Sciences', 'Atmospheric Science', 'Space and Planetary Science', 'Earth and Planetary Sciences (miscellaneous)']",
         "The phenomenon of urban heat islands (UHI) presents a critical challenge for urban sustainability, exacerbating local temperatures, increasing energy demands, and impairing public health. Traditional methods for addressing UHI are often resource-intensive and slow.",
         "This study introduces a novel approach, utilizing a Hybrid CycleGAN-SVM (HCGS) model that leverages the synergy of Generative Adversarial Networks (GANs) and Support Vector Machines (SVMs) to efficiently analyze and mitigate UHI effects through high-resolution satellite imagery and temperature data. The model incorporates Enhanced Vision Transformers (EViTs) for superior feature extraction, adept at capturing intricate spatial and spectral urban patterns. The CycleGAN component of the model generates high-quality synthetic imagery, enhancing the dataset and addressing class imbalances, thereby bolstering the SVM classifier’s ability to precisely pinpoint heat-prone urban areas. Implemented in Google Colab, the HCGS model demonstrated exceptional performance, achieving a classification accuracy of 0.98. This indicates its potential as an effective tool for urban heat mitigation, offering actionable insights for urban planning and policy-making. By integrating advanced machine learning techniques with remote sensing data, the HCGS model paves the way for innovative climate adaptation strategies, fostering more sustainable and resilient urban environments.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9803084135000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9803084135000001, 0.0196915213]}",
         "True",
         "0.9803084135000001",
         "['Environment', 'Sustainability', 'Urban Planning', 'Urban Management', 'Climate Change', 'Human', 'Housing', 'Buildings', 'Living', 'Public Policies', 'Energy Management', 'Citizens', 'Pollution Control', 'Construction', 'Socioeconomics', 'Public Services', 'People', 'Industry', 'Business', 'Economic Management', 'Governance', 'Logistics', 'Emergency Safety', 'Economy', 'Air Quality', 'Healthcare', 'Mobility', 'Transportation Systems', 'Multimodal Transport', 'Power Distribution', 'Social Equity', 'Pedestrian', 'Citizen Engagement', 'Public Transit', 'Renewable Energy', 'Finance', 'Electric Vehicles', 'Green Spaces', 'Waste Management', 'Tourism', 'Smart Grids', 'Culture', 'Marketing', 'Bicycle', 'Education', 'Cybersecurity', 'Water Quality', 'Traffic Management']",
         "[0.9944773912, 0.9352784753000001, 0.9180570841000001, 0.8558225632, 0.4381697774, 0.1450367272, 0.1091162935, 0.0932563394, 0.0867028311, 0.061091795600000005, 0.0352990814, 0.0281310286, 0.0278498325, 0.0224774964, 0.018610751300000002, 0.0185370371, 0.0158630703, 0.014913920300000001, 0.0103153056, 0.0085436581, 0.0057732067, 0.005171190500000001, 0.0040426496, 0.0031196836, 0.002782562, 0.0015902914, 0.000789458, 0.0006921891, 0.0006470719, 0.0005752284, 0.0005502937, 0.0005348971, 0.0005179307, 0.0004942472, 0.0004632414, 0.0004509769, 0.0004424732, 0.0004340551, 0.0004197483, 0.00041005910000000003, 0.0003977216, 0.00038953200000000005, 0.0003846885, 0.0003837707, 0.0003805754, 0.00037915210000000004, 0.0003413122, 0.0003140507]",
         "[{'domain': 'Smart Environment', 'score': 0.9944773912}, {'domain': 'Smart Governance', 'score': 0.9180570841000001}]",
         "{'is_genai': True, 'confidence': 0.523221492767334, 'matched_keywords': ['adv-gan', '3d gan', 'generative model', 'cycle gan', 'score-based model', 'generative adversarial network', 'cyclegan', 'gan', 'shape generation', '3d reconstruction', 'sr-gan', 'multimodal model', 'vision-language model', 'neural rendering'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('model', 6), ('urban', 6), ('svm', 4), ('hcgs', 4), ('cyclegan', 3)], 'semantic_matches': [('adv-gan', 0.523221492767334), ('3d gan', 0.48843321204185486), ('generative model', 0.482794851064682), ('cycle gan', 0.48272621631622314), ('score-based model', 0.4822181165218353), ('generative adversarial network', 0.46800392866134644), ('cyclegan', 0.4647102952003479), ('gan', 0.4499949514865875), ('shape generation', 0.44335776567459106), ('3d reconstruction', 0.4428902268409729), ('sr-gan', 0.4416477084159851), ('multimodal model', 0.435941219329834), ('vision-language model', 0.43485307693481445), ('neural rendering', 0.4039323329925537)]}",
         "True",
         "0.523221492767334",
         "['adv-gan', '3d gan', 'generative model', 'cycle gan', 'score-based model', 'generative adversarial network', 'cyclegan', 'gan', 'shape generation', '3d reconstruction', 'sr-gan', 'multimodal model', 'vision-language model', 'neural rendering']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('model', 6), ('urban', 6), ('svm', 4), ('hcgs', 4), ('cyclegan', 3)]",
         "[('adv-gan', 0.523221492767334), ('3d gan', 0.48843321204185486), ('generative model', 0.482794851064682), ('cycle gan', 0.48272621631622314), ('score-based model', 0.4822181165218353), ('generative adversarial network', 0.46800392866134644), ('cyclegan', 0.4647102952003479), ('gan', 0.4499949514865875), ('shape generation', 0.44335776567459106), ('3d reconstruction', 0.4428902268409729), ('sr-gan', 0.4416477084159851), ('multimodal model', 0.435941219329834), ('vision-language model', 0.43485307693481445), ('neural rendering', 0.4039323329925537)]"
        ],
        [
         "41",
         "A method to promote safe cycling powered by large language models and AI agents",
         "Costa D.G.",
         "MethodsX",
         "10.1016/j.mex.2024.102880",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85200231800",
         "85200231800",
         "This paper presents a novel information generation methodology to support safer cycling patterns in urban environments, leveraging for that Large Language Models (LLMs), AI-based agents, and open geospatial data. By processing multiple files containing previously computed urban risk levels and existing mobility infrastructure, which are generated by exploiting open data sources, our method exploits multi-layer data preprocessing procedures and prompt engineering to create easy-to-use, user-friendly assistive systems that are able to provide useful information concerning cycling safety. Through a well-defined processing pipeline based on Data Ingestion and Preparation, Agents Orchestration, and Decision Execution methodological steps, our method shows how to integrate open-source tools and datasets, ensuring reproducibility and accessibility for urban planners and cyclists. Moreover, an AI agent is also provided, which fully implements our method and acts as a proof-of-concept implementation. This paper demonstrates the effectiveness of our method in enhancing cycling safety and urban mobility planning. • A novel method that combines LLMs and AI agents is defined to enhance the processing of multi-domain open geospatial data, potentially promoting cycling safety. • It integrates urban risk data and cycling infrastructure for a more comprehensive understanding of cycling resources, which become accessible by textual or audio prompts.",
         "['Artificial Intelligence', 'Open data', 'Smart cities', 'Urban mobility']",
         "['Clinical Biochemistry', 'Medical Laboratory Technology']",
         "This paper presents a novel information generation methodology to support safer cycling patterns in urban environments, leveraging for that Large Language Models (LLMs), AI-based agents, and open geospatial data. By processing multiple files containing previously computed urban risk levels and existing mobility infrastructure, which are generated by exploiting open data sources, our method exploits multi-layer data preprocessing procedures and prompt engineering to create easy-to-use, user-friendly assistive systems that are able to provide useful information concerning cycling safety. Through a well-defined processing pipeline based on Data Ingestion and Preparation, Agents Orchestration, and Decision Execution methodological steps, our method shows how to integrate open-source tools and datasets, ensuring reproducibility and accessibility for urban planners and cyclists. Moreover, an AI agent is also provided, which fully implements our method and acts as a proof-of-concept implementation. This paper demonstrates the effectiveness of our method in enhancing cycling safety and urban mobility planning. • A novel method that combines LLMs and AI agents is defined to enhance the processing of multi-domain open geospatial data, potentially promoting cycling safety. • It integrates urban risk data and cycling infrastructure for a more comprehensive understanding of cycling resources, which become accessible by textual or audio prompts.",
         "This paper presents a novel information generation methodology to support safer cycling patterns in urban environments, leveraging for that Large Language Models (LLMs), AI-based agents, and open geospatial data. By processing multiple files containing previously computed urban risk levels and existing mobility infrastructure, which are generated by exploiting open data sources, our method exploits multi-layer data preprocessing procedures and prompt engineering to create easy-to-use, user-friendly assistive systems that are able to provide useful information concerning cycling safety. Through a well-defined processing pipeline based on Data Ingestion and Preparation, Agents Orchestration, and Decision Execution methodological steps, our method shows how to integrate open-source tools and datasets, ensuring reproducibility and accessibility for urban planners and cyclists. Moreover, an AI agent is also provided, which fully implements our method and acts as a proof-of-concept implementation. This paper demonstrates the effectiveness of our method in enhancing cycling safety and urban mobility planning. • A novel method that combines LLMs and AI agents is defined to enhance the processing of multi-domain open geospatial data, potentially promoting cycling safety. • It integrates urban risk data and cycling infrastructure for a more comprehensive understanding of cycling resources, which become accessible by textual or audio prompts.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9842799902, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9842799902, 0.0157200061]}",
         "True",
         "0.9842799902",
         "['Urban Planning', 'Mobility', 'Transportation Systems', 'Environment', 'Urban Management', 'Multimodal Transport', 'Public Services', 'Living', 'Construction', 'Traffic Management', 'Logistics', 'Socioeconomics', 'People', 'Industry', 'Sustainability', 'Public Policies', 'Human', 'Economic Management', 'Business', 'Education', 'Citizens', 'Bicycle', 'Power Distribution', 'Social Equity', 'Citizen Engagement', 'Economy', 'Governance', 'Smart Grids', 'Emergency Safety', 'Marketing', 'Climate Change', 'Renewable Energy', 'Pollution Control', 'Energy Management', 'Water Quality', 'Healthcare', 'Public Transit', 'Electric Vehicles', 'Cybersecurity', 'Green Spaces', 'Buildings', 'Air Quality', 'Finance', 'Culture', 'Tourism', 'Waste Management', 'Housing', 'Pedestrian']",
         "[0.9068331718, 0.8494178653000001, 0.8401851654, 0.5284352899, 0.5272411704000001, 0.21003866200000001, 0.10283675040000001, 0.0812307522, 0.034889716700000004, 0.0343213938, 0.0294034798, 0.0285440385, 0.0250626449, 0.023114450300000002, 0.015042427, 0.0150293475, 0.012324280100000001, 0.0106019368, 0.0096217785, 0.0084793773, 0.008263496700000001, 0.0075913696, 0.0062053963, 0.0049382895, 0.0042310487, 0.0028371119, 0.0022888973, 0.0019720071, 0.0017415311, 0.0011999019, 0.0010148081, 0.0009967382000000001, 0.0009802649, 0.0009782602, 0.0007598174, 0.000723216, 0.0007198157, 0.0007000495000000001, 0.0006875481, 0.0006807745, 0.0006504293, 0.0006416608, 0.0006305533, 0.0006179982, 0.0005556503, 0.0005199776, 0.0004154203, 0.0003810298]",
         "[{'domain': 'Smart Governance', 'score': 0.9068331718}, {'domain': 'Smart Mobility', 'score': 0.8494178653000001}, {'domain': 'Smart Environment', 'score': 0.5284352899}]",
         "{'is_genai': True, 'confidence': 0.6273543238639832, 'matched_keywords': ['ai capability', 'designed with ai', 'implicit representation', 'gen ai', 'cyclegan'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('cycling', 6), ('urban', 6), ('open', 5), ('datum', 5), ('method', 5)], 'semantic_matches': [('ai capability', 0.6273543238639832), ('designed with ai', 0.5855188369750977), ('implicit representation', 0.43888264894485474), ('gen ai', 0.42933952808380127), ('cyclegan', 0.41716286540031433)]}",
         "True",
         "0.6273543238639832",
         "['ai capability', 'designed with ai', 'implicit representation', 'gen ai', 'cyclegan']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models']",
         "[('cycling', 6), ('urban', 6), ('open', 5), ('datum', 5), ('method', 5)]",
         "[('ai capability', 0.6273543238639832), ('designed with ai', 0.5855188369750977), ('implicit representation', 0.43888264894485474), ('gen ai', 0.42933952808380127), ('cyclegan', 0.41716286540031433)]"
        ],
        [
         "42",
         "Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models",
         "Han B.",
         "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
         "10.1145/3678717.3691296",
         "2024",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/85215132750",
         "85215132750",
         "Equitable urban transportation applications require high-fidelity digital representations of the built environment (streets, crossings, curb ramps and more). Direct inspections and manual annotations are costly at scale, while conventional machine learning methods require substantial annotated training data for adequate performance. This study explores vision language models as a tool for annotating diverse urban features from satellite images, reducing the dependence on human annotation. Although these models excel at describing common objects in human-centric images, their training sets may lack signals for esoteric built environment features, making their performance uncertain. We demonstrate a proof-of-concept using a vision language model and a visual prompting strategy that considers segmented image elements. Experiments on two urban features - stop lines and raised tables - show that while zero-shot prompting rarely works, the segmentation and visual prompting strategies achieve nearly 40% intersection-over-union accuracy. We describe how these results motivate further research in automatic annotation of the built environment to improve equity, accessibility, and safety at scale and in diverse environments.",
         "['Image Segmentation', 'Large Language Model', 'Urban Computing', 'Urban Data Annotation', 'Vision Language Model']",
         "['Information Systems', 'Earth-Surface Processes', 'Modeling and Simulation', 'Computer Graphics and Computer-Aided Design', 'Computer Science Applications']",
         "Equitable urban transportation applications require high-fidelity digital representations of the built environment (streets, crossings, curb ramps and more). Direct inspections and manual annotations are costly at scale, while conventional machine learning methods require substantial annotated training data for adequate performance.",
         "This study explores vision language models as a tool for annotating diverse urban features from satellite images, reducing the dependence on human annotation. Although these models excel at describing common objects in human-centric images, their training sets may lack signals for esoteric built environment features, making their performance uncertain. We demonstrate a proof-of-concept using a vision language model and a visual prompting strategy that considers segmented image elements. Experiments on two urban features - stop lines and raised tables - show that while zero-shot prompting rarely works, the segmentation and visual prompting strategies achieve nearly 40% intersection-over-union accuracy. We describe how these results motivate further research in automatic annotation of the built environment to improve equity, accessibility, and safety at scale and in diverse environments.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7009364963, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7009364963, 0.2990635037]}",
         "True",
         "0.7009364963",
         "['Transportation Systems', 'Mobility', 'Multimodal Transport', 'Environment', 'Traffic Management', 'Urban Management', 'Urban Planning', 'Social Equity', 'Public Services', 'Pedestrian', 'Business', 'Public Transit', 'Construction', 'Buildings', 'Industry', 'Logistics', 'Socioeconomics', 'Living', 'Public Policies', 'Smart Grids', 'Human', 'Citizens', 'Electric Vehicles', 'Sustainability', 'Emergency Safety', 'Economic Management', 'Economy', 'Governance', 'Citizen Engagement', 'Power Distribution', 'Energy Management', 'People', 'Bicycle', 'Climate Change', 'Cybersecurity', 'Renewable Energy', 'Education', 'Finance', 'Culture', 'Healthcare', 'Green Spaces', 'Air Quality', 'Marketing', 'Housing', 'Waste Management', 'Water Quality', 'Pollution Control', 'Tourism']",
         "[0.9070447683, 0.8657572269, 0.5071098804, 0.2554080486, 0.2159538865, 0.16648559270000002, 0.0984933898, 0.08527792990000001, 0.053171213700000004, 0.0210027285, 0.013407815200000001, 0.0051535219, 0.0046696626, 0.0023840887, 0.0020400952, 0.0015281006, 0.0013093135, 0.0011388236, 0.0008687093000000001, 0.0008299297, 0.0008182408000000001, 0.0006872779, 0.0006492119, 0.0006384670000000001, 0.0005871191, 0.0005421083, 0.0005364723000000001, 0.00047211970000000003, 0.00046094640000000003, 0.0003939446, 0.0003901685, 0.00038409290000000003, 0.00038274260000000003, 0.0003607468, 0.0003545793, 0.0003366926, 0.00032962620000000003, 0.0003202276, 0.00031998840000000003, 0.0003140859, 0.0003114696, 0.00031062310000000003, 0.000307075, 0.00030110900000000003, 0.0002981576, 0.00029431760000000004, 0.0002917188, 0.0002914086]",
         "[{'domain': 'Smart Mobility', 'score': 0.9070447683}]",
         "{'is_genai': True, 'confidence': 0.7151023149490356, 'matched_keywords': ['vision-language model', 'large language model', 'small language model', 'neural rendering', 'foundational framework', 'pretrained language model', 'foundation framework', '3d generative model', 'imagen', 'generative capability'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('model', 5), ('language', 4), ('urban', 4), ('image', 4), ('vision', 3)], 'semantic_matches': [('vision-language model', 0.7151023149490356), ('large language model', 0.5691015720367432), ('small language model', 0.4926612377166748), ('neural rendering', 0.4755184054374695), ('foundational framework', 0.4367746114730835), ('pretrained language model', 0.4223954677581787), ('foundation framework', 0.4138067364692688), ('3d generative model', 0.40971848368644714), ('imagen', 0.4067409038543701), ('generative capability', 0.40039563179016113)]}",
         "True",
         "0.7151023149490356",
         "['vision-language model', 'large language model', 'small language model', 'neural rendering', 'foundational framework', 'pretrained language model', 'foundation framework', '3d generative model', 'imagen', 'generative capability']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('model', 5), ('language', 4), ('urban', 4), ('image', 4), ('vision', 3)]",
         "[('vision-language model', 0.7151023149490356), ('large language model', 0.5691015720367432), ('small language model', 0.4926612377166748), ('neural rendering', 0.4755184054374695), ('foundational framework', 0.4367746114730835), ('pretrained language model', 0.4223954677581787), ('foundation framework', 0.4138067364692688), ('3d generative model', 0.40971848368644714), ('imagen', 0.4067409038543701), ('generative capability', 0.40039563179016113)]"
        ],
        [
         "43",
         "Harnessing LLMs for Cross-City OD Flow Prediction",
         "Yu C.",
         "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
         "10.1145/3678717.3691308",
         "2024",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/85215081956",
         "85215081956",
         "Understanding and predicting Origin-Destination (OD) flows is crucial for urban planning and transportation management. Traditional OD prediction models, while effective within single cities, often face limitations when applied across different cities due to varied traffic conditions, urban layouts, and socio-economic factors. In this paper, by employing Large Language Models (LLMs), we introduce a new method for cross-city OD flow prediction. Our approach leverages the advanced semantic understanding and contextual learning capabilities of LLMs to bridge the gap between cities with different characteristics, providing a robust and adaptable solution for accurate OD flow prediction that can be transferred from one city to another. Our novel framework involves four major components: collecting OD training datasets from a source city, instruction-tuning the LLMs, predicting destination POIs in a target city, and identifying the locations that best match the predicted destination POIs. We introduce a new loss function that integrates POI semantics and trip distance during training. By extracting high-quality semantic features from human mobility and POI data, the model understands spatial and functional relationships within urban spaces and captures interactions between individuals and various POIs. Extensive experimental results demonstrate the superiority of our approach over the state-of-the-art learning-based methods in cross-city OD flow prediction.",
         "['Cross-City Transferability', 'Large Language Models(LLMs)', 'origin-destination', 'Urban Computing']",
         "['Information Systems', 'Earth-Surface Processes', 'Modeling and Simulation', 'Computer Graphics and Computer-Aided Design', 'Computer Science Applications']",
         "Understanding and predicting Origin-Destination (OD) flows is crucial for urban planning and transportation management. Traditional OD prediction models, while effective within single cities, often face limitations when applied across different cities due to varied traffic conditions, urban layouts, and socio-economic factors.",
         "In this paper, by employing Large Language Models (LLMs), we introduce a new method for cross-city OD flow prediction. Our approach leverages the advanced semantic understanding and contextual learning capabilities of LLMs to bridge the gap between cities with different characteristics, providing a robust and adaptable solution for accurate OD flow prediction that can be transferred from one city to another. Our novel framework involves four major components: collecting OD training datasets from a source city, instruction-tuning the LLMs, predicting destination POIs in a target city, and identifying the locations that best match the predicted destination POIs. We introduce a new loss function that integrates POI semantics and trip distance during training. By extracting high-quality semantic features from human mobility and POI data, the model understands spatial and functional relationships within urban spaces and captures interactions between individuals and various POIs. Extensive experimental results demonstrate the superiority of our approach over the state-of-the-art learning-based methods in cross-city OD flow prediction.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.6938591599, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.6938591599, 0.3061408699]}",
         "True",
         "0.6938591599",
         "['Transportation Systems', 'Urban Planning', 'Mobility', 'Logistics', 'Urban Management', 'Traffic Management', 'Public Transit', 'Multimodal Transport', 'Environment', 'Economy', 'People', 'Economic Management', 'Public Policies', 'Business', 'Living', 'Power Distribution', 'Socioeconomics', 'Public Services', 'Human', 'Construction', 'Governance', 'Industry', 'Citizens', 'Sustainability', 'Energy Management', 'Emergency Safety', 'Electric Vehicles', 'Tourism', 'Climate Change', 'Bicycle', 'Waste Management', 'Education', 'Smart Grids', 'Housing', 'Finance', 'Pedestrian', 'Renewable Energy', 'Air Quality', 'Green Spaces', 'Buildings', 'Social Equity', 'Pollution Control', 'Cybersecurity', 'Healthcare', 'Citizen Engagement', 'Water Quality', 'Marketing', 'Culture']",
         "[0.9551379681000001, 0.9328907728, 0.9224598408, 0.9090462327000001, 0.8446670771, 0.3883445561, 0.0691400021, 0.0577753633, 0.0516294762, 0.0212934203, 0.013989198000000001, 0.012844327800000001, 0.0126736443, 0.011347265, 0.0083059426, 0.0079954667, 0.0074559632, 0.0067510279000000005, 0.006335761400000001, 0.0031804629, 0.0023739988000000003, 0.0017504276000000001, 0.0013672225000000001, 0.0008534089, 0.0008504803, 0.0008480672, 0.0006873948, 0.0006453031, 0.000567663, 0.0005545357, 0.0005483982, 0.0005391405, 0.0005352387, 0.0005117095, 0.0005113273, 0.0005076575000000001, 0.0004977249, 0.0004948952, 0.0004685386, 0.0004645771, 0.0004612291, 0.0004609023, 0.00045764540000000004, 0.00045305890000000003, 0.0004338979, 0.0004257883, 0.0004251994, 0.0003851794]",
         "[{'domain': 'Smart Mobility', 'score': 0.9551379681000001}, {'domain': 'Smart Governance', 'score': 0.9328907728}, {'domain': 'Smart Economy', 'score': 0.9090462327000001}]",
         "{'is_genai': True, 'confidence': 0.6343147158622742, 'matched_keywords': ['large flow model', 'flow model', 'large language model', 'pretrained language model', 'small language model', 'multimodal model', 'vision-language model', 'noise prediction', 'contrastive learning', 'signed distance function'], 'technology_categories': ['Transformer-Based Models', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('city', 7), ('poi', 5), ('llms', 3), ('cross', 3), ('flow', 3)], 'semantic_matches': [('large flow model', 0.6343147158622742), ('flow model', 0.6241797804832458), ('large language model', 0.582014262676239), ('pretrained language model', 0.4822777807712555), ('small language model', 0.4753526449203491), ('multimodal model', 0.4613826870918274), ('vision-language model', 0.45588457584381104), ('noise prediction', 0.45046889781951904), ('contrastive learning', 0.40628868341445923), ('signed distance function', 0.4002750813961029)]}",
         "True",
         "0.6343147158622742",
         "['large flow model', 'flow model', 'large language model', 'pretrained language model', 'small language model', 'multimodal model', 'vision-language model', 'noise prediction', 'contrastive learning', 'signed distance function']",
         "['Transformer-Based Models', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('city', 7), ('poi', 5), ('llms', 3), ('cross', 3), ('flow', 3)]",
         "[('large flow model', 0.6343147158622742), ('flow model', 0.6241797804832458), ('large language model', 0.582014262676239), ('pretrained language model', 0.4822777807712555), ('small language model', 0.4753526449203491), ('multimodal model', 0.4613826870918274), ('vision-language model', 0.45588457584381104), ('noise prediction', 0.45046889781951904), ('contrastive learning', 0.40628868341445923), ('signed distance function', 0.4002750813961029)]"
        ],
        [
         "44",
         "MobGLM: A Large Language Model for Synthetic Human Mobility Generation",
         "Zhang K.",
         "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
         "10.1145/3678717.3691311",
         "2024",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/85215078760",
         "85215078760",
         "Human mobility generation plays a critical role in urban transportation planning. Existing human mobility generation models often fall short of understanding travelers’ demographics and integrating multimodal information, including activity purposes, destination choices and transport mode preferences. Recently, mobility generation models leveraging Large Language Models (LLMs) have gained significant attention, while they are limited in directly reproducing spatial information in human mobility profiles. To address these challenges, this paper proposes the Mobility Generative Language Model (MobGLM), a novel approach for generating synthetic human mobility data to support urban planning, transport management, energy consumption and epidemic control. MobGLM addresses these limitations by capturing the complex relationships between agents’ mobility patterns and individual demographics. By incorporating personal information, activity types, locations and traffic modes as encoders, MobGLM uniquely identifies and replicates features of human mobility. Our framework is evaluated using a large, real-world mobility dataset and benchmarked against state-of-the-art personal mobility generation techniques. The results demonstrate the effectiveness of MobGLM in producing accurate and reliable synthetic mobility data, highlighting its potential applications in various urban mobility contexts.",
         "['Human Mobility', 'Logit Adjustment', 'NLP', 'Non-Daily Activity', 'Sequence Generation', 'Transformer']",
         "['Information Systems', 'Earth-Surface Processes', 'Modeling and Simulation', 'Computer Graphics and Computer-Aided Design', 'Computer Science Applications']",
         "Human mobility generation plays a critical role in urban transportation planning. Existing human mobility generation models often fall short of understanding travelers’ demographics and integrating multimodal information, including activity purposes, destination choices and transport mode preferences. Recently, mobility generation models leveraging Large Language Models (LLMs) have gained significant attention, while they are limited in directly reproducing spatial information in human mobility profiles.",
         "To address these challenges, this paper proposes the Mobility Generative Language Model (MobGLM), a novel approach for generating synthetic human mobility data to support urban planning, transport management, energy consumption and epidemic control. MobGLM addresses these limitations by capturing the complex relationships between agents’ mobility patterns and individual demographics. By incorporating personal information, activity types, locations and traffic modes as encoders, MobGLM uniquely identifies and replicates features of human mobility. Our framework is evaluated using a large, real-world mobility dataset and benchmarked against state-of-the-art personal mobility generation techniques. The results demonstrate the effectiveness of MobGLM in producing accurate and reliable synthetic mobility data, highlighting its potential applications in various urban mobility contexts.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9778548479, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9778548479, 0.0221452005]}",
         "True",
         "0.9778548479",
         "['Mobility', 'Human', 'People', 'Transportation Systems', 'Urban Planning', 'Multimodal Transport', 'Public Transit', 'Urban Management', 'Living', 'Pedestrian', 'Citizens', 'Public Services', 'Logistics', 'Public Policies', 'Environment', 'Business', 'Socioeconomics', 'Traffic Management', 'Construction', 'Economy', 'Sustainability', 'Economic Management', 'Governance', 'Tourism', 'Bicycle', 'Emergency Safety', 'Industry', 'Citizen Engagement', 'Social Equity', 'Education', 'Electric Vehicles', 'Finance', 'Marketing', 'Air Quality', 'Climate Change', 'Healthcare', 'Smart Grids', 'Cybersecurity', 'Culture', 'Energy Management', 'Power Distribution', 'Green Spaces', 'Renewable Energy', 'Water Quality', 'Pollution Control', 'Waste Management', 'Housing', 'Buildings']",
         "[0.9929317236, 0.9757986069000001, 0.9686552286000001, 0.911033988, 0.767172575, 0.6886330843, 0.1400222182, 0.09613410380000001, 0.0451874398, 0.021103482700000002, 0.0197691116, 0.0185396839, 0.0160426535, 0.013131990100000001, 0.0063086161, 0.004158197000000001, 0.0018004879, 0.0015220743, 0.0013861845000000001, 0.0009454021000000001, 0.0009435163, 0.0009342402, 0.0008077111, 0.0007614350000000001, 0.0006449684, 0.0006342539000000001, 0.0006290501000000001, 0.0006141909, 0.0005324653, 0.0004891264, 0.0004545547, 0.0003996437, 0.00039622320000000003, 0.0003825213, 0.0003800052, 0.0003669711, 0.0003575837, 0.0003570002, 0.0003531412, 0.0003432409, 0.00033782900000000005, 0.0003364878, 0.0003266589, 0.0003200479, 0.00031493680000000004, 0.00031379300000000004, 0.00030743780000000003, 0.0003019522]",
         "[{'domain': 'Smart Mobility', 'score': 0.9929317236}, {'domain': 'Smart People', 'score': 0.9757986069000001}, {'domain': 'Smart Governance', 'score': 0.767172575}]",
         "{'is_genai': True, 'confidence': 0.4890144467353821, 'matched_keywords': ['generative pretrained transformer', 'transformer', 'generative model', 'small language model', '3d generative model', 'large language model'], 'technology_categories': ['Transformer-Based Models', 'Neural Radiance Fields & 3D Models'], 'bridge_terms': [('mobility', 9), ('mobglm', 4), ('human', 3), ('address', 2), ('synthetic', 2)], 'semantic_matches': [('generative pretrained transformer', 0.4890144467353821), ('transformer', 0.45696255564689636), ('generative model', 0.45178282260894775), ('small language model', 0.4145638346672058), ('3d generative model', 0.40742233395576477), ('large language model', 0.4028164744377136)]}",
         "True",
         "0.4890144467353821",
         "['generative pretrained transformer', 'transformer', 'generative model', 'small language model', '3d generative model', 'large language model']",
         "['Transformer-Based Models', 'Neural Radiance Fields & 3D Models']",
         "[('mobility', 9), ('mobglm', 4), ('human', 3), ('address', 2), ('synthetic', 2)]",
         "[('generative pretrained transformer', 0.4890144467353821), ('transformer', 0.45696255564689636), ('generative model', 0.45178282260894775), ('small language model', 0.4145638346672058), ('3d generative model', 0.40742233395576477), ('large language model', 0.4028164744377136)]"
        ],
        [
         "45",
         "From Geolocated Images to Urban Region Identification and Description: a Large Language Model Approach",
         "Rocchietti G.",
         "32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM SIGSPATIAL 2024",
         "10.1145/3678717.3691317",
         "2024",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/85215067432",
         "85215067432",
         "Urban research faces challenges in understanding and describing city regions, which are essential for urban planning and tourism management. Traditional methods rely on predefined areas and non-human-readable representations. This paper presents a new unsupervised approach that overcomes these limitations using a data-driven method with Instruction-tuned Large Language Models (ILLMs). Our technique dynamically identifies urban regions with similar features and generates human-readable descriptions. We validate this method using Flickr images from Pisa, Italy, and our results show that it effectively captures the semantic features of urban regions and generates comprehensible textual descriptions.",
         "['Image Captioning', 'Large Language Models', 'Sum-marization', 'Urban Regions']",
         "['Information Systems', 'Earth-Surface Processes', 'Modeling and Simulation', 'Computer Graphics and Computer-Aided Design', 'Computer Science Applications']",
         "Urban research faces challenges in understanding and describing city regions, which are essential for urban planning and tourism management. Traditional methods rely on predefined areas and non-human-readable representations.",
         "This paper presents a new unsupervised approach that overcomes these limitations using a data-driven method with Instruction-tuned Large Language Models (ILLMs). Our technique dynamically identifies urban regions with similar features and generates human-readable descriptions. We validate this method using Flickr images from Pisa, Italy, and our results show that it effectively captures the semantic features of urban regions and generates comprehensible textual descriptions.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.8989712596, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.8989712596, 0.10102875530000001]}",
         "True",
         "0.8989712596",
         "['Urban Planning', 'Environment', 'Urban Management', 'Living', 'Socioeconomics', 'Human', 'Housing', 'Governance', 'Public Policies', 'Citizens', 'Public Services', 'People', 'Construction', 'Logistics', 'Economy', 'Business', 'Economic Management', 'Pedestrian', 'Multimodal Transport', 'Mobility', 'Emergency Safety', 'Social Equity', 'Green Spaces', 'Citizen Engagement', 'Public Transit', 'Culture', 'Power Distribution', 'Sustainability', 'Transportation Systems', 'Buildings', 'Tourism', 'Electric Vehicles', 'Climate Change', 'Industry', 'Education', 'Energy Management', 'Renewable Energy', 'Air Quality', 'Smart Grids', 'Water Quality', 'Waste Management', 'Finance', 'Pollution Control', 'Healthcare', 'Bicycle', 'Marketing', 'Cybersecurity', 'Traffic Management']",
         "[0.6284909248, 0.0901732147, 0.0288147684, 0.0255013499, 0.0043063518, 0.0024982132, 0.0014934288, 0.0012859175, 0.0009865189000000001, 0.0009681017, 0.0007728040000000001, 0.0006210123, 0.0005517377, 0.0005341391, 0.0005155895000000001, 0.0005099425, 0.0005003203000000001, 0.0004808324, 0.0004586975, 0.0004458062, 0.000430673, 0.0004149747, 0.00040097740000000003, 0.0003996056, 0.0003943086, 0.0003748211, 0.0003706553, 0.00037055430000000004, 0.0003584427, 0.000358153, 0.00034975290000000003, 0.00034727090000000004, 0.0003445775, 0.0003401141, 0.0003399694, 0.00033800780000000003, 0.0003279475, 0.00032735990000000003, 0.0003222573, 0.0003185687, 0.00031696510000000003, 0.0003164065, 0.0003112789, 0.0003076142, 0.0003039017, 0.0003022052, 0.0002901596, 0.0002723205]",
         "[{'domain': 'Smart Governance', 'score': 0.6284909248}]",
         "{'is_genai': True, 'confidence': 0.605814516544342, 'matched_keywords': ['large language model', 'small language model', 'pretrained language model', 'vision-language model', 'classifier-free guidance', 'generative model'], 'technology_categories': ['Transformer-Based Models', 'Diffusion Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('urban', 3), ('method', 2), ('large', 2), ('language', 2), ('models', 2)], 'semantic_matches': [('large language model', 0.605814516544342), ('small language model', 0.6039201021194458), ('pretrained language model', 0.5819958448410034), ('vision-language model', 0.5121129155158997), ('classifier-free guidance', 0.4549313485622406), ('generative model', 0.4400729238986969)]}",
         "True",
         "0.605814516544342",
         "['large language model', 'small language model', 'pretrained language model', 'vision-language model', 'classifier-free guidance', 'generative model']",
         "['Transformer-Based Models', 'Diffusion Models', 'Hybrid & Multimodal Architectures']",
         "[('urban', 3), ('method', 2), ('large', 2), ('language', 2), ('models', 2)]",
         "[('large language model', 0.605814516544342), ('small language model', 0.6039201021194458), ('pretrained language model', 0.5819958448410034), ('vision-language model', 0.5121129155158997), ('classifier-free guidance', 0.4549313485622406), ('generative model', 0.4400729238986969)]"
        ],
        [
         "46",
         "Leveraging Multi-Source Data for the Trustworthy Evaluation of the Vibrancy of Child-Friendly Cities: A Case Study of Tianjin, China",
         "Zhang D.",
         "Electronics (Switzerland)",
         "10.3390/electronics13224564",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85210296341",
         "85210296341",
         "The vitality of a city is shaped by its social structure, environmental quality, and spatial form, with child-friendliness being an essential component of urban vitality. While there are numerous qualitative studies on the relationship between child-friendliness and various indicators of urban vitality, quantitative research remains relatively scarce, leading to a lack of sufficient objective and trustworthy data to guide urban planning and the development of child-friendly cities. This paper presents an analytical framework, using Heping District in Tianjin, China, as a case study. It defines four main indicators—social vitality, environmental vitality, spatial vitality, and urban scene perception—for a trustworthy and transparent quantitative evaluation. The study integrates multi-source data, including primary education (POI) data, street view image (SVI) data, spatiotemporal big data, normalized difference vegetation index (NDVI), and large visual language models (LVLMs) for the trustworthy analysis. These data are visualized using corresponding big data and weighted analysis methods, ensuring transparent and accurate assessments of the child-friendliness of urban blocks. This research introduces an innovative and trustworthy method for evaluating the child-friendliness of urban blocks, addressing gaps in the quantitative theory of child-friendliness in urban planning. It also provides a practical and reliable tool for urban planners, offering a solid theoretical foundation to create environments that better meet the needs of children in a trustworthy manner.",
         "['child-friendly', 'multi-source data', 'urban analysis', 'urban vitality', 'vision large language models']",
         "['Control and Systems Engineering', 'Signal Processing', 'Hardware and Architecture', 'Computer Networks and Communications', 'Electrical and Electronic Engineering']",
         "The vitality of a city is shaped by its social structure, environmental quality, and spatial form, with child-friendliness being an essential component of urban vitality. While there are numerous qualitative studies on the relationship between child-friendliness and various indicators of urban vitality, quantitative research remains relatively scarce, leading to a lack of sufficient objective and trustworthy data to guide urban planning and the development of child-friendly cities.",
         "This paper presents an analytical framework, using Heping District in Tianjin, China, as a case study. It defines four main indicators—social vitality, environmental vitality, spatial vitality, and urban scene perception—for a trustworthy and transparent quantitative evaluation. The study integrates multi-source data, including primary education (POI) data, street view image (SVI) data, spatiotemporal big data, normalized difference vegetation index (NDVI), and large visual language models (LVLMs) for the trustworthy analysis. These data are visualized using corresponding big data and weighted analysis methods, ensuring transparent and accurate assessments of the child-friendliness of urban blocks. This research introduces an innovative and trustworthy method for evaluating the child-friendliness of urban blocks, addressing gaps in the quantitative theory of child-friendliness in urban planning. It also provides a practical and reliable tool for urban planners, offering a solid theoretical foundation to create environments that better meet the needs of children in a trustworthy manner.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9480716586000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9480716586000001, 0.051928415900000004]}",
         "True",
         "0.9480716586000001",
         "['Urban Planning', 'Urban Management', 'Construction', 'Living', 'Socioeconomics', 'Environment', 'Human', 'People', 'Buildings', 'Housing', 'Public Services', 'Citizens', 'Governance', 'Social Equity', 'Public Policies', 'Culture', 'Economy', 'Business', 'Green Spaces', 'Economic Management', 'Sustainability', 'Emergency Safety', 'Power Distribution', 'Mobility', 'Logistics', 'Pedestrian', 'Public Transit', 'Multimodal Transport', 'Education', 'Citizen Engagement', 'Transportation Systems', 'Water Quality', 'Tourism', 'Energy Management', 'Marketing', 'Electric Vehicles', 'Pollution Control', 'Waste Management', 'Healthcare', 'Smart Grids', 'Renewable Energy', 'Industry', 'Climate Change', 'Finance', 'Air Quality', 'Bicycle', 'Cybersecurity', 'Traffic Management']",
         "[0.9908850789, 0.5774332285, 0.354033798, 0.1901358813, 0.15388487280000002, 0.10637278850000001, 0.0843300745, 0.0744518489, 0.0588463545, 0.0459608771, 0.032858628800000005, 0.032225664700000003, 0.019286558000000002, 0.0192444194, 0.0165454205, 0.0114729218, 0.0068760486, 0.0058851736, 0.0056919716, 0.005156785200000001, 0.0043464107, 0.0040316316, 0.0036150625000000002, 0.0035765101000000002, 0.0032151041, 0.0024357922, 0.0022496958, 0.0022430099, 0.0017768909, 0.0011786306, 0.0010526673, 0.0010073257000000001, 0.0009928995, 0.0009161761, 0.0008871528, 0.0008577238000000001, 0.000843593, 0.0008244436, 0.0007683253, 0.0007675982, 0.0007642451, 0.0007325871000000001, 0.0007104053, 0.000672933, 0.000606766, 0.0005381555, 0.0004971533000000001, 0.00044907940000000004]",
         "[{'domain': 'Smart Governance', 'score': 0.9908850789}]",
         "{'is_genai': True, 'confidence': 0.6086879968643188, 'matched_keywords': ['vision-language model', 'large language model', 'small language model', 'foundational framework', 'pretrained language model', 'foundation framework'], 'technology_categories': ['Transformer-Based Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('urban', 7), ('datum', 7), ('child', 5), ('vitality', 4), ('trustworthy', 4)], 'semantic_matches': [('vision-language model', 0.6086879968643188), ('large language model', 0.510867714881897), ('small language model', 0.48345303535461426), ('foundational framework', 0.44236889481544495), ('pretrained language model', 0.4094294309616089), ('foundation framework', 0.40705493092536926)]}",
         "True",
         "0.6086879968643188",
         "['vision-language model', 'large language model', 'small language model', 'foundational framework', 'pretrained language model', 'foundation framework']",
         "['Transformer-Based Models', 'Hybrid & Multimodal Architectures']",
         "[('urban', 7), ('datum', 7), ('child', 5), ('vitality', 4), ('trustworthy', 4)]",
         "[('vision-language model', 0.6086879968643188), ('large language model', 0.510867714881897), ('small language model', 0.48345303535461426), ('foundational framework', 0.44236889481544495), ('pretrained language model', 0.4094294309616089), ('foundation framework', 0.40705493092536926)]"
        ],
        [
         "47",
         "Spatial–Temporal Similarity Fusion Graph Adversarial Convolutional Networks for traffic flow forecasting",
         "Wang B.",
         "Journal of the Franklin Institute",
         "10.1016/j.jfranklin.2024.107299",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85205570650",
         "85205570650",
         "Traffic flow forecasting is integral to the advancement of intelligent transportation systems and the development of smart cities. This paper introduces a novel model, the Spatial–Temporal Similarity Fusion Graphs Adversarial Convolutional Networks (STSF-GACN), which leverages advanced data preprocessing techniques to enhance the predictive accuracy and efficiency of traffic flow forecasting. The innovation of our approach lies in the meticulous construction of the spatial–temporal similarity matrix through the precise calculation of temporal and spatial similarities. This matrix forms the backbone of our model, serving as the generator in the integrated Generative Adversarial Network (GAN) architecture. The Spatial–Temporal Similarity Fusion Adaptive Graph Convolutional Network, developed as part of our GAN's generator, utilizes cutting-edge techniques such as the Wasserstein distance and Dynamic Time Warping to optimize the adaptive adjacency matrix, enabling the model to capture latent spatial–temporal correlations with unprecedented depth and precision. The discriminator of the GAN further refines the model by evaluating the accuracy of the traffic predictions, ensuring that the generative model produces results that are not only accurate but also robust against varying traffic conditions. This cohesive integration of GAN into the model architecture allows for a significant improvement in prediction accuracy and convergence speed, moving beyond traditional forecasting methods.",
         "['Graph Convolutional Neural Network', 'Similarity measure', 'Traffic flow forecasting']",
         "['Control and Systems Engineering', 'Signal Processing', 'Computer Networks and Communications', 'Applied Mathematics']",
         "Traffic flow forecasting is integral to the advancement of intelligent transportation systems and the development of smart cities.",
         "This paper introduces a novel model, the Spatial–Temporal Similarity Fusion Graphs Adversarial Convolutional Networks (STSF-GACN), which leverages advanced data preprocessing techniques to enhance the predictive accuracy and efficiency of traffic flow forecasting. The innovation of our approach lies in the meticulous construction of the spatial–temporal similarity matrix through the precise calculation of temporal and spatial similarities. This matrix forms the backbone of our model, serving as the generator in the integrated Generative Adversarial Network (GAN) architecture. The Spatial–Temporal Similarity Fusion Adaptive Graph Convolutional Network, developed as part of our GAN's generator, utilizes cutting-edge techniques such as the Wasserstein distance and Dynamic Time Warping to optimize the adaptive adjacency matrix, enabling the model to capture latent spatial–temporal correlations with unprecedented depth and precision. The discriminator of the GAN further refines the model by evaluating the accuracy of the traffic predictions, ensuring that the generative model produces results that are not only accurate but also robust against varying traffic conditions. This cohesive integration of GAN into the model architecture allows for a significant improvement in prediction accuracy and convergence speed, moving beyond traditional forecasting methods.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.9138829112, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.9138829112, 0.08611707390000001]}",
         "True",
         "0.9138829112",
         "['Transportation Systems', 'Mobility', 'Logistics', 'Urban Management', 'Traffic Management', 'Public Services', 'Multimodal Transport', 'Public Policies', 'Business', 'Industry', 'Living', 'Urban Planning', 'Citizens', 'Environment', 'People', 'Economy', 'Public Transit', 'Economic Management', 'Governance', 'Human', 'Socioeconomics', 'Construction', 'Electric Vehicles', 'Sustainability', 'Citizen Engagement', 'Emergency Safety', 'Smart Grids', 'Energy Management', 'Renewable Energy', 'Climate Change', 'Power Distribution', 'Finance', 'Social Equity', 'Green Spaces', 'Buildings', 'Pollution Control', 'Cybersecurity', 'Education', 'Air Quality', 'Marketing', 'Healthcare', 'Waste Management', 'Water Quality', 'Tourism', 'Housing', 'Culture', 'Pedestrian', 'Bicycle']",
         "[0.9961928725, 0.9916003942, 0.9278615713, 0.7577143908, 0.7441433072, 0.3978741169, 0.3442052007, 0.1021519229, 0.06556249410000001, 0.022476295, 0.020225575200000002, 0.0186341517, 0.014838507400000001, 0.0112448502, 0.0047047934, 0.0032340665, 0.0024768191, 0.0021126375000000003, 0.0011586038, 0.0010898162, 0.0008825255000000001, 0.0006112913, 0.0005594043, 0.0004862394, 0.00046950400000000004, 0.0004606293, 0.0004230797, 0.00041455130000000003, 0.0004045984, 0.00039815170000000004, 0.00038755960000000004, 0.0003755202, 0.0003704089, 0.00036686630000000003, 0.0003544625, 0.0003518916, 0.0003501916, 0.0003419279, 0.00034154810000000004, 0.0003411751, 0.0003362199, 0.0003327198, 0.0003260073, 0.0003196979, 0.0003158556, 0.00031474540000000004, 0.0003070608, 0.0002953763]",
         "[{'domain': 'Smart Mobility', 'score': 0.9961928725}, {'domain': 'Smart Economy', 'score': 0.9278615713}, {'domain': 'Smart Governance', 'score': 0.7577143908}]",
         "{'is_genai': True, 'confidence': 0.5812524557113647, 'matched_keywords': ['conditional gan', 'generative adversarial network', 'progressive gan', 'gan', 'sr-gan', 'generative model', 'cycle gan', 'adv-gan', 'generative capabilities', 'multimodal fusion', 'multimodal model', 'multimodal alignment', '3d gan', 'flow model', 'occupancy network'], 'technology_categories': ['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('model', 6), ('spatial', 5), ('temporal', 5), ('similarity', 5), ('traffic', 4)], 'semantic_matches': [('conditional gan', 0.5812524557113647), ('generative adversarial network', 0.5812404155731201), ('progressive gan', 0.5469446182250977), ('gan', 0.5458754301071167), ('sr-gan', 0.5321396589279175), ('generative model', 0.5320148468017578), ('cycle gan', 0.5183238387107849), ('adv-gan', 0.5112993717193604), ('generative capabilities', 0.48105329275131226), ('multimodal fusion', 0.44262731075286865), ('multimodal model', 0.43197548389434814), ('multimodal alignment', 0.42979684472084045), ('3d gan', 0.4129061996936798), ('flow model', 0.40910953283309937), ('occupancy network', 0.4079206585884094)]}",
         "True",
         "0.5812524557113647",
         "['conditional gan', 'generative adversarial network', 'progressive gan', 'gan', 'sr-gan', 'generative model', 'cycle gan', 'adv-gan', 'generative capabilities', 'multimodal fusion', 'multimodal model', 'multimodal alignment', '3d gan', 'flow model', 'occupancy network']",
         "['Transformer-Based Models', 'Generative Adversarial Networks', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('model', 6), ('spatial', 5), ('temporal', 5), ('similarity', 5), ('traffic', 4)]",
         "[('conditional gan', 0.5812524557113647), ('generative adversarial network', 0.5812404155731201), ('progressive gan', 0.5469446182250977), ('gan', 0.5458754301071167), ('sr-gan', 0.5321396589279175), ('generative model', 0.5320148468017578), ('cycle gan', 0.5183238387107849), ('adv-gan', 0.5112993717193604), ('generative capabilities', 0.48105329275131226), ('multimodal fusion', 0.44262731075286865), ('multimodal model', 0.43197548389434814), ('multimodal alignment', 0.42979684472084045), ('3d gan', 0.4129061996936798), ('flow model', 0.40910953283309937), ('occupancy network', 0.4079206585884094)]"
        ],
        [
         "48",
         "Dataset Generation for Korean Urban Parks Analysis with Large Language Models",
         "Kim H.",
         "International Conference on Information and Knowledge Management, Proceedings",
         "10.1145/3627673.3679109",
         "2024",
         "Conference Paper",
         "https://api.elsevier.com/content/abstract/scopus_id/85210013106",
         "85210013106",
         "Understanding how urban parks are utilized and perceived by the public is crucial for effective urban planning and management. This study introduces a novel dataset derived from Instagram, using 42,187 images tagged with #Seoul and #Park hashtags from 2017 to 2023. These images were filtered using InternLM-XComposer2, a Multimodal Large Language Model (MLLM), to confirm they depicted park scenes. GPT-4 then annotated the filtered images, resulting in 29,866 valid image annotations of physical elements, human activities, animals, and emotions. The dataset is publicly available at https://huggingface.co/datasets/RedBall/seoul-urban-park-analysis-by-llm.",
         "['datasets', 'image annotation', 'large language models', 'urban park']",
         "['Business, Management and Accounting (all)', 'Decision Sciences (all)']",
         "Understanding how urban parks are utilized and perceived by the public is crucial for effective urban planning and management.",
         "This study introduces a novel dataset derived from Instagram, using 42,187 images tagged with #Seoul and #Park hashtags from 2017 to 2023. These images were filtered using InternLM-XComposer2, a Multimodal Large Language Model (MLLM), to confirm they depicted park scenes. GPT-4 then annotated the filtered images, resulting in 29,866 valid image annotations of physical elements, human activities, animals, and emotions. The dataset is publicly available at https://huggingface.co/datasets/RedBall/seoul-urban-park-analysis-by-llm.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7949786186000001, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7949786186000001, 0.2050213367]}",
         "True",
         "0.7949786186000001",
         "['Urban Planning', 'Urban Management', 'Green Spaces', 'Citizens', 'Citizen Engagement', 'Environment', 'People', 'Public Services', 'Living', 'Culture', 'Socioeconomics', 'Human', 'Public Policies', 'Governance', 'Social Equity', 'Pedestrian', 'Economic Management', 'Tourism', 'Business', 'Logistics', 'Education', 'Sustainability', 'Construction', 'Mobility', 'Electric Vehicles', 'Emergency Safety', 'Multimodal Transport', 'Power Distribution', 'Bicycle', 'Public Transit', 'Economy', 'Climate Change', 'Renewable Energy', 'Water Quality', 'Housing', 'Marketing', 'Transportation Systems', 'Air Quality', 'Buildings', 'Energy Management', 'Smart Grids', 'Industry', 'Waste Management', 'Pollution Control', 'Healthcare', 'Finance', 'Traffic Management', 'Cybersecurity']",
         "[0.9884337187000001, 0.9537333846, 0.9352575541, 0.7745136023, 0.7203162909, 0.7011356354, 0.4126365483, 0.3962488174, 0.3538921177, 0.15915960070000001, 0.0437739715, 0.0427905358, 0.025731772200000003, 0.0220525134, 0.0048769671, 0.0029216986, 0.001648259, 0.0016413789, 0.0008348977, 0.0008053380000000001, 0.0007192428, 0.0007184148000000001, 0.0006874204, 0.0006478491000000001, 0.0006108405, 0.00058093, 0.0005642151, 0.0005150892, 0.0004988407, 0.0004793023, 0.0004697761, 0.00045693350000000003, 0.00044638070000000004, 0.000446129, 0.00042401360000000004, 0.0004215262, 0.00041685450000000004, 0.0004144799, 0.0004126999, 0.00041054110000000003, 0.0004096355, 0.0003937196, 0.00038974, 0.00038342110000000003, 0.000374271, 0.00037045810000000003, 0.0003564724, 0.0003245767]",
         "[{'domain': 'Smart Governance', 'score': 0.9884337187000001}, {'domain': 'Smart Environment', 'score': 0.9352575541}, {'domain': 'Smart People', 'score': 0.7745136023}]",
         "{'is_genai': True, 'confidence': 0.552354097366333, 'matched_keywords': ['large language model', 'vision-language model', 'small language model', 'multimodal embedding', 'multimodal model', 'text-to-image diffusion', 'pretrained language model', 'neural rendering', 'imagen', 'generative model'], 'technology_categories': ['Transformer-Based Models', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('image', 5), ('dataset', 3), ('park', 3), ('filter', 2), ('large', 2)], 'semantic_matches': [('large language model', 0.552354097366333), ('vision-language model', 0.5333410501480103), ('small language model', 0.4591076374053955), ('multimodal embedding', 0.45744937658309937), ('multimodal model', 0.4571024775505066), ('text-to-image diffusion', 0.44689130783081055), ('pretrained language model', 0.4310368001461029), ('neural rendering', 0.430782675743103), ('imagen', 0.4289986789226532), ('generative model', 0.4058360159397125)]}",
         "True",
         "0.552354097366333",
         "['large language model', 'vision-language model', 'small language model', 'multimodal embedding', 'multimodal model', 'text-to-image diffusion', 'pretrained language model', 'neural rendering', 'imagen', 'generative model']",
         "['Transformer-Based Models', 'Diffusion Models', 'Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('image', 5), ('dataset', 3), ('park', 3), ('filter', 2), ('large', 2)]",
         "[('large language model', 0.552354097366333), ('vision-language model', 0.5333410501480103), ('small language model', 0.4591076374053955), ('multimodal embedding', 0.45744937658309937), ('multimodal model', 0.4571024775505066), ('text-to-image diffusion', 0.44689130783081055), ('pretrained language model', 0.4310368001461029), ('neural rendering', 0.430782675743103), ('imagen', 0.4289986789226532), ('generative model', 0.4058360159397125)]"
        ],
        [
         "49",
         "Application of mask R-CNN for building detection in UAV remote sensing images",
         "Hou T.",
         "Heliyon",
         "10.1016/j.heliyon.2024.e38141",
         "2024",
         "Article",
         "https://api.elsevier.com/content/abstract/scopus_id/85204876529",
         "85204876529",
         "This study aims to tackle the challenges of low accuracy in building feature extraction and insufficient details in three-dimensional (3D) modeling faced by traditional methods, particularly in complex backgrounds. To address these issues, a method for building feature extraction based on Mask Region-Convolutional Neural Network (Mask R-CNN) is proposed. This approach combines deep learning techniques with aerial images to ensure precise and efficient automatic detection and feature extraction. Urban building images are captured through aerial photography, and building outlines are annotated to create a comprehensive dataset of building features. The Mask R-CNN-based method efficiently processes and classifies the features of the dataset, generating candidate regions for further analysis. Additionally, this method demonstrates significant advantages in building feature extraction by employing the Mask R-CNN model to generate adaptive features. Comparative analysis with models such as Convolutional Neural Network (CNN), Region-based Convolutional Neural Network (R-CNN), Fast Region-based Convolutional Neural Network (Fast R-CNN), Faster Region-based Convolutional Neural Network (Faster R-CNN), and Generative Adversarial Network (GAN) indicates that Mask R-CNN exhibits superior performance in building feature extraction. The Mask R-CNN-based approach achieved approximately 95 % classification accuracy, while also showcasing strong stability and generalization capabilities. This study provides new methodologies and insights for enhancing feature extraction in aerial building imagery, offering significant reference value for the fields of architectural design and urban planning.",
         "['Deep learning', 'Instance segmentation', 'UAV remote sensing']",
         "['Multidisciplinary']",
         "This study aims to tackle the challenges of low accuracy in building feature extraction and insufficient details in three-dimensional (3D) modeling faced by traditional methods, particularly in complex backgrounds. To address these issues, a method for building feature extraction based on Mask Region-Convolutional Neural Network (Mask R-CNN) is proposed. This approach combines deep learning techniques with aerial images to ensure precise and efficient automatic detection and feature extraction. Urban building images are captured through aerial photography, and building outlines are annotated to create a comprehensive dataset of building features. The Mask R-CNN-based method efficiently processes and classifies the features of the dataset, generating candidate regions for further analysis. Additionally, this method demonstrates significant advantages in building feature extraction by employing the Mask R-CNN model to generate adaptive features. Comparative analysis with models such as Convolutional Neural Network (CNN), Region-based Convolutional Neural Network (R-CNN), Fast Region-based Convolutional Neural Network (Fast R-CNN), Faster Region-based Convolutional Neural Network (Faster R-CNN), and Generative Adversarial Network (GAN) indicates that Mask R-CNN exhibits superior performance in building feature extraction. The Mask R-CNN-based approach achieved approximately 95 % classification accuracy, while also showcasing strong stability and generalization capabilities. This study provides new methodologies and insights for enhancing feature extraction in aerial building imagery, offering significant reference value for the fields of architectural design and urban planning.",
         "This study aims to tackle the challenges of low accuracy in building feature extraction and insufficient details in three-dimensional (3D) modeling faced by traditional methods, particularly in complex backgrounds. To address these issues, a method for building feature extraction based on Mask Region-Convolutional Neural Network (Mask R-CNN) is proposed. This approach combines deep learning techniques with aerial images to ensure precise and efficient automatic detection and feature extraction. Urban building images are captured through aerial photography, and building outlines are annotated to create a comprehensive dataset of building features. The Mask R-CNN-based method efficiently processes and classifies the features of the dataset, generating candidate regions for further analysis. Additionally, this method demonstrates significant advantages in building feature extraction by employing the Mask R-CNN model to generate adaptive features. Comparative analysis with models such as Convolutional Neural Network (CNN), Region-based Convolutional Neural Network (R-CNN), Fast Region-based Convolutional Neural Network (Fast R-CNN), Faster Region-based Convolutional Neural Network (Faster R-CNN), and Generative Adversarial Network (GAN) indicates that Mask R-CNN exhibits superior performance in building feature extraction. The Mask R-CNN-based approach achieved approximately 95 % classification accuracy, while also showcasing strong stability and generalization capabilities. This study provides new methodologies and insights for enhancing feature extraction in aerial building imagery, offering significant reference value for the fields of architectural design and urban planning.",
         "{'is_genai_application': True, 'top_label': 'GenAI used for smart city application', 'score': 0.7046051621, 'all_labels': ['GenAI used for smart city application', 'Not related'], 'all_scores': [0.7046051621, 0.2953948081]}",
         "True",
         "0.7046051621",
         "['Buildings', 'Urban Planning', 'Environment', 'Urban Management', 'Industry', 'Construction', 'Housing', 'Business', 'Public Services', 'Socioeconomics', 'Emergency Safety', 'Education', 'Economic Management', 'Multimodal Transport', 'Renewable Energy', 'Logistics', 'Power Distribution', 'Mobility', 'Sustainability', 'Public Policies', 'Energy Management', 'Citizens', 'Living', 'Smart Grids', 'Electric Vehicles', 'Governance', 'Social Equity', 'Economy', 'Citizen Engagement', 'Tourism', 'Water Quality', 'Public Transit', 'Culture', 'Climate Change', 'Air Quality', 'Transportation Systems', 'Marketing', 'Waste Management', 'Green Spaces', 'Pollution Control', 'Cybersecurity', 'People', 'Finance', 'Traffic Management', 'Healthcare', 'Pedestrian', 'Human', 'Bicycle']",
         "[0.9747657776, 0.2614999712, 0.2119278461, 0.0730283409, 0.0605802052, 0.0514031649, 0.0424348004, 0.007511622700000001, 0.0074668038, 0.0037870978, 0.0036776166, 0.0035367212, 0.0034676136000000002, 0.0028645028, 0.0025379243, 0.0022877455, 0.0022164558000000003, 0.0021861205, 0.0021251088, 0.0018697327, 0.0018303503, 0.0015956938, 0.0015493426, 0.0014567161, 0.0013717482, 0.001367619, 0.0012759377, 0.0012143246000000001, 0.0012132927, 0.0011954601, 0.0010718842, 0.0010679252, 0.0010671982, 0.000952179, 0.0009395324, 0.0008885027, 0.0008386998, 0.0008014298, 0.0007565459, 0.0007446814, 0.0007239178, 0.0007031163, 0.0006442223000000001, 0.0005794078, 0.0005578315, 0.0005405362000000001, 0.0005092153, 0.0004136645]",
         "[{'domain': 'Smart Living', 'score': 0.9747657776}]",
         "{'is_genai': True, 'confidence': 0.49830928444862366, 'matched_keywords': ['3d generative model', 'neural rendering', 'contrastive learning', '3d reconstruction', 'neural implicit surface', 'imagen'], 'technology_categories': ['Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures'], 'bridge_terms': [('feature', 9), ('cnn', 9), ('extraction', 6), ('base', 6), ('mask', 6)], 'semantic_matches': [('3d generative model', 0.49830928444862366), ('neural rendering', 0.4923974275588989), ('contrastive learning', 0.4912826120853424), ('3d reconstruction', 0.47024187445640564), ('neural implicit surface', 0.43342286348342896), ('imagen', 0.4088079333305359)]}",
         "True",
         "0.49830928444862366",
         "['3d generative model', 'neural rendering', 'contrastive learning', '3d reconstruction', 'neural implicit surface', 'imagen']",
         "['Neural Radiance Fields & 3D Models', 'Hybrid & Multimodal Architectures']",
         "[('feature', 9), ('cnn', 9), ('extraction', 6), ('base', 6), ('mask', 6)]",
         "[('3d generative model', 0.49830928444862366), ('neural rendering', 0.4923974275588989), ('contrastive learning', 0.4912826120853424), ('3d reconstruction', 0.47024187445640564), ('neural implicit surface', 0.43342286348342896), ('imagen', 0.4088079333305359)]"
        ]
       ],
       "shape": {
        "columns": 26,
        "rows": 238
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>prism:url</th>\n",
       "      <th>scopus_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author_keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>classification_labels</th>\n",
       "      <th>classification_scores</th>\n",
       "      <th>macro_domains</th>\n",
       "      <th>semantic_detection</th>\n",
       "      <th>semantic_is_genai</th>\n",
       "      <th>semantic_confidence</th>\n",
       "      <th>semantic_keywords</th>\n",
       "      <th>semantic_categories</th>\n",
       "      <th>bridge_terms</th>\n",
       "      <th>semantic_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GeoAvatar: A big mobile phone positioning data-driven method for individualized pseudo personal ...</td>\n",
       "      <td>Li P.</td>\n",
       "      <td>Computers, Environment and Urban Systems</td>\n",
       "      <td>10.1016/j.compenvurbsys.2025.102252</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/86000553754</td>\n",
       "      <td>86000553754</td>\n",
       "      <td>The importance of personal mobility data is widely recognized in various fields. However, the ut...</td>\n",
       "      <td>[Big mobility data, Generative model, GIS, Mahince learning, Smart City]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Mobility, Human, People, Transportation Systems, Logistics, Living, Business, Economic Manageme...</td>\n",
       "      <td>[0.9896059632, 0.8164116144, 0.8087953925, 0.5389818549000001, 0.3266232014, 0.2026114315, 0.063...</td>\n",
       "      <td>[{'domain': 'Smart Mobility', 'score': 0.9896059632}, {'domain': 'Smart People', 'score': 0.8164...</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.48666954040527344, 'matched_keywords': ['generative model', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.486670</td>\n",
       "      <td>[generative model, 3d generative model]</td>\n",
       "      <td>[Transformer-Based Models, Neural Radiance Fields &amp; 3D Models]</td>\n",
       "      <td>[(method, 4), (generate, 4), (mobility, 4), (model, 3), (individual, 3)]</td>\n",
       "      <td>[(generative model, 0.48666954040527344), (3d generative model, 0.41732609272003174)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demystifying SAR with attention</td>\n",
       "      <td>Patnaik N.</td>\n",
       "      <td>Expert Systems with Applications</td>\n",
       "      <td>10.1016/j.eswa.2025.127182</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/86000797212</td>\n",
       "      <td>86000797212</td>\n",
       "      <td>Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the abil...</td>\n",
       "      <td>[Attention, Deep learning, Generative adversarial networks, Image colorization, Image restoratio...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Environment, Public Services, Business, Climate Change, Living, Buildings, Construction, Human,...</td>\n",
       "      <td>[0.6324490309, 0.028749804900000002, 0.0051401048, 0.0038975298, 0.0037373602, 0.0037206223, 0.0...</td>\n",
       "      <td>[{'domain': 'Smart Environment', 'score': 0.6324490309}]</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.6297489404678345, 'matched_keywords': ['attention mechanism',...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.629749</td>\n",
       "      <td>[attention mechanism, wgan-gp, self-attention, cross-attention, sr-gan, generative adversarial n...</td>\n",
       "      <td>[Transformer-Based Models, Generative Adversarial Networks, Diffusion Models, Neural Radiance Fi...</td>\n",
       "      <td>[(attention, 5), (image, 4), (sar, 3), (colorization, 2), (base, 2)]</td>\n",
       "      <td>[(attention mechanism, 0.6297489404678345), (wgan-gp, 0.524022102355957), (self-attention, 0.480...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MiM-UNet: An efficient building image segmentation network integrating state space models</td>\n",
       "      <td>Liu D.</td>\n",
       "      <td>Alexandria Engineering Journal</td>\n",
       "      <td>10.1016/j.aej.2025.02.035</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85218637730</td>\n",
       "      <td>85218637730</td>\n",
       "      <td>With the advancement of remote sensing technology, the analysis of complex terrain images has be...</td>\n",
       "      <td>[Building segmentation, Complex terrain, Deep learning, Remote sensing images, State space models]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Environment, Urban Planning, Buildings, Urban Management, Housing, Business, Construction, Indu...</td>\n",
       "      <td>[0.8005703092, 0.7748115659, 0.5123480558, 0.26313909890000003, 0.017528373700000002, 0.00406645...</td>\n",
       "      <td>[{'domain': 'Smart Environment', 'score': 0.8005703092}, {'domain': 'Smart Governance', 'score':...</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.632642388343811, 'matched_keywords': ['encoder-decoder', 'lat...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.632642</td>\n",
       "      <td>[encoder-decoder, latent space modeling, autoencoder, shape generation, neural rendering, vision...</td>\n",
       "      <td>[Transformer-Based Models, Variational Autoencoders, Neural Radiance Fields &amp; 3D Models, Hybrid ...</td>\n",
       "      <td>[(mamba, 4), (mim, 3), (unet, 3), (state, 3), (model, 3)]</td>\n",
       "      <td>[(encoder-decoder, 0.632642388343811), (latent space modeling, 0.44094717502593994), (autoencode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Building Change Detection in Aerial Imagery Using End-to-End Deep Learning Semantic Segmentation...</td>\n",
       "      <td>Teo T.A.</td>\n",
       "      <td>Buildings</td>\n",
       "      <td>10.3390/buildings15050695</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/86000578375</td>\n",
       "      <td>86000578375</td>\n",
       "      <td>Automatic building change detection is essential for updating geospatial data, urban planning, a...</td>\n",
       "      <td>[buildings, change detection, deep learning, map updating]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Buildings, Urban Planning, Construction, Urban Management, Public Services, Environment, Housin...</td>\n",
       "      <td>[0.9861167073, 0.898650229, 0.6620252132000001, 0.6395537853000001, 0.2649227679, 0.2593763471, ...</td>\n",
       "      <td>[{'domain': 'Smart Living', 'score': 0.9861167073}, {'domain': 'Smart Governance', 'score': 0.89...</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.5988814830780029, 'matched_keywords': ['transformer', 'genera...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.598881</td>\n",
       "      <td>[transformer, generative pretrained transformer, multimodal transformer, imagen, multimodal fusi...</td>\n",
       "      <td>[Transformer-Based Models, Neural Radiance Fields &amp; 3D Models, Hybrid &amp; Multimodal Architectures]</td>\n",
       "      <td>[(change, 5), (base, 4), (end, 4), (building, 4), (detection, 4)]</td>\n",
       "      <td>[(transformer, 0.5988814830780029), (generative pretrained transformer, 0.5384024381637573), (mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow...</td>\n",
       "      <td>Huang J.</td>\n",
       "      <td>Environmental Science and Ecotechnology</td>\n",
       "      <td>10.1016/j.ese.2025.100526</td>\n",
       "      <td>2025</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85216848180</td>\n",
       "      <td>85216848180</td>\n",
       "      <td>Rapid urbanization, alongside escalating resource depletion and ecological degradation, undersco...</td>\n",
       "      <td>[Foundation models, Generative artificial intelligence, Generative spatial artificial intelligen...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Urban Planning, Urban Management, Sustainability, Multimodal Transport, Construction, Environme...</td>\n",
       "      <td>[0.9958809614, 0.8571100831, 0.40149432420000003, 0.036717657, 0.0271584447, 0.0257922839, 0.023...</td>\n",
       "      <td>[{'domain': 'Smart Governance', 'score': 0.9958809614}, {'domain': 'Smart Environment', 'score':...</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.6537469625473022, 'matched_keywords': ['large flow model', 'f...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.653747</td>\n",
       "      <td>[large flow model, flow model, foundational framework, foundation model, foundation framework, l...</td>\n",
       "      <td>[Transformer-Based Models, Neural Radiance Fields &amp; 3D Models]</td>\n",
       "      <td>[(urban, 9), (flow, 5), (model, 5), (city, 5), (lfm, 4)]</td>\n",
       "      <td>[(large flow model, 0.6537469625473022), (flow model, 0.6234424114227295), (foundational framewo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Demonstration of Electrically Injected Semipolar Laser Diodes Grown on Low-Cost and Scalable Sap...</td>\n",
       "      <td>Khoury M.</td>\n",
       "      <td>ACS Applied Materials and Interfaces</td>\n",
       "      <td>10.1021/acsami.9b17525</td>\n",
       "      <td>2019</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85076790759</td>\n",
       "      <td>85076790759</td>\n",
       "      <td>The last two decades have shown an increasing need for GaN-based laser diodes (LDs), which are c...</td>\n",
       "      <td>[GaN, laser diodes, scalable, semipolar, templates]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Industry, Business, Economy, Socioeconomics, Economic Management, Marketing, Environment, Mobil...</td>\n",
       "      <td>[0.5686096549, 0.5395241976, 0.0077464948, 0.0021609876000000003, 0.001608802, 0.0012988048, 0.0...</td>\n",
       "      <td>[{'domain': 'Smart Economy', 'score': 0.5686096549}]</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.6290763020515442, 'matched_keywords': ['3d gan', '5gt-gan', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.629076</td>\n",
       "      <td>[3d gan, 5gt-gan, sr-gan, conditional gan, gan, progressive gan, adv-gan, cycle gan]</td>\n",
       "      <td>[Generative Adversarial Networks, Neural Radiance Fields &amp; 3D Models]</td>\n",
       "      <td>[(semipolar, 3), (low, 3), (gan, 3), (density, 2), (template, 2)]</td>\n",
       "      <td>[(3d gan, 0.6290763020515442), (5gt-gan, 0.5917875170707703), (sr-gan, 0.58832848072052), (condi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Phytogan: Unpaired dead-to-live phytoplankton translation</td>\n",
       "      <td>Han S.</td>\n",
       "      <td>Proceedings - 2019 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted ...</td>\n",
       "      <td>10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00109</td>\n",
       "      <td>2019</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85083593256</td>\n",
       "      <td>85083593256</td>\n",
       "      <td>Detecting phytoplankton that causes red tide is an urgent task. However, the live phytoplankton ...</td>\n",
       "      <td>[Contour, PCALoss, PhytoGAN, Phytoplankton]</td>\n",
       "      <td>...</td>\n",
       "      <td>[Environment, Water Quality, Living, Emergency Safety, Public Services, Pollution Control, Cultu...</td>\n",
       "      <td>[0.9808947444, 0.2901338637, 0.0916244462, 0.031032999999999998, 0.0146472873, 0.0032697413, 0.0...</td>\n",
       "      <td>[{'domain': 'Smart Environment', 'score': 0.9808947444}]</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.48289957642555237, 'matched_keywords': ['generative adversari...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>[generative adversarial network, neural rendering, imagen, diffusion model]</td>\n",
       "      <td>[Generative Adversarial Networks, Diffusion Models, Neural Radiance Fields &amp; 3D Models, Hybrid &amp;...</td>\n",
       "      <td>[(phytoplankton, 5), (image, 4), (phytogan, 3), (pcaloss, 3), (paper, 2)]</td>\n",
       "      <td>[(generative adversarial network, 0.48289957642555237), (neural rendering, 0.45412594079971313),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>A GAN-based active terrain mapping for collaborative air-ground robotic system</td>\n",
       "      <td>Chen J.</td>\n",
       "      <td>2019 4th IEEE International Conference on Advanced Robotics and Mechatronics, ICARM 2019</td>\n",
       "      <td>10.1109/ICARM.2019.8833919</td>\n",
       "      <td>2019</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85073261923</td>\n",
       "      <td>85073261923</td>\n",
       "      <td>Collaborative air-ground robotic system has recently emerged as an important research area and s...</td>\n",
       "      <td>[Active Learning, Collaborative Air-Ground Robotic System, Convolutional Neural Networks (CNN), ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Mobility, Multimodal Transport, Transportation Systems, Industry, Logistics, Business, Urban Ma...</td>\n",
       "      <td>[0.9317734838, 0.9130275249, 0.40025082230000003, 0.0498190336, 0.0333033353, 0.0136193736, 0.01...</td>\n",
       "      <td>[{'domain': 'Smart Mobility', 'score': 0.9317734838}]</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.5831387639045715, 'matched_keywords': ['adv-gan', '3d gan', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.583139</td>\n",
       "      <td>[adv-gan, 3d gan, gan, generative adversarial network, progressive gan, sr-gan, conditional gan,...</td>\n",
       "      <td>[Transformer-Based Models, Generative Adversarial Networks, Neural Radiance Fields &amp; 3D Models]</td>\n",
       "      <td>[(gan, 5), (terrain, 4), (map, 3), (active, 3), (system, 2)]</td>\n",
       "      <td>[(adv-gan, 0.5831387639045715), (3d gan, 0.531076967716217), (gan, 0.5111932754516602), (generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Macro-level traffic safety analysis in Shanghai, China</td>\n",
       "      <td>Wang X.</td>\n",
       "      <td>Accident Analysis and Prevention</td>\n",
       "      <td>10.1016/j.aap.2019.02.014</td>\n",
       "      <td>2019</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85061832713</td>\n",
       "      <td>85061832713</td>\n",
       "      <td>Continuing rapid growth in Shanghai, China, requires traffic safety to be considered at the earl...</td>\n",
       "      <td>[Bayesian conditional autoregressive model, Macro-level safety modeling, Traffic analysis zone, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Transportation Systems, Mobility, Traffic Management, Urban Management, Urban Planning, Economy...</td>\n",
       "      <td>[0.9042782784000001, 0.8140229583, 0.8014292121000001, 0.4872630835, 0.2150092274, 0.0802951008,...</td>\n",
       "      <td>[{'domain': 'Smart Mobility', 'score': 0.9042782784000001}, {'domain': 'Smart Governance', 'scor...</td>\n",
       "      <td>{'is_genai': False, 'confidence': 0.0, 'matched_keywords': [], 'technology_categories': [], 'bri...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(safety, 4), (model, 4), (traffic, 4), (crash, 4), (frequency, 4)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Geographical area network-structural health monitoring utility computing model</td>\n",
       "      <td>Tariq H.</td>\n",
       "      <td>ISPRS International Journal of Geo-Information</td>\n",
       "      <td>10.3390/ijgi8030154</td>\n",
       "      <td>2019</td>\n",
       "      <td>Article</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scopus_id/85063745308</td>\n",
       "      <td>85063745308</td>\n",
       "      <td>In view of intensified disasters and fatalities caused by natural phenomena and geographical exp...</td>\n",
       "      <td>[Geographical Area Network (GAN), Internet of Things (IoT), Structural Health Monitoring (SHM), ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Environment, Climate Change, Urban Planning, Logistics, Urban Management, Emergency Safety, Pub...</td>\n",
       "      <td>[0.9980217218, 0.8643752337, 0.7800527215, 0.373268038, 0.3273755312, 0.24258549510000002, 0.187...</td>\n",
       "      <td>[{'domain': 'Smart Environment', 'score': 0.9980217218}, {'domain': 'Smart Governance', 'score':...</td>\n",
       "      <td>{'is_genai': True, 'confidence': 0.45435819029808044, 'matched_keywords': ['noise prediction', '...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.454358</td>\n",
       "      <td>[noise prediction, foundation model, flow model, gan, llm, slm]</td>\n",
       "      <td>[Transformer-Based Models, Generative Adversarial Networks, Diffusion Models]</td>\n",
       "      <td>[(shm, 12), (ucm, 5), (propose, 4), (system, 4), (model, 3)]</td>\n",
       "      <td>[(noise prediction, 0.45435819029808044), (foundation model, 0.423215389251709), (flow model, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   title  \\\n",
       "0    GeoAvatar: A big mobile phone positioning data-driven method for individualized pseudo personal ...   \n",
       "1                                                                        Demystifying SAR with attention   \n",
       "2              MiM-UNet: An efficient building image segmentation network integrating state space models   \n",
       "3    Building Change Detection in Aerial Imagery Using End-to-End Deep Learning Semantic Segmentation...   \n",
       "4    Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow...   \n",
       "..                                                                                                   ...   \n",
       "233  Demonstration of Electrically Injected Semipolar Laser Diodes Grown on Low-Cost and Scalable Sap...   \n",
       "234                                            Phytogan: Unpaired dead-to-live phytoplankton translation   \n",
       "235                       A GAN-based active terrain mapping for collaborative air-ground robotic system   \n",
       "236                                               Macro-level traffic safety analysis in Shanghai, China   \n",
       "237                       Geographical area network-structural health monitoring utility computing model   \n",
       "\n",
       "        authors  \\\n",
       "0         Li P.   \n",
       "1    Patnaik N.   \n",
       "2        Liu D.   \n",
       "3      Teo T.A.   \n",
       "4      Huang J.   \n",
       "..          ...   \n",
       "233   Khoury M.   \n",
       "234      Han S.   \n",
       "235     Chen J.   \n",
       "236     Wang X.   \n",
       "237    Tariq H.   \n",
       "\n",
       "                                                                                                 journal  \\\n",
       "0                                                               Computers, Environment and Urban Systems   \n",
       "1                                                                       Expert Systems with Applications   \n",
       "2                                                                         Alexandria Engineering Journal   \n",
       "3                                                                                              Buildings   \n",
       "4                                                                Environmental Science and Ecotechnology   \n",
       "..                                                                                                   ...   \n",
       "233                                                                 ACS Applied Materials and Interfaces   \n",
       "234  Proceedings - 2019 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted ...   \n",
       "235             2019 4th IEEE International Conference on Advanced Robotics and Mechatronics, ICARM 2019   \n",
       "236                                                                     Accident Analysis and Prevention   \n",
       "237                                                       ISPRS International Journal of Geo-Information   \n",
       "\n",
       "                                                       doi  publication_date  \\\n",
       "0                      10.1016/j.compenvurbsys.2025.102252              2025   \n",
       "1                               10.1016/j.eswa.2025.127182              2025   \n",
       "2                                10.1016/j.aej.2025.02.035              2025   \n",
       "3                                10.3390/buildings15050695              2025   \n",
       "4                                10.1016/j.ese.2025.100526              2025   \n",
       "..                                                     ...               ...   \n",
       "233                                 10.1021/acsami.9b17525              2019   \n",
       "234  10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00109              2019   \n",
       "235                             10.1109/ICARM.2019.8833919              2019   \n",
       "236                              10.1016/j.aap.2019.02.014              2019   \n",
       "237                                    10.3390/ijgi8030154              2019   \n",
       "\n",
       "        document_type  \\\n",
       "0             Article   \n",
       "1             Article   \n",
       "2             Article   \n",
       "3             Article   \n",
       "4             Article   \n",
       "..                ...   \n",
       "233           Article   \n",
       "234  Conference Paper   \n",
       "235  Conference Paper   \n",
       "236           Article   \n",
       "237           Article   \n",
       "\n",
       "                                                           prism:url  \\\n",
       "0    https://api.elsevier.com/content/abstract/scopus_id/86000553754   \n",
       "1    https://api.elsevier.com/content/abstract/scopus_id/86000797212   \n",
       "2    https://api.elsevier.com/content/abstract/scopus_id/85218637730   \n",
       "3    https://api.elsevier.com/content/abstract/scopus_id/86000578375   \n",
       "4    https://api.elsevier.com/content/abstract/scopus_id/85216848180   \n",
       "..                                                               ...   \n",
       "233  https://api.elsevier.com/content/abstract/scopus_id/85076790759   \n",
       "234  https://api.elsevier.com/content/abstract/scopus_id/85083593256   \n",
       "235  https://api.elsevier.com/content/abstract/scopus_id/85073261923   \n",
       "236  https://api.elsevier.com/content/abstract/scopus_id/85061832713   \n",
       "237  https://api.elsevier.com/content/abstract/scopus_id/85063745308   \n",
       "\n",
       "       scopus_id  \\\n",
       "0    86000553754   \n",
       "1    86000797212   \n",
       "2    85218637730   \n",
       "3    86000578375   \n",
       "4    85216848180   \n",
       "..           ...   \n",
       "233  85076790759   \n",
       "234  85083593256   \n",
       "235  85073261923   \n",
       "236  85061832713   \n",
       "237  85063745308   \n",
       "\n",
       "                                                                                                abstract  \\\n",
       "0    The importance of personal mobility data is widely recognized in various fields. However, the ut...   \n",
       "1    Synthetic Aperture Radar (SAR) imagery is indispensable for earth observation, offering the abil...   \n",
       "2    With the advancement of remote sensing technology, the analysis of complex terrain images has be...   \n",
       "3    Automatic building change detection is essential for updating geospatial data, urban planning, a...   \n",
       "4    Rapid urbanization, alongside escalating resource depletion and ecological degradation, undersco...   \n",
       "..                                                                                                   ...   \n",
       "233  The last two decades have shown an increasing need for GaN-based laser diodes (LDs), which are c...   \n",
       "234  Detecting phytoplankton that causes red tide is an urgent task. However, the live phytoplankton ...   \n",
       "235  Collaborative air-ground robotic system has recently emerged as an important research area and s...   \n",
       "236  Continuing rapid growth in Shanghai, China, requires traffic safety to be considered at the earl...   \n",
       "237  In view of intensified disasters and fatalities caused by natural phenomena and geographical exp...   \n",
       "\n",
       "                                                                                         author_keywords  \\\n",
       "0                               [Big mobility data, Generative model, GIS, Mahince learning, Smart City]   \n",
       "1    [Attention, Deep learning, Generative adversarial networks, Image colorization, Image restoratio...   \n",
       "2     [Building segmentation, Complex terrain, Deep learning, Remote sensing images, State space models]   \n",
       "3                                             [buildings, change detection, deep learning, map updating]   \n",
       "4    [Foundation models, Generative artificial intelligence, Generative spatial artificial intelligen...   \n",
       "..                                                                                                   ...   \n",
       "233                                                  [GaN, laser diodes, scalable, semipolar, templates]   \n",
       "234                                                          [Contour, PCALoss, PhytoGAN, Phytoplankton]   \n",
       "235  [Active Learning, Collaborative Air-Ground Robotic System, Convolutional Neural Networks (CNN), ...   \n",
       "236  [Bayesian conditional autoregressive model, Macro-level safety modeling, Traffic analysis zone, ...   \n",
       "237  [Geographical Area Network (GAN), Internet of Things (IoT), Structural Health Monitoring (SHM), ...   \n",
       "\n",
       "     ...  \\\n",
       "0    ...   \n",
       "1    ...   \n",
       "2    ...   \n",
       "3    ...   \n",
       "4    ...   \n",
       "..   ...   \n",
       "233  ...   \n",
       "234  ...   \n",
       "235  ...   \n",
       "236  ...   \n",
       "237  ...   \n",
       "\n",
       "                                                                                   classification_labels  \\\n",
       "0    [Mobility, Human, People, Transportation Systems, Logistics, Living, Business, Economic Manageme...   \n",
       "1    [Environment, Public Services, Business, Climate Change, Living, Buildings, Construction, Human,...   \n",
       "2    [Environment, Urban Planning, Buildings, Urban Management, Housing, Business, Construction, Indu...   \n",
       "3    [Buildings, Urban Planning, Construction, Urban Management, Public Services, Environment, Housin...   \n",
       "4    [Urban Planning, Urban Management, Sustainability, Multimodal Transport, Construction, Environme...   \n",
       "..                                                                                                   ...   \n",
       "233  [Industry, Business, Economy, Socioeconomics, Economic Management, Marketing, Environment, Mobil...   \n",
       "234  [Environment, Water Quality, Living, Emergency Safety, Public Services, Pollution Control, Cultu...   \n",
       "235  [Mobility, Multimodal Transport, Transportation Systems, Industry, Logistics, Business, Urban Ma...   \n",
       "236  [Transportation Systems, Mobility, Traffic Management, Urban Management, Urban Planning, Economy...   \n",
       "237  [Environment, Climate Change, Urban Planning, Logistics, Urban Management, Emergency Safety, Pub...   \n",
       "\n",
       "                                                                                   classification_scores  \\\n",
       "0    [0.9896059632, 0.8164116144, 0.8087953925, 0.5389818549000001, 0.3266232014, 0.2026114315, 0.063...   \n",
       "1    [0.6324490309, 0.028749804900000002, 0.0051401048, 0.0038975298, 0.0037373602, 0.0037206223, 0.0...   \n",
       "2    [0.8005703092, 0.7748115659, 0.5123480558, 0.26313909890000003, 0.017528373700000002, 0.00406645...   \n",
       "3    [0.9861167073, 0.898650229, 0.6620252132000001, 0.6395537853000001, 0.2649227679, 0.2593763471, ...   \n",
       "4    [0.9958809614, 0.8571100831, 0.40149432420000003, 0.036717657, 0.0271584447, 0.0257922839, 0.023...   \n",
       "..                                                                                                   ...   \n",
       "233  [0.5686096549, 0.5395241976, 0.0077464948, 0.0021609876000000003, 0.001608802, 0.0012988048, 0.0...   \n",
       "234  [0.9808947444, 0.2901338637, 0.0916244462, 0.031032999999999998, 0.0146472873, 0.0032697413, 0.0...   \n",
       "235  [0.9317734838, 0.9130275249, 0.40025082230000003, 0.0498190336, 0.0333033353, 0.0136193736, 0.01...   \n",
       "236  [0.9042782784000001, 0.8140229583, 0.8014292121000001, 0.4872630835, 0.2150092274, 0.0802951008,...   \n",
       "237  [0.9980217218, 0.8643752337, 0.7800527215, 0.373268038, 0.3273755312, 0.24258549510000002, 0.187...   \n",
       "\n",
       "                                                                                           macro_domains  \\\n",
       "0    [{'domain': 'Smart Mobility', 'score': 0.9896059632}, {'domain': 'Smart People', 'score': 0.8164...   \n",
       "1                                               [{'domain': 'Smart Environment', 'score': 0.6324490309}]   \n",
       "2    [{'domain': 'Smart Environment', 'score': 0.8005703092}, {'domain': 'Smart Governance', 'score':...   \n",
       "3    [{'domain': 'Smart Living', 'score': 0.9861167073}, {'domain': 'Smart Governance', 'score': 0.89...   \n",
       "4    [{'domain': 'Smart Governance', 'score': 0.9958809614}, {'domain': 'Smart Environment', 'score':...   \n",
       "..                                                                                                   ...   \n",
       "233                                                 [{'domain': 'Smart Economy', 'score': 0.5686096549}]   \n",
       "234                                             [{'domain': 'Smart Environment', 'score': 0.9808947444}]   \n",
       "235                                                [{'domain': 'Smart Mobility', 'score': 0.9317734838}]   \n",
       "236  [{'domain': 'Smart Mobility', 'score': 0.9042782784000001}, {'domain': 'Smart Governance', 'scor...   \n",
       "237  [{'domain': 'Smart Environment', 'score': 0.9980217218}, {'domain': 'Smart Governance', 'score':...   \n",
       "\n",
       "                                                                                      semantic_detection  \\\n",
       "0    {'is_genai': True, 'confidence': 0.48666954040527344, 'matched_keywords': ['generative model', '...   \n",
       "1    {'is_genai': True, 'confidence': 0.6297489404678345, 'matched_keywords': ['attention mechanism',...   \n",
       "2    {'is_genai': True, 'confidence': 0.632642388343811, 'matched_keywords': ['encoder-decoder', 'lat...   \n",
       "3    {'is_genai': True, 'confidence': 0.5988814830780029, 'matched_keywords': ['transformer', 'genera...   \n",
       "4    {'is_genai': True, 'confidence': 0.6537469625473022, 'matched_keywords': ['large flow model', 'f...   \n",
       "..                                                                                                   ...   \n",
       "233  {'is_genai': True, 'confidence': 0.6290763020515442, 'matched_keywords': ['3d gan', '5gt-gan', '...   \n",
       "234  {'is_genai': True, 'confidence': 0.48289957642555237, 'matched_keywords': ['generative adversari...   \n",
       "235  {'is_genai': True, 'confidence': 0.5831387639045715, 'matched_keywords': ['adv-gan', '3d gan', '...   \n",
       "236  {'is_genai': False, 'confidence': 0.0, 'matched_keywords': [], 'technology_categories': [], 'bri...   \n",
       "237  {'is_genai': True, 'confidence': 0.45435819029808044, 'matched_keywords': ['noise prediction', '...   \n",
       "\n",
       "     semantic_is_genai  semantic_confidence  \\\n",
       "0                 True             0.486670   \n",
       "1                 True             0.629749   \n",
       "2                 True             0.632642   \n",
       "3                 True             0.598881   \n",
       "4                 True             0.653747   \n",
       "..                 ...                  ...   \n",
       "233               True             0.629076   \n",
       "234               True             0.482900   \n",
       "235               True             0.583139   \n",
       "236              False             0.000000   \n",
       "237               True             0.454358   \n",
       "\n",
       "                                                                                       semantic_keywords  \\\n",
       "0                                                                [generative model, 3d generative model]   \n",
       "1    [attention mechanism, wgan-gp, self-attention, cross-attention, sr-gan, generative adversarial n...   \n",
       "2    [encoder-decoder, latent space modeling, autoencoder, shape generation, neural rendering, vision...   \n",
       "3    [transformer, generative pretrained transformer, multimodal transformer, imagen, multimodal fusi...   \n",
       "4    [large flow model, flow model, foundational framework, foundation model, foundation framework, l...   \n",
       "..                                                                                                   ...   \n",
       "233                 [3d gan, 5gt-gan, sr-gan, conditional gan, gan, progressive gan, adv-gan, cycle gan]   \n",
       "234                          [generative adversarial network, neural rendering, imagen, diffusion model]   \n",
       "235  [adv-gan, 3d gan, gan, generative adversarial network, progressive gan, sr-gan, conditional gan,...   \n",
       "236                                                                                                   []   \n",
       "237                                      [noise prediction, foundation model, flow model, gan, llm, slm]   \n",
       "\n",
       "                                                                                     semantic_categories  \\\n",
       "0                                         [Transformer-Based Models, Neural Radiance Fields & 3D Models]   \n",
       "1    [Transformer-Based Models, Generative Adversarial Networks, Diffusion Models, Neural Radiance Fi...   \n",
       "2    [Transformer-Based Models, Variational Autoencoders, Neural Radiance Fields & 3D Models, Hybrid ...   \n",
       "3      [Transformer-Based Models, Neural Radiance Fields & 3D Models, Hybrid & Multimodal Architectures]   \n",
       "4                                         [Transformer-Based Models, Neural Radiance Fields & 3D Models]   \n",
       "..                                                                                                   ...   \n",
       "233                                [Generative Adversarial Networks, Neural Radiance Fields & 3D Models]   \n",
       "234  [Generative Adversarial Networks, Diffusion Models, Neural Radiance Fields & 3D Models, Hybrid &...   \n",
       "235      [Transformer-Based Models, Generative Adversarial Networks, Neural Radiance Fields & 3D Models]   \n",
       "236                                                                                                   []   \n",
       "237                        [Transformer-Based Models, Generative Adversarial Networks, Diffusion Models]   \n",
       "\n",
       "                                                                  bridge_terms  \\\n",
       "0     [(method, 4), (generate, 4), (mobility, 4), (model, 3), (individual, 3)]   \n",
       "1         [(attention, 5), (image, 4), (sar, 3), (colorization, 2), (base, 2)]   \n",
       "2                    [(mamba, 4), (mim, 3), (unet, 3), (state, 3), (model, 3)]   \n",
       "3            [(change, 5), (base, 4), (end, 4), (building, 4), (detection, 4)]   \n",
       "4                     [(urban, 9), (flow, 5), (model, 5), (city, 5), (lfm, 4)]   \n",
       "..                                                                         ...   \n",
       "233          [(semipolar, 3), (low, 3), (gan, 3), (density, 2), (template, 2)]   \n",
       "234  [(phytoplankton, 5), (image, 4), (phytogan, 3), (pcaloss, 3), (paper, 2)]   \n",
       "235               [(gan, 5), (terrain, 4), (map, 3), (active, 3), (system, 2)]   \n",
       "236        [(safety, 4), (model, 4), (traffic, 4), (crash, 4), (frequency, 4)]   \n",
       "237               [(shm, 12), (ucm, 5), (propose, 4), (system, 4), (model, 3)]   \n",
       "\n",
       "                                                                                        semantic_matches  \n",
       "0                  [(generative model, 0.48666954040527344), (3d generative model, 0.41732609272003174)]  \n",
       "1    [(attention mechanism, 0.6297489404678345), (wgan-gp, 0.524022102355957), (self-attention, 0.480...  \n",
       "2    [(encoder-decoder, 0.632642388343811), (latent space modeling, 0.44094717502593994), (autoencode...  \n",
       "3    [(transformer, 0.5988814830780029), (generative pretrained transformer, 0.5384024381637573), (mu...  \n",
       "4    [(large flow model, 0.6537469625473022), (flow model, 0.6234424114227295), (foundational framewo...  \n",
       "..                                                                                                   ...  \n",
       "233  [(3d gan, 0.6290763020515442), (5gt-gan, 0.5917875170707703), (sr-gan, 0.58832848072052), (condi...  \n",
       "234  [(generative adversarial network, 0.48289957642555237), (neural rendering, 0.45412594079971313),...  \n",
       "235  [(adv-gan, 0.5831387639045715), (3d gan, 0.531076967716217), (gan, 0.5111932754516602), (generat...  \n",
       "236                                                                                                   []  \n",
       "237  [(noise prediction, 0.45435819029808044), (foundation model, 0.423215389251709), (flow model, 0....  \n",
       "\n",
       "[238 rows x 26 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries with empty semantic matches\n",
    "df = df[df[\"semantic_matches\"].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"../data/07_semantic_kw_genai_detection.json\", orient=\"records\", indent=4, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
