{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries for data processing, regex pattern matching, transformer models, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "# Data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Regex pattern matching\n",
    "import re\n",
    "\n",
    "# Transformer models\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style for plots\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Data\n",
    "Load the JSON file containing abstracts, extract the abstracts, and perform basic cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Building rooftop extraction has been applied in various fields, such as cartography, urban planning, automatic driving, and intelligent city construction. Automatic building detection and extraction algorithms using high spatial resolution aerial images can provide precise location and geometry information, significantly reducing time, costs, and labor. Recently, deep learning algorithms, especially convolution neural networks (CNNs) and Transformer, have robust local or global feature extraction ability, achieving advanced performance in intelligent interpretation compared with conventional methods. However, buildings often exhibit scale variation, spectral heterogeneity, and similarity with complex geometric shapes. Hence, the building rooftop extraction results exist fragmentation and lack spatial details using these methods. To address these issues, this study developed a multi-scale global perceptron network based on Transformer and CNN using novel encoder-decoders for enhancing contextual representation of buildings. Specifically, an improved multi-head-attention encoder is employed by constructing multi-scale tokens to enhance global semantic correlations. Meanwhile, the context refinement decoder is developed and synergistically uses high-level semantic representation and shallow features to restore spatial details. Overall, quantitative analysis and visual experiments confirmed that the proposed model is more efficient and superior to other state-of-the-art methods, with a 95.18% F1 score on the WHU dataset and a 93.29% F1 score on the Massub dataset.',\n",
       " 'Problem: Modernizing and standardizing place names and addresses is a key challenge in the development of smart cities. Purpose: This paper proposes a solution to address matching challenges, such as incomplete descriptions, reversed word order, and the diverse descriptions often found in Chinese addresses. Method: Leveraging the hierarchical structure of Chinese addresses, this study introduces the interactive address matching graph attention model (IAMGAM). In the IAMGAM, an attention-based feature interaction method (AFIM) is employed. To reflect the hierarchical nature of address elements, a directed graph is used to model the address data, and the model is trained and tested using a graph attention mechanism. Results: Experiments demonstrate that the IAMGAM achieves an accuracy and F1-score of 99.61%. Compared with the existing address matching methods, the IAMGAM improves the accuracy by 0.66% to 2.57%, and the F1-score by 0.68% to 2.55%, outperforming baseline models. Additionally, ablation experiments confirm the effectiveness of each component within the model. Furthermore, when fine-tuned using ChatGLM2-6B, the results show that the IAMGAM still outperforms ChatGLM2-6B. Conclusion: IAMGAM demonstrates excellent performance in Chinese address matching tasks, and the Large Language Model (LLM)-based methods, such as ChatGLM2-6B, show great potential for future development in this area.',\n",
       " 'Distributed multivariate time series anomaly detection is widely-used in industrial equipment monitoring, financial risk management, and smart cities. Although Federated learning (FL) has garnered significant interest and achieved decent performance in various scenarios, most existing FL-based distributed anomaly detection methods still face challenges including: inadequate detection performance in global model, insufficient essential features extraction caused by the fragmentation of local time series, and lack for practical anomaly localization. To address these challenges, we propose an Unsupervised Federated Hypernetwork Method for Distributed Multivariate Time Series Anomaly Detection and Diagnosis (uFedHy-DisMTSADD). Specifically, we introduce a federated hypernetwork architecture that effectively mitigates the heterogeneity and fluctuations in distributed environments while protecting client data privacy. Then, we adopt the Series Conversion Normalization Transformer (SC Nor-Transformer) to tackle the timing bias due to model aggregation through series conversion. Series normalization improves the temporal dependence of capturing subsequences. Finally, uFedHy-DisMTSADD simultaneously localizes the root cause of the anomaly by reconstructing the anomaly scores obtained from each subsequence. We performed an extensive evaluation on nine datasets, in which uFedHy-DisMTSADD outperformed the existing state-of-the-art baseline average F1 score by 9.19% and the average AUROC by 2.41%. Moreover, the average localization fault accuracy of uFedHy-DisMTSADD is 9.23% higher than that of the optimal baseline method. Code is available at this repository:https://github.com/Hjfyoyo/uFedHy-DisMTSADD.',\n",
       " \"The integration of renewable energy into power networks introduces challenges due to intermittency and unpredictability, making precise expansion planning essential. This research introduces a novel two-stage stochastic approach for distribution network expansion planning in smart grids with high renewable energy penetration, addressing uncertainty, risk, and distributed generators' remuneration. Key contributions include: the incorporation of third-party generation owners' economic remuneration into a risk-based stochastic model; the use of conditional value-at-risk to manage uncertainty and extreme events, with a detailed analysis of cost evolution for various confidence levels and risk aversion parameters; the optimization of energy storage systems sizing and placement, alongside the location and type of new power lines and substation transformers, ensuring a reliable and radial network topology; and the integration of multiple factors, including uncertainty, risk aversion, ESS allocation, remuneration, and reliability, into a unified model that ensures optimal network design under technical constraints. Tested on a 180-bus network in Leiria, Portugal and on a 13-bus smart city mockup from Salamanca, Spain, the approach proved economically viable, reducing extreme scenario costs by up to 34 % through CVaR-based risk management, and demonstrating its potential for sustainable, risk-averse network expansion.\",\n",
       " 'Crowd anomaly detection is one of the most popular topics in computer vision in the context of smart cities. A plethora of deep learning methods have been proposed that generally outperform other machine learning solutions. Our review primarily discusses algorithms that were published in mainstream conferences and journals between 2020 and 2022. We present datasets that are typically used for benchmarking, produce a taxonomy of the developed algorithms, and discuss and compare their performances. Our main findings are that the heterogeneities of pre-trained convolutional models have a negligible impact on crowd video anomaly detection performance. We conclude our discussion with fruitful directions for future research.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Prepare Data\n",
    "\n",
    "# Load the JSON file containing abstracts\n",
    "import json\n",
    "\n",
    "with open('/Users/joaocarlos/Developer/Projects/genai-smartcity/data/02_document_search_results.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract abstracts from the JSON data\n",
    "abstracts = [entry['abstract'] for entry in data if 'abstract' in entry]\n",
    "\n",
    "# Perform basic cleaning operations\n",
    "def clean_text(text):\n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "cleaned_abstracts = [clean_text(abstract) for abstract in abstracts]\n",
    "\n",
    "# Display the first few cleaned abstracts\n",
    "cleaned_abstracts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Descriptive Sentences\n",
    "Use regex patterns to extract sentences containing phrases like 'This paper', 'This work', 'This study', etc. that describe the focus of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total descriptive sentences extracted: 909\n",
      "Number of abstracts with extracted sentences: 452\n",
      "Percentage of abstracts with extracted sentences: 88.28%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['To address these issues, this study developed a multi-scale global perceptron network based on Transformer and CNN using novel encoder-decoders for enhancing contextual representation of buildings.',\n",
       " 'Purpose: This paper proposes a solution to address matching challenges, such as incomplete descriptions, reversed word order, and the diverse descriptions often found in Chinese addresses.',\n",
       " 'Method: Leveraging the hierarchical structure of Chinese addresses, this study introduces the interactive address matching graph attention model (IAMGAM).',\n",
       " 'To address these challenges, we propose an Unsupervised Federated Hypernetwork Method for Distributed Multivariate Time Series Anomaly Detection and Diagnosis (uFedHy-DisMTSADD).',\n",
       " 'Specifically, we introduce a federated hypernetwork architecture that effectively mitigates the heterogeneity and fluctuations in distributed environments while protecting client data privacy.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Descriptive Sentences with Expanded Patterns\n",
    "\n",
    "# Define expanded regex patterns to match descriptive sentences\n",
    "patterns = [\n",
    "    r\"\\b[Tt]his (article|work|study|paper|research|review|survey)\\b\",\n",
    "    r\"\\b[Ii]n this (work|study|paper|research|review|survey)\\b\",\n",
    "    r\"\\b[Ww]e (propose|introduce|present|develop|describe|demonstrate|report|discuss|analyze|examine|investigate|explore|evaluate|address|outline)\\b\",\n",
    "    r\"\\b[Ii]n this (manuscript|article|contribution|approach|framework|investigation|analysis|implementation)\\b\",\n",
    "    r\"\\b[Tt]he (article|paper|study|work|research|review|survey|manuscript|current study|present study|present work|current work)\\b\",\n",
    "    r\"\\b[Oo]ur (work|study|paper|research|approach|framework|method|system|contribution|focus|aim|objective|goal)\\b\",\n",
    "    r\"\\b[Tt]his (manuscript|contribution|investigation|analysis|implementation|approach|framework|method|system)\\b\",\n",
    "    r\"\\b[Tt]he (purpose|aim|goal|objective) of this (paper|work|study|research|article|manuscript)\\b\",\n",
    "    r\"\\b[Hh]ere(,)? we\\b\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to extract sentences matching the patterns\n",
    "def extract_descriptive_sentences(text, patterns):\n",
    "    sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\", text)\n",
    "    descriptive_sentences = []\n",
    "    for sentence in sentences:\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, sentence):\n",
    "                descriptive_sentences.append(sentence)\n",
    "                break\n",
    "    return descriptive_sentences\n",
    "\n",
    "\n",
    "# Apply the function to all cleaned abstracts\n",
    "descriptive_sentences = [\n",
    "    extract_descriptive_sentences(abstract, patterns) for abstract in cleaned_abstracts\n",
    "]\n",
    "\n",
    "# Flatten the list of lists\n",
    "descriptive_sentences = [\n",
    "    sentence for sublist in descriptive_sentences for sentence in sublist\n",
    "]\n",
    "\n",
    "# Display statistics about extracted sentences\n",
    "print(f\"Total descriptive sentences extracted: {len(descriptive_sentences)}\")\n",
    "print(\n",
    "    f\"Number of abstracts with extracted sentences: {sum(1 for sublist in [extract_descriptive_sentences(abstract, patterns) for abstract in cleaned_abstracts] if sublist)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percentage of abstracts with extracted sentences: {sum(1 for sublist in [extract_descriptive_sentences(abstract, patterns) for abstract in cleaned_abstracts] if sublist) / len(cleaned_abstracts) * 100:.2f}%\"\n",
    ")\n",
    "\n",
    "# Display the first few descriptive sentences\n",
    "descriptive_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Smart City Domains\n",
    "Create a comprehensive dictionary of smart city domains (e.g., governance, mobility, safety, infrastructure, environment, healthcare) with detailed descriptions for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Economy',\n",
       " 'Business',\n",
       " 'Economic Management',\n",
       " 'Innovation Policy',\n",
       " 'Socioeconomics',\n",
       " 'Governance',\n",
       " 'Public Services',\n",
       " 'Public Policies',\n",
       " 'Urban Planning',\n",
       " 'Social Equity',\n",
       " 'Cybersecurity',\n",
       " 'Living',\n",
       " 'Home',\n",
       " 'Tourism',\n",
       " 'Culture',\n",
       " 'Buildings',\n",
       " 'Education',\n",
       " 'Healthcare',\n",
       " 'Emergency Safety',\n",
       " 'Mobility',\n",
       " 'Traffic Management',\n",
       " 'Transportation Systems',\n",
       " 'Electric Vehicles',\n",
       " 'Public Transit',\n",
       " 'People',\n",
       " 'Citizens',\n",
       " 'Community Engagement',\n",
       " 'Learning and Teaching',\n",
       " 'Waste Management',\n",
       " 'Pollution Control',\n",
       " 'Resource Conservation',\n",
       " 'Energy',\n",
       " 'Smart Grids',\n",
       " 'Lightning',\n",
       " 'Air Quality',\n",
       " 'Water Quality',\n",
       " 'Green Spaces']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define Smart City Domains\n",
    "\n",
    "# Create a dictionary of smart city domains with detailed descriptions\n",
    "# smart_city_domains = {\n",
    "#     \"Governance\": \"the frameworks, policies, and processes that ensure effective management and administration of smart city initiatives, including aspects like public policy, community and citizen engagement and social equity.\",\n",
    "#     \"Planning\": \"the strategic development, modeling, design and expansion of building urban spaces, covering land use, zoning and infrastructure planning to enhance livability and sustainability.\",\n",
    "#     # \"Social Aspects\": \"Addresses the societal dimensions of smart cities, focusing on community engagement, social equity, and the impact of technology on daily life.\",\n",
    "#     \"Mobility and Transportation\": \"transportation systems, traffic flow management, and infrastructure of roads and streets that facilitate efficient movement of people and goods within the city.\",\n",
    "#     \"Public Safety\": \"measures and technologies aimed at ensuring the security and well-being of citizens, such as surveillance systems, emergency response, and crime prevention.\",\n",
    "#     \"Infrastructure\": \"the physical and digital structures that support city functions, including utilities, buildings, streets, and communication networks.\",\n",
    "#     \"Environment\": \"initiatives for reducing pollution, waste management, air quality preservation, resource conservation, and enhancing green spaces.\",\n",
    "#     \"Healthcare\": \"the integration of technology and data to improve healthcare delivery, public health monitoring, and overall citizen well-being.\",\n",
    "#     \"Education\": \"the use of technology in educational institutions, promoting lifelong learning opportunities and community involvement in educational initiatives.\",\n",
    "#     \"Energy\": \"the optimization of energy resources, including renewable energy sources, smart grids, and energy efficiency programs.\",\n",
    "# }\n",
    "\n",
    "# Read from a json file\n",
    "with open('../data/config/smart_city_domains_extended.json', 'r') as f:\n",
    "    smart_city_domains = json.load(f)\n",
    "\n",
    "# Display the smart city domains dictionary\n",
    "smart_city_domains\n",
    "\n",
    "# Flatten the hierarchy into subdomain labels with their context\n",
    "flattened_domains = {}\n",
    "for main_domain, subdomains in smart_city_domains.items():\n",
    "    for subdomain in subdomains:\n",
    "        # Create a key-value pair where the subdomain is the key\n",
    "        # and includes context about its parent domain\n",
    "        flattened_domains[subdomain] = f\"{subdomain} (part of {main_domain})\"\n",
    "\n",
    "# Create labels list from subdomains\n",
    "labels = list(flattened_domains.keys())\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Classification\n",
    "Process the extracted sentences and domain definitions to create inputs suitable for the transformer model. This may include tokenization and encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 37500, 23135,  ...,     1,     1,     1],\n",
       "        [    0, 47481,    35,  ...,     1,     1,     1],\n",
       "        [    0, 42390, 18926,  ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [    0,   713,  2225,  ...,     1,     1,     1],\n",
       "        [    0,   713,  1566,  ...,     1,     1,     1],\n",
       "        [    0, 10105,     9,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare for Classification\n",
    "\n",
    "# model = \"tasksource/ModernBERT-base-nli\"\n",
    "model = \"facebook/bart-large-mnli\"\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom\")\n",
    "\n",
    "# Tokenize and encode the descriptive sentences\n",
    "encoded_inputs = tokenizer(\n",
    "    cleaned_abstracts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Display the tokenized and encoded inputs\n",
    "encoded_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Transformer Model\n",
    "Initialize a pre-trained transformer model (e.g., BERT, RoBERTa) and set up either a zero-shot classification approach or fine-tune the model if labeled data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "MPS available: True\n",
      "Using MPS (Metal Performance Shaders)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier initialized successfully\n",
      "\n",
      "Testing single classification...\n",
      "Test successful!\n",
      "Result: {'sequence': 'Fire detection has held stringent importance in computer vision for over half a century. The development of early fire detection strategies is pivotal to the realization of safe and smart cities, inhabitable in the future. However, the development of optimal fire and smoke detection models is hindered by limitations like publicly available datasets, lack of diversity, and class imbalance. In this work, we explore the possible ways forward to overcome these challenges posed by available datasets. We study the impact of a class-balanced dataset to improve the fire detection capability of state-of-the-art (SOTA) vision-based models and propose the use of generative models for data augmentation, as a future work direction. First, a comparative analysis of two prominent object detection architectures, You Only Look Once version 7 (YOLOv7) and YOLOv8 has been carried out using a balanced dataset, where both models have been evaluated across various evaluation metrics including precision, recall, and mean Average Precision (mAP). The results are compared to other recent fire detection models, highlighting the superior performance and efficiency of the proposed YOLOv8 architecture as trained on our balanced dataset. Next, a fractal dimension analysis gives a deeper insight into the repetition of patterns in fire, and the effectiveness of the results has been demonstrated by a windowing-based inference approach. The proposed Slicing-Aided Hyper Inference (SAHI) improves the fire and smoke detection capability of YOLOv8 for real-life applications with a significantly improved mAP performance over a strict confidence threshold. YOLOv8 with SAHI inference gives a mAP:50-95 improvement of more than 25% compared to the base YOLOv8 model. The study also provides insights into future work direction by exploring the potential of generative models like deep convolutional generative adversarial network (DCGAN) and diffusion models like stable diffusion, for data augmentation.', 'labels': ['Emergency Safety', 'Home', 'Public Services', 'Culture', 'Living', 'Citizens', 'Public Policies', 'Community Engagement', 'Innovation Policy', 'Mobility', 'Green Spaces', 'Urban Planning', 'Smart Grids', 'Business', 'Social Equity', 'Learning and Teaching', 'Buildings', 'Resource Conservation', 'Lightning', 'Economy', 'People', 'Governance', 'Air Quality', 'Energy', 'Transportation Systems', 'Cybersecurity', 'Education', 'Economic Management', 'Traffic Management', 'Pollution Control', 'Healthcare', 'Electric Vehicles', 'Public Transit', 'Water Quality', 'Tourism', 'Socioeconomics', 'Waste Management'], 'scores': [0.06706657260656357, 0.056574370712041855, 0.05075244605541229, 0.0466817170381546, 0.045971889048814774, 0.04544827342033386, 0.04503343626856804, 0.041905250400304794, 0.03692973032593727, 0.03291119262576103, 0.03174757584929466, 0.0317404605448246, 0.0304198507219553, 0.029462391510605812, 0.028703557327389717, 0.026217209175229073, 0.02569488435983658, 0.02568434365093708, 0.02511284127831459, 0.024163905531167984, 0.02398952655494213, 0.022276489064097404, 0.019715728238224983, 0.019594760611653328, 0.016180410981178284, 0.015864616259932518, 0.014893095940351486, 0.013980560936033726, 0.012806172482669353, 0.012426741421222687, 0.012340153567492962, 0.011913914233446121, 0.011882921680808067, 0.01164296269416809, 0.010947031900286674, 0.010792885906994343, 0.010530142113566399]}\n",
      "\n",
      "Classifying 5 descriptive sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:06<00:00, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully classified 5 out of 5 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Transformer Model for Zero-Shot Classification\n",
    "\n",
    "# Set tokenizers parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Check available devices\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "\n",
    "# Set device for Apple Silicon\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"Using MPS (Metal Performance Shaders)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = 0\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = -1\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Initialize the classifier with device setting\n",
    "try:\n",
    "    classifier = pipeline(\n",
    "        \"zero-shot-classification\", model=model, device=device\n",
    "    )\n",
    "    print(\"Classifier initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing with {device}, falling back to CPU\")\n",
    "    device = -1\n",
    "    classifier = pipeline(\n",
    "        \"zero-shot-classification\", model=model, device=device\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the labels for classification based on smart city domains\n",
    "# labels = list(smart_city_domains.keys())\n",
    "\n",
    "# Function to classify sentences into smart city domains\n",
    "def classify_sentences(sentences, labels):\n",
    "    results = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        if sentence:  # Check if sentence is not empty\n",
    "            try:\n",
    "                result = classifier(\n",
    "                    sentence,\n",
    "                    candidate_labels=labels,\n",
    "                    hypothesis_template=\"This text is about {}.\",\n",
    "                )\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sentence: {str(e)}\")\n",
    "                results.append(None)\n",
    "    return results\n",
    "\n",
    "\n",
    "def classify_with_definitions(texts, domains):\n",
    "    \"\"\"\n",
    "    Classify texts using domain definitions for enhanced context.\n",
    "\n",
    "    Args:\n",
    "        texts: Either a single string or list of strings to classify\n",
    "        domains: Dictionary of domain labels and their definitions\n",
    "\n",
    "    Returns:\n",
    "        List of (label, score) tuples sorted by score in descending order\n",
    "    \"\"\"\n",
    "    # Convert single string to list for consistent processing\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    all_results = []\n",
    "    for text in tqdm(texts):\n",
    "        if not text or not isinstance(text, str):\n",
    "            all_results.append((text, None))\n",
    "            continue\n",
    "\n",
    "        text_results = []\n",
    "        for label, definition in domains.items():\n",
    "            try:\n",
    "                result = classifier(\n",
    "                    text,\n",
    "                    candidate_labels=[label],\n",
    "                    hypothesis_template=f\"This text is about {{}}, which relates to {definition}\",\n",
    "                )\n",
    "                text_results.append((label, result[\"scores\"][0]))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing text: {text[:50]}... Error: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        if text_results:\n",
    "            all_results.append((text,\n",
    "                sorted(text_results, key=lambda x: x[1], reverse=True))\n",
    "            )\n",
    "        else:\n",
    "            all_results.append((text,None))\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Test with a single sentence first\n",
    "# test_sentence = \"This is a test sentence about guidelines and policies that promote innovation and creativity through scientific research and advanced technology. These economies emphasize competitiveness, the effective use of information and communication technologies, and the socially responsible management of resources.\"\n",
    "test_sentence = \"Fire detection has held stringent importance in computer vision for over half a century. The development of early fire detection strategies is pivotal to the realization of safe and smart cities, inhabitable in the future. However, the development of optimal fire and smoke detection models is hindered by limitations like publicly available datasets, lack of diversity, and class imbalance. In this work, we explore the possible ways forward to overcome these challenges posed by available datasets. We study the impact of a class-balanced dataset to improve the fire detection capability of state-of-the-art (SOTA) vision-based models and propose the use of generative models for data augmentation, as a future work direction. First, a comparative analysis of two prominent object detection architectures, You Only Look Once version 7 (YOLOv7) and YOLOv8 has been carried out using a balanced dataset, where both models have been evaluated across various evaluation metrics including precision, recall, and mean Average Precision (mAP). The results are compared to other recent fire detection models, highlighting the superior performance and efficiency of the proposed YOLOv8 architecture as trained on our balanced dataset. Next, a fractal dimension analysis gives a deeper insight into the repetition of patterns in fire, and the effectiveness of the results has been demonstrated by a windowing-based inference approach. The proposed Slicing-Aided Hyper Inference (SAHI) improves the fire and smoke detection capability of YOLOv8 for real-life applications with a significantly improved mAP performance over a strict confidence threshold. YOLOv8 with SAHI inference gives a mAP:50-95 improvement of more than 25% compared to the base YOLOv8 model. The study also provides insights into future work direction by exploring the potential of generative models like deep convolutional generative adversarial network (DCGAN) and diffusion models like stable diffusion, for data augmentation.\"\n",
    "print(\"\\nTesting single classification...\")\n",
    "test_result = classifier(\n",
    "    test_sentence, candidate_labels=labels, hypothesis_template=\"This text is about {}.\"\n",
    ")\n",
    "print(\"Test successful!\")\n",
    "print(f\"Result: {test_result}\")\n",
    "\n",
    "# If test passes, proceed with batch classification\n",
    "print(f\"\\nClassifying {len(cleaned_abstracts[:5])} descriptive sentences...\")\n",
    "classification_results = classify_sentences(cleaned_abstracts[:5], labels)\n",
    "# classification_results = classification_results = classify_with_definitions(cleaned_abstracts[:50], smart_city_domains)\n",
    "# Display results summary\n",
    "valid_results = [r for r in classification_results if r is not None]\n",
    "print(\n",
    "    f\"\\nSuccessfully classified {len(valid_results)} out of {len(classification_results)} sentences\"\n",
    ")\n",
    "\n",
    "# Display first 3 results with abstracts\n",
    "# print(\"\\nFirst 3 classification results:\")\n",
    "# for i, (text, results) in enumerate(valid_results[:3]):\n",
    "#     print(f\"\\nAbstract {i+1}:\")\n",
    "#     print(f\"Text: {text[:200]}...\")  # Show first 200 characters\n",
    "#     print(\"Classifications:\")\n",
    "#     for label, score in results:\n",
    "#         print(f\"- {label}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "Sequence: Building rooftop extraction has been applied in various fields, such as cartography, urban planning, automatic driving, and intelligent city construction. Automatic building detection and extraction a...\n",
      "Top Predicted Domains:\n",
      "  - Buildings: 0.2422\n",
      "  - Urban Planning: 0.0699\n",
      "  - Living: 0.0517\n",
      "----------------------------------------\n",
      "Result 2:\n",
      "Sequence: Problem: Modernizing and standardizing place names and addresses is a key challenge in the development of smart cities. Purpose: This paper proposes a solution to address matching challenges, such as ...\n",
      "Top Predicted Domains:\n",
      "  - Home: 0.0877\n",
      "  - Citizens: 0.0639\n",
      "  - Living: 0.0549\n",
      "----------------------------------------\n",
      "Result 3:\n",
      "Sequence: Distributed multivariate time series anomaly detection is widely-used in industrial equipment monitoring, financial risk management, and smart cities. Although Federated learning (FL) has garnered sig...\n",
      "Top Predicted Domains:\n",
      "  - Business: 0.0740\n",
      "  - Home: 0.0585\n",
      "  - Community Engagement: 0.0533\n",
      "----------------------------------------\n",
      "Result 4:\n",
      "Sequence: The integration of renewable energy into power networks introduces challenges due to intermittency and unpredictability, making precise expansion planning essential. This research introduces a novel t...\n",
      "Top Predicted Domains:\n",
      "  - Smart Grids: 0.2259\n",
      "  - Energy: 0.0857\n",
      "  - Home: 0.0446\n",
      "----------------------------------------\n",
      "Result 5:\n",
      "Sequence: Crowd anomaly detection is one of the most popular topics in computer vision in the context of smart cities. A plethora of deep learning methods have been proposed that generally outperform other mach...\n",
      "Top Predicted Domains:\n",
      "  - Home: 0.0757\n",
      "  - Culture: 0.0526\n",
      "  - Community Engagement: 0.0515\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def display_classification_results(results):\n",
    "    \"\"\"\n",
    "    Displays the classification results, including the sequence,\n",
    "    predicted labels, and corresponding scores in a formatted manner.\n",
    "\n",
    "    Args:\n",
    "        results (list): A list of dictionaries, where each dictionary contains\n",
    "                        the sequence, labels, and scores from the classification.\n",
    "    \"\"\"\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i + 1}:\")\n",
    "        print(f\"Sequence: {result['sequence'][:200]}...\")  # Display first 200 characters\n",
    "        print(\"Top Predicted Domains:\")\n",
    "        for label, score in zip(result['labels'][:3], result['scores'][:3]):  # Display top 3\n",
    "            print(f\"  - {label}: {score:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Call the display function with the classification results\n",
    "display_classification_results(valid_results[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Abstracts\n",
    "Apply the transformer model to classify each abstract into the most appropriate smart city domain based on the extracted descriptive sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Abstracts\n",
    "\n",
    "# Apply the transformer model to classify each abstract into the most appropriate smart city domain based on the extracted descriptive sentences.\n",
    "\n",
    "# Function to classify abstracts based on descriptive sentences\n",
    "def classify_abstracts(abstracts, labels):\n",
    "    abstract_classifications = []\n",
    "    for abstract in abstracts:\n",
    "        sentences = extract_descriptive_sentences(abstract, patterns)\n",
    "        if sentences:\n",
    "            classification = classify_sentences(sentences, labels)\n",
    "            # Aggregate the classification results to determine the most frequent domain\n",
    "            domain_counts = {}\n",
    "            for result in classification:\n",
    "                for label, score in zip(result['labels'], result['scores']):\n",
    "                    if label in domain_counts:\n",
    "                        domain_counts[label] += score\n",
    "                    else:\n",
    "                        domain_counts[label] = score\n",
    "            # Determine the domain with the highest aggregated score\n",
    "            most_frequent_domain = max(domain_counts, key=domain_counts.get)\n",
    "            abstract_classifications.append(most_frequent_domain)\n",
    "        else:\n",
    "            abstract_classifications.append(\"Unclassified\")\n",
    "    return abstract_classifications\n",
    "\n",
    "# Classify the cleaned abstracts\n",
    "abstract_classifications = classify_abstracts(cleaned_abstracts[:50], labels)\n",
    "\n",
    "# Display the first few abstract classifications\n",
    "abstract_classifications[:5]\n",
    "\n",
    "# Create a DataFrame to visualize the classification results\n",
    "df_classifications = pd.DataFrame({\n",
    "    'Abstract': cleaned_abstracts[:50],\n",
    "    'Classification': abstract_classifications\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df_classifications.head()\n",
    "\n",
    "# Plot the distribution of classifications\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='Classification', data=df_classifications, order=df_classifications['Classification'].value_counts().index)\n",
    "plt.title('Distribution of Smart City Domain Classifications')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Smart City Domain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Unclassified Abstracts\n",
    "unclassified_abstracts = df_classifications[df_classifications['Classification'] == 'Unclassified']\n",
    "print(f\"Number of unclassified abstracts: {len(unclassified_abstracts)}\")\n",
    "unclassified_abstracts_list = unclassified_abstracts['Abstract'].tolist()\n",
    "print(\"Unclassified abstracts:\")\n",
    "for abstract in unclassified_abstracts_list:\n",
    "    print(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Results\n",
    "Assess the performance of the classification model using appropriate metrics and analyze any misclassifications to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Results\n",
    "\n",
    "# Import necessary libraries for evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Assuming we have true labels for evaluation purposes\n",
    "# For demonstration, let's create some dummy true labels\n",
    "true_labels = [\"Governance\", \"Mobility\", \"Safety\", \"Infrastructure\", \"Environment\", \"Healthcare\"] * (len(abstract_classifications) // 6)\n",
    "true_labels += true_labels[:len(abstract_classifications) % 6]  # Add remaining labels\n",
    "true_labels = true_labels[:len(abstract_classifications)]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, abstract_classifications)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Generate classification report\n",
    "extended_labels = labels + [\"Unclassified\"]\n",
    "report = classification_report(true_labels, abstract_classifications, target_names=extended_labels, zero_division=0)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, abstract_classifications, labels=extended_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=extended_labels, yticklabels=extended_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Analyze misclassifications\n",
    "misclassified = df_classifications[df_classifications['Classification'] != pd.Series(true_labels, index=df_classifications.index)]\n",
    "print(\"Misclassified Abstracts:\\n\", misclassified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Domain Distribution\n",
    "Create visualizations (e.g., bar charts, word clouds) to display the distribution of smart city domains in the dataset and highlight key terms associated with each domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Domain Distribution\n",
    "\n",
    "# Import necessary libraries for visualization\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create a bar chart to display the distribution of smart city domains\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='Classification', data=df_classifications, order=df_classifications['Classification'].value_counts().index)\n",
    "plt.title('Distribution of Smart City Domain Classifications')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Smart City Domain')\n",
    "plt.show()\n",
    "\n",
    "# Create word clouds for each smart city domain\n",
    "for domain in labels:\n",
    "    domain_sentences = ' '.join(df_classifications[df_classifications['Classification'] == domain]['Abstract'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(domain_sentences)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f'Word Cloud for {domain}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
